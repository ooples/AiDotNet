[
  {
    "id": 2494980039,
    "node_id": "PRRC_kwDOKSXUF86Utl_H",
    "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980039",
    "pull_request_review_id": 3422732638,
    "diff_hunk": "@@ -0,0 +1,285 @@\n+using AiDotNet.Helpers;\n+using AiDotNet.LinearAlgebra;\n+using AiDotNet.RetrievalAugmentedGeneration.Models;\n+using System;\n+using System.Collections.Generic;\n+using System.Linq;\n+\n+namespace AiDotNet.RetrievalAugmentedGeneration.DocumentStores\n+{\n+    /// <summary>\n+    /// Azure Cognitive Search-inspired document store with field-based indexing and search capabilities.\n+    /// Provides in-memory simulation of Azure Search features including field-level search and faceted filtering.\n+    /// </summary>\n+    /// <typeparam name=\"T\">The numeric type for vector operations.</typeparam>\n+    public class AzureSearchDocumentStore<T> : DocumentStoreBase<T>\n+    {\n+        private readonly Dictionary<string, VectorDocument<T>> _documents;\n+        private readonly Dictionary<string, Dictionary<string, HashSet<string>>> _invertedIndex;\n+        private readonly string _serviceName;\n+        private readonly string _indexName;\n+        private int _vectorDimension;\n+\n+        public override int DocumentCount => _documents.Count;\n+        public override int VectorDimension => _vectorDimension;\n+\n+        public AzureSearchDocumentStore(string serviceName, string indexName, int initialCapacity = 1000)\n+        {\n+            if (string.IsNullOrWhiteSpace(serviceName))\n+                throw new ArgumentException(\"Service name cannot be empty\", nameof(serviceName));\n+            if (string.IsNullOrWhiteSpace(indexName))\n+                throw new ArgumentException(\"Index name cannot be empty\", nameof(indexName));\n+            if (initialCapacity <= 0)\n+                throw new ArgumentException(\"Initial capacity must be greater than zero\", nameof(initialCapacity));\n+\n+            _serviceName = serviceName;\n+            _indexName = indexName;\n+            _documents = new Dictionary<string, VectorDocument<T>>(initialCapacity);\n+            _invertedIndex = new Dictionary<string, Dictionary<string, HashSet<string>>>();\n+            _vectorDimension = 0;\n+        }\n+\n+        protected override void AddCore(VectorDocument<T> vectorDocument)\n+        {\n+            if (_documents.Count == 0)\n+            {\n+                _vectorDimension = vectorDocument.Embedding.Length;\n+            }\n+\n+            _documents[vectorDocument.Document.Id] = vectorDocument;\n+            IndexMetadata(vectorDocument.Document);\n+        }\n+\n+        protected override void AddBatchCore(IList<VectorDocument<T>> vectorDocuments)\n+        {\n+            if (vectorDocuments.Count == 0)\n+                return;\n+\n+            if (_documents.Count == 0)\n+            {\n+                _vectorDimension = vectorDocuments[0].Embedding.Length;\n+            }\n+\n+            foreach (var vectorDoc in vectorDocuments)\n+            {\n+                _documents[vectorDoc.Document.Id] = vectorDoc;\n+                IndexMetadata(vectorDoc.Document);\n+            }\n+        }\n+\n+        protected override IEnumerable<Document<T>> GetSimilarCore(Vector<T> queryVector, int topK, Dictionary<string, object> metadataFilters)\n+        {\n+            var candidateIds = GetCandidateIds(metadataFilters);\n+            var scoredDocuments = new List<(Document<T> Document, T Score)>();\n+\n+            IEnumerable<VectorDocument<T>> candidates;\n+            if (candidateIds != null)\n+            {\n+                candidates = candidateIds\n+                    .Where(id => _documents.ContainsKey(id))\n+                    .Select(id => _documents[id]);\n+            }\n+            else\n+            {\n+                candidates = _documents.Values;\n+            }\n+\n+            var matchingDocuments = candidates\n+                .Where(vectorDoc => MatchesFilters(vectorDoc.Document, metadataFilters));\n+\n+            foreach (var vectorDoc in matchingDocuments)\n+            {\n+                var similarity = StatisticsHelper<T>.CosineSimilarity(queryVector, vectorDoc.Embedding);\n+                scoredDocuments.Add((vectorDoc.Document, similarity));\n+            }\n+\n+            var results = scoredDocuments\n+                .OrderByDescending(x => x.Score)\n+                .Take(topK)\n+                .Select(x =>\n+                {\n+                    x.Document.RelevanceScore = x.Score;\n+                    x.Document.HasRelevanceScore = true;\n+                    return x.Document;\n+                })\n+                .ToList();\n+\n+            return results;\n+        }\n+\n+        protected override Document<T>? GetByIdCore(string documentId)\n+        {\n+            return _documents.TryGetValue(documentId, out var vectorDoc) ? vectorDoc.Document : null;\n+        }\n+\n+        protected override bool RemoveCore(string documentId)\n+        {\n+            if (!_documents.TryGetValue(documentId, out var vectorDoc))\n+                return false;\n+\n+            RemoveFromIndex(vectorDoc.Document);\n+            _documents.Remove(documentId);\n+\n+            if (_documents.Count == 0)\n+            {\n+                _vectorDimension = 0;\n+            }\n+\n+            return true;\n+        }\n+\n+        /// <summary>\n+        /// Core logic for retrieving all documents in the index.\n+        /// </summary>\n+        /// <returns>An enumerable of all documents without their vector embeddings.</returns>\n+        /// <remarks>\n+        /// <para>\n+        /// Returns all documents from the Azure Search index in no particular order.\n+        /// Vector embeddings are not included, only document content and metadata.\n+        /// </para>\n+        /// <para><b>For Beginners:</b> Gets every document in the index.\n+        /// \n+        /// Use cases:\n+        /// - Export all documents for backup\n+        /// - Migrate to a different index or service\n+        /// - Bulk reindexing or analysis\n+        /// - Debugging facet indices\n+        /// \n+        /// Warning: For large indices (> 10K documents), this can use significant memory.\n+        /// In real Azure Search, use continuation tokens for pagination.\n+        /// \n+        /// Example:\n+        /// <code>\n+        /// // Get all documents\n+        /// var allDocs = store.GetAll().ToList();\n+        /// Console.WriteLine($\"Total documents in {_indexName}: {allDocs.Count}\");\n+        /// \n+        /// // Export to JSON\n+        /// var json = JsonConvert.SerializeObject(allDocs);\n+        /// File.WriteAllText($\"{_serviceName}_{_indexName}_export.json\", json);\n+        /// </code>\n+        /// </para>\n+        /// </remarks>\n+        protected override IEnumerable<Document<T>> GetAllCore()\n+        {\n+            return _documents.Values.Select(vd => vd.Document).ToList();\n+        }\n+\n+        /// <summary>\n+        /// Removes all documents from the index and clears all inverted indices.\n+        /// </summary>\n+        /// <remarks>\n+        /// <para>\n+        /// Clears all documents, field-level inverted indices, and resets the vector dimension to 0.\n+        /// The service and index names remain unchanged and the index is ready to accept new documents.\n+        /// </para>\n+        /// <para><b>For Beginners:</b> Completely empties the Azure Search index and all its facet indices.\n+        /// \n+        /// After calling Clear():\n+        /// - All documents are removed\n+        /// - Inverted index is cleared (all facets)\n+        /// - Vector dimension resets to 0\n+        /// - Index is ready for new documents\n+        /// \n+        /// Use with caution - this cannot be undone!\n+        /// \n+        /// Example:\n+        /// <code>\n+        /// store.Clear();\n+        /// Console.WriteLine($\"Documents in index: {store.DocumentCount}\"); // 0\n+        /// </code>\n+        /// </para>\n+        /// </remarks>\n+        public override void Clear()\n+        {\n+            _documents.Clear();\n+            _invertedIndex.Clear();\n+            _vectorDimension = 0;\n+        }\n+\n+        private void IndexMetadata(Document<T> document)\n+        {\n+            foreach (var kvp in document.Metadata)\n+            {\n+                var fieldName = kvp.Key;\n+                var fieldValue = kvp.Value?.ToString() ?? string.Empty;\n+\n+                if (!_invertedIndex.ContainsKey(fieldName))\n+                {\n+                    _invertedIndex[fieldName] = new Dictionary<string, HashSet<string>>();\n+                }\n+\n+                if (!_invertedIndex[fieldName].ContainsKey(fieldValue))\n+                {\n+                    _invertedIndex[fieldName][fieldValue] = new HashSet<string>();\n+                }\n+\n+                _invertedIndex[fieldName][fieldValue].Add(document.Id);\n+            }\n+        }",
    "path": "src/RetrievalAugmentedGeneration/DocumentStores/AzureSearchDocumentStore.cs",
    "position": 219,
    "original_position": 219,
    "commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "user": {
      "login": "coderabbitai[bot]",
      "id": 136622811,
      "node_id": "BOT_kgDOCCSy2w",
      "avatar_url": "https://avatars.githubusercontent.com/in/347564?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/coderabbitai%5Bbot%5D",
      "html_url": "https://github.com/apps/coderabbitai",
      "followers_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/followers",
      "following_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/following{/other_user}",
      "gists_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/subscriptions",
      "organizations_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/orgs",
      "repos_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/repos",
      "events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/events{/privacy}",
      "received_events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/received_events",
      "type": "Bot",
      "user_view_type": "public",
      "site_admin": false
    },
    "body": "_ΓÜá∩╕Å Potential issue_ | _≡ƒƒá Major_\n\n**Preserve metadata types in inverted index.**\n\nLines 205 and 256 convert all metadata values to strings via `ToString()`, which loses type information. This breaks:\n- Range comparisons in `MatchesFilters` (which expects `IComparable` numeric/date values)\n- Boolean equality checks\n- Any filtering on non-string metadata\n\nThe inverted index should key by the actual typed value, not its string representation.\n\n\n\nConsider this approach:\n\n```diff\n private void IndexMetadata(Document<T> document)\n {\n     foreach (var kvp in document.Metadata)\n     {\n         var fieldName = kvp.Key;\n-        var fieldValue = kvp.Value?.ToString() ?? string.Empty;\n+        var fieldValue = kvp.Value;\n\n         if (!_invertedIndex.ContainsKey(fieldName))\n         {\n-            _invertedIndex[fieldName] = new Dictionary<string, HashSet<string>>();\n+            _invertedIndex[fieldName] = new Dictionary<object, HashSet<string>>();\n         }\n\n         if (!_invertedIndex[fieldName].ContainsKey(fieldValue))\n         {\n             _invertedIndex[fieldName][fieldValue] = new HashSet<string>();\n         }\n\n         _invertedIndex[fieldName][fieldValue].Add(document.Id);\n     }\n }\n```\n\nUpdate the field type from `Dictionary<string, Dictionary<string, HashSet<string>>>` to `Dictionary<string, Dictionary<object, HashSet<string>>>` and apply similar changes to `RemoveFromIndex` and `GetCandidateIds`. This preserves original types for correct filter matching.\n\n\nAlso applies to: 246-283\n\n<details>\n<summary>≡ƒñû Prompt for AI Agents</summary>\n\n```\nIn src/RetrievalAugmentedGeneration/DocumentStores/AzureSearchDocumentStore.cs\naround lines 200-219 (and similarly 246-283), the current code converts all\nmetadata values to strings which loses type information and breaks\nnumeric/date/boolean filtering; change the inverted index type from\nDictionary<string, Dictionary<string, HashSet<string>>> to Dictionary<string,\nDictionary<object, HashSet<string>>> (or Dictionary<string, Dictionary<object,\nHashSet<string>>> with an appropriate IEqualityComparer if needed), stop calling\nToString() when inserting keys, and use the raw metadata value (kvp.Value) as\nthe inner-dictionary key when adding in IndexMetadata; apply the same typed-key\nchange and use object keys in RemoveFromIndex and GetCandidateIds (ensure\ncomparisons use Equals/GetHashCode and preserve null handling, e.g., use a\nsentinel or null key) so MatchesFilters can receive original IComparable/boolean\ntypes for correct filtering.\n```\n\n</details>\n\n<!-- This is an auto-generated comment by CodeRabbit -->",
    "created_at": "2025-11-05T15:09:17Z",
    "updated_at": "2025-11-05T15:09:20Z",
    "html_url": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980039",
    "pull_request_url": "https://api.github.com/repos/ooples/AiDotNet/pulls/304",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980039"
      },
      "html": {
        "href": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980039"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/304"
      }
    },
    "original_commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "reactions": {
      "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980039/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    }
  },
  {
    "id": 2494980055,
    "node_id": "PRRC_kwDOKSXUF86Utl_X",
    "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980055",
    "pull_request_review_id": 3422732638,
    "diff_hunk": "@@ -0,0 +1,287 @@\n+using AiDotNet.Helpers;\n+using AiDotNet.Interfaces;\n+using AiDotNet.LinearAlgebra;\n+using AiDotNet.RetrievalAugmentedGeneration.Models;\n+using Newtonsoft.Json.Linq;\n+using System;\n+using System.Collections.Generic;\n+using System.Linq;\n+using System.Net.Http;\n+using System.Text;\n+\n+namespace AiDotNet.RetrievalAugmentedGeneration.DocumentStores;\n+\n+/// <summary>\n+/// ChromaDB-based document store designed for simplicity and developer experience.\n+/// </summary>\n+/// <typeparam name=\"T\">The numeric data type used for vector operations.</typeparam>\n+/// <remarks>\n+/// ChromaDB is an open-source vector database that emphasizes ease of use while maintaining\n+/// high performance for similarity search operations.\n+/// </remarks>\n+public class ChromaDBDocumentStore<T> : DocumentStoreBase<T>\n+{\n+    private readonly HttpClient _httpClient;\n+    private readonly string _collectionName;\n+    private int _vectorDimension;\n+    private int _documentCount;\n+    private readonly Dictionary<string, VectorDocument<T>> _cache;\n+\n+    public override int DocumentCount => _documentCount;\n+    public override int VectorDimension => _vectorDimension;\n+\n+    public ChromaDBDocumentStore(string endpoint, string collectionName, string apiKey)\n+    {\n+        if (string.IsNullOrWhiteSpace(endpoint))\n+            throw new ArgumentException(\"Endpoint cannot be empty\", nameof(endpoint));\n+        if (string.IsNullOrWhiteSpace(collectionName))\n+            throw new ArgumentException(\"Collection name cannot be empty\", nameof(collectionName));\n+\n+        _httpClient = new HttpClient { BaseAddress = new Uri(endpoint) };\n+        if (!string.IsNullOrWhiteSpace(apiKey))\n+            _httpClient.DefaultRequestHeaders.Add(\"X-Chroma-Token\", apiKey);\n+\n+        _collectionName = collectionName;\n+        _vectorDimension = 0;\n+        _documentCount = 0;\n+        _cache = new Dictionary<string, VectorDocument<T>>();\n+\n+        EnsureCollection();\n+    }\n+\n+    private void EnsureCollection()\n+    {\n+        var payload = new { name = _collectionName };\n+        var content = new StringContent(\n+            Newtonsoft.Json.JsonConvert.SerializeObject(payload),\n+            Encoding.UTF8,\n+            \"application/json\");\n+\n+        _httpClient.PostAsync(\"/api/v1/collections\", content).Wait();\n+    }\n+\n+    protected override void AddCore(VectorDocument<T> vectorDocument)\n+    {\n+        if (_vectorDimension == 0)\n+            _vectorDimension = vectorDocument.Embedding.Length;\n+\n+        _cache[vectorDocument.Document.Id] = vectorDocument;\n+\n+        var embedding = vectorDocument.Embedding.ToArray().Select(v => Convert.ToDouble(v)).ToList();\n+        \n+        var payload = new\n+        {\n+            ids = new[] { vectorDocument.Document.Id },\n+            embeddings = new[] { embedding },\n+            documents = new[] { vectorDocument.Document.Content },\n+            metadatas = new[] { vectorDocument.Document.Metadata }\n+        };\n+\n+        var content = new StringContent(\n+            Newtonsoft.Json.JsonConvert.SerializeObject(payload),\n+            Encoding.UTF8,\n+            \"application/json\");\n+\n+        var response = _httpClient.PostAsync($\"/api/v1/collections/{_collectionName}/add\", content).Result;\n+        if (response.IsSuccessStatusCode)\n+            _documentCount++;\n+    }\n+\n+    protected override void AddBatchCore(IList<VectorDocument<T>> vectorDocuments)\n+    {\n+        if (vectorDocuments.Count == 0) return;\n+        \n+        if (_vectorDimension == 0)\n+            _vectorDimension = vectorDocuments[0].Embedding.Length;\n+\n+        foreach (var vd in vectorDocuments)\n+            _cache[vd.Document.Id] = vd;\n+\n+        var ids = vectorDocuments.Select(vd => vd.Document.Id).ToList();\n+        var embeddings = vectorDocuments.Select(vd => \n+            vd.Embedding.ToArray().Select(v => Convert.ToDouble(v)).ToList()).ToList();\n+        var documents = vectorDocuments.Select(vd => vd.Document.Content).ToList();\n+        var metadatas = vectorDocuments.Select(vd => vd.Document.Metadata).ToList();\n+\n+        var payload = new { ids, embeddings, documents, metadatas };\n+        var content = new StringContent(\n+            Newtonsoft.Json.JsonConvert.SerializeObject(payload),\n+            Encoding.UTF8,\n+            \"application/json\");\n+\n+        var response = _httpClient.PostAsync($\"/api/v1/collections/{_collectionName}/add\", content).Result;\n+        if (response.IsSuccessStatusCode)\n+            _documentCount += vectorDocuments.Count;\n+    }\n+\n+    protected override IEnumerable<Document<T>> GetSimilarCore(Vector<T> queryVector, int topK, Dictionary<string, object> metadataFilters)\n+    {\n+        var embedding = queryVector.ToArray().Select(v => Convert.ToDouble(v)).ToList();\n+        \n+        var payload = new\n+        {\n+            query_embeddings = new[] { embedding },\n+            n_results = topK\n+        };\n+\n+        var content = new StringContent(\n+            Newtonsoft.Json.JsonConvert.SerializeObject(payload),\n+            Encoding.UTF8,\n+            \"application/json\");\n+\n+        var response = _httpClient.PostAsync($\"/api/v1/collections/{_collectionName}/query\", content).Result;\n+        var responseContent = response.Content.ReadAsStringAsync().Result;\n+        var result = JObject.Parse(responseContent);\n+\n+        var results = new List<Document<T>>();\n+        var ids = result[\"ids\"]?[0];\n+        var documents = result[\"documents\"]?[0];\n+        var metadatas = result[\"metadatas\"]?[0];\n+        var distances = result[\"distances\"]?[0];\n+\n+        if (ids == null || documents == null) return results;\n+\n+        for (int i = 0; i < ids.Count(); i++)\n+        {\n+            var idToken = ids[i];\n+            var docToken = documents[i];\n+            if (idToken == null || docToken == null) continue;\n+\n+            var id = idToken.ToString();\n+            var doc = docToken.ToString();\n+            var metadataObj = metadatas?[i]?.ToObject<Dictionary<string, string>>() ?? new Dictionary<string, string>();\n+            var metadata = new Dictionary<string, object>();\n+            foreach (var kvp in metadataObj)\n+                metadata[kvp.Key] = kvp.Value;\n+\n+            var distance = distances != null ? Convert.ToDouble(distances[i]) : 0.0;\n+\n+            var document = new Document<T>(id, doc, metadata);\n+            document.RelevanceScore = NumOps.FromDouble(1.0 / (1.0 + distance));",
    "path": "src/RetrievalAugmentedGeneration/DocumentStores/ChromaDBDocumentStore.cs",
    "position": 160,
    "original_position": 160,
    "commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "user": {
      "login": "coderabbitai[bot]",
      "id": 136622811,
      "node_id": "BOT_kgDOCCSy2w",
      "avatar_url": "https://avatars.githubusercontent.com/in/347564?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/coderabbitai%5Bbot%5D",
      "html_url": "https://github.com/apps/coderabbitai",
      "followers_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/followers",
      "following_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/following{/other_user}",
      "gists_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/subscriptions",
      "organizations_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/orgs",
      "repos_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/repos",
      "events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/events{/privacy}",
      "received_events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/received_events",
      "type": "Bot",
      "user_view_type": "public",
      "site_admin": false
    },
    "body": "_ΓÜá∩╕Å Potential issue_ | _≡ƒƒá Major_\n\n**Fix metadata deserialization and set relevance flag.**\n\nTwo issues:\n\n1. **Metadata type mismatch** (line 152-155): Deserializing to `Dictionary<string, string>` strips numeric and boolean types, breaking filter comparisons in `MatchesFilters`. Use `Dictionary<string, object>` instead.\n2. **Missing flag** (line 160): `HasRelevanceScore` is never set to `true`, which downstream code may rely on.\n\n\n\nApply this diff:\n\n```diff\n             var id = idToken.ToString();\n             var doc = docToken.ToString();\n-            var metadataObj = metadatas?[i]?.ToObject<Dictionary<string, string>>() ?? new Dictionary<string, string>();\n-            var metadata = new Dictionary<string, object>();\n-            foreach (var kvp in metadataObj)\n-                metadata[kvp.Key] = kvp.Value;\n+            var metadata = metadatas?[i]?.ToObject<Dictionary<string, object>>() ?? new Dictionary<string, object>();\n\n             var distance = distances != null ? Convert.ToDouble(distances[i]) : 0.0;\n\n             var document = new Document<T>(id, doc, metadata);\n             document.RelevanceScore = NumOps.FromDouble(1.0 / (1.0 + distance));\n+            document.HasRelevanceScore = true;\n\n             results.Add(document);\n```\n\n<details>\n<summary>≡ƒñû Prompt for AI Agents</summary>\n\n```\nIn src/RetrievalAugmentedGeneration/DocumentStores/ChromaDBDocumentStore.cs\naround lines 152 to 160, the metadata is deserialized into\nDictionary<string,string> which strips numeric/boolean types and breaks filter\ncomparisons, and the document's HasRelevanceScore flag is never set; change the\ndeserialization target to Dictionary<string, object> (preserve original value\ntypes) and copy those values into the metadata Dictionary<string,object> used to\nconstruct the Document<T>, then after setting document.RelevanceScore set\ndocument.HasRelevanceScore = true so downstream code knows the score is present.\n```\n\n</details>\n\n<!-- This is an auto-generated comment by CodeRabbit -->",
    "created_at": "2025-11-05T15:09:18Z",
    "updated_at": "2025-11-05T15:09:20Z",
    "html_url": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980055",
    "pull_request_url": "https://api.github.com/repos/ooples/AiDotNet/pulls/304",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980055"
      },
      "html": {
        "href": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980055"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/304"
      }
    },
    "original_commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "reactions": {
      "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980055/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    }
  },
  {
    "id": 2494980071,
    "node_id": "PRRC_kwDOKSXUF86Utl_n",
    "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980071",
    "pull_request_review_id": 3422732638,
    "diff_hunk": "@@ -0,0 +1,345 @@\n+using AiDotNet.Helpers;\n+using AiDotNet.Interfaces;\n+using AiDotNet.LinearAlgebra;\n+using AiDotNet.RetrievalAugmentedGeneration.Models;\n+using Newtonsoft.Json.Linq;\n+using System;\n+using System.Collections.Generic;\n+using System.Linq;\n+using System.Net.Http;\n+using System.Text;\n+\n+namespace AiDotNet.RetrievalAugmentedGeneration.DocumentStores;\n+\n+/// <summary>\n+/// Elasticsearch-based document store providing hybrid search capabilities (BM25 + dense vectors).\n+/// </summary>\n+/// <typeparam name=\"T\">The numeric data type used for vector operations.</typeparam>\n+/// <remarks>\n+/// Elasticsearch combines traditional full-text search (BM25) with vector similarity search,\n+/// making it ideal for hybrid retrieval scenarios where both keyword matching and semantic\n+/// similarity are important.\n+/// </remarks>\n+public class ElasticsearchDocumentStore<T> : DocumentStoreBase<T>\n+{\n+    private readonly HttpClient _httpClient;\n+    private readonly string _indexName;\n+    private int _vectorDimension;\n+    private int _documentCount;\n+    private readonly Dictionary<string, VectorDocument<T>> _cache;\n+\n+    public override int DocumentCount => _documentCount;\n+    public override int VectorDimension => _vectorDimension;\n+\n+    public ElasticsearchDocumentStore(string endpoint, string indexName, string apiKey, string username, string password)\n+    {\n+        if (string.IsNullOrWhiteSpace(endpoint))\n+            throw new ArgumentException(\"Endpoint cannot be empty\", nameof(endpoint));\n+        if (string.IsNullOrWhiteSpace(indexName))\n+            throw new ArgumentException(\"Index name cannot be empty\", nameof(indexName));\n+\n+        _httpClient = new HttpClient { BaseAddress = new Uri(endpoint) };\n+        \n+        if (!string.IsNullOrWhiteSpace(apiKey))\n+            _httpClient.DefaultRequestHeaders.Add(\"Authorization\", $\"ApiKey {apiKey}\");\n+        else if (!string.IsNullOrWhiteSpace(username) && !string.IsNullOrWhiteSpace(password))\n+        {\n+            var auth = Convert.ToBase64String(Encoding.UTF8.GetBytes($\"{username}:{password}\"));\n+            _httpClient.DefaultRequestHeaders.Add(\"Authorization\", $\"Basic {auth}\");\n+        }\n+\n+        _indexName = indexName.ToLowerInvariant();\n+        _vectorDimension = 0;\n+        _documentCount = 0;\n+        _cache = new Dictionary<string, VectorDocument<T>>();\n+\n+        EnsureIndex();\n+    }\n+\n+    private void EnsureIndex()\n+    {\n+        var checkResponse = _httpClient.GetAsync($\"/{_indexName}\").Result;\n+        if (checkResponse.IsSuccessStatusCode) \n+        {\n+            UpdateDocumentCount();\n+            return;\n+        }\n+\n+        var mapping = new\n+        {\n+            mappings = new\n+            {\n+                properties = new\n+                {\n+                    id = new { type = \"keyword\" },\n+                    content = new { type = \"text\" },\n+                    embedding = new { type = \"dense_vector\", dims = 1536 },\n+                    metadata = new { type = \"object\", enabled = true }\n+                }\n+            }\n+        };\n+\n+        var content = new StringContent(\n+            Newtonsoft.Json.JsonConvert.SerializeObject(mapping),\n+            Encoding.UTF8,\n+            \"application/json\");\n+\n+        _httpClient.PutAsync($\"/{_indexName}\", content).Wait();",
    "path": "src/RetrievalAugmentedGeneration/DocumentStores/ElasticsearchDocumentStore.cs",
    "position": 87,
    "original_position": 87,
    "commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "user": {
      "login": "coderabbitai[bot]",
      "id": 136622811,
      "node_id": "BOT_kgDOCCSy2w",
      "avatar_url": "https://avatars.githubusercontent.com/in/347564?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/coderabbitai%5Bbot%5D",
      "html_url": "https://github.com/apps/coderabbitai",
      "followers_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/followers",
      "following_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/following{/other_user}",
      "gists_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/subscriptions",
      "organizations_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/orgs",
      "repos_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/repos",
      "events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/events{/privacy}",
      "received_events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/received_events",
      "type": "Bot",
      "user_view_type": "public",
      "site_admin": false
    },
    "body": "_ΓÜá∩╕Å Potential issue_ | _≡ƒö┤ Critical_\n\n**Make the dense vector dimension configurable (1536 breaks other models).**\n\nThe mapping hardcodes `dims = 1536`, but `AddCore` later sets `_vectorDimension` from the first embedding. If that embedding isnΓÇÖt length 1536, Elasticsearch rejects the insert/search with a 400. Please supply the actual dimensionΓÇöeither by accepting it in the constructor or by creating/updating the mapping lazily once `_vectorDimension` is known.\n\n<details>\n<summary>≡ƒñû Prompt for AI Agents</summary>\n\n```\nIn src/RetrievalAugmentedGeneration/DocumentStores/ElasticsearchDocumentStore.cs\naround lines 68 to 87, the mapping currently hardcodes \"dims = 1536\" which can\nbreak for other embedding sizes; change the implementation to use the actual\nvector dimension instead: accept an int vectorDimension in the class constructor\n(or a nullable field), or defer creating/updating the index mapping until\n_vectorDimension is known (after AddCore reads the first embedding), then\nserialize the mapping with dims = _vectorDimension and PUT/PUT-mapping only\nonce; ensure you check whether the index already exists and handle concurrent\ncalls (create-if-not-exists or update mapping safely) so Elasticsearch receives\nthe correct dense_vector dims.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:sabertoothed -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->",
    "created_at": "2025-11-05T15:09:18Z",
    "updated_at": "2025-11-05T15:09:20Z",
    "html_url": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980071",
    "pull_request_url": "https://api.github.com/repos/ooples/AiDotNet/pulls/304",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980071"
      },
      "html": {
        "href": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980071"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/304"
      }
    },
    "original_commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "reactions": {
      "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980071/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    }
  },
  {
    "id": 2494980089,
    "node_id": "PRRC_kwDOKSXUF86Utl_5",
    "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980089",
    "pull_request_review_id": 3422732638,
    "diff_hunk": "@@ -0,0 +1,345 @@\n+using AiDotNet.Helpers;\n+using AiDotNet.Interfaces;\n+using AiDotNet.LinearAlgebra;\n+using AiDotNet.RetrievalAugmentedGeneration.Models;\n+using Newtonsoft.Json.Linq;\n+using System;\n+using System.Collections.Generic;\n+using System.Linq;\n+using System.Net.Http;\n+using System.Text;\n+\n+namespace AiDotNet.RetrievalAugmentedGeneration.DocumentStores;\n+\n+/// <summary>\n+/// Elasticsearch-based document store providing hybrid search capabilities (BM25 + dense vectors).\n+/// </summary>\n+/// <typeparam name=\"T\">The numeric data type used for vector operations.</typeparam>\n+/// <remarks>\n+/// Elasticsearch combines traditional full-text search (BM25) with vector similarity search,\n+/// making it ideal for hybrid retrieval scenarios where both keyword matching and semantic\n+/// similarity are important.\n+/// </remarks>\n+public class ElasticsearchDocumentStore<T> : DocumentStoreBase<T>\n+{\n+    private readonly HttpClient _httpClient;\n+    private readonly string _indexName;\n+    private int _vectorDimension;\n+    private int _documentCount;\n+    private readonly Dictionary<string, VectorDocument<T>> _cache;\n+\n+    public override int DocumentCount => _documentCount;\n+    public override int VectorDimension => _vectorDimension;\n+\n+    public ElasticsearchDocumentStore(string endpoint, string indexName, string apiKey, string username, string password)\n+    {\n+        if (string.IsNullOrWhiteSpace(endpoint))\n+            throw new ArgumentException(\"Endpoint cannot be empty\", nameof(endpoint));\n+        if (string.IsNullOrWhiteSpace(indexName))\n+            throw new ArgumentException(\"Index name cannot be empty\", nameof(indexName));\n+\n+        _httpClient = new HttpClient { BaseAddress = new Uri(endpoint) };\n+        \n+        if (!string.IsNullOrWhiteSpace(apiKey))\n+            _httpClient.DefaultRequestHeaders.Add(\"Authorization\", $\"ApiKey {apiKey}\");\n+        else if (!string.IsNullOrWhiteSpace(username) && !string.IsNullOrWhiteSpace(password))\n+        {\n+            var auth = Convert.ToBase64String(Encoding.UTF8.GetBytes($\"{username}:{password}\"));\n+            _httpClient.DefaultRequestHeaders.Add(\"Authorization\", $\"Basic {auth}\");\n+        }\n+\n+        _indexName = indexName.ToLowerInvariant();\n+        _vectorDimension = 0;\n+        _documentCount = 0;\n+        _cache = new Dictionary<string, VectorDocument<T>>();\n+\n+        EnsureIndex();\n+    }\n+\n+    private void EnsureIndex()\n+    {\n+        var checkResponse = _httpClient.GetAsync($\"/{_indexName}\").Result;\n+        if (checkResponse.IsSuccessStatusCode) \n+        {\n+            UpdateDocumentCount();\n+            return;\n+        }\n+\n+        var mapping = new\n+        {\n+            mappings = new\n+            {\n+                properties = new\n+                {\n+                    id = new { type = \"keyword\" },\n+                    content = new { type = \"text\" },\n+                    embedding = new { type = \"dense_vector\", dims = 1536 },\n+                    metadata = new { type = \"object\", enabled = true }\n+                }\n+            }\n+        };\n+\n+        var content = new StringContent(\n+            Newtonsoft.Json.JsonConvert.SerializeObject(mapping),\n+            Encoding.UTF8,\n+            \"application/json\");\n+\n+        _httpClient.PutAsync($\"/{_indexName}\", content).Wait();\n+    }\n+\n+    private void UpdateDocumentCount()\n+    {\n+        var response = _httpClient.GetAsync($\"/{_indexName}/_count\").Result;\n+        if (response.IsSuccessStatusCode)\n+        {\n+            var responseContent = response.Content.ReadAsStringAsync().Result;\n+            var result = JObject.Parse(responseContent);\n+            _documentCount = result[\"count\"]?.Value<int>() ?? 0;\n+        }\n+    }\n+\n+    protected override void AddCore(VectorDocument<T> vectorDocument)\n+    {\n+        if (_vectorDimension == 0)\n+            _vectorDimension = vectorDocument.Embedding.Length;\n+\n+        _cache[vectorDocument.Document.Id] = vectorDocument;\n+\n+        var embedding = vectorDocument.Embedding.ToArray().Select(v => Convert.ToDouble(v)).ToArray();\n+        \n+        var doc = new\n+        {\n+            id = vectorDocument.Document.Id,\n+            content = vectorDocument.Document.Content,\n+            embedding,\n+            metadata = vectorDocument.Document.Metadata\n+        };\n+\n+        var content = new StringContent(\n+            Newtonsoft.Json.JsonConvert.SerializeObject(doc),\n+            Encoding.UTF8,\n+            \"application/json\");\n+\n+        var response = _httpClient.PutAsync($\"/{_indexName}/_doc/{vectorDocument.Document.Id}\", content).Result;\n+        if (response.IsSuccessStatusCode)\n+            _documentCount++;\n+    }\n+\n+    protected override void AddBatchCore(IList<VectorDocument<T>> vectorDocuments)\n+    {\n+        if (vectorDocuments.Count == 0) return;\n+        \n+        if (_vectorDimension == 0)\n+            _vectorDimension = vectorDocuments[0].Embedding.Length;\n+\n+        foreach (var vd in vectorDocuments)\n+            _cache[vd.Document.Id] = vd;\n+\n+        var bulkBody = new StringBuilder();\n+        foreach (var vd in vectorDocuments)\n+        {\n+            var indexAction = new { index = new { _index = _indexName, _id = vd.Document.Id } };\n+            bulkBody.AppendLine(Newtonsoft.Json.JsonConvert.SerializeObject(indexAction));\n+\n+            var embedding = vd.Embedding.ToArray().Select(v => Convert.ToDouble(v)).ToArray();\n+            var doc = new\n+            {\n+                id = vd.Document.Id,\n+                content = vd.Document.Content,\n+                embedding,\n+                metadata = vd.Document.Metadata\n+            };\n+            bulkBody.AppendLine(Newtonsoft.Json.JsonConvert.SerializeObject(doc));\n+        }\n+\n+        var content = new StringContent(bulkBody.ToString(), Encoding.UTF8, \"application/x-ndjson\");\n+        var response = _httpClient.PostAsync($\"/{_indexName}/_bulk\", content).Result;\n+        if (response.IsSuccessStatusCode)\n+            _documentCount += vectorDocuments.Count;\n+    }\n+\n+    protected override IEnumerable<Document<T>> GetSimilarCore(Vector<T> queryVector, int topK, Dictionary<string, object> metadataFilters)\n+    {\n+        var embedding = queryVector.ToArray().Select(v => Convert.ToDouble(v)).ToArray();\n+        \n+        var query = new\n+        {\n+            size = topK,\n+            query = new\n+            {\n+                script_score = new\n+                {\n+                    query = new { match_all = new { } },\n+                    script = new\n+                    {\n+                        source = \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\n+                        @params = new { query_vector = embedding }\n+                    }\n+                }\n+            }\n+        };\n+\n+        var content = new StringContent(\n+            Newtonsoft.Json.JsonConvert.SerializeObject(query),\n+            Encoding.UTF8,\n+            \"application/json\");\n+",
    "path": "src/RetrievalAugmentedGeneration/DocumentStores/ElasticsearchDocumentStore.cs",
    "position": 186,
    "original_position": 186,
    "commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "user": {
      "login": "coderabbitai[bot]",
      "id": 136622811,
      "node_id": "BOT_kgDOCCSy2w",
      "avatar_url": "https://avatars.githubusercontent.com/in/347564?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/coderabbitai%5Bbot%5D",
      "html_url": "https://github.com/apps/coderabbitai",
      "followers_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/followers",
      "following_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/following{/other_user}",
      "gists_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/subscriptions",
      "organizations_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/orgs",
      "repos_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/repos",
      "events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/events{/privacy}",
      "received_events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/received_events",
      "type": "Bot",
      "user_view_type": "public",
      "site_admin": false
    },
    "body": "_ΓÜá∩╕Å Potential issue_ | _≡ƒƒá Major_\n\n**Apply metadata filters in the ES query.**\n\n`GetSimilarCore` always runs `match_all`, so requests that include `metadataFilters` ignore the callerΓÇÖs constraints. Please translate `metadataFilters` into an appropriate `bool`/`filter` clause (e.g., `term`/`range`) before calculating scores.\n\n<!-- fingerprinting:phantom:medusa:sabertoothed -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->",
    "created_at": "2025-11-05T15:09:18Z",
    "updated_at": "2025-11-05T15:09:20Z",
    "html_url": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980089",
    "pull_request_url": "https://api.github.com/repos/ooples/AiDotNet/pulls/304",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980089"
      },
      "html": {
        "href": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980089"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/304"
      }
    },
    "original_commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "reactions": {
      "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980089/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    }
  },
  {
    "id": 2494980098,
    "node_id": "PRRC_kwDOKSXUF86UtmAC",
    "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980098",
    "pull_request_review_id": 3422732638,
    "diff_hunk": "@@ -0,0 +1,345 @@\n+using AiDotNet.Helpers;\n+using AiDotNet.Interfaces;\n+using AiDotNet.LinearAlgebra;\n+using AiDotNet.RetrievalAugmentedGeneration.Models;\n+using Newtonsoft.Json.Linq;\n+using System;\n+using System.Collections.Generic;\n+using System.Linq;\n+using System.Net.Http;\n+using System.Text;\n+\n+namespace AiDotNet.RetrievalAugmentedGeneration.DocumentStores;\n+\n+/// <summary>\n+/// Elasticsearch-based document store providing hybrid search capabilities (BM25 + dense vectors).\n+/// </summary>\n+/// <typeparam name=\"T\">The numeric data type used for vector operations.</typeparam>\n+/// <remarks>\n+/// Elasticsearch combines traditional full-text search (BM25) with vector similarity search,\n+/// making it ideal for hybrid retrieval scenarios where both keyword matching and semantic\n+/// similarity are important.\n+/// </remarks>\n+public class ElasticsearchDocumentStore<T> : DocumentStoreBase<T>\n+{\n+    private readonly HttpClient _httpClient;\n+    private readonly string _indexName;\n+    private int _vectorDimension;\n+    private int _documentCount;\n+    private readonly Dictionary<string, VectorDocument<T>> _cache;\n+\n+    public override int DocumentCount => _documentCount;\n+    public override int VectorDimension => _vectorDimension;\n+\n+    public ElasticsearchDocumentStore(string endpoint, string indexName, string apiKey, string username, string password)\n+    {\n+        if (string.IsNullOrWhiteSpace(endpoint))\n+            throw new ArgumentException(\"Endpoint cannot be empty\", nameof(endpoint));\n+        if (string.IsNullOrWhiteSpace(indexName))\n+            throw new ArgumentException(\"Index name cannot be empty\", nameof(indexName));\n+\n+        _httpClient = new HttpClient { BaseAddress = new Uri(endpoint) };\n+        \n+        if (!string.IsNullOrWhiteSpace(apiKey))\n+            _httpClient.DefaultRequestHeaders.Add(\"Authorization\", $\"ApiKey {apiKey}\");\n+        else if (!string.IsNullOrWhiteSpace(username) && !string.IsNullOrWhiteSpace(password))\n+        {\n+            var auth = Convert.ToBase64String(Encoding.UTF8.GetBytes($\"{username}:{password}\"));\n+            _httpClient.DefaultRequestHeaders.Add(\"Authorization\", $\"Basic {auth}\");\n+        }\n+\n+        _indexName = indexName.ToLowerInvariant();\n+        _vectorDimension = 0;\n+        _documentCount = 0;\n+        _cache = new Dictionary<string, VectorDocument<T>>();\n+\n+        EnsureIndex();\n+    }\n+\n+    private void EnsureIndex()\n+    {\n+        var checkResponse = _httpClient.GetAsync($\"/{_indexName}\").Result;\n+        if (checkResponse.IsSuccessStatusCode) \n+        {\n+            UpdateDocumentCount();\n+            return;\n+        }\n+\n+        var mapping = new\n+        {\n+            mappings = new\n+            {\n+                properties = new\n+                {\n+                    id = new { type = \"keyword\" },\n+                    content = new { type = \"text\" },\n+                    embedding = new { type = \"dense_vector\", dims = 1536 },\n+                    metadata = new { type = \"object\", enabled = true }\n+                }\n+            }\n+        };\n+\n+        var content = new StringContent(\n+            Newtonsoft.Json.JsonConvert.SerializeObject(mapping),\n+            Encoding.UTF8,\n+            \"application/json\");\n+\n+        _httpClient.PutAsync($\"/{_indexName}\", content).Wait();\n+    }\n+\n+    private void UpdateDocumentCount()\n+    {\n+        var response = _httpClient.GetAsync($\"/{_indexName}/_count\").Result;\n+        if (response.IsSuccessStatusCode)\n+        {\n+            var responseContent = response.Content.ReadAsStringAsync().Result;\n+            var result = JObject.Parse(responseContent);\n+            _documentCount = result[\"count\"]?.Value<int>() ?? 0;\n+        }\n+    }\n+\n+    protected override void AddCore(VectorDocument<T> vectorDocument)\n+    {\n+        if (_vectorDimension == 0)\n+            _vectorDimension = vectorDocument.Embedding.Length;\n+\n+        _cache[vectorDocument.Document.Id] = vectorDocument;\n+\n+        var embedding = vectorDocument.Embedding.ToArray().Select(v => Convert.ToDouble(v)).ToArray();\n+        \n+        var doc = new\n+        {\n+            id = vectorDocument.Document.Id,\n+            content = vectorDocument.Document.Content,\n+            embedding,\n+            metadata = vectorDocument.Document.Metadata\n+        };\n+\n+        var content = new StringContent(\n+            Newtonsoft.Json.JsonConvert.SerializeObject(doc),\n+            Encoding.UTF8,\n+            \"application/json\");\n+\n+        var response = _httpClient.PutAsync($\"/{_indexName}/_doc/{vectorDocument.Document.Id}\", content).Result;\n+        if (response.IsSuccessStatusCode)\n+            _documentCount++;\n+    }\n+\n+    protected override void AddBatchCore(IList<VectorDocument<T>> vectorDocuments)\n+    {\n+        if (vectorDocuments.Count == 0) return;\n+        \n+        if (_vectorDimension == 0)\n+            _vectorDimension = vectorDocuments[0].Embedding.Length;\n+\n+        foreach (var vd in vectorDocuments)\n+            _cache[vd.Document.Id] = vd;\n+\n+        var bulkBody = new StringBuilder();\n+        foreach (var vd in vectorDocuments)\n+        {\n+            var indexAction = new { index = new { _index = _indexName, _id = vd.Document.Id } };\n+            bulkBody.AppendLine(Newtonsoft.Json.JsonConvert.SerializeObject(indexAction));\n+\n+            var embedding = vd.Embedding.ToArray().Select(v => Convert.ToDouble(v)).ToArray();\n+            var doc = new\n+            {\n+                id = vd.Document.Id,\n+                content = vd.Document.Content,\n+                embedding,\n+                metadata = vd.Document.Metadata\n+            };\n+            bulkBody.AppendLine(Newtonsoft.Json.JsonConvert.SerializeObject(doc));\n+        }\n+\n+        var content = new StringContent(bulkBody.ToString(), Encoding.UTF8, \"application/x-ndjson\");\n+        var response = _httpClient.PostAsync($\"/{_indexName}/_bulk\", content).Result;\n+        if (response.IsSuccessStatusCode)\n+            _documentCount += vectorDocuments.Count;\n+    }\n+\n+    protected override IEnumerable<Document<T>> GetSimilarCore(Vector<T> queryVector, int topK, Dictionary<string, object> metadataFilters)\n+    {\n+        var embedding = queryVector.ToArray().Select(v => Convert.ToDouble(v)).ToArray();\n+        \n+        var query = new\n+        {\n+            size = topK,\n+            query = new\n+            {\n+                script_score = new\n+                {\n+                    query = new { match_all = new { } },\n+                    script = new\n+                    {\n+                        source = \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\n+                        @params = new { query_vector = embedding }\n+                    }\n+                }\n+            }\n+        };\n+\n+        var content = new StringContent(\n+            Newtonsoft.Json.JsonConvert.SerializeObject(query),\n+            Encoding.UTF8,\n+            \"application/json\");\n+\n+        var response = _httpClient.PostAsync($\"/{_indexName}/_search\", content).Result;\n+        var responseContent = response.Content.ReadAsStringAsync().Result;\n+        var result = JObject.Parse(responseContent);\n+\n+        var results = new List<Document<T>>();\n+        var hits = result[\"hits\"]?[\"hits\"];\n+        if (hits == null) return results;\n+\n+        foreach (var hit in hits)\n+        {\n+            var source = hit[\"_source\"];\n+            if (source == null) continue;\n+\n+            var id = source[\"id\"]?.ToString() ?? string.Empty;\n+            var docContent = source[\"content\"]?.ToString() ?? string.Empty;\n+            var metadataObj = source[\"metadata\"]?.ToObject<Dictionary<string, string>>() ?? new Dictionary<string, string>();\n+            var metadata = new Dictionary<string, object>();\n+            foreach (var kvp in metadataObj)\n+                metadata[kvp.Key] = kvp.Value;\n+\n+            var score = Convert.ToDouble(hit[\"_score\"]);\n+\n+            var document = new Document<T>(id, docContent, metadata);\n+            document.RelevanceScore = NumOps.FromDouble(score);\n+\n+            results.Add(document);",
    "path": "src/RetrievalAugmentedGeneration/DocumentStores/ElasticsearchDocumentStore.cs",
    "position": 212,
    "original_position": 212,
    "commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "user": {
      "login": "coderabbitai[bot]",
      "id": 136622811,
      "node_id": "BOT_kgDOCCSy2w",
      "avatar_url": "https://avatars.githubusercontent.com/in/347564?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/coderabbitai%5Bbot%5D",
      "html_url": "https://github.com/apps/coderabbitai",
      "followers_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/followers",
      "following_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/following{/other_user}",
      "gists_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/subscriptions",
      "organizations_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/orgs",
      "repos_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/repos",
      "events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/events{/privacy}",
      "received_events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/received_events",
      "type": "Bot",
      "user_view_type": "public",
      "site_admin": false
    },
    "body": "_ΓÜá∩╕Å Potential issue_ | _≡ƒƒá Major_\n\n**Preserve metadata types and mark relevance on the returned documents.**\n\nCasting `_source[\"metadata\"]` to `Dictionary<string,string>` drops numeric/bool values and breaks range equality checks later. Deserialize into `Dictionary<string,object>` (or `JsonElement`) and rehydrate accordingly. Also, set `HasRelevanceScore = true` when assigning `RelevanceScore` so downstream code sees that the document was scored.\n\n<details>\n<summary>≡ƒñû Prompt for AI Agents</summary>\n\n```\nIn src/RetrievalAugmentedGeneration/DocumentStores/ElasticsearchDocumentStore.cs\naround lines 191 to 212, the code currently deserializes _source[\"metadata\"] to\nDictionary<string,string> which strips numeric and boolean types and then\nrecreates a Dictionary<string,object>, losing original types; change the\ndeserialization to Dictionary<string,object> (or use JsonElement and convert\nvalues to appropriate CLR types) so metadata retains numeric/bool types when\nadding to the document metadata dictionary, and after setting\ndocument.RelevanceScore also set document.HasRelevanceScore = true so downstream\ncode recognizes the score.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:sabertoothed -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->",
    "created_at": "2025-11-05T15:09:18Z",
    "updated_at": "2025-11-05T15:09:20Z",
    "html_url": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980098",
    "pull_request_url": "https://api.github.com/repos/ooples/AiDotNet/pulls/304",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980098"
      },
      "html": {
        "href": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980098"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/304"
      }
    },
    "original_commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "reactions": {
      "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980098/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    }
  },
  {
    "id": 2494980108,
    "node_id": "PRRC_kwDOKSXUF86UtmAM",
    "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980108",
    "pull_request_review_id": 3422732638,
    "diff_hunk": "@@ -0,0 +1,337 @@\n+using AiDotNet.Helpers;\n+using AiDotNet.LinearAlgebra;\n+using AiDotNet.RetrievalAugmentedGeneration.Models;\n+using System;\n+using System.Collections.Generic;\n+using System.Linq;\n+\n+namespace AiDotNet.RetrievalAugmentedGeneration.DocumentStores\n+{\n+    /// <summary>\n+    /// FAISS-inspired document store with indexed vectors for efficient similarity search.\n+    /// </summary>\n+    /// <remarks>\n+    /// <para>\n+    /// This implementation provides an in-memory simulation of Facebook AI Similarity Search (FAISS),\n+    /// using integer-based indexing for fast vector lookup. It maintains both document storage and\n+    /// a separate index mapping for optimized retrieval operations.\n+    /// </para>\n+    /// <para><b>For Beginners:</b> FAISS is Facebook's ultra-fast vector search library.\n+    /// \n+    /// Think of it like a specialized phone book for vectors:\n+    /// - Each document gets a unique number (index)\n+    /// - Vectors are stored separately for faster search\n+    /// - Can handle millions of vectors efficiently\n+    /// \n+    /// This in-memory version is good for:\n+    /// - Testing FAISS-style indexing patterns\n+    /// - Medium-sized collections (< 100K documents)\n+    /// - Prototyping before deploying real FAISS\n+    /// \n+    /// Real FAISS provides:\n+    /// - GPU acceleration for billion-scale search\n+    /// - Advanced indexing (IVF, HNSW, Product Quantization)\n+    /// - Sub-millisecond search on huge datasets\n+    /// </para>\n+    /// </remarks>\n+    /// <typeparam name=\"T\">The numeric type for vector operations.</typeparam>\n+    public class FAISSDocumentStore<T> : DocumentStoreBase<T>\n+    {\n+        private readonly Dictionary<string, VectorDocument<T>> _documents;\n+        private readonly Dictionary<int, Vector<T>> _indexedVectors;\n+        private int _vectorDimension;\n+        private int _currentIndex;\n+\n+        /// <summary>\n+        /// Gets the number of documents currently stored.\n+        /// </summary>\n+        public override int DocumentCount => _documents.Count;\n+\n+        /// <summary>\n+        /// Gets the dimensionality of vectors stored in this index.\n+        /// </summary>\n+        public override int VectorDimension => _vectorDimension;\n+\n+        /// <summary>\n+        /// Initializes a new instance of the FAISSDocumentStore class.\n+        /// </summary>\n+        /// <param name=\"initialCapacity\">The initial capacity for internal dictionaries (default: 1000).</param>\n+        /// <exception cref=\"ArgumentException\">Thrown when initial capacity is not positive.</exception>\n+        /// <remarks>\n+        /// <para><b>For Beginners:</b> Creates a new FAISS-style document store.\n+        /// \n+        /// Example:\n+        /// <code>\n+        /// // Create a store for embeddings\n+        /// var store = new FAISSDocumentStore&lt;float&gt;();\n+        /// \n+        /// // Create a larger store\n+        /// var bigStore = new FAISSDocumentStore&lt;double&gt;(initialCapacity: 50000);\n+        /// </code>\n+        /// \n+        /// The initial capacity is just a hint - the store can grow beyond it.\n+        /// </para>\n+        /// </remarks>\n+        public FAISSDocumentStore(int initialCapacity = 1000)\n+        {\n+            if (initialCapacity <= 0)\n+                throw new ArgumentException(\"Initial capacity must be greater than zero\", nameof(initialCapacity));\n+\n+            _documents = new Dictionary<string, VectorDocument<T>>(initialCapacity);\n+            _indexedVectors = new Dictionary<int, Vector<T>>(initialCapacity);\n+            _vectorDimension = 0;\n+            _currentIndex = 0;\n+        }\n+\n+        /// <summary>\n+        /// Core logic for adding a single vector document with automatic indexing.\n+        /// </summary>\n+        /// <param name=\"vectorDocument\">The validated vector document to add.</param>\n+        /// <remarks>\n+        /// <para>\n+        /// Assigns a unique integer index to each document for fast lookup in the vector index.\n+        /// The first document added determines the vector dimension for all subsequent additions.\n+        /// </para>\n+        /// </remarks>\n+        protected override void AddCore(VectorDocument<T> vectorDocument)\n+        {\n+            if (_documents.Count == 0)\n+            {\n+                _vectorDimension = vectorDocument.Embedding.Length;\n+            }\n+\n+            var index = _currentIndex++;\n+            _documents[vectorDocument.Document.Id] = vectorDocument;\n+            _indexedVectors[index] = vectorDocument.Embedding;\n+        }\n+\n+        /// <summary>\n+        /// Core logic for adding multiple vector documents in a batch with automatic indexing.\n+        /// </summary>\n+        /// <param name=\"vectorDocuments\">The validated list of vector documents to add.</param>\n+        /// <exception cref=\"ArgumentException\">Thrown when a document's embedding has inconsistent dimensions.</exception>\n+        /// <remarks>\n+        /// <para>\n+        /// Batch operations are more efficient than adding documents individually. Each document\n+        /// receives a sequential integer index for fast vector lookup.\n+        /// </para>\n+        /// <para><b>For Beginners:</b> Adding many documents at once is faster.\n+        /// \n+        /// Instead of:\n+        /// <code>\n+        /// // Slow - one at a time\n+        /// foreach (var doc in docs)\n+        ///     store.Add(doc);\n+        /// </code>\n+        /// \n+        /// Do this:\n+        /// <code>\n+        /// // Fast - all at once\n+        /// store.AddBatch(docs);\n+        /// </code>\n+        /// </para>\n+        /// </remarks>\n+        protected override void AddBatchCore(IList<VectorDocument<T>> vectorDocuments)\n+        {\n+            if (_vectorDimension == 0 && vectorDocuments.Count > 0)\n+            {\n+                _vectorDimension = vectorDocuments[0].Embedding.Length;\n+            }\n+\n+            foreach (var vectorDocument in vectorDocuments)\n+            {\n+                if (vectorDocument.Embedding.Length != _vectorDimension)\n+                    throw new ArgumentException(\n+                        $\"Vector dimension mismatch in batch. Expected {_vectorDimension}, got {vectorDocument.Embedding.Length}\",\n+                        nameof(vectorDocuments));\n+\n+                var index = _currentIndex++;\n+                _documents[vectorDocument.Document.Id] = vectorDocument;\n+                _indexedVectors[index] = vectorDocument.Embedding;\n+            }\n+        }\n+\n+        /// <summary>\n+        /// Core logic for similarity search using cosine similarity with optional metadata filtering.\n+        /// </summary>\n+        /// <param name=\"queryVector\">The validated query vector.</param>\n+        /// <param name=\"topK\">The validated number of documents to return.</param>\n+        /// <param name=\"metadataFilters\">The validated metadata filters.</param>\n+        /// <returns>Top-k similar documents ordered by cosine similarity score.</returns>\n+        /// <remarks>\n+        /// <para>\n+        /// Searches through all documents, filters by metadata, computes cosine similarity scores,\n+        /// and returns the top-k most similar documents ordered by descending similarity.\n+        /// </para>\n+        /// <para><b>For Beginners:</b> Finds documents most similar to your query.\n+        /// \n+        /// Process:\n+        /// 1. Filter documents by metadata (if filters provided)\n+        /// 2. Calculate similarity between query and each document\n+        /// 3. Sort by similarity score (highest first)\n+        /// 4. Return top-k matches\n+        /// \n+        /// Example:\n+        /// <code>\n+        /// // Find 5 most similar documents\n+        /// var results = store.GetSimilar(queryVector, topK: 5);\n+        /// \n+        /// // Find 10 similar documents from 2024\n+        /// var filters = new Dictionary&lt;string, object&gt; { [\"year\"] = \"2024\" };\n+        /// var filtered = store.GetSimilarWithFilters(queryVector, 10, filters);\n+        /// </code>\n+        /// </para>\n+        /// </remarks>\n+        protected override IEnumerable<Document<T>> GetSimilarCore(Vector<T> queryVector, int topK, Dictionary<string, object> metadataFilters)\n+        {\n+            var scoredDocuments = new List<(Document<T> Document, T Score)>();\n+\n+            var matchingDocuments = _documents.Values\n+                .Where(vectorDoc => MatchesFilters(vectorDoc.Document, metadataFilters));\n+\n+            foreach (var vectorDoc in matchingDocuments)\n+            {\n+                var similarity = StatisticsHelper<T>.CosineSimilarity(queryVector, vectorDoc.Embedding);\n+                scoredDocuments.Add((vectorDoc.Document, similarity));\n+            }\n+\n+            var results = scoredDocuments\n+                .OrderByDescending(x => x.Score)\n+                .Take(topK)\n+                .Select(x =>\n+                {\n+                    x.Document.RelevanceScore = x.Score;\n+                    x.Document.HasRelevanceScore = true;\n+                    return x.Document;\n+                })\n+                .ToList();\n+\n+            return results;\n+        }\n+\n+        /// <summary>\n+        /// Core logic for retrieving a document by its unique identifier.\n+        /// </summary>\n+        /// <param name=\"documentId\">The validated document ID.</param>\n+        /// <returns>The document if found; otherwise, null.</returns>\n+        /// <remarks>\n+        /// <para><b>For Beginners:</b> Gets a specific document by its ID.\n+        /// \n+        /// Example:\n+        /// <code>\n+        /// var doc = store.GetById(\"doc123\");\n+        /// if (doc != null)\n+        ///     Console.WriteLine($\"Found: {doc.Content}\");\n+        /// </code>\n+        /// </para>\n+        /// </remarks>\n+        protected override Document<T>? GetByIdCore(string documentId)\n+        {\n+            return _documents.TryGetValue(documentId, out var vectorDoc) ? vectorDoc.Document : null;\n+        }\n+\n+        /// <summary>\n+        /// Core logic for removing a document from the store.\n+        /// </summary>\n+        /// <param name=\"documentId\">The validated document ID.</param>\n+        /// <returns>True if the document was found and removed; otherwise, false.</returns>\n+        /// <remarks>\n+        /// <para>\n+        /// Removes the document from storage. When the last document is removed, the vector dimension\n+        /// is reset and indices are cleared, allowing a new dimension on next add.\n+        /// </para>\n+        /// <para><b>For Beginners:</b> Removes a document from the store.\n+        /// \n+        /// Example:\n+        /// <code>\n+        /// if (store.Remove(\"doc123\"))\n+        ///     Console.WriteLine(\"Document removed\");\n+        /// else\n+        ///     Console.WriteLine(\"Document not found\");\n+        /// </code>\n+        /// </para>\n+        /// </remarks>\n+        protected override bool RemoveCore(string documentId)\n+        {\n+            var removed = _documents.Remove(documentId);\n+            if (removed && _documents.Count == 0)\n+            {\n+                _vectorDimension = 0;\n+                _currentIndex = 0;\n+                _indexedVectors.Clear();\n+            }\n+            return removed;\n+        }",
    "path": "src/RetrievalAugmentedGeneration/DocumentStores/FAISSDocumentStore.cs",
    "position": 264,
    "original_position": 264,
    "commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "user": {
      "login": "coderabbitai[bot]",
      "id": 136622811,
      "node_id": "BOT_kgDOCCSy2w",
      "avatar_url": "https://avatars.githubusercontent.com/in/347564?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/coderabbitai%5Bbot%5D",
      "html_url": "https://github.com/apps/coderabbitai",
      "followers_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/followers",
      "following_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/following{/other_user}",
      "gists_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/subscriptions",
      "organizations_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/orgs",
      "repos_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/repos",
      "events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/events{/privacy}",
      "received_events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/received_events",
      "type": "Bot",
      "user_view_type": "public",
      "site_admin": false
    },
    "body": "_ΓÜá∩╕Å Potential issue_ | _≡ƒƒá Major_\n\n**Keep the FAISS index in sync when removing documents.**\n\n`RemoveCore` deletes the entry from `_documents` but leaves the corresponding embedding in `_indexedVectors`. Over time that leaks memory and makes `_indexedVectors` diverge from the live corpus. Please track the per-document index (e.g., via a reverse map) and delete the entry from `_indexedVectors` when a document is removed.\n\n<!-- fingerprinting:phantom:medusa:sabertoothed -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->",
    "created_at": "2025-11-05T15:09:18Z",
    "updated_at": "2025-11-05T15:09:20Z",
    "html_url": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980108",
    "pull_request_url": "https://api.github.com/repos/ooples/AiDotNet/pulls/304",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980108"
      },
      "html": {
        "href": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980108"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/304"
      }
    },
    "original_commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "reactions": {
      "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980108/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    }
  },
  {
    "id": 2494980122,
    "node_id": "PRRC_kwDOKSXUF86UtmAa",
    "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980122",
    "pull_request_review_id": 3422732638,
    "diff_hunk": "@@ -0,0 +1,326 @@\n+using AiDotNet.Helpers;\n+using AiDotNet.LinearAlgebra;\n+using AiDotNet.RetrievalAugmentedGeneration.Models;\n+using System;\n+using System.Collections.Generic;\n+using System.Linq;\n+\n+namespace AiDotNet.RetrievalAugmentedGeneration.DocumentStores\n+{\n+    /// <summary>\n+    /// Pinecone-inspired document store with index-based vector organization.\n+    /// </summary>\n+    /// <remarks>\n+    /// <para>\n+    /// This implementation provides an in-memory simulation of Pinecone, a fully managed vector database service.\n+    /// It organizes documents into named indices and uses cosine similarity for retrieval.\n+    /// </para>\n+    /// <para><b>For Beginners:</b> Pinecone is a popular cloud-based vector database.\n+    /// \n+    /// Think of indices like separate databases:\n+    /// - Each index has a unique name (like \"ProductSearchIndex\")\n+    /// - Documents are grouped by use case\n+    /// - Makes it easy to manage multiple vector search applications\n+    /// \n+    /// This in-memory version is good for:\n+    /// - Prototyping before using real Pinecone\n+    /// - Testing Pinecone-style index organization\n+    /// - Small to medium document collections (< 100K documents)\n+    /// \n+    /// Real Pinecone provides:\n+    /// - Fully managed cloud service (no infrastructure to manage)\n+    /// - Auto-scaling to handle any load\n+    /// - Advanced filtering and hybrid search\n+    /// - Sub-50ms query latency at scale\n+    /// </para>\n+    /// </remarks>\n+    /// <typeparam name=\"T\">The numeric type for vector operations.</typeparam>\n+    public class PineconeDocumentStore<T> : DocumentStoreBase<T>\n+    {\n+        private readonly Dictionary<string, VectorDocument<T>> _documents;\n+        private readonly string _indexName;\n+        private int _vectorDimension;\n+\n+        /// <summary>\n+        /// Gets the number of documents currently stored in the index.\n+        /// </summary>\n+        public override int DocumentCount => _documents.Count;\n+\n+        /// <summary>\n+        /// Gets the dimensionality of vectors stored in this index.\n+        /// </summary>\n+        public override int VectorDimension => _vectorDimension;\n+\n+        /// <summary>\n+        /// Initializes a new instance of the PineconeDocumentStore class.\n+        /// </summary>\n+        /// <param name=\"indexName\">The name of the index to organize documents.</param>\n+        /// <param name=\"initialCapacity\">The initial capacity for the internal dictionary (default: 1000).</param>\n+        /// <exception cref=\"ArgumentException\">Thrown when index name is empty or initial capacity is not positive.</exception>\n+        /// <remarks>\n+        /// <para><b>For Beginners:</b> Creates a new Pinecone-style index.\n+        /// \n+        /// Example:\n+        /// <code>\n+        /// // Create an index for product vectors\n+        /// var store = new PineconeDocumentStore&lt;float&gt;(\"ProductIndex\");\n+        /// \n+        /// // Create a larger index for articles\n+        /// var bigStore = new PineconeDocumentStore&lt;double&gt;(\"ArticleIndex\", 10000);\n+        /// </code>\n+        /// \n+        /// The index name helps organize different vector collections.\n+        /// </para>\n+        /// </remarks>\n+        public PineconeDocumentStore(string indexName, int initialCapacity = 1000)\n+        {\n+            if (string.IsNullOrWhiteSpace(indexName))\n+                throw new ArgumentException(\"Index name cannot be empty\", nameof(indexName));\n+            if (initialCapacity <= 0)\n+                throw new ArgumentException(\"Initial capacity must be greater than zero\", nameof(initialCapacity));\n+\n+            _indexName = indexName;\n+            _documents = new Dictionary<string, VectorDocument<T>>(initialCapacity);\n+            _vectorDimension = 0;\n+        }\n+\n+        /// <summary>\n+        /// Core logic for adding a single vector document to the index.\n+        /// </summary>\n+        /// <param name=\"vectorDocument\">The validated vector document to add.</param>\n+        /// <remarks>\n+        /// <para>\n+        /// The first document added determines the vector dimension for the entire index.\n+        /// All subsequent documents must have embeddings of the same dimension.\n+        /// </para>\n+        /// </remarks>\n+        protected override void AddCore(VectorDocument<T> vectorDocument)\n+        {\n+            if (_documents.Count == 0)\n+            {\n+                _vectorDimension = vectorDocument.Embedding.Length;\n+            }\n+\n+            _documents[vectorDocument.Document.Id] = vectorDocument;\n+        }\n+\n+        /// <summary>\n+        /// Core logic for adding multiple vector documents in a batch operation.\n+        /// </summary>\n+        /// <param name=\"vectorDocuments\">The validated list of vector documents to add.</param>\n+        /// <exception cref=\"ArgumentException\">Thrown when a document's embedding has inconsistent dimensions.</exception>\n+        /// <remarks>\n+        /// <para>\n+        /// Batch addition is significantly more efficient than adding documents one at a time.\n+        /// All documents in the batch must have embeddings with the same dimension.\n+        /// </para>\n+        /// <para><b>For Beginners:</b> Adding documents in batches is much faster.\n+        /// \n+        /// Bad (slow):\n+        /// <code>\n+        /// foreach (var doc in documents)\n+        ///     store.Add(doc);\n+        /// </code>\n+        /// \n+        /// Good (fast):\n+        /// <code>\n+        /// store.AddBatch(documents);\n+        /// </code>\n+        /// </para>\n+        /// </remarks>\n+        protected override void AddBatchCore(IList<VectorDocument<T>> vectorDocuments)\n+        {\n+            if (_vectorDimension == 0 && vectorDocuments.Count > 0)\n+            {\n+                _vectorDimension = vectorDocuments[0].Embedding.Length;\n+            }\n+\n+            foreach (var vectorDocument in vectorDocuments)\n+            {\n+                if (vectorDocument.Embedding.Length != _vectorDimension)\n+                    throw new ArgumentException(\n+                        $\"Vector dimension mismatch in batch. Expected {_vectorDimension}, got {vectorDocument.Embedding.Length} for document {vectorDocument.Document.Id}\",\n+                        nameof(vectorDocuments));\n+\n+                _documents[vectorDocument.Document.Id] = vectorDocument;\n+            }\n+        }\n+\n+        /// <summary>\n+        /// Core logic for similarity search using cosine similarity with optional metadata filtering.\n+        /// </summary>\n+        /// <param name=\"queryVector\">The validated query vector.</param>\n+        /// <param name=\"topK\">The validated number of documents to return.</param>\n+        /// <param name=\"metadataFilters\">The validated metadata filters.</param>\n+        /// <returns>Top-k similar documents ordered by cosine similarity score.</returns>\n+        /// <remarks>\n+        /// <para>\n+        /// Performs a similarity search across all documents in the index, optionally filtering\n+        /// by metadata. Results are ordered by decreasing cosine similarity and limited to top-k matches.\n+        /// </para>\n+        /// <para><b>For Beginners:</b> Finds the most similar documents to your query.\n+        /// \n+        /// How it works:\n+        /// 1. Filter documents by metadata (if provided)\n+        /// 2. Calculate similarity between query and each document's embedding\n+        /// 3. Sort by similarity (highest first)\n+        /// 4. Return the top-k best matches\n+        /// \n+        /// Example:\n+        /// <code>\n+        /// // Find 10 most similar products\n+        /// var results = store.GetSimilar(queryVector, topK: 10);\n+        /// \n+        /// // Find similar products in \"Electronics\" category\n+        /// var filters = new Dictionary&lt;string, object&gt; { [\"category\"] = \"Electronics\" };\n+        /// var filtered = store.GetSimilarWithFilters(queryVector, 5, filters);\n+        /// </code>\n+        /// </para>\n+        /// </remarks>\n+        protected override IEnumerable<Document<T>> GetSimilarCore(Vector<T> queryVector, int topK, Dictionary<string, object> metadataFilters)\n+        {\n+            var scoredDocuments = new List<(Document<T> Document, T Score)>();\n+\n+            var matchingDocuments = _documents.Values\n+                .Where(vectorDoc => MatchesFilters(vectorDoc.Document, metadataFilters));\n+\n+            foreach (var vectorDoc in matchingDocuments)\n+            {\n+                var similarity = StatisticsHelper<T>.CosineSimilarity(queryVector, vectorDoc.Embedding);\n+                scoredDocuments.Add((vectorDoc.Document, similarity));\n+            }\n+\n+            var results = scoredDocuments\n+                .OrderByDescending(x => x.Score)\n+                .Take(topK)\n+                .Select(x =>\n+                {\n+                    x.Document.RelevanceScore = x.Score;\n+                    x.Document.HasRelevanceScore = true;\n+                    return x.Document;\n+                })\n+                .ToList();",
    "path": "src/RetrievalAugmentedGeneration/DocumentStores/PineconeDocumentStore.cs",
    "position": 202,
    "original_position": 202,
    "commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "user": {
      "login": "coderabbitai[bot]",
      "id": 136622811,
      "node_id": "BOT_kgDOCCSy2w",
      "avatar_url": "https://avatars.githubusercontent.com/in/347564?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/coderabbitai%5Bbot%5D",
      "html_url": "https://github.com/apps/coderabbitai",
      "followers_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/followers",
      "following_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/following{/other_user}",
      "gists_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/subscriptions",
      "organizations_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/orgs",
      "repos_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/repos",
      "events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/events{/privacy}",
      "received_events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/received_events",
      "type": "Bot",
      "user_view_type": "public",
      "site_admin": false
    },
    "body": "_ΓÜá∩╕Å Potential issue_ | _≡ƒƒá Major_\n\n**Return scored copies instead of mutating cached documents.**\n\nSetting `RelevanceScore` and `HasRelevanceScore` directly on `_documents` leaves stale scores hanging around for future calls. Please clone the document (or otherwise produce a new instance) before attaching the relevance metadata.\n\n<details>\n<summary>≡ƒñû Prompt for AI Agents</summary>\n\n```\nIn src/RetrievalAugmentedGeneration/DocumentStores/PineconeDocumentStore.cs\naround lines 193 to 202, the code mutates cached document instances by setting\nRelevanceScore and HasRelevanceScore; instead create and return new document\ninstances so the cache isnΓÇÖt modified. Fix by cloning each x.Document (shallow\ncopy or create a new Document populated from x.Document fields) inside the\nSelect, set RelevanceScore and HasRelevanceScore on the clone, and return the\nclone; ensure the original _documents collection is never mutated.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:sabertoothed -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->",
    "created_at": "2025-11-05T15:09:18Z",
    "updated_at": "2025-11-05T15:09:20Z",
    "html_url": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980122",
    "pull_request_url": "https://api.github.com/repos/ooples/AiDotNet/pulls/304",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980122"
      },
      "html": {
        "href": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980122"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/304"
      }
    },
    "original_commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "reactions": {
      "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980122/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    }
  },
  {
    "id": 2494980138,
    "node_id": "PRRC_kwDOKSXUF86UtmAq",
    "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980138",
    "pull_request_review_id": 3422732638,
    "diff_hunk": "@@ -0,0 +1,327 @@\n+using AiDotNet.Helpers;\n+using AiDotNet.LinearAlgebra;\n+using AiDotNet.RetrievalAugmentedGeneration.Models;\n+using System;\n+using System.Collections.Generic;\n+using System.Linq;\n+\n+namespace AiDotNet.RetrievalAugmentedGeneration.DocumentStores\n+{\n+    /// <summary>\n+    /// PostgreSQL with pgvector-inspired document store for relational database vector storage.\n+    /// </summary>\n+    /// <remarks>\n+    /// <para>\n+    /// This implementation provides an in-memory simulation of PostgreSQL with the pgvector extension,\n+    /// which adds vector similarity search capabilities to the popular relational database.\n+    /// It organizes documents in table-like structures with cosine similarity for retrieval.\n+    /// </para>\n+    /// <para><b>For Beginners:</b> PostgreSQL is a powerful open-source relational database, and pgvector adds AI capabilities.\n+    /// \n+    /// Think of it like a smart database table:\n+    /// - Each table stores documents with vector embeddings\n+    /// - Combines traditional SQL queries with vector search\n+    /// - Leverage existing PostgreSQL infrastructure\n+    /// \n+    /// This in-memory version is good for:\n+    /// - Prototyping pgvector applications\n+    /// - Testing table-based organization\n+    /// - Small to medium collections (< 100K documents)\n+    /// \n+    /// Real PostgreSQL + pgvector provides:\n+    /// - ACID transactions for data integrity\n+    /// - Complex SQL joins with vector search\n+    /// - Proven reliability and scalability\n+    /// - Integration with existing database infrastructure\n+    /// </para>\n+    /// </remarks>\n+    /// <typeparam name=\"T\">The numeric type for vector operations.</typeparam>\n+    public class PostgresVectorDocumentStore<T> : DocumentStoreBase<T>\n+    {\n+        private readonly Dictionary<string, VectorDocument<T>> _documents;\n+        private readonly string _tableName;\n+        private int _vectorDimension;\n+\n+        /// <summary>\n+        /// Gets the number of documents currently stored in the table.\n+        /// </summary>\n+        public override int DocumentCount => _documents.Count;\n+\n+        /// <summary>\n+        /// Gets the dimensionality of vectors stored in this table.\n+        /// </summary>\n+        public override int VectorDimension => _vectorDimension;\n+\n+        /// <summary>\n+        /// Initializes a new instance of the PostgresVectorDocumentStore class.\n+        /// </summary>\n+        /// <param name=\"tableName\">The table name to organize documents.</param>\n+        /// <param name=\"initialCapacity\">The initial capacity for the internal dictionary (default: 1000).</param>\n+        /// <exception cref=\"ArgumentException\">Thrown when table name is empty or initial capacity is not positive.</exception>\n+        /// <remarks>\n+        /// <para><b>For Beginners:</b> Creates a new pgvector-style document table.\n+        /// \n+        /// Example:\n+        /// <code>\n+        /// // Create a table for documents\n+        /// var store = new PostgresVectorDocumentStore&lt;float&gt;(\"documents\");\n+        /// \n+        /// // Create a table for embeddings\n+        /// var embStore = new PostgresVectorDocumentStore&lt;double&gt;(\"embeddings\", 10000);\n+        /// </code>\n+        /// \n+        /// The table name helps organize different document collections.\n+        /// </para>\n+        /// </remarks>\n+        public PostgresVectorDocumentStore(string tableName, int initialCapacity = 1000)\n+        {\n+            if (string.IsNullOrWhiteSpace(tableName))\n+                throw new ArgumentException(\"Table name cannot be empty\", nameof(tableName));\n+            if (initialCapacity <= 0)\n+                throw new ArgumentException(\"Initial capacity must be greater than zero\", nameof(initialCapacity));\n+\n+            _tableName = tableName;\n+            _documents = new Dictionary<string, VectorDocument<T>>(initialCapacity);\n+            _vectorDimension = 0;\n+        }\n+\n+        /// <summary>\n+        /// Core logic for adding a single vector document to the table.\n+        /// </summary>\n+        /// <param name=\"vectorDocument\">The validated vector document to add.</param>\n+        /// <remarks>\n+        /// <para>\n+        /// The first document added determines the vector dimension for all documents in this table.\n+        /// All subsequent documents must have embeddings of the same dimension.\n+        /// </para>\n+        /// </remarks>\n+        protected override void AddCore(VectorDocument<T> vectorDocument)\n+        {\n+            if (_documents.Count == 0)\n+            {\n+                _vectorDimension = vectorDocument.Embedding.Length;\n+            }\n+\n+            _documents[vectorDocument.Document.Id] = vectorDocument;\n+        }\n+\n+        /// <summary>\n+        /// Core logic for adding multiple vector documents in a batch operation.\n+        /// </summary>\n+        /// <param name=\"vectorDocuments\">The validated list of vector documents to add.</param>\n+        /// <exception cref=\"ArgumentException\">Thrown when a document's embedding has inconsistent dimensions.</exception>\n+        /// <remarks>\n+        /// <para>\n+        /// Batch operations are more efficient than adding documents individually, similar to PostgreSQL's\n+        /// bulk insert capabilities. All documents must have embeddings with the same dimension.\n+        /// </para>\n+        /// <para><b>For Beginners:</b> Adding many documents at once is much faster.\n+        /// \n+        /// Slow way:\n+        /// <code>\n+        /// foreach (var doc in documents)\n+        ///     store.Add(doc); // Many individual inserts\n+        /// </code>\n+        /// \n+        /// Fast way:\n+        /// <code>\n+        /// store.AddBatch(documents); // Single bulk insert\n+        /// </code>\n+        /// </para>\n+        /// </remarks>\n+        protected override void AddBatchCore(IList<VectorDocument<T>> vectorDocuments)\n+        {\n+            if (_vectorDimension == 0 && vectorDocuments.Count > 0)\n+            {\n+                _vectorDimension = vectorDocuments[0].Embedding.Length;\n+            }\n+\n+            foreach (var vectorDocument in vectorDocuments)\n+            {\n+                if (vectorDocument.Embedding.Length != _vectorDimension)\n+                    throw new ArgumentException(\n+                        $\"Vector dimension mismatch in batch. Expected {_vectorDimension}, got {vectorDocument.Embedding.Length} for document {vectorDocument.Document.Id}\",\n+                        nameof(vectorDocuments));\n+\n+                _documents[vectorDocument.Document.Id] = vectorDocument;\n+            }\n+        }\n+\n+        /// <summary>\n+        /// Core logic for similarity search using cosine similarity with optional metadata filtering.\n+        /// </summary>\n+        /// <param name=\"queryVector\">The validated query vector.</param>\n+        /// <param name=\"topK\">The validated number of documents to return.</param>\n+        /// <param name=\"metadataFilters\">The validated metadata filters.</param>\n+        /// <returns>Top-k similar documents ordered by cosine similarity score.</returns>\n+        /// <remarks>\n+        /// <para>\n+        /// Performs vector similarity search across all documents in the table, optionally filtering by metadata.\n+        /// In real pgvector, this would use the vector similarity operators (<->, <=>, <#>) in SQL.\n+        /// </para>\n+        /// <para><b>For Beginners:</b> Finds the most similar documents to your query.\n+        /// \n+        /// How it works:\n+        /// 1. Filter documents by metadata (like SQL WHERE clause)\n+        /// 2. Calculate similarity between query and each document\n+        /// 3. Sort by similarity (highest first, like SQL ORDER BY)\n+        /// 4. Return top-k matches (like SQL LIMIT)\n+        /// \n+        /// Example:\n+        /// <code>\n+        /// // Find 10 most similar documents\n+        /// var results = store.GetSimilar(queryVector, topK: 10);\n+        /// \n+        /// // Find similar documents from 2024\n+        /// var filters = new Dictionary&lt;string, object&gt; { [\"year\"] = \"2024\" };\n+        /// var filtered = store.GetSimilarWithFilters(queryVector, 5, filters);\n+        /// </code>\n+        /// </para>\n+        /// </remarks>\n+        protected override IEnumerable<Document<T>> GetSimilarCore(Vector<T> queryVector, int topK, Dictionary<string, object> metadataFilters)\n+        {\n+            var scoredDocuments = new List<(Document<T> Document, T Score)>();\n+\n+            var matchingDocuments = _documents.Values\n+                .Where(vectorDoc => MatchesFilters(vectorDoc.Document, metadataFilters));\n+\n+            foreach (var vectorDoc in matchingDocuments)\n+            {\n+                var similarity = StatisticsHelper<T>.CosineSimilarity(queryVector, vectorDoc.Embedding);\n+                scoredDocuments.Add((vectorDoc.Document, similarity));\n+            }\n+\n+            var results = scoredDocuments\n+                .OrderByDescending(x => x.Score)\n+                .Take(topK)\n+                .Select(x =>\n+                {\n+                    x.Document.RelevanceScore = x.Score;\n+                    x.Document.HasRelevanceScore = true;\n+                    return x.Document;\n+                })\n+                .ToList();",
    "path": "src/RetrievalAugmentedGeneration/DocumentStores/PostgresVectorDocumentStore.cs",
    "position": 203,
    "original_position": 203,
    "commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "user": {
      "login": "coderabbitai[bot]",
      "id": 136622811,
      "node_id": "BOT_kgDOCCSy2w",
      "avatar_url": "https://avatars.githubusercontent.com/in/347564?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/coderabbitai%5Bbot%5D",
      "html_url": "https://github.com/apps/coderabbitai",
      "followers_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/followers",
      "following_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/following{/other_user}",
      "gists_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/subscriptions",
      "organizations_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/orgs",
      "repos_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/repos",
      "events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/events{/privacy}",
      "received_events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/received_events",
      "type": "Bot",
      "user_view_type": "public",
      "site_admin": false
    },
    "body": "_ΓÜá∩╕Å Potential issue_ | _≡ƒƒá Major_\n\n**Avoid leaking query-specific state into stored documents.**\n\nThe selector mutates the cached `Document<T>` by setting `RelevanceScore`/`HasRelevanceScore`. That score persists after the query and shows up in unrelated contexts. Please return a copy (or clone) with the relevance metadata instead of altering the stored instance.\n\n<details>\n<summary>≡ƒñû Prompt for AI Agents</summary>\n\n```\nIn\nsrc/RetrievalAugmentedGeneration/DocumentStores/PostgresVectorDocumentStore.cs\naround lines 194 to 203, the LINQ selector is mutating the cached Document by\nsetting RelevanceScore/HasRelevanceScore which leaks query-specific state;\ninstead create and return a copy of the Document with the relevance metadata\nset. Fix by instantiating a new Document (or calling an existing Clone/Copy\nmethod) populated from x.Document, set RelevanceScore and HasRelevanceScore on\nthat new instance, and return the new instance so the stored cached document is\nnot modified.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:sabertoothed -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->",
    "created_at": "2025-11-05T15:09:19Z",
    "updated_at": "2025-11-05T15:09:20Z",
    "html_url": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980138",
    "pull_request_url": "https://api.github.com/repos/ooples/AiDotNet/pulls/304",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980138"
      },
      "html": {
        "href": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980138"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/304"
      }
    },
    "original_commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "reactions": {
      "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980138/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    }
  },
  {
    "id": 2494980154,
    "node_id": "PRRC_kwDOKSXUF86UtmA6",
    "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980154",
    "pull_request_review_id": 3422732638,
    "diff_hunk": "@@ -0,0 +1,312 @@\n+using AiDotNet.Helpers;\n+using AiDotNet.Interfaces;\n+using AiDotNet.LinearAlgebra;\n+using AiDotNet.RetrievalAugmentedGeneration.Models;\n+using System;\n+using System.Collections.Generic;\n+using System.Linq;\n+\n+namespace AiDotNet.RetrievalAugmentedGeneration.DocumentStores;\n+\n+/// <summary>\n+/// Lightweight SQLite-based vector store using the SQLite-VSS extension.\n+/// </summary>\n+/// <remarks>\n+/// <para>\n+/// This implementation provides an in-memory simulation of SQLite with the VSS (Vector Similarity Search) extension,\n+/// which adds vector search capabilities to the serverless, file-based SQLite database. Perfect for\n+/// edge deployments, mobile apps, and development environments.\n+/// </para>\n+/// <para><b>For Beginners:</b> SQLite is a tiny, serverless database that stores data in a single file, and VSS adds AI search.\n+/// \n+/// Think of it like an Excel file with AI superpowers:\n+/// - No server needed - just a file on disk\n+/// - Perfect for apps, IoT devices, mobile\n+/// - Combine SQL queries with vector search\n+/// \n+/// This in-memory version is good for:\n+/// - Prototyping SQLite-VSS applications\n+/// - Testing local vector search\n+/// - Small collections (< 10K documents)\n+/// \n+/// Real SQLite-VSS provides:\n+/// - Zero-configuration deployment\n+/// - Single-file database (easy backup/transfer)\n+/// - ACID transactions for data integrity\n+/// - Perfect for edge AI and mobile apps\n+/// </para>\n+/// </remarks>\n+/// <typeparam name=\"T\">The numeric data type used for vector operations.</typeparam>\n+public class SQLiteVSSDocumentStore<T> : DocumentStoreBase<T>\n+{\n+    private readonly Dictionary<string, VectorDocument<T>> _store;\n+    private int _vectorDimension;\n+\n+    /// <summary>\n+    /// Gets the number of documents currently stored in the database.\n+    /// </summary>\n+    public override int DocumentCount => _store.Count;\n+\n+    /// <summary>\n+    /// Gets the dimensionality of vectors stored in this database.\n+    /// </summary>\n+    public override int VectorDimension => _vectorDimension;\n+\n+    /// <summary>\n+    /// Initializes a new instance of the SQLiteVSSDocumentStore class.\n+    /// </summary>\n+    /// <param name=\"databasePath\">The path to the SQLite database file.</param>\n+    /// <param name=\"tableName\">The table name to organize documents.</param>\n+    /// <param name=\"vectorDimension\">The dimension of vector embeddings.</param>\n+    /// <exception cref=\"ArgumentException\">Thrown when parameters are invalid.</exception>\n+    /// <remarks>\n+    /// <para><b>For Beginners:</b> Creates a new SQLite vector store.\n+    /// \n+    /// Example:\n+    /// <code>\n+    /// // Create a store with 384-dimensional embeddings\n+    /// var store = new SQLiteVSSDocumentStore&lt;float&gt;(\n+    ///     \"vectors.db\",\n+    ///     \"documents\",\n+    ///     vectorDimension: 384\n+    /// );\n+    /// </code>\n+    /// \n+    /// The database file will be created if it doesn't exist.\n+    /// Vector dimension must be known upfront to create the table properly.\n+    /// </para>\n+    /// </remarks>\n+    public SQLiteVSSDocumentStore(string databasePath, string tableName, int vectorDimension)\n+    {\n+        if (string.IsNullOrWhiteSpace(databasePath))\n+            throw new ArgumentException(\"Database path cannot be empty\", nameof(databasePath));\n+        if (string.IsNullOrWhiteSpace(tableName))\n+            throw new ArgumentException(\"Table name cannot be empty\", nameof(tableName));\n+        if (vectorDimension <= 0)\n+            throw new ArgumentException(\"Vector dimension must be positive\", nameof(vectorDimension));\n+\n+        _store = new Dictionary<string, VectorDocument<T>>();\n+        _vectorDimension = vectorDimension;\n+    }\n+\n+    /// <summary>\n+    /// Core logic for adding a single vector document to the database.\n+    /// </summary>\n+    /// <param name=\"vectorDocument\">The validated vector document to add.</param>\n+    /// <remarks>\n+    /// <para>\n+    /// Stores the document in the SQLite table with its vector embedding.\n+    /// In real SQLite-VSS, this would use INSERT statements with vss0 virtual table functions.\n+    /// </para>\n+    /// </remarks>\n+    protected override void AddCore(VectorDocument<T> vectorDocument)\n+    {\n+        if (_vectorDimension == 0)\n+            _vectorDimension = vectorDocument.Embedding.Length;\n+\n+        _store[vectorDocument.Document.Id] = vectorDocument;\n+    }\n+\n+    /// <summary>\n+    /// Core logic for adding multiple vector documents in a batch operation.\n+    /// </summary>\n+    /// <param name=\"vectorDocuments\">The validated list of vector documents to add.</param>\n+    /// <remarks>\n+    /// <para>\n+    /// Batch operations use SQLite transactions for better performance, inserting all documents\n+    /// in a single ACID transaction.\n+    /// </para>\n+    /// <para><b>For Beginners:</b> Batch operations are much faster in SQLite.\n+    /// \n+    /// Slow (many transactions):\n+    /// <code>\n+    /// foreach (var doc in documents)\n+    ///     store.Add(doc); // Each insert is a separate transaction\n+    /// </code>\n+    /// \n+    /// Fast (single transaction):\n+    /// <code>\n+    /// store.AddBatch(documents); // All inserts in one transaction\n+    /// </code>\n+    /// \n+    /// This can be 100x faster for large batches!\n+    /// </para>\n+    /// </remarks>\n+    protected override void AddBatchCore(IList<VectorDocument<T>> vectorDocuments)\n+    {\n+        if (vectorDocuments.Count == 0) return;\n+\n+        if (_vectorDimension == 0)\n+            _vectorDimension = vectorDocuments[0].Embedding.Length;\n+\n+        foreach (var vd in vectorDocuments)\n+            _store[vd.Document.Id] = vd;\n+    }",
    "path": "src/RetrievalAugmentedGeneration/DocumentStores/SQLiteVSSDocumentStore.cs",
    "position": 144,
    "original_position": 144,
    "commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "user": {
      "login": "coderabbitai[bot]",
      "id": 136622811,
      "node_id": "BOT_kgDOCCSy2w",
      "avatar_url": "https://avatars.githubusercontent.com/in/347564?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/coderabbitai%5Bbot%5D",
      "html_url": "https://github.com/apps/coderabbitai",
      "followers_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/followers",
      "following_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/following{/other_user}",
      "gists_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/subscriptions",
      "organizations_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/orgs",
      "repos_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/repos",
      "events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/events{/privacy}",
      "received_events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/received_events",
      "type": "Bot",
      "user_view_type": "public",
      "site_admin": false
    },
    "body": "_ΓÜá∩╕Å Potential issue_ | _≡ƒƒá Major_\n\n**Validate batch dimensions before accepting documents.**\n\nWhen `_vectorDimension` was provided in the constructor, `_vectorDimension == 0` is false during the first batch insert, so this loop adds embeddings without ever checking their length. A single mismatched vector will then poison the store and cause later `Add`/`GetSimilar` calls to throw dimension errors. Please assert `vectorDocument.Embedding.Length == _vectorDimension` for every document (including the first batch) or derive the dimension from the first document and validate subsequent entries accordingly.\n\n<details>\n<summary>≡ƒñû Prompt for AI Agents</summary>\n\n```\nIn src/RetrievalAugmentedGeneration/DocumentStores/SQLiteVSSDocumentStore.cs\naround lines 136 to 144, the batch insert does not validate embedding lengths\nwhen _vectorDimension is already set, which can allow mismatched-dimension\nvectors to be stored; update the method to (a) if _vectorDimension == 0, set it\nfrom the first vector's Embedding.Length, (b) for every vector in\nvectorDocuments assert/throw if vd.Embedding.Length != _vectorDimension, and (c)\nonly after validation add the documents to _store so no invalid-dimension\nvectors are persisted.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:sabertoothed -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->",
    "created_at": "2025-11-05T15:09:19Z",
    "updated_at": "2025-11-05T15:09:20Z",
    "html_url": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980154",
    "pull_request_url": "https://api.github.com/repos/ooples/AiDotNet/pulls/304",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980154"
      },
      "html": {
        "href": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980154"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/304"
      }
    },
    "original_commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "reactions": {
      "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980154/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    }
  },
  {
    "id": 2494980172,
    "node_id": "PRRC_kwDOKSXUF86UtmBM",
    "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980172",
    "pull_request_review_id": 3422732638,
    "diff_hunk": "@@ -0,0 +1,312 @@\n+using AiDotNet.Helpers;\n+using AiDotNet.Interfaces;\n+using AiDotNet.LinearAlgebra;\n+using AiDotNet.RetrievalAugmentedGeneration.Models;\n+using System;\n+using System.Collections.Generic;\n+using System.Linq;\n+\n+namespace AiDotNet.RetrievalAugmentedGeneration.DocumentStores;\n+\n+/// <summary>\n+/// Lightweight SQLite-based vector store using the SQLite-VSS extension.\n+/// </summary>\n+/// <remarks>\n+/// <para>\n+/// This implementation provides an in-memory simulation of SQLite with the VSS (Vector Similarity Search) extension,\n+/// which adds vector search capabilities to the serverless, file-based SQLite database. Perfect for\n+/// edge deployments, mobile apps, and development environments.\n+/// </para>\n+/// <para><b>For Beginners:</b> SQLite is a tiny, serverless database that stores data in a single file, and VSS adds AI search.\n+/// \n+/// Think of it like an Excel file with AI superpowers:\n+/// - No server needed - just a file on disk\n+/// - Perfect for apps, IoT devices, mobile\n+/// - Combine SQL queries with vector search\n+/// \n+/// This in-memory version is good for:\n+/// - Prototyping SQLite-VSS applications\n+/// - Testing local vector search\n+/// - Small collections (< 10K documents)\n+/// \n+/// Real SQLite-VSS provides:\n+/// - Zero-configuration deployment\n+/// - Single-file database (easy backup/transfer)\n+/// - ACID transactions for data integrity\n+/// - Perfect for edge AI and mobile apps\n+/// </para>\n+/// </remarks>\n+/// <typeparam name=\"T\">The numeric data type used for vector operations.</typeparam>\n+public class SQLiteVSSDocumentStore<T> : DocumentStoreBase<T>\n+{\n+    private readonly Dictionary<string, VectorDocument<T>> _store;\n+    private int _vectorDimension;\n+\n+    /// <summary>\n+    /// Gets the number of documents currently stored in the database.\n+    /// </summary>\n+    public override int DocumentCount => _store.Count;\n+\n+    /// <summary>\n+    /// Gets the dimensionality of vectors stored in this database.\n+    /// </summary>\n+    public override int VectorDimension => _vectorDimension;\n+\n+    /// <summary>\n+    /// Initializes a new instance of the SQLiteVSSDocumentStore class.\n+    /// </summary>\n+    /// <param name=\"databasePath\">The path to the SQLite database file.</param>\n+    /// <param name=\"tableName\">The table name to organize documents.</param>\n+    /// <param name=\"vectorDimension\">The dimension of vector embeddings.</param>\n+    /// <exception cref=\"ArgumentException\">Thrown when parameters are invalid.</exception>\n+    /// <remarks>\n+    /// <para><b>For Beginners:</b> Creates a new SQLite vector store.\n+    /// \n+    /// Example:\n+    /// <code>\n+    /// // Create a store with 384-dimensional embeddings\n+    /// var store = new SQLiteVSSDocumentStore&lt;float&gt;(\n+    ///     \"vectors.db\",\n+    ///     \"documents\",\n+    ///     vectorDimension: 384\n+    /// );\n+    /// </code>\n+    /// \n+    /// The database file will be created if it doesn't exist.\n+    /// Vector dimension must be known upfront to create the table properly.\n+    /// </para>\n+    /// </remarks>\n+    public SQLiteVSSDocumentStore(string databasePath, string tableName, int vectorDimension)\n+    {\n+        if (string.IsNullOrWhiteSpace(databasePath))\n+            throw new ArgumentException(\"Database path cannot be empty\", nameof(databasePath));\n+        if (string.IsNullOrWhiteSpace(tableName))\n+            throw new ArgumentException(\"Table name cannot be empty\", nameof(tableName));\n+        if (vectorDimension <= 0)\n+            throw new ArgumentException(\"Vector dimension must be positive\", nameof(vectorDimension));\n+\n+        _store = new Dictionary<string, VectorDocument<T>>();\n+        _vectorDimension = vectorDimension;\n+    }\n+\n+    /// <summary>\n+    /// Core logic for adding a single vector document to the database.\n+    /// </summary>\n+    /// <param name=\"vectorDocument\">The validated vector document to add.</param>\n+    /// <remarks>\n+    /// <para>\n+    /// Stores the document in the SQLite table with its vector embedding.\n+    /// In real SQLite-VSS, this would use INSERT statements with vss0 virtual table functions.\n+    /// </para>\n+    /// </remarks>\n+    protected override void AddCore(VectorDocument<T> vectorDocument)\n+    {\n+        if (_vectorDimension == 0)\n+            _vectorDimension = vectorDocument.Embedding.Length;\n+\n+        _store[vectorDocument.Document.Id] = vectorDocument;\n+    }\n+\n+    /// <summary>\n+    /// Core logic for adding multiple vector documents in a batch operation.\n+    /// </summary>\n+    /// <param name=\"vectorDocuments\">The validated list of vector documents to add.</param>\n+    /// <remarks>\n+    /// <para>\n+    /// Batch operations use SQLite transactions for better performance, inserting all documents\n+    /// in a single ACID transaction.\n+    /// </para>\n+    /// <para><b>For Beginners:</b> Batch operations are much faster in SQLite.\n+    /// \n+    /// Slow (many transactions):\n+    /// <code>\n+    /// foreach (var doc in documents)\n+    ///     store.Add(doc); // Each insert is a separate transaction\n+    /// </code>\n+    /// \n+    /// Fast (single transaction):\n+    /// <code>\n+    /// store.AddBatch(documents); // All inserts in one transaction\n+    /// </code>\n+    /// \n+    /// This can be 100x faster for large batches!\n+    /// </para>\n+    /// </remarks>\n+    protected override void AddBatchCore(IList<VectorDocument<T>> vectorDocuments)\n+    {\n+        if (vectorDocuments.Count == 0) return;\n+\n+        if (_vectorDimension == 0)\n+            _vectorDimension = vectorDocuments[0].Embedding.Length;\n+\n+        foreach (var vd in vectorDocuments)\n+            _store[vd.Document.Id] = vd;\n+    }\n+\n+    /// <summary>\n+    /// Core logic for similarity search using cosine similarity with optional metadata filtering.\n+    /// </summary>\n+    /// <param name=\"queryVector\">The validated query vector.</param>\n+    /// <param name=\"topK\">The validated number of documents to return.</param>\n+    /// <param name=\"metadataFilters\">The validated metadata filters.</param>\n+    /// <returns>Top-k similar documents ordered by cosine similarity score.</returns>\n+    /// <remarks>\n+    /// <para>\n+    /// Performs vector similarity search using in-memory calculations. In real SQLite-VSS, this would use\n+    /// the vss_search() SQL function to efficiently find nearest neighbors.\n+    /// </para>\n+    /// <para><b>For Beginners:</b> Finds the most similar documents in the SQLite database.\n+    /// \n+    /// How it works:\n+    /// 1. Filter documents by metadata (like SQL WHERE clause)\n+    /// 2. Calculate similarity for each document\n+    /// 3. Sort by similarity (highest first, like SQL ORDER BY)\n+    /// 4. Return top-k matches (like SQL LIMIT)\n+    /// \n+    /// In real SQLite-VSS, this uses efficient indexing structures like HNSW\n+    /// for fast approximate nearest neighbor search.\n+    /// \n+    /// Example:\n+    /// <code>\n+    /// // Find 10 most similar documents\n+    /// var results = store.GetSimilar(queryVector, topK: 10);\n+    /// </code>\n+    /// </para>\n+    /// </remarks>\n+    protected override IEnumerable<Document<T>> GetSimilarCore(Vector<T> queryVector, int topK, Dictionary<string, object> metadataFilters)\n+    {\n+        var results = new List<(Document<T> doc, T score)>();\n+\n+        foreach (var vd in _store.Values)\n+        {\n+            var similarity = StatisticsHelper<T>.CosineSimilarity(queryVector, vd.Embedding);\n+            vd.Document.RelevanceScore = similarity;\n+            results.Add((vd.Document, similarity));\n+        }\n+\n+        return results\n+            .OrderByDescending(x => Convert.ToDouble(x.score))\n+            .Take(topK)\n+            .Select(x => x.doc);\n+    }",
    "path": "src/RetrievalAugmentedGeneration/DocumentStores/SQLiteVSSDocumentStore.cs",
    "position": 191,
    "original_position": 191,
    "commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "user": {
      "login": "coderabbitai[bot]",
      "id": 136622811,
      "node_id": "BOT_kgDOCCSy2w",
      "avatar_url": "https://avatars.githubusercontent.com/in/347564?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/coderabbitai%5Bbot%5D",
      "html_url": "https://github.com/apps/coderabbitai",
      "followers_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/followers",
      "following_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/following{/other_user}",
      "gists_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/subscriptions",
      "organizations_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/orgs",
      "repos_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/repos",
      "events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/events{/privacy}",
      "received_events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/received_events",
      "type": "Bot",
      "user_view_type": "public",
      "site_admin": false
    },
    "body": "_ΓÜá∩╕Å Potential issue_ | _≡ƒƒá Major_\n\n**Respect metadata filters and set relevance metadata on the results.**\n\n`metadataFilters` is ignored here, so filtered searches return unfiltered documents. Also, the returned documents never get `HasRelevanceScore = true`, leaving downstream consumers thinking no score is available. Please use `MatchesFilters` to gate the candidate set and hydrate both `RelevanceScore` and `HasRelevanceScore` on the objects you return.\n\n<details>\n<summary>≡ƒñû Prompt for AI Agents</summary>\n\n```\nIn src/RetrievalAugmentedGeneration/DocumentStores/SQLiteVSSDocumentStore.cs\naround lines 176 to 191, the method ignores metadataFilters and never sets\nHasRelevanceScore; update the loop to only consider entries where\nMatchesFilters(metadataFilters, vd.Document.Metadata) returns true (handle\nnull/empty filters), compute and assign vd.Document.RelevanceScore as before,\nand also set vd.Document.HasRelevanceScore = true for any document you add to\nresults; finally order, take topK and return the documents as before.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:sabertoothed -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->",
    "created_at": "2025-11-05T15:09:19Z",
    "updated_at": "2025-11-05T15:09:20Z",
    "html_url": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980172",
    "pull_request_url": "https://api.github.com/repos/ooples/AiDotNet/pulls/304",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980172"
      },
      "html": {
        "href": "https://github.com/ooples/AiDotNet/pull/304#discussion_r2494980172"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/ooples/AiDotNet/pulls/304"
      }
    },
    "original_commit_id": "e972697ed5a758045091402fb3f80cadcdfa8829",
    "reactions": {
      "url": "https://api.github.com/repos/ooples/AiDotNet/pulls/comments/2494980172/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    }
  }
]
