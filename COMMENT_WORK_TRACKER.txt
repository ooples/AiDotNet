# PR #256 Critical/Major Issues Work Tracker
# Total Issues: 105 (Critical + Major)
# Generated: 2025-11-02 18:25 UTC

## FIXED IN THIS SESSION (Commits: ac2d695, 7e40b22, 2af0d24, d875025, b58dc04, 71fe623)

✅ AdaLoRAAdapter - Static RNG field added (Issue #2, ac2d695)
✅ NOLAAdapter - Null guard in ParameterCount (Issue #62, ac2d695)  
✅ LoHaAdapter - Added _loraLayer.ResetState() call (Issue #17, 7e40b22)
✅ DoRAAdapter - Fixed magnitude gradients with input dot product (Issue #45, 2af0d24)
✅ DoRAAdapter - Removed dead code in forward pass (Issue #45, 2af0d24)
✅ BFGSOptimizer - Removed UTF-8 BOM (Issue #94, d875025)
✅ AdaLoRAAdapter - Clarified pruning documentation (Issue #1, b58dc04)
✅ LoRADropAdapter - Added inference-mode scaling (1-dropout_rate) in Forward (Issue #14, 71fe623)
✅ LoRADropAdapter - Added inference-mode gradient scaling in Backward (Issue #14, 71fe623)

## REMAINING CRITICAL ISSUES (Sorted by File)

### src/LoRA/Adapters/AdaLoRAAdapter.cs
[4-PARTIAL] Line 244 - Pruning implementation (already clarified, may need more work)
[4] Line 516 - Expanded rank components remain zeroed
[4] Line 580 - Always creates DenseLayer, losing type information

### src/LoRA/Adapters/ChainLoRAAdapter.cs  
[5] Line 630 - ParameterCount doesn't include chain
[5] Line 229 - Unused LoRA layer in base class
[5] Line 402 - Confusing merge semantics
[5] Line 539 - MergeToOriginalLayer is stub

### src/LoRA/Adapters/DVoRAAdapter.cs
[6] Line 175 - ParameterCount initialization issue
[6] Line 922 - Parameter packing alignment
[6] Line 1099 - Activation not carried through merge

### src/LoRA/Adapters/DoRAAdapter.cs
[7-PARTIAL] Line 105 - ParameterCount guard (may be fixed)
[7-FIXED] Line 381 - Dead code removed (2af0d24)
[7-FIXED] Line 501 - Magnitude gradients fixed (2af0d24)

### src/LoRA/Adapters/DyLoRAAdapter.cs
[8] Line 387 - Forward never primes _loraLayer

### src/LoRA/Adapters/FloraAdapter.cs
[9] Line 179 - Resampled momentum transform order

### src/LoRA/Adapters/GLoRAAdapter.cs
[10] Line 90 - ParameterCount NullReferenceException

### src/LoRA/Adapters/HRAAdapter.cs
[11] Line 186 - ParameterCount NullReferenceException
[11] Line 497 - Sparse gradient computation
[11] Line 712 - Override SetParameters for sparse weights

### src/LoRA/Adapters/LoHaAdapter.cs
[12-FIXED] Line 902 - ResetState fixed (7e40b22)
[12] Line 49 - Documentation error on efficiency
[12] Line 181 - ParameterCount efficiency concerns
[12] Line 374 - HadamardProduct mathematically incorrect
[12] Line 503 - Gradient computation for B matrices incorrect
[12] Line 582 - HadamardGradient inconsistent

### src/LoRA/Adapters/LoKrAdapter.cs
[13] Line 104 - Include base layer in ParameterCount
[13] Line 320 - Forward materializes full Kronecker (performance)
[13] Line 402 - Backward materializes full Kronecker (performance)
[13] Line 664 - Fix parameter packing
[13] Line 690 - Fix parameter unpacking
[13] Line 722 - Fix gradient packing

### src/LoRA/Adapters/LoRADropAdapter.cs
[14-FIXED] Line 299 - Inference scaling fixed (71fe623)
[14-FIXED] Line 369 - Inference gradient scaling fixed (71fe623)

### src/LoRA/Adapters/LoRAPlusAdapter.cs
[15] Line 359 - Code duplication with other adapters
[15] Line 390 - Code duplication with LoftQAdapter

### src/LoRA/Adapters/LoRETTAAdapter.cs
[16] Line 584 - Backward pass not properly implemented
[16] Line 876 - Tensor-train contraction not implemented

### src/LoRA/Adapters/LoftQAdapter.cs
[17] Line 566 - Guard zero-range quantization

### src/LoRA/Adapters/LongLoRAAdapter.cs
[18] Line 423 - Shifted attention indexing breaks multi-dim inputs

### src/LoRA/Adapters/MoRAAdapter.cs
[19] Line 415 - ParameterCount constructor crash
[19] Line 434 - Merged layer drops base weights

### src/LoRA/Adapters/MultiLoRAAdapter.cs
[20] Line 120 - Guard ParameterCount before initialization
[20] Line 618 - Align parameter-gradient packing

### src/LoRA/Adapters/QALoRAAdapter.cs
[22] Line 456 - Signed quantization range needed

### Other files (non-LoRA)
[1] src/AiDotNet.csproj:3 - CI/CD pipeline error
[2] src/Interfaces/ILoRAAdapter.cs:46 - Missing namespace
[3] src/Interfaces/IPredictionModelBuilder.cs:353 - Breaking change
... (see full PR for complete list)

## WORK IN PROGRESS
Currently fixing: ParameterCount null reference issues in multiple adapters

## NOTES
- Total fixed this session: 9 issues
- Remaining critical LoRA issues: ~50+
- Focus on ParameterCount guards and mathematical correctness
