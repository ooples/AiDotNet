Analyze the entire AiDotNet codebase with focus on:

1. **Architecture Patterns**: How are features organized? Look at existing features like Evaluation, DataProcessor, etc. to understand:
   - Do we use "Base" folders or do base classes live within their namespace folders?
   - How are interfaces organized?
   - How are concrete implementations structured?
   - What naming conventions are used?

2. **StatisticsHelper Integration**: Examine src/Helpers/StatisticsHelper.cs:
   - What statistical methods exist (e.g., Jaccard similarity, cosine similarity)?
   - How should RAG evaluation metrics integrate with existing statistics?
   - Are there overlapping calculations we should reuse?

3. **Existing Evaluation Framework**: Look at src/Evaluation/:
   - How are evaluators structured?
   - What patterns do they follow?
   - How should RAG evaluation integrate?

4. **Generic Types & INumericOperations**: Check how Vector<T>, Matrix<T>, Tensor<T> are used:
   - Where should we use these instead of arrays?
   - How is INumericOperations<T> applied?

5. **Documentation Standards**: Review XML documentation across the codebase:
   - What format is used for beginner explanations?
   - How detailed should remarks be?

6. **Test Console Project**: Find C:\Users\cheat\source\repos\AiDotNet\testconsole\AiDotNetTestConsole.csproj:
   - How are examples structured?
   - Where should RAG examples go?

Please provide:
- Specific examples from the codebase
- Recommended folder structure for RAG following existing patterns
- List of StatisticsHelper methods that RAG should use instead of reimplementing
- How to properly integrate with existing evaluation framework
