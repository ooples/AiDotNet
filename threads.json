{"data":{"repository":{"pullRequest":{"reviewThreads":{"totalCount":74,"pageInfo":{"hasNextPage":false,"endCursor":"Y3Vyc29yOnYyOpK0MjAyNi0wMS0zMFQxOToxNDoxN1rOa-0xIg=="},"nodes":[{"id":"PRRT_kwDOKSXUF85rkndI","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepAR.cs","line":832,"body":"_‚ö†Ô∏è Potential issue_ | _üî¥ Critical_\n\n**Backward path treats sigma and mu as sequential layers.**  \n`Forward` returns `mu` only, but `Backward` routes gradients through `_sigmaProjection` and then `_muProjection` as if they were sequential, which is incorrect (and will distort gradients for both). Either include sigma in the forward output/loss or skip sigma in the backward path.  \n\n<details>\n<summary>üßØ Minimal fix (if output remains mu only)</summary>\n\n```diff\n private void Backward(Tensor<T> gradOutput)\n {\n     var grad = gradOutput;\n\n-    // Backward through distribution heads\n-    if (_sigmaProjection is not null)\n-    {\n-        grad = _sigmaProjection.Backward(grad);\n-    }\n-\n-    if (_muProjection is not null)\n+    // Backward through mu head only (sigma isn‚Äôt part of the forward output)\n+    if (_muProjection is not null)\n     {\n         grad = _muProjection.Backward(grad);\n     }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepAR.cs` around lines 760 - 822, The\nBackward method incorrectly treats _sigmaProjection and _muProjection as\nsequential by calling _sigmaProjection.Backward(grad) then\n_muProjection.Backward(grad) even though Forward returns only mu (and sigma was\nnot part of the forward output/loss); fix by either (A) if you intend to keep\nForward returning only mu, remove the call to _sigmaProjection.Backward(grad) so\nonly _muProjection.Backward(grad) receives gradients, or (B) if sigma should\nreceive gradients, modify Forward to include sigma in the returned outputs/loss\nso gradOutput contains separate gradients for mu and sigma and propagate each\ngradient through _muProjection.Backward(...) and _sigmaProjection.Backward(...)\nappropriately (ensure the gradient tensors are split/mapped consistently).\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit 1265ef9"}]}},{"id":"PRRT_kwDOKSXUF85rldnG","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Data/FinancialDataLoaderFactory.cs","line":66,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Add a null guard for `series`.**\n\n`FromProvider` throws `ArgumentNullException` for a null provider, but `FromSeries` has no equivalent guard for `series`. This can surface as a less clear exception downstream.\n\n\n\n<details>\n<summary>‚úÖ Suggested fix</summary>\n\n```diff\n     public static FinancialDataLoader<T> FromSeries<T>(\n         IReadOnlyList<MarketDataPoint<T>> series,\n         int sequenceLength,\n         int predictionHorizon,\n         bool includeVolume = true,\n         bool includeReturns = false,\n         bool predictReturns = false,\n         bool normalizeMinMax = false,\n         FinancialPreprocessor<T>? preprocessor = null,\n         int batchSize = 32)\n     {\n+        if (series is null)\n+        {\n+            throw new ArgumentNullException(nameof(series));\n+        }\n+\n         return new FinancialDataLoader<T>(\n             series,\n             sequenceLength,\n             predictionHorizon,\n             includeVolume,\n             includeReturns,\n             predictReturns,\n             normalizeMinMax,\n             preprocessor,\n             batchSize);\n     }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    public static FinancialDataLoader<T> FromSeries<T>(\n        IReadOnlyList<MarketDataPoint<T>> series,\n        int sequenceLength,\n        int predictionHorizon,\n        bool includeVolume = true,\n        bool includeReturns = false,\n        bool predictReturns = false,\n        bool normalizeMinMax = false,\n        FinancialPreprocessor<T>? preprocessor = null,\n        int batchSize = 32)\n    {\n        if (series is null)\n        {\n            throw new ArgumentNullException(nameof(series));\n        }\n\n        return new FinancialDataLoader<T>(\n            series,\n            sequenceLength,\n            predictionHorizon,\n            includeVolume,\n            includeReturns,\n            predictReturns,\n            normalizeMinMax,\n            preprocessor,\n            batchSize);\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Data/FinancialDataLoaderFactory.cs` around lines 40 - 61, Add a\nnull guard at the start of the static FromSeries<T> method to throw\nArgumentNullException if the series parameter is null; specifically, in\nFinancialDataLoaderFactory.FromSeries<T> validate series and throw new\nArgumentNullException(nameof(series)) before calling the FinancialDataLoader<T>\nconstructor so callers get a clear immediate error instead of downstream\nfailures.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85ry4SP","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Chronos.cs","line":151,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Tokenization scaling state is not serialized and not thread-safe.**\n\nThe fields `_lastTokenMin`, `_lastTokenRange`, and `_hasTokenScale` (Lines 149-151) are:\n\n1. **Not serialized**: After deserialization, `_hasTokenScale` will be `false`, causing `Detokenize` to fall back to normalized range instead of the original scaling.\n\n2. **Not thread-safe**: Multiple concurrent calls to `Forecast` ‚Üí `Tokenize` will race on these shared fields, potentially corrupting predictions.\n\nConsider either:\n- Passing scaling parameters through method calls rather than storing in instance fields, or\n- Adding thread synchronization if concurrent access is expected.\n\n\n\n<details>\n<summary>üîß Suggested approach: Pass scaling through method parameters</summary>\n\n```diff\n-private T _lastTokenMin = default!;\n-private T _lastTokenRange = default!;\n-private bool _hasTokenScale;\n+// Remove instance-level tokenization state\n\n-private Tensor<T> Tokenize(Tensor<T> values)\n+private (Tensor<T> tokenized, T min, T range) Tokenize(Tensor<T> values)\n {\n     // ... existing scaling logic ...\n-    _lastTokenMin = min;\n-    _lastTokenRange = range;\n-    _hasTokenScale = true;\n     // ...\n-    return tokenized;\n+    return (tokenized, min, range);\n }\n\n-private Tensor<T> Detokenize(Tensor<T> logits)\n+private Tensor<T> Detokenize(Tensor<T> logits, T min, T range)\n {\n     // Use passed min/range instead of instance fields\n }\n```\n</details>\n\n\nAlso applies to: 558-594\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Chronos.cs` around lines 149 - 151, The\nfields _lastTokenMin, _lastTokenRange and _hasTokenScale are instance state that\nis neither serialized nor thread-safe and can cause incorrect Detokenize\nbehavior and races during concurrent Forecast‚ÜíTokenize calls; refactor to remove\nthese shared fields by threading the scaling parameters through method\nsignatures (e.g., change Tokenize/Detokenize and any callers like Forecast to\naccept tokenMin, tokenRange, and hasTokenScale parameters) so state is passed\nexplicitly and can be serialized, or if you must keep shared state add proper\nsynchronization around reads/writes and ensure they are included in\nserialization; locate uses in methods named Tokenize, Detokenize and Forecast\nand update all callers accordingly.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85ry4ST","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Chronos.cs","line":485,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Training mode not reset on exception.**\n\nSame issue as TimeGPT: if an exception occurs during forward pass or loss computation, `SetTrainingMode(false)` won't be called. Consider wrapping in try/finally.\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Chronos.cs` around lines 456 - 479, In\nTrain(Tensor<T> input, Tensor<T> target) ensure SetTrainingMode(false) is always\ncalled by wrapping the training sequence (tokenization, Forward, loss/derivative\ncalculation, Backward, and _optimizer.UpdateParameters(Layers)) in a\ntry/finally: call SetTrainingMode(true) before the try, put the existing logic\n(Tokenize, Forward, loss/derivative, Backward, _optimizer.UpdateParameters)\ninside the try, and call SetTrainingMode(false) in the finally block, rethrowing\nany exception after cleanup so failures during Forward, loss computation, or\nBackward still reset training mode.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85ry4SU","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Chronos.cs","line":null,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Division by zero when `_numTokens == 1`.**\n\nAt Line 956, `maxIdx / (double)(_numTokens - 1)` will cause a division by zero if `_numTokens` is 1 (which passes validation at Line 408). The same issue exists at Line 1000.\n\n\n\n<details>\n<summary>üõ°Ô∏è Proposed fix</summary>\n\n```diff\n-double scaledValue = maxIdx / (double)(_numTokens - 1);\n+double scaledValue = _numTokens > 1 ? maxIdx / (double)(_numTokens - 1) : 0.5;\n```\n\nOr strengthen the validation:\n```diff\n if (options.NumTokens < 1)\n-    errors.Add(\"NumTokens must be at least 1.\");\n+if (options.NumTokens < 2)\n+    errors.Add(\"NumTokens must be at least 2.\");\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n            double scaledValue = _numTokens > 1 ? maxIdx / (double)(_numTokens - 1) : 0.5;\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Chronos.cs` at line 956, Avoid dividing by\n(_numTokens - 1); when _numTokens == 1 the expression maxIdx /\n(double)(_numTokens - 1) will divide by zero. Update the calculations that set\nscaledValue (and the similar computation near line 1000) to handle the\nsingle-token case explicitly ‚Äî e.g., if (_numTokens <= 1) set scaledValue = 0\n(or use a safe denominator like Math.Max(1, _numTokens - 1)) before performing\nthe division ‚Äî referencing the field _numTokens and the scaledValue assignment\nto locate the changes.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85ry4SY","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/TimeGPT.cs","line":66,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**`_useNativeMode` is not serialized/deserialized but is mutable.**\n\nThe field `_useNativeMode` is non-readonly, yet it's not included in `SerializeNetworkSpecificData`/`DeserializeNetworkSpecificData`. After deserialization, the model will default to whatever value was set in the constructor used for deserialization, which may not match the original serialized model's mode.\n\nEither serialize/deserialize this field to preserve the original state, or make it `readonly` if it's intended to be constructor-determined.\n\n\n\n<details>\n<summary>üîß Proposed fix to serialize _useNativeMode</summary>\n\n```diff\n protected override void SerializeNetworkSpecificData(BinaryWriter writer)\n {\n+    writer.Write(_useNativeMode);\n     writer.Write(_contextLength);\n     // ... rest of serialization\n```\n\n```diff\n protected override void DeserializeNetworkSpecificData(BinaryReader reader)\n {\n+    _useNativeMode = reader.ReadBoolean();\n     _contextLength = reader.ReadInt32();\n     // ... rest of deserialization\n```\n</details>\n\n\nAlso applies to: 499-555\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/TimeGPT.cs` at line 66, The non-readonly\nfield _useNativeMode is mutable but not included in serialization, causing\ndeserialized objects to lose the original mode; either add reading/writing of\n_useNativeMode in SerializeNetworkSpecificData and\nDeserializeNetworkSpecificData (ensure you serialize a boolean and restore it\nduring deserialization) or make _useNativeMode readonly and only set it via the\nconstructor used for deserialization (update the constructor signatures\naccordingly). Locate the members named _useNativeMode,\nSerializeNetworkSpecificData, and DeserializeNetworkSpecificData in TimeGPT.cs\nand apply one of these fixes so the runtime mode is preserved across\nserialization boundaries.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85ry4Sa","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/TimeGPT.cs","line":430,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Training mode not reset on exception.**\n\nIf an exception occurs during `Forward`, loss calculation, or `Backward`, `SetTrainingMode(false)` at Line 425 won't be called, leaving the model in training mode. Consider using try/finally to ensure cleanup.\n\n\n\n<details>\n<summary>üõ°Ô∏è Proposed fix using try/finally</summary>\n\n```diff\n public override void Train(Tensor<T> input, Tensor<T> target)\n {\n     if (!_useNativeMode)\n         throw new InvalidOperationException(\"Training is only supported in native mode.\");\n\n     SetTrainingMode(true);\n-\n-    var output = Forward(input);\n-\n-    // Compute loss\n-    LastLoss = _lossFunction.CalculateLoss(output.ToVector(), target.ToVector());\n-\n-    // Backward pass\n-    var gradient = _lossFunction.CalculateDerivative(output.ToVector(), target.ToVector());\n-    Backward(Tensor<T>.FromVector(gradient, output.Shape));\n-\n-    _optimizer.UpdateParameters(Layers);\n-\n-    SetTrainingMode(false);\n+    try\n+    {\n+        var output = Forward(input);\n+\n+        // Compute loss\n+        LastLoss = _lossFunction.CalculateLoss(output.ToVector(), target.ToVector());\n+\n+        // Backward pass\n+        var gradient = _lossFunction.CalculateDerivative(output.ToVector(), target.ToVector());\n+        Backward(Tensor<T>.FromVector(gradient, output.Shape));\n+\n+        _optimizer.UpdateParameters(Layers);\n+    }\n+    finally\n+    {\n+        SetTrainingMode(false);\n+    }\n }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/TimeGPT.cs` around lines 407 - 426, The\nTrain method can leave the model stuck in training mode if an exception occurs;\nwrap the body that calls SetTrainingMode(true), Forward, loss calculations\n(LastLoss/_lossFunction), Backward(Tensor<T>.FromVector(...)) and\n_optimizer.UpdateParameters(Layers) in a try/finally block so that\nSetTrainingMode(false) is always executed in the finally; ensure any exception\nis rethrown after cleanup so behavior is unchanged.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85ry4Sb","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/TimeGPT.cs","line":933,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Potential `IndexOutOfRangeException` when `values` list is empty.**\n\nAt Line 904, if `values.Count` is 0 (which can happen if all samples have length ‚â§ `t`), the calculation `Math.Min((int)(quantiles[q] * 0), -1)` yields -1, causing an `IndexOutOfRangeException` when accessing `values[idx]`.\n\nAlso, `SetTrainingMode(true/false)` should use try/finally for exception safety.\n\n\n\n<details>\n<summary>üõ°Ô∏è Proposed fix</summary>\n\n```diff\n private Tensor<T> GenerateQuantilePredictions(Tensor<T> input, double[] quantiles)\n {\n     int numSamples = 100;\n     var samples = new List<Tensor<T>>();\n\n     // Enable dropout for MC sampling\n     SetTrainingMode(true);\n-\n-    for (int s = 0; s < numSamples; s++)\n+    try\n     {\n-        samples.Add(Forward(input));\n+        for (int s = 0; s < numSamples; s++)\n+        {\n+            samples.Add(Forward(input));\n+        }\n+    }\n+    finally\n+    {\n+        SetTrainingMode(false);\n     }\n\n-    SetTrainingMode(false);\n-\n     // Compute quantiles\n     var result = new Tensor<T>(new[] { 1, _forecastHorizon, quantiles.Length });\n\n     for (int t = 0; t < _forecastHorizon; t++)\n     {\n         var values = new List<double>();\n         foreach (var sample in samples)\n         {\n             if (t < sample.Length)\n             {\n                 values.Add(NumOps.ToDouble(sample.Data.Span[t]));\n             }\n         }\n\n+        if (values.Count == 0)\n+            continue;\n+\n         values.Sort();\n\n         for (int q = 0; q < quantiles.Length; q++)\n         {\n             int idx = Math.Min((int)(quantiles[q] * values.Count), values.Count - 1);\n             result.Data.Span[t * quantiles.Length + q] = NumOps.FromDouble(values[idx]);\n         }\n     }\n\n     return result;\n }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/TimeGPT.cs` around lines 871 - 910,\nGenerateQuantilePredictions can throw when values is empty and also leaves\ntraining mode set if Forward throws; fix by wrapping the MC\nsampling/SetTrainingMode(true) block in try/finally and calling\nSetTrainingMode(false) in finally, and when computing quantiles guard against\nvalues.Count == 0 (e.g., set idx = 0 or write a default value such as\nNumOps.FromDouble(0) or NaN via NumOps if available) before accessing\nvalues[idx]; update the loop that builds result.Data.Span (referencing\nGenerateQuantilePredictions, SetTrainingMode, Forward, _forecastHorizon, and\nresult.Data.Span) to handle empty values safely and ensure training mode is\nalways reset.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85ry4Se","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/TimeGPT.cs","line":1012,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Potential out-of-bounds access when `input.Length < _contextLength`.**\n\nLine 974 accesses `input.Data.Span[i + steps]` assuming `input.Length >= _contextLength`. If the input tensor is shorter than `_contextLength`, this will cause an `IndexOutOfRangeException`.\n\n\n\n<details>\n<summary>üõ°Ô∏è Proposed fix with bounds checking</summary>\n\n```diff\n protected override Tensor<T> ShiftInputWithPredictions(Tensor<T> input, Tensor<T> predictions, int stepsUsed)\n {\n     var result = new Tensor<T>(input.Shape);\n     int contextLen = _contextLength;\n     int steps = Math.Min(stepsUsed, contextLen);\n\n     // Shift old values left\n-    for (int i = 0; i < contextLen - steps; i++)\n+    for (int i = 0; i < contextLen - steps && i + steps < input.Length; i++)\n     {\n         result.Data.Span[i] = input.Data.Span[i + steps];\n     }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    protected override Tensor<T> ShiftInputWithPredictions(Tensor<T> input, Tensor<T> predictions, int stepsUsed)\n    {\n        var result = new Tensor<T>(input.Shape);\n        int contextLen = _contextLength;\n        int steps = Math.Min(stepsUsed, contextLen);\n\n        // Shift old values left\n        for (int i = 0; i < contextLen - steps && i + steps < input.Length; i++)\n        {\n            result.Data.Span[i] = input.Data.Span[i + steps];\n        }\n\n        // Append predictions\n        for (int i = 0; i < steps && i < predictions.Length; i++)\n        {\n            result.Data.Span[contextLen - steps + i] = predictions.Data.Span[i];\n        }\n\n        return result;\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/TimeGPT.cs` around lines 965 - 984, The\nShiftInputWithPredictions method assumes input.Length >= _contextLength which\ncan cause out-of-bounds when input is shorter; update the loop bounds to use the\nactual input length and avoid indexing past input.Data.Span or\npredictions.Data.Span: compute an effectiveContext = Math.Min(_contextLength,\ninput.Length), compute steps = Math.Min(stepsUsed, effectiveContext), then when\ncopying \"old values left\" iterate using effectiveContext and input.Length (e.g.,\ncopy up to input.Length - steps) and when appending predictions clamp by\npredictions.Length so result.Data.Span indices are always within [0,\nresult.Length); adjust any offset calculations (contextLen - steps) to use\neffectiveContext so ShiftInputWithPredictions, input, predictions and result\naccesses are all guarded.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85ry4Si","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/TimeLLM.cs","line":343,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Add option guards before computing `_numPatches`.**  \n`_numPatches = (_contextLength - _patchLength) / _patchStride + 1` will throw for `_patchStride <= 0` and can go negative when `_patchLength > _contextLength`. Add validation (similar to Timer/TimesFM) in both constructors.\n\n<details>\n<summary>üõ°Ô∏è Suggested guard (apply in both constructors)</summary>\n\n```diff\n         _contextLength = options.ContextLength;\n         _forecastHorizon = options.ForecastHorizon;\n         _patchLength = options.PatchLength;\n         _patchStride = options.PatchStride;\n+        if (_contextLength < 1)\n+            throw new ArgumentOutOfRangeException(nameof(options.ContextLength), \"Context length must be at least 1.\");\n+        if (_patchLength < 1)\n+            throw new ArgumentOutOfRangeException(nameof(options.PatchLength), \"Patch length must be at least 1.\");\n+        if (_patchStride < 1)\n+            throw new ArgumentOutOfRangeException(nameof(options.PatchStride), \"Patch stride must be at least 1.\");\n+        if (_patchLength > _contextLength)\n+            throw new ArgumentOutOfRangeException(nameof(options.PatchLength), \"Patch length cannot exceed context length.\");\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/TimeLLM.cs` around lines 238 - 323, The\nconstructors for TimeLLM compute _numPatches using (_contextLength -\n_patchLength) / _patchStride + 1 without validating _patchStride and the\nrelationship between _contextLength and _patchLength; add guards in both TimeLLM\nconstructors to throw meaningful exceptions (e.g.,\nArgumentOutOfRangeException/ArgumentException) when _patchStride <= 0 or\n_patchLength > _contextLength (or when resulting _numPatches <= 0), referencing\nthe fields _contextLength, _patchLength, _patchStride and computing _numPatches\nonly after validation (before calling InitializeLayers()); ensure the error\nmessages name the offending option and are consistent across the OnnxModelPath\nconstructor and the native-mode constructor.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85ry4Sj","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Timer.cs","line":981,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Autoregressive helpers assume 1D/univariate input without enforcing it.**  \n`AutoregressiveGenerate` and `ShiftInputWithPredictions` index as if the input is a flat `[context_length]` vector, but constructors allow `numFeatures > 1`. This will silently produce incorrect shifts for multivariate inputs.\n\n<details>\n<summary>üõ°Ô∏è Suggested guard to avoid silent mis-shifts</summary>\n\n```diff\n private Tensor<T> AutoregressiveGenerate(Tensor<T> input, int steps)\n {\n+    if (input.Shape.Length != 1 || _numFeatures != 1)\n+        throw new InvalidOperationException(\"Autoregressive generation currently supports a single univariate series with shape [context_length].\");\n     var result = new Tensor<T>(new[] { 1, steps, 1 });\n     var currentInput = input;\n```\n\n```diff\n protected override Tensor<T> ShiftInputWithPredictions(Tensor<T> input, Tensor<T> predictions, int stepsUsed)\n {\n+    if (input.Shape.Length != 1 || _numFeatures != 1)\n+        throw new InvalidOperationException(\"ShiftInputWithPredictions currently supports a single univariate series with shape [context_length].\");\n     var result = new Tensor<T>(input.Shape);\n     int contextLen = _contextLength;\n```\n</details>\n\n\n\nAlso applies to: 1003-1022\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Timer.cs` around lines 822 - 863,\nAutoregressiveGenerate and ShiftInputWithPredictions currently assume a\nunivariate flat input and will mis-shift when numFeatures > 1; add an\ninput-shape guard or proper multivariate handling: check the tensor shape (or\n_numFeatures) at the top of AutoregressiveGenerate and ShiftInputWithPredictions\nand either throw a clear ArgumentException when numFeatures != 1, or implement\ncorrect shifting by treating the tensor as [batch, contextLength, numFeatures]\nand shifting along the time axis for each feature (use _contextLength and\n_numFeatures to build the shifted Tensor and set the last timestep across all\nfeatures to the predicted values returned by Forward). Ensure references to\nForward, Tensor<T>, _contextLength and _numFeatures are used so the fix is\napplied to both AutoregressiveGenerate and the corresponding\nShiftInputWithPredictions helper.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commits c6f36c0 to d858f69"}]}},{"id":"PRRT_kwDOKSXUF85ry4Sk","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepAR.cs","line":936,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Rank-2 inputs are allowed but processed as batched tensors.**  \n`ValidateInputShape` accepts 2D inputs, but `ApplyScaling`, `ReverseScaling`, and `ShiftInputWithPredictions` treat `Shape[0]` as batch size. For rank-2 input this mis-scales and mis-shifts data (per-timestep ‚Äúbatch‚Äù behavior). Either normalize rank-2 to batch=1 in helpers or fail fast.\n\n<details>\n<summary>üõ†Ô∏è Suggested guard (fail fast until rank‚Äë2 handling is added)</summary>\n\n```diff\n-        if (input.Rank != 2 && input.Rank != 3)\n-            throw new ArgumentException(\"Input tensor must be 2D [context_length, num_features] or 3D [batch_size, context_length, num_features].\", nameof(input));\n-\n-        int actualSeqLen = input.Rank == 3 ? input.Shape[1] : input.Shape[0];\n-        int actualNumFeatures = input.Rank == 3 ? input.Shape[2] : input.Shape[1];\n+        if (input.Rank != 3)\n+            throw new ArgumentException(\"Input tensor must be 3D [batch_size, context_length, num_features].\", nameof(input));\n+\n+        int actualSeqLen = input.Shape[1];\n+        int actualNumFeatures = input.Shape[2];\n```\n</details>\n\n\n\nAlso applies to: 933-961, 1135-1168\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepAR.cs` around lines 847 - 920,\nValidateInputShape currently allows Rank==2 but ApplyScaling, ReverseScaling and\nShiftInputWithPredictions assume Rank==3 (batch first), causing incorrect\nindexing; change ValidateInputShape to reject 2D inputs (only allow input.Rank\n== 3) so callers must pass batched tensors, and add a TODO comment in\nApplyScaling, ReverseScaling and ShiftInputWithPredictions noting they must be\nupdated to support Rank==2 (or to normalize 2D -> batch=1) if 2D support is ever\nadded. Mention the functions ValidateInputShape, ApplyScaling, ReverseScaling,\nand ShiftInputWithPredictions when making the change.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85ry4Sm","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepFactor.cs","line":355,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Wire custom layers into DeepFactor paths.**\n\nWhen `Architecture.Layers` is provided, the model never calls `ExtractLayerReferences()`, so `_factorInputProjection`, `_factorRnnLayers`, etc. remain null/empty and the forward/backward path ignores the custom layers. Please extract references after validating the custom layers.  \n\n\n<details>\n<summary>Suggested fix</summary>\n\n```diff\n         if (Architecture.Layers is not null && Architecture.Layers.Count > 0)\n         {\n             Layers.AddRange(Architecture.Layers);\n             ValidateCustomLayers(Layers);\n+            ExtractLayerReferences();\n         }\n         else if (_useNativeMode)\n         {\n             Layers.AddRange(LayerHelper<T>.CreateDefaultDeepFactorLayers(\n                 Architecture, _lookbackWindow, _forecastHorizon, _numFeatures,\n                 _numFactors, _factorHiddenDim, _localHiddenDim,\n                 _numFactorLayers, _numLocalLayers, _dropout));\n \n             ExtractLayerReferences();\n         }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n        if (Architecture.Layers is not null && Architecture.Layers.Count > 0)\n        {\n            Layers.AddRange(Architecture.Layers);\n            ValidateCustomLayers(Layers);\n            ExtractLayerReferences();\n        }\n        else if (_useNativeMode)\n        {\n            Layers.AddRange(LayerHelper<T>.CreateDefaultDeepFactorLayers(\n                Architecture, _lookbackWindow, _forecastHorizon, _numFeatures,\n                _numFactors, _factorHiddenDim, _localHiddenDim,\n                _numFactorLayers, _numLocalLayers, _dropout));\n\n            ExtractLayerReferences();\n        }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepFactor.cs` around lines 341 - 354, When\nArchitecture.Layers is supplied the code validates custom layers but never\npopulates internal references, so call ExtractLayerReferences() after\nValidateCustomLayers(Layers). Specifically, in DeepFactor (class DeepFactor<T>)\ninside the branch that handles Architecture.Layers (where\nLayers.AddRange(Architecture.Layers) and ValidateCustomLayers(Layers) are\ncalled), add a call to ExtractLayerReferences() so _factorInputProjection,\n_factorRnnLayers, etc. are populated for both custom and native modes.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85ry4Sq","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepFactor.cs","line":1013,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Autoregressive shift drops features for multivariate inputs.**\n\nFor multivariate series, the shift only writes one value per step (`predictions[i]`), leaving the other features as zeros. This corrupts the input window and will degrade forecasts when `_numFeatures > 1`.  \n\n\n<details>\n<summary>Suggested fix</summary>\n\n```diff\n-        for (int i = 0; i < stepsUsed && i < predictions.Length; i++)\n-        {\n-            int targetIdx = totalElements - shift + i * _numFeatures;\n-            if (targetIdx < totalElements)\n-            {\n-                newInput.Data.Span[targetIdx] = predictions[i];\n-            }\n-        }\n+        for (int step = 0; step < stepsUsed; step++)\n+        {\n+            for (int f = 0; f < _numFeatures; f++)\n+            {\n+                int predIdx = step * _numFeatures + f;\n+                int targetIdx = totalElements - shift + step * _numFeatures + f;\n+                if (predIdx < predictions.Length && targetIdx < totalElements)\n+                {\n+                    newInput.Data.Span[targetIdx] = predictions.Data.Span[predIdx];\n+                }\n+            }\n+        }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepFactor.cs` around lines 988 - 1003, The\nautoregressive refill logic in DeepFactor.cs currently writes only a single\nvalue per time step (predictions[i]) into newInput, which zeroes out the\nremaining features for multivariate series; update the refill to copy all\nfeature values for each step by treating predictions as containing _numFeatures\nvalues per step and writing predictions[i * _numFeatures + f] into\nnewInput.Data.Span[targetIdx + f] for f in 0.._numFeatures-1, ensuring the\nearlier shift math (totalElements, shift) and targetIdx computation remain\nconsistent with multi-feature indexing and bounds checks.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85ry4St","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepState.cs","line":1011,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Silent shape mismatch could produce incorrect results.**\n\nWhen tensor lengths differ, `AddTensors` silently returns the first tensor unchanged. This can mask architectural bugs during training or inference‚Äîif transition/observation parameters have an unexpected shape, they're silently ignored rather than flagged.\n\nConsider throwing an exception or at minimum logging a warning to surface configuration issues early:\n\n\n\n<details>\n<summary>üõ°Ô∏è Proposed fix to fail fast on shape mismatch</summary>\n\n```diff\n private Tensor<T> AddTensors(Tensor<T> a, Tensor<T> b)\n {\n     if (a.Length != b.Length)\n-        return a;\n+        throw new ArgumentException(\n+            $\"Tensor shape mismatch in AddTensors: {a.Length} vs {b.Length}. \" +\n+            \"This may indicate a layer configuration issue.\");\n\n     var result = new Tensor<T>(a.Shape);\n     for (int i = 0; i < a.Length; i++)\n     {\n         result.Data.Span[i] = NumOps.Add(a.Data.Span[i], b.Data.Span[i]);\n     }\n     return result;\n }\n```\n\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepState.cs` around lines 930 - 941, The\nAddTensors method currently returns the first tensor when shapes differ which\nsilently hides bugs; change it to perform an explicit check on a.Length and/or\na.Shape vs b.Length/b.Shape and throw a descriptive exception (e.g.,\nArgumentException) including both tensor shapes/lengths so callers fail fast;\nupdate the method name reference AddTensors and the shape/length checks\n(a.Length, b.Length, a.Shape, b.Shape) to throw rather than return when they\nmismatch.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85ry4Sv","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/NBEATSFinance.cs","line":851,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Backward pass ignores residual/backcast/forecast graph.**  \nForward updates residuals and sums forecasts, but Backward just walks layers linearly, which won‚Äôt propagate gradients through the residual and additive branches correctly. This will distort training updates.\n\nPlease capture per-block backcast/forecast outputs (or residuals) during Forward and propagate gradients through both paths (backcast subtraction and forecast summation) when backpropagating.\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/NBEATSFinance.cs` around lines 690 - 778,\nForward currently discards per-block intermediates so Backward walks layers\nlinearly; capture and store per-block tensors (e.g., residuals, backcast,\nforecast) during Forward‚Äîcreate lists like perBlockResiduals, perBlockBackcasts,\nperBlockForecasts keyed to _blocks order‚Äîand use those in Backward to route\ngradients correctly: when iterating blocks in reverse, compute gradForecast from\nthe gradient of totalForecast and pass it into the block forecast layer's\nBackward; compute gradBackcast as the negative of the gradient flowing into the\nresidual (because residual = residual_prev - backcast) and pass that into the\nblock backcast layer's Backward; ensure hidden layers receive gradients from\nboth backcast/forecast paths (sum their contributions) and use the stored\nper-block \"current\" (hidden input) values when calling layer.Backward; update\nusage of SubtractTensors/AddTensors semantics when forming these gradient splits\nso parameter gradients are propagated through the residual and additive branches\ncorrectly.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFC","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Base/PortfolioOptimizerBase.cs","line":67,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Validate `numAssets` to prevent invalid tensor shapes.**\n\nA non-positive asset count can produce invalid tensor shapes and downstream exceptions. Add a guard in both constructors.  \n\n\n<details>\n<summary>üîß Proposed guard</summary>\n\n```diff\n protected PortfolioOptimizerBase(NeuralNetworkArchitecture<T> architecture, int numAssets, int numFeatures = 10, ILossFunction<T>? lossFunction = null)\n     : base(architecture, 1, 1, numFeatures, lossFunction)\n {\n-    _numAssets = numAssets;\n+    if (numAssets < 1)\n+        throw new ArgumentOutOfRangeException(nameof(numAssets), \"Number of assets must be at least 1.\");\n+    _numAssets = numAssets;\n }\n```\n</details>\n\n\nAlso applies to: 75-79\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Base/PortfolioOptimizerBase.cs` around lines 56 - 60, Add\nvalidation in both PortfolioOptimizerBase constructors to ensure the incoming\nnumAssets is positive; if numAssets <= 0 throw an ArgumentOutOfRangeException\n(include the parameter name \"numAssets\" and a short message). Place the guard\nbefore assigning _numAssets and before calling base(...) if needed, so invalid\nvalues are rejected early in the\nPortfolioOptimizerBase(NeuralNetworkArchitecture<T> architecture, int numAssets,\n...) and the other overloaded constructor referenced in the review.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFG","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Base/PortfolioOptimizerBase.cs","line":null,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Ensure training mode resets on exceptions.**\n\nIf loss/gradient calculation throws, training mode stays enabled. Wrap the body in try/finally.  \n\n\n<details>\n<summary>üõ°Ô∏è Suggested fix</summary>\n\n```diff\n protected override void TrainCore(Tensor<T> input, Tensor<T> target, Tensor<T> output)\n {\n     // Default training implementation\n     SetTrainingMode(true);\n-    var grad = LossFunction.CalculateDerivative(output.ToVector(), target.ToVector());\n-    // Backward pass would be implemented here or in derived classes\n-    SetTrainingMode(false);\n+    try\n+    {\n+        var grad = LossFunction.CalculateDerivative(output.ToVector(), target.ToVector());\n+        // Backward pass would be implemented here or in derived classes\n+    }\n+    finally\n+    {\n+        SetTrainingMode(false);\n+    }\n }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    protected override void TrainCore(Tensor<T> input, Tensor<T> target, Tensor<T> output)\n    {\n        // Default training implementation\n        SetTrainingMode(true);\n        try\n        {\n            var grad = LossFunction.CalculateDerivative(output.ToVector(), target.ToVector());\n            // Backward pass would be implemented here or in derived classes\n        }\n        finally\n        {\n            SetTrainingMode(false);\n        }\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Base/PortfolioOptimizerBase.cs` around lines 283 - 289, The\nTrainCore method currently sets training mode with SetTrainingMode(true) but if\nLossFunction.CalculateDerivative or other operations throw,\nSetTrainingMode(false) is never called; wrap the body of TrainCore in a\ntry/finally so SetTrainingMode(false) is executed in the finally block, leaving\nthe try to contain the gradient calculation\n(LossFunction.CalculateDerivative(output.ToVector(), target.ToVector())) and any\nbackward-pass calls, and the finally to call SetTrainingMode(false) to ensure\ntraining mode is always reset.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFK","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Base/RiskModelBase.cs","line":315,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Deserialize should re-validate invariants.**  \nCorrupted or mismatched model files can load invalid confidence levels or time horizons, leaving the instance in an inconsistent state.  \n\n<details>\n<summary>üõ†Ô∏è Suggested fix</summary>\n\n```diff\n protected override void DeserializeModelSpecificData(BinaryReader reader)\n {\n     _confidenceLevel = reader.ReadDouble();\n     _timeHorizon = reader.ReadInt32();\n+    if (_confidenceLevel <= 0 || _confidenceLevel >= 1)\n+        throw new InvalidDataException(\"Confidence level must be between 0 and 1 (exclusive).\");\n+    if (_timeHorizon < 1)\n+        throw new InvalidDataException(\"Time horizon must be at least 1.\");\n }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    protected override void DeserializeModelSpecificData(BinaryReader reader)\n    {\n        _confidenceLevel = reader.ReadDouble();\n        _timeHorizon = reader.ReadInt32();\n        if (_confidenceLevel <= 0 || _confidenceLevel >= 1)\n            throw new InvalidDataException(\"Confidence level must be between 0 and 1 (exclusive).\");\n        if (_timeHorizon < 1)\n            throw new InvalidDataException(\"Time horizon must be at least 1.\");\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Base/RiskModelBase.cs` around lines 297 - 315, After reading\nvalues in DeserializeModelSpecificData, validate invariants for _confidenceLevel\nand _timeHorizon (e.g. _confidenceLevel must be within (0,1] or your project's\ndefined range and _timeHorizon must be positive); if a value is out of range, do\nnot leave the instance in an inconsistent state‚Äîeither throw an\nInvalidDataException (or a project-appropriate exception) with a clear message\ncontaining the offending values, or reset to validated defaults and log the\nproblem. Update DeserializeModelSpecificData to perform these checks immediately\nafter reader.ReadDouble()/ReadInt32(), and ensure SerializeModelSpecificData and\nany callers expect and handle the potential exception or fallback behavior.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFL","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Base/RiskModelBase.cs","line":364,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Ensure training mode resets on failure.**  \nIf an exception is thrown during gradient/parameter updates, training mode stays enabled and can corrupt subsequent inference or training steps.  \n\n<details>\n<summary>üõ°Ô∏è Suggested fix</summary>\n\n```diff\n protected override void TrainCore(Tensor<T> input, Tensor<T> target, Tensor<T> output)\n {\n     SetTrainingMode(true);\n-    var grad = LossFunction.CalculateDerivative(output.ToVector(), target.ToVector());\n-    var gradTensor = Tensor<T>.FromVector(grad, output.Shape);\n-\n-    Backpropagate(gradTensor);\n-\n-    // Default SGD-style update for layers\n-    var learningRate = MathHelper.GetNumericOperations<T>().FromDouble(0.001);\n-    foreach (var layer in Layers)\n-    {\n-        layer.UpdateParameters(learningRate);\n-    }\n-    SetTrainingMode(false);\n+    try\n+    {\n+        var grad = LossFunction.CalculateDerivative(output.ToVector(), target.ToVector());\n+        var gradTensor = Tensor<T>.FromVector(grad, output.Shape);\n+\n+        Backpropagate(gradTensor);\n+\n+        // Default SGD-style update for layers\n+        var learningRate = MathHelper.GetNumericOperations<T>().FromDouble(0.001);\n+        foreach (var layer in Layers)\n+        {\n+            layer.UpdateParameters(learningRate);\n+        }\n+    }\n+    finally\n+    {\n+        SetTrainingMode(false);\n+    }\n }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    protected override void TrainCore(Tensor<T> input, Tensor<T> target, Tensor<T> output)\n    {\n        SetTrainingMode(true);\n        try\n        {\n            var grad = LossFunction.CalculateDerivative(output.ToVector(), target.ToVector());\n            var gradTensor = Tensor<T>.FromVector(grad, output.Shape);\n\n            Backpropagate(gradTensor);\n\n            // Default SGD-style update for layers\n            var learningRate = MathHelper.GetNumericOperations<T>().FromDouble(0.001);\n            foreach (var layer in Layers)\n            {\n                layer.UpdateParameters(learningRate);\n            }\n        }\n        finally\n        {\n            SetTrainingMode(false);\n        }\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Base/RiskModelBase.cs` around lines 330 - 345, TrainCore sets\ntraining mode then performs backprop and parameter updates but doesn't reset\ntraining mode if an exception occurs; wrap the body after SetTrainingMode(true)\nin a try/finally so SetTrainingMode(false) runs regardless of errors, keeping\nexisting calls such as Backpropagate(gradTensor), iterating Layers and calling\nlayer.UpdateParameters(learningRate) inside the try and rethrowing any exception\nif needed so behavior is unchanged aside from guaranteed reset.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFO","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Chronos.cs","line":1170,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Clamp `stepsUsed` to avoid negative indices.**\n\nIf `stepsUsed > _contextLength`, `targetIdx` becomes negative and can index out of bounds. Clamp `stepsUsed` to `_contextLength` (or guard `targetIdx >= 0`).  \n\n\n<details>\n<summary>üîß Suggested fix</summary>\n\n```diff\n protected override Tensor<T> ShiftInputWithPredictions(Tensor<T> input, Tensor<T> predictions, int stepsUsed)\n {\n     var newInput = new Tensor<T>(input.Shape);\n+    int steps = Math.Min(stepsUsed, _contextLength);\n\n     // Shift existing data\n-    for (int i = 0; i < _contextLength - stepsUsed; i++)\n+    for (int i = 0; i < _contextLength - steps; i++)\n     {\n-        if (i + stepsUsed < input.Length)\n-            newInput.Data.Span[i] = input.Data.Span[i + stepsUsed];\n+        if (i + steps < input.Length)\n+            newInput.Data.Span[i] = input.Data.Span[i + steps];\n     }\n\n     // Add predictions at the end\n-    for (int i = 0; i < stepsUsed && i < predictions.Length; i++)\n+    for (int i = 0; i < steps && i < predictions.Length; i++)\n     {\n-        int targetIdx = _contextLength - stepsUsed + i;\n-        if (targetIdx < _contextLength)\n+        int targetIdx = _contextLength - steps + i;\n+        if (targetIdx >= 0 && targetIdx < _contextLength)\n         {\n             newInput.Data.Span[targetIdx] = predictions[i];\n         }\n     }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Chronos.cs` around lines 1108 - 1126, The\nShiftInputWithPredictions method can produce negative targetIdx when stepsUsed >\n_contextLength; clamp or bound stepsUsed to avoid negative indices. Modify\nShiftInputWithPredictions to compute an effectiveSteps = Math.Min(stepsUsed,\n_contextLength) (or guard targetIdx >= 0) and use effectiveSteps in both the\nexisting-data shift loop and the predictions loop so targetIdx and source\nindices into newInput.Data.Span and input.Data.Span never go out of range;\nupdate references to stepsUsed in the method accordingly\n(ShiftInputWithPredictions, targetIdx, _contextLength, newInput).\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFQ","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/TimeGPT.cs","line":588,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Guard quantile generation in ONNX mode.**\n\nWhen `_useNativeMode == false` and conformal isn‚Äôt available, `GenerateQuantilePredictions` runs native `Forward` (often with empty layers) and can return invalid quantiles. Consider throwing or returning point forecasts in this path.  \n\n\n<details>\n<summary>üîß Suggested guard</summary>\n\n```diff\n if (quantiles is not null && quantiles.Length > 0)\n {\n     if (_useConformalPrediction && _calibrationResiduals is not null)\n     {\n         return GenerateConformalIntervals(output, quantiles);\n     }\n-    else\n-    {\n-        return GenerateQuantilePredictions(historicalData, quantiles);\n-    }\n+    if (!_useNativeMode)\n+        throw new InvalidOperationException(\"Quantile forecasts require native mode or conformal calibration.\");\n+\n+    return GenerateQuantilePredictions(historicalData, quantiles);\n }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/TimeGPT.cs` around lines 573 - 587, The\nForecast method currently calls GenerateQuantilePredictions even when\n_useNativeMode is false and conformal prediction isn't available, which can\ninvoke native Forward unexpectedly and produce invalid quantiles; modify\nForecast so that if quantiles is provided but _useNativeMode == false and\n(!_useConformalPrediction || _calibrationResiduals is null) it does not call\nGenerateQuantilePredictions‚Äîeither throw a clear InvalidOperationException or\nreturn point forecasts (the previously computed output) for the requested\nquantiles; adjust the branch around Forecast/ForecastOnnx,\n_useConformalPrediction, _calibrationResiduals, GenerateConformalIntervals and\nGenerateQuantilePredictions accordingly so ONNX mode never triggers native\nForward unexpectedly.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFS","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/TimeLLM.cs","line":458,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Reset training mode on exceptions.**\n\nIf `Forward`/loss/backward throws, `SetTrainingMode(false)` is skipped. Wrap the block in try/finally.  \n\n\n<details>\n<summary>üõ°Ô∏è Suggested fix</summary>\n\n```diff\n SetTrainingMode(true);\n-\n- var output = Forward(input);\n- // Compute loss\n- LastLoss = _lossFunction.CalculateLoss(output.ToVector(), target.ToVector());\n- // Backward pass\n- var gradient = _lossFunction.CalculateDerivative(output.ToVector(), target.ToVector());\n- Backward(Tensor<T>.FromVector(gradient, output.Shape));\n- _optimizer.UpdateParameters(Layers);\n-\n- SetTrainingMode(false);\n+try\n+{\n+    var output = Forward(input);\n+    // Compute loss\n+    LastLoss = _lossFunction.CalculateLoss(output.ToVector(), target.ToVector());\n+    // Backward pass\n+    var gradient = _lossFunction.CalculateDerivative(output.ToVector(), target.ToVector());\n+    Backward(Tensor<T>.FromVector(gradient, output.Shape));\n+    _optimizer.UpdateParameters(Layers);\n+}\n+finally\n+{\n+    SetTrainingMode(false);\n+}\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    public override void Train(Tensor<T> input, Tensor<T> target)\n    {\n        if (!_useNativeMode)\n            throw new InvalidOperationException(\"Training is only supported in native mode.\");\n\n        SetTrainingMode(true);\n        try\n        {\n            var output = Forward(input);\n\n            // Compute loss\n            LastLoss = _lossFunction.CalculateLoss(output.ToVector(), target.ToVector());\n\n            // Backward pass\n            var gradient = _lossFunction.CalculateDerivative(output.ToVector(), target.ToVector());\n            Backward(Tensor<T>.FromVector(gradient, output.Shape));\n\n            _optimizer.UpdateParameters(Layers);\n        }\n        finally\n        {\n            SetTrainingMode(false);\n        }\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/TimeLLM.cs` around lines 435 - 454, The\nTrain method currently sets training mode with SetTrainingMode(true) but can\nskip resetting it if Forward/ loss/ Backward or _optimizer.UpdateParameters\nthrows; wrap the core work (output = Forward(...), LastLoss = ..., gradient\ncalc, Backward(...), _optimizer.UpdateParameters(Layers)) in a try/finally and\nmove SetTrainingMode(false) into the finally block so SetTrainingMode(false)\nalways runs while preserving the current behavior and exception propagation in\nTrain.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFT","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/TimeLLM.cs","line":863,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Guard empty quantile samples and reset training mode.**\n\nIf no sample provides a value for a step, `values.Count` is 0 and `values[idx]` throws. Also, `SetTrainingMode(false)` should run even if `Forward` fails.  \n\n\n<details>\n<summary>üõ°Ô∏è Suggested fix</summary>\n\n```diff\n // Enable dropout for MC sampling\n SetTrainingMode(true);\n-\n-for (int s = 0; s < numSamples; s++)\n-{\n-    samples.Add(Forward(input));\n-}\n-\n-SetTrainingMode(false);\n+try\n+{\n+    for (int s = 0; s < numSamples; s++)\n+    {\n+        samples.Add(Forward(input));\n+    }\n+}\n+finally\n+{\n+    SetTrainingMode(false);\n+}\n@@\n-    values.Sort();\n+    if (values.Count == 0)\n+        continue;\n+\n+    values.Sort();\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    private Tensor<T> GenerateQuantilePredictions(Tensor<T> input, double[] quantiles)\n    {\n        if (!_useNativeMode)\n        {\n            return ForecastOnnx(input);\n        }\n\n        int numSamples = 100;\n        var samples = new List<Tensor<T>>();\n\n        // Enable dropout for MC sampling\n        SetTrainingMode(true);\n        try\n        {\n            for (int s = 0; s < numSamples; s++)\n            {\n                samples.Add(Forward(input));\n            }\n        }\n        finally\n        {\n            SetTrainingMode(false);\n        }\n\n        // Compute quantiles\n        var result = new Tensor<T>(new[] { 1, _forecastHorizon, quantiles.Length });\n\n        for (int t = 0; t < _forecastHorizon; t++)\n        {\n            var values = new List<double>();\n            foreach (var sample in samples)\n            {\n                if (t < sample.Length)\n                {\n                    values.Add(NumOps.ToDouble(sample.Data.Span[t]));\n                }\n            }\n\n            if (values.Count == 0)\n                continue;\n\n            values.Sort();\n\n            for (int q = 0; q < quantiles.Length; q++)\n            {\n                int idx = Math.Min((int)(quantiles[q] * values.Count), values.Count - 1);\n                result.Data.Span[t * quantiles.Length + q] = NumOps.FromDouble(values[idx]);\n            }\n        }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/TimeLLM.cs` around lines 804 - 845, Wrap\nthe MC sampling loop in a try/finally so SetTrainingMode(false) always runs (use\nSetTrainingMode(true) before sampling and SetTrainingMode(false) in finally),\nand when computing per-step quantiles in GenerateQuantilePredictions guard\nagainst empty samples by checking values.Count==0; if empty, assign a sensible\ndefault (e.g. NumOps.FromDouble(double.NaN) or 0.0) into result.Data.Span[t *\nquantiles.Length + q], otherwise compute idx and assign values[idx] as before.\nEnsure references to Forward, samples, result, and SetTrainingMode are updated\naccordingly.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFY","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Timer.cs","line":618,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Quantile forecasts bypass ONNX inference in ONNX mode.**  \nWhen `_useNativeMode` is false, `Forecast` still calls `GenerateQuantilePredictions`, which uses `Forward` (native path) and ignores `ForecastOnnx`. If layers are empty or differ from the ONNX graph, results are wrong or inconsistent. Consider disallowing quantiles in ONNX mode or implementing ONNX-based sampling.\n\n\n\n<details>\n<summary>üîß Proposed guard (native-only quantiles)</summary>\n\n```diff\n public override Tensor<T> Forecast(Tensor<T> historicalData, double[]? quantiles = null)\n {\n     var output = _useNativeMode ? Forward(historicalData) : ForecastOnnx(historicalData);\n\n     // For quantile forecasts, we generate samples through temperature scaling\n     if (quantiles is not null && quantiles.Length > 0)\n     {\n+        if (!_useNativeMode)\n+            throw new NotSupportedException(\"Quantile forecasts are only supported in native mode.\");\n         return GenerateQuantilePredictions(historicalData, quantiles);\n     }\n\n     return output;\n }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Timer.cs` around lines 595 - 603, Forecast\ncurrently ignores ONNX inference for quantiles because\nGenerateQuantilePredictions calls the native Forward path; to fix, add a guard\nin Forecast that checks _useNativeMode before calling\nGenerateQuantilePredictions and throw a clear NotSupportedException (or\nArgumentException) when quantile sampling is requested while _useNativeMode is\nfalse, referencing Forecast, _useNativeMode, GenerateQuantilePredictions,\nForward and ForecastOnnx; alternatively, implement ONNX-based sampling in\nGenerateQuantilePredictions if ONNX support is required‚Äîupdate the exception\nmessage and unit tests to reflect the native-only quantile limitation or the new\nONNX sampling behavior.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFb","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Timer.cs","line":635,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Autoregressive decoding path ignores ONNX mode.**  \nIf `_useAutoregressiveDecoding` is true in ONNX mode, `AutoregressiveForecast` calls `AutoregressiveGenerate`, which uses `Forward` and bypasses `ForecastOnnx`. This can silently return incorrect results. Gate this path to native mode or force the multi-step ONNX fallback.\n\n\n\n<details>\n<summary>üîß Proposed guard (native-only autoregressive decoding)</summary>\n\n```diff\n public override Tensor<T> AutoregressiveForecast(Tensor<T> input, int steps)\n {\n-    if (_useAutoregressiveDecoding)\n+    if (_useAutoregressiveDecoding && _useNativeMode)\n     {\n         return AutoregressiveGenerate(input, steps);\n     }\n\n     // Fall back to standard multi-step forecasting\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Timer.cs` around lines 614 - 619, The\nAutoregressiveForecast method currently calls AutoregressiveGenerate when\n_useAutoregressiveDecoding is true, which in ONNX mode causes\nAutoregressiveGenerate to call Forward and bypass ForecastOnnx; modify\nAutoregressiveForecast to detect ONNX mode and prevent using\nAutoregressiveGenerate there‚Äîeither (a) only allow the AutoregressiveGenerate\npath when running in native mode (i.e., guard the _useAutoregressiveDecoding\nbranch with a native-mode check) or (b) when ONNX mode is active, skip\nAutoregressiveGenerate and invoke the multi-step ONNX fallback (ForecastOnnx)\ninstead; update the branching around AutoregressiveForecast, referencing\n_useAutoregressiveDecoding, AutoregressiveGenerate, Forward, and ForecastOnnx to\nensure ONNX never hits Forward.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFe","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepAR.cs","line":null,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**`_scaleMean` is allocated but never used.**\n\nThe tensor is created and sized but no values are ever written to it, and it's never read. This wastes memory.\n\n\n\n<details>\n<summary>üßπ Remove unused allocation</summary>\n\n```diff\n-        _scaleMean = new Tensor<T>(new[] { batchSize, 1, features });\n         _scaleStd = new Tensor<T>(new[] { batchSize, 1, features });\n```\n\nAlso remove the `_scaleMean` field declaration at line 105 if it's not needed elsewhere.\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n        _scaleStd = new Tensor<T>(new[] { batchSize, 1, features });\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepAR.cs` around lines 885 - 886, _scaleMean\nis allocated in the DeepAR constructor but never used; remove the dead\nallocation and its field: delete the new Tensor<T> creation for _scaleMean (the\nline \"_scaleMean = new Tensor<T>(new[] { batchSize, 1, features });\") and also\nremove the _scaleMean field declaration (previously at line ~105) after\nverifying there are no other references to _scaleMean in the class (search for\n\"_scaleMean\"). Leave _scaleStd allocation and usage intact.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFi","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepAR.cs","line":null,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Sigma estimation ignores the learned `_sigmaProjection` output.**\n\nDeepAR's key feature is learning uncertainty from data via the sigma head, but `SampleQuantiles` hardcodes sigma as 10% of mu. The `Forward` method computes sigma via `_sigmaProjection` but discards it. This undermines the probabilistic forecasting capability.\n\nConsider modifying `Forward` to return both mu and sigma (or storing sigma as a field), then using the learned sigma here instead of the crude approximation.\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepAR.cs` around lines 997 - 999, The\nSampleQuantiles implementation is ignoring the learned sigma head and instead\nhardcodes sigma; update the model so the learned sigma from the Forward pass\n(produced by _sigmaProjection / sigma output) is returned or stored (e.g.,\nextend Forward to return (mu, sigma) or set a field like _lastSigma) and then\nreplace the hardcoded sigma computation in SampleQuantiles with that learned\nsigma tensor, preserving shape and applying a small floor/epsilon (e.g.,\nmax(sigma, 1e-3)) to avoid zeros; ensure any necessary normalization/activation\nused in Forward (e.g., softplus on _sigmaProjection output) is consistent so\nSampleQuantiles uses the same processed sigma.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFl","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepFactor.cs","line":1058,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**ConcatenatePredictions drops features for multivariate outputs.**  \n`result` is sized to `totalSteps`, but `pred` likely contains `totalSteps * _numFeatures` values. This truncates outputs when `_numFeatures > 1`.  \n\n<details>\n<summary>üõ†Ô∏è Suggested fix</summary>\n\n```diff\n protected override Tensor<T> ConcatenatePredictions(List<Tensor<T>> predictions, int totalSteps)\n {\n-    var result = new Tensor<T>(new[] { totalSteps });\n+    int totalElements = totalSteps * _numFeatures;\n+    var result = new Tensor<T>(new[] { totalElements });\n\n     int resultIdx = 0;\n     int stepsAdded = 0;\n\n     foreach (var pred in predictions)\n     {\n         int stepsToAdd = Math.Min(_forecastHorizon, totalSteps - stepsAdded);\n\n-        for (int i = 0; i < stepsToAdd && resultIdx < totalSteps; i++)\n-        {\n-            if (i < pred.Length)\n-                result.Data.Span[resultIdx++] = pred[i];\n-        }\n+        int elementsToAdd = stepsToAdd * _numFeatures;\n+        int maxElements = Math.Min(elementsToAdd, pred.Length);\n+        for (int i = 0; i < maxElements && resultIdx < totalElements; i++)\n+        {\n+            result.Data.Span[resultIdx++] = pred.Data.Span[i];\n+        }\n\n         stepsAdded += stepsToAdd;\n         if (stepsAdded >= totalSteps)\n             break;\n     }\n\n     return result;\n }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    protected override Tensor<T> ConcatenatePredictions(List<Tensor<T>> predictions, int totalSteps)\n    {\n        int totalElements = totalSteps * _numFeatures;\n        var result = new Tensor<T>(new[] { totalElements });\n\n        int resultIdx = 0;\n        int stepsAdded = 0;\n\n        foreach (var pred in predictions)\n        {\n            int stepsToAdd = Math.Min(_forecastHorizon, totalSteps - stepsAdded);\n\n            int elementsToAdd = stepsToAdd * _numFeatures;\n            int maxElements = Math.Min(elementsToAdd, pred.Length);\n            for (int i = 0; i < maxElements && resultIdx < totalElements; i++)\n            {\n                result.Data.Span[resultIdx++] = pred.Data.Span[i];\n            }\n\n            stepsAdded += stepsToAdd;\n            if (stepsAdded >= totalSteps)\n                break;\n        }\n\n        return result;\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepFactor.cs` around lines 1024 - 1046,\nConcatenatePredictions currently allocates result as new Tensor<T>(new[] {\ntotalSteps }) which drops features for multivariate outputs; change the sizing\nand indexing so result holds totalSteps * _numFeatures values and copy all\nfeature values from each pred chunk. Specifically, in ConcatenatePredictions\nupdate the Tensor<T> allocation to use totalSteps * _numFeatures (or a 2D shape\n[totalSteps, _numFeatures] if your Tensor supports it), compute stepsToAdd as\nbefore but copy stepsToAdd * _numFeatures elements from each pred (iterate over\ntime steps and inner-loop over feature index) and advance resultIdx accordingly;\nuse _forecastHorizon, _numFeatures, ConcatenatePredictions and pred.Length to\nguard bounds when pred may be shorter.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFq","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/NBEATSFinance.cs","line":574,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Deserialization leaves model in inconsistent state.**\n\nTwo issues:\n\n1. `_useNativeMode` is not serialized/deserialized, so a loaded model may have incorrect mode.\n2. After deserializing, `_blocks` and `_outputProjection` remain empty because `ExtractLayerReferences()` isn't called.\n\n\n<details>\n<summary>üîß Proposed fix</summary>\n\n```diff\n protected override void SerializeNetworkSpecificData(BinaryWriter writer)\n {\n+    writer.Write(_useNativeMode);\n     writer.Write(_lookbackWindow);\n     writer.Write(_forecastHorizon);\n     // ... rest unchanged\n }\n\n protected override void DeserializeNetworkSpecificData(BinaryReader reader)\n {\n+    _useNativeMode = reader.ReadBoolean();\n     _lookbackWindow = reader.ReadInt32();\n     _forecastHorizon = reader.ReadInt32();\n     _numStacks = reader.ReadInt32();\n     _numBlocksPerStack = reader.ReadInt32();\n     _hiddenSize = reader.ReadInt32();\n     _numHiddenLayers = reader.ReadInt32();\n     _polynomialDegree = reader.ReadInt32();\n     _useInterpretableBasis = reader.ReadBoolean();\n     _shareWeightsInStack = reader.ReadBoolean();\n+\n+    // Restore layer references after base class restores Layers collection\n+    ExtractLayerReferences();\n }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/NBEATSFinance.cs` around lines 528 - 561, The\nSerializeNetworkSpecificData/DeserializeNetworkSpecificData pair currently omits\n_useNativeMode and does not rebuild runtime references, leaving _blocks and\n_outputProjection empty after load; update SerializeNetworkSpecificData to write\nthe boolean _useNativeMode, update DeserializeNetworkSpecificData to read it\nback into _useNativeMode in the same order, and at the end of\nDeserializeNetworkSpecificData call ExtractLayerReferences() so _blocks and\n_outputProjection are repopulated for the deserialized model.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzFs","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/NBEATSFinance.cs","line":974,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Silent data corruption when tensor shapes don't match.**\n\nBoth `SubtractTensors` and `AddTensors` iterate only up to `Math.Min(a.Length, b.Length)`, leaving remaining elements in `result` as default(T) (zero). If `backcast` or `forecast` shapes don't match `residual` or `totalForecast`, computations will silently produce incorrect results.\n\nConsider either throwing on shape mismatch or logging a warning during development.\n\n\n<details>\n<summary>üîß Proposed fix with shape validation</summary>\n\n```diff\n private Tensor<T> SubtractTensors(Tensor<T> a, Tensor<T> b)\n {\n+    if (a.Length != b.Length)\n+    {\n+        throw new ArgumentException(\n+            $\"Tensor shape mismatch in SubtractTensors: a.Length={a.Length}, b.Length={b.Length}\");\n+    }\n     var result = new Tensor<T>(a.Shape);\n-    int length = Math.Min(a.Length, b.Length);\n-    for (int i = 0; i < length; i++)\n+    for (int i = 0; i < a.Length; i++)\n     {\n         result.Data.Span[i] = NumOps.Subtract(a.Data.Span[i], b.Data.Span[i]);\n     }\n     return result;\n }\n\n private Tensor<T> AddTensors(Tensor<T> a, Tensor<T> b)\n {\n+    if (a.Length != b.Length)\n+    {\n+        throw new ArgumentException(\n+            $\"Tensor shape mismatch in AddTensors: a.Length={a.Length}, b.Length={b.Length}\");\n+    }\n     var result = new Tensor<T>(a.Shape);\n-    int length = Math.Min(a.Length, b.Length);\n-    for (int i = 0; i < length; i++)\n+    for (int i = 0; i < a.Length; i++)\n     {\n         result.Data.Span[i] = NumOps.Add(a.Data.Span[i], b.Data.Span[i]);\n     }\n     return result;\n }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    private Tensor<T> SubtractTensors(Tensor<T> a, Tensor<T> b)\n    {\n        if (a.Length != b.Length)\n        {\n            throw new ArgumentException(\n                $\"Tensor shape mismatch in SubtractTensors: a.Length={a.Length}, b.Length={b.Length}\");\n        }\n        var result = new Tensor<T>(a.Shape);\n        for (int i = 0; i < a.Length; i++)\n        {\n            result.Data.Span[i] = NumOps.Subtract(a.Data.Span[i], b.Data.Span[i]);\n        }\n        return result;\n    }\n\n    /// <summary>\n    /// Adds two tensors element-wise.\n    /// </summary>\n    /// <param name=\"a\">First tensor.</param>\n    /// <param name=\"b\">Second tensor.</param>\n    /// <returns>Result tensor.</returns>\n    /// <remarks>\n    /// <para>\n    /// <b>For Beginners:</b> This computes a + b for each element.\n    /// Used to accumulate forecasts from all blocks.\n    /// </para>\n    /// </remarks>\n    private Tensor<T> AddTensors(Tensor<T> a, Tensor<T> b)\n    {\n        if (a.Length != b.Length)\n        {\n            throw new ArgumentException(\n                $\"Tensor shape mismatch in AddTensors: a.Length={a.Length}, b.Length={b.Length}\");\n        }\n        var result = new Tensor<T>(a.Shape);\n        for (int i = 0; i < a.Length; i++)\n        {\n            result.Data.Span[i] = NumOps.Add(a.Data.Span[i], b.Data.Span[i]);\n        }\n        return result;\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/NBEATSFinance.cs` around lines 915 - 947, The\nAddTensors and SubtractTensors functions currently process only up to\nMath.Min(a.Length, b.Length), causing silent corruption when tensor shapes\ndiffer; update both methods (AddTensors and SubtractTensors) to validate that\na.Shape and b.Shape (or a.Length and b.Length) are equal at the start and throw\na descriptive exception (e.g., ArgumentException) if they differ, so mismatched\nbackcast/forecast/residual shapes fail fast rather than leaving result elements\nas default(T).\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85rzzF0","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/NBEATSFinance.cs","line":null,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Hardcoded batch size when predictions list is empty.**\n\nReturning `new Tensor<T>(new[] { 1, totalSteps })` uses a hardcoded batch size of 1, which may not match the caller's expected batch dimension. Consider accepting a batch size parameter or throwing an exception since an empty predictions list likely indicates a logic error upstream.\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/NBEATSFinance.cs` around lines 1006 - 1007,\nThe code returns a Tensor with a hardcoded batch size of 1 when\npredictions.Count == 0; update the method that contains predictions and\ntotalSteps (the NBEATSFinance prediction/aggregation method) to either (a)\naccept an explicit batchSize parameter and use new Tensor<T>(new[] { batchSize,\ntotalSteps }) when predictions is empty, or (b) throw a clear\nArgumentException/InvalidOperationException indicating empty predictions so\ncallers must not pass an empty list; replace the hardcoded new Tensor<T>(new[] {\n1, totalSteps }) accordingly and ensure callers are updated to provide batchSize\nif you choose option (a).\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85r2gMI","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Base/FinancialNLPModelBase.cs","line":260,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Guard against empty tokenization before creating a tensor.**  \nIf `Tokenize` returns an empty array (e.g., unconfigured MaxSequenceLength or empty input), you‚Äôll build a `[1, 0]` tensor and can hit runtime errors downstream. Consider short‚Äëcircuiting to an ‚Äúunknown‚Äù result early.\n\n\n<details>\n<summary>üõ†Ô∏è Proposed fix</summary>\n\n```diff\n         for (int i = 0; i < texts.Length; i++)\n         {\n             var tokenIds = Tokenize(texts[i]);\n+            if (tokenIds.Length == 0)\n+            {\n+                results[i] = new SentimentResult<T>\n+                {\n+                    OriginalText = texts[i],\n+                    PredictedClass = \"unknown\",\n+                    Confidence = NumOps.Zero,\n+                    ClassProbabilities = new Dictionary<string, T>()\n+                };\n+                continue;\n+            }\n             // Create a 2D tensor [1, sequence_length] since NLP models expect batch dimension\n             var tokenVector = new Vector<T>(tokenIds.Select(id => NumOps.FromDouble(id)).ToArray());\n             var inputTensor = new Tensor<T>(new[] { 1, tokenIds.Length }, tokenVector);\n             var prediction = AnalyzeSentiment(inputTensor);\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    public virtual SentimentResult<T>[] AnalyzeSentiment(string[] texts)\n    {\n        var results = new SentimentResult<T>[texts.Length];\n        for (int i = 0; i < texts.Length; i++)\n        {\n            var tokenIds = Tokenize(texts[i]);\n            if (tokenIds.Length == 0)\n            {\n                results[i] = new SentimentResult<T>\n                {\n                    OriginalText = texts[i],\n                    PredictedClass = \"unknown\",\n                    Confidence = NumOps.Zero,\n                    ClassProbabilities = new Dictionary<string, T>()\n                };\n                continue;\n            }\n            // Create a 2D tensor [1, sequence_length] since NLP models expect batch dimension\n            var tokenVector = new Vector<T>(tokenIds.Select(id => NumOps.FromDouble(id)).ToArray());\n            var inputTensor = new Tensor<T>(new[] { 1, tokenIds.Length }, tokenVector);\n            var prediction = AnalyzeSentiment(inputTensor);\n\n            if (prediction.Length == 0)\n            {\n                results[i] = new SentimentResult<T>\n                {\n                    OriginalText = texts[i],\n                    PredictedClass = \"unknown\",\n                    Confidence = NumOps.Zero,\n                    ClassProbabilities = new Dictionary<string, T>()\n                };\n                continue;\n            }\n\n            int classCount = Math.Max(1, NumSentimentClasses);\n            int count = Math.Min(classCount, prediction.Length);\n            int bestIdx = 0;\n            T bestVal = prediction.Data.Span[0];\n            var probabilities = new Dictionary<string, T>();\n\n            for (int c = 0; c < count; c++)\n            {\n                var value = prediction.Data.Span[c];\n                if (NumOps.GreaterThan(value, bestVal))\n                {\n                    bestVal = value;\n                    bestIdx = c;\n                }\n\n                probabilities[GetSentimentLabel(c, classCount)] = value;\n            }\n\n            results[i] = new SentimentResult<T>\n            {\n                OriginalText = texts[i],\n                PredictedClass = GetSentimentLabel(bestIdx, classCount),\n                Confidence = bestVal,\n                ClassProbabilities = probabilities\n            };\n        }\n\n        return results;\n    }\n\n    private static string GetSentimentLabel(int index, int classCount)\n    {\n        if (classCount == 3)\n        {\n            return index switch\n            {\n                0 => \"negative\",\n                1 => \"neutral\",\n                2 => \"positive\",\n                _ => $\"class_{index}\"\n            };\n        }\n\n        return $\"class_{index}\";\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Base/FinancialNLPModelBase.cs` around lines 157 - 224, The\nAnalyzeSentiment method must guard against Tokenize returning an empty tokenIds\narray before constructing the input tensor; if tokenIds.Length == 0,\nshort‚Äëcircuit and populate results[i] with an \"unknown\" SentimentResult\n(OriginalText = texts[i], PredictedClass = \"unknown\", Confidence = NumOps.Zero,\nempty ClassProbabilities) instead of creating a [1,0] Tensor and calling\nAnalyzeSentiment(Tensor<T>); update the loop in AnalyzeSentiment to check\ntokenIds length right after calling Tokenize and reuse the same result\nshape/fields as the existing prediction.Length == 0 branch, referencing\nTokenize, AnalyzeSentiment(string[])/AnalyzeSentiment(Tensor<T>),\nSentimentResult<T>, GetSentimentLabel and NumSentimentClasses.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commits d89ea34 to d4345dc"}]}},{"id":"PRRT_kwDOKSXUF85r2gMZ","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Base/FinancialNLPModelBase.cs","line":313,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Include NumSentimentClasses in metrics for completeness.**  \nThis is part of the public config surface and should be reported alongside the other NLP settings.\n\n\n<details>\n<summary>üõ†Ô∏è Proposed fix</summary>\n\n```diff\n         var metrics = base.GetFinancialMetrics();\n         metrics[\"MaxSequenceLength\"] = NumOps.FromDouble(MaxSequenceLength);\n         metrics[\"VocabularySize\"] = NumOps.FromDouble(VocabularySize);\n         metrics[\"HiddenDimension\"] = NumOps.FromDouble(HiddenDimension);\n+        metrics[\"NumSentimentClasses\"] = NumOps.FromDouble(NumSentimentClasses);\n         \n         return metrics;\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    public override Dictionary<string, T> GetFinancialMetrics()\n    {\n        var metrics = base.GetFinancialMetrics();\n        metrics[\"MaxSequenceLength\"] = NumOps.FromDouble(MaxSequenceLength);\n        metrics[\"VocabularySize\"] = NumOps.FromDouble(VocabularySize);\n        metrics[\"HiddenDimension\"] = NumOps.FromDouble(HiddenDimension);\n        metrics[\"NumSentimentClasses\"] = NumOps.FromDouble(NumSentimentClasses);\n        \n        return metrics;\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Base/FinancialNLPModelBase.cs` around lines 269 - 276, The\nGetFinancialMetrics override in FinancialNLPModelBase is missing\nNumSentimentClasses in the returned metrics; update the method\n(GetFinancialMetrics) to add metrics[\"NumSentimentClasses\"] =\nNumOps.FromDouble(NumSentimentClasses) alongside MaxSequenceLength,\nVocabularySize, and HiddenDimension so the public config surface includes\nsentiment class count.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commits d89ea34 to d4345dc"}]}},{"id":"PRRT_kwDOKSXUF85r2gMk","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/LagLlama.cs","line":329,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Custom layers are ignored in forward/backward paths.**\n\nWhen `Architecture.Layers` is provided, references like `_inputEmbedding` and `_transformerLayers` never get set, so `Forward`/`Backward` skip the custom stack. This effectively bypasses the model logic for custom layers.  \n\n\n<details>\n<summary>üí° Suggested fix</summary>\n\n```diff\nif (Architecture.Layers is not null && Architecture.Layers.Count > 0)\n{\n    Layers.AddRange(Architecture.Layers);\n    ValidateCustomLayers(Layers);\n+   ExtractLayerReferences();\n}\nelse if (_useNativeMode)\n{\n    Layers.AddRange(LayerHelper<T>.CreateDefaultLagLlamaLayers(\n        Architecture, _contextLength, _forecastHorizon, 1,\n        _lagIndices.Length, _hiddenDimension, _numLayers, _numHeads,\n        _intermediateSize, _dropout));\n\n    ExtractLayerReferences();\n}\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n        if (Architecture.Layers is not null && Architecture.Layers.Count > 0)\n        {\n            Layers.AddRange(Architecture.Layers);\n            ValidateCustomLayers(Layers);\n            ExtractLayerReferences();\n        }\n        else if (_useNativeMode)\n        {\n            Layers.AddRange(LayerHelper<T>.CreateDefaultLagLlamaLayers(\n                Architecture, _contextLength, _forecastHorizon, 1,\n                _lagIndices.Length, _hiddenDimension, _numLayers, _numHeads,\n                _intermediateSize, _dropout));\n\n            ExtractLayerReferences();\n        }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/LagLlama.cs` around lines 314 - 327, When\ncustom Architecture.Layers is provided the code adds them to Layers but never\npopulates internal references like _inputEmbedding and _transformerLayers, so\nForward/Backward skip the custom stack; after adding and validating custom\nlayers (Layers.AddRange(...) and ValidateCustomLayers(Layers)) call\nExtractLayerReferences() so the internal pointers are initialized for the custom\nstack (i.e., ensure ExtractLayerReferences() runs for the branch that handles\nArchitecture.Layers as well as the native branch), and keep\nValidateCustomLayers(Layers) in place to preserve validation.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commits d89ea34 to d4345dc"}]}},{"id":"PRRT_kwDOKSXUF85r2gMu","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/LagLlama.cs","line":419,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Validate `DistributionOutput` to avoid invalid param strides.**\n\n`ExtractPointPredictions` assumes 3 params per step (mu/sigma/nu), but options allow any string. Without validation, a non-StudentT configuration will produce incorrect outputs.  \n\n\n<details>\n<summary>‚úÖ Suggested guard</summary>\n\n```diff\nif (options.DropoutRate < 0 || options.DropoutRate >= 1)\n    errors.Add(\"DropoutRate must be between 0 and 1 (exclusive).\");\n+if (!string.Equals(options.DistributionOutput, \"StudentT\", StringComparison.OrdinalIgnoreCase))\n+    errors.Add(\"DistributionOutput must be 'StudentT' for LagLlama.\");\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    private static void ValidateOptions(LagLlamaOptions<T> options)\n    {\n        var errors = new List<string>();\n\n        if (options.ContextLength < 1)\n            errors.Add(\"ContextLength must be at least 1.\");\n        if (options.ForecastHorizon < 1)\n            errors.Add(\"ForecastHorizon must be at least 1.\");\n        if (options.HiddenDimension < 1)\n            errors.Add(\"HiddenDimension must be at least 1.\");\n        if (options.NumLayers < 1)\n            errors.Add(\"NumLayers must be at least 1.\");\n        if (options.NumHeads < 1)\n            errors.Add(\"NumHeads must be at least 1.\");\n        if (options.HiddenDimension % options.NumHeads != 0)\n            errors.Add(\"HiddenDimension must be divisible by NumHeads.\");\n        if (options.IntermediateSize < 1)\n            errors.Add(\"IntermediateSize must be at least 1.\");\n        if (options.LagIndices == null || options.LagIndices.Length == 0)\n            errors.Add(\"LagIndices must contain at least one lag.\");\n        if (options.DropoutRate < 0 || options.DropoutRate >= 1)\n            errors.Add(\"DropoutRate must be between 0 and 1 (exclusive).\");\n        if (!string.Equals(options.DistributionOutput, \"StudentT\", StringComparison.OrdinalIgnoreCase))\n            errors.Add(\"DistributionOutput must be 'StudentT' for LagLlama.\");\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/LagLlama.cs` around lines 396 - 417, The\nValidateOptions method must guard against unsupported distribution shapes:\nupdate ValidateOptions(LagLlamaOptions<T> options) to verify that\noptions.DistributionOutput (or whatever property encodes the output\ndistribution) is the StudentT/3-parameter distribution expected by\nExtractPointPredictions (which assumes mu/sigma/nu per time-step) or otherwise\nensure the configured output size matches 3 * (ContextLength or ForecastHorizon\nas applicable); if the distribution is not StudentT (or the param stride is not\n3) add a clear error like \"DistributionOutput must be StudentT (3 params) or\nOutputDim must equal 3 * steps.\" This uses the ValidateOptions and\nLagLlamaOptions<T> symbols and references ExtractPointPredictions to locate the\nrelated assumption.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commits d89ea34 to d4345dc"}]}},{"id":"PRRT_kwDOKSXUF85r2gM1","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/LagLlama.cs","line":null,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Backward pass gradient shape doesn‚Äôt match distribution output.**\n\n`Forward` produces distribution parameters, but training computes loss on extracted point predictions and backprops a gradient shaped like `[_forecastHorizon]`. This will mismatch the distribution head output shape (likely `3 * horizon`) and either fail or silently skip sigma/nu.  \n\n\n<details>\n<summary>üß≠ Minimal fix: map gradients to mu positions</summary>\n\n```diff\nvar predictions = Forward(input);\n\n// Extract point predictions from distribution parameters (use mean)\nvar pointPredictions = ExtractPointPredictions(predictions);\nvar predVector = pointPredictions.ToVector();\n...\nvar gradient = _lossFunction.CalculateDerivative(predVector, alignedTarget);\n-Backward(Tensor<T>.FromVector(gradient, pointPredictions.Shape));\n+var gradParams = new Tensor<T>(predictions.Shape);\n+gradParams.Fill(NumOps.Zero);\n+for (int i = 0; i < _forecastHorizon; i++)\n+{\n+    int idx = i * 3; // mu position\n+    if (idx < gradParams.Length)\n+        gradParams.Data.Span[idx] = gradient[i];\n+}\n+Backward(gradParams);\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n        var predictions = Forward(input);\n\n        // Extract point predictions from distribution parameters (use mean)\n        var pointPredictions = ExtractPointPredictions(predictions);\n        var predVector = pointPredictions.ToVector();\n\n        // Align target to match point predictions length\n        // Target may be raw distribution params or point values of different size\n        var targetVector = target.ToVector();\n        Vector<T> alignedTarget;\n        if (targetVector.Length == predVector.Length)\n        {\n            alignedTarget = targetVector;\n        }\n        else if (targetVector.Length >= predVector.Length)\n        {\n            // Take first N elements if target is larger\n            alignedTarget = new Vector<T>(predVector.Length);\n            for (int i = 0; i < predVector.Length; i++)\n            {\n                alignedTarget[i] = targetVector[i];\n            }\n        }\n        else\n        {\n            // Pad with last value if target is smaller\n            alignedTarget = new Vector<T>(predVector.Length);\n            for (int i = 0; i < targetVector.Length; i++)\n            {\n                alignedTarget[i] = targetVector[i];\n            }\n            T lastVal = targetVector.Length > 0 ? targetVector[targetVector.Length - 1] : NumOps.Zero;\n            for (int i = targetVector.Length; i < predVector.Length; i++)\n            {\n                alignedTarget[i] = lastVal;\n            }\n        }\n\n        LastLoss = _lossFunction.CalculateLoss(predVector, alignedTarget);\n\n        var gradient = _lossFunction.CalculateDerivative(predVector, alignedTarget);\n        var gradParams = new Tensor<T>(predictions.Shape);\n        gradParams.Fill(NumOps.Zero);\n        for (int i = 0; i < _forecastHorizon; i++)\n        {\n            int idx = i * 3; // mu position\n            if (idx < gradParams.Length)\n                gradParams.Data.Span[idx] = gradient[i];\n        }\n        Backward(gradParams);\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/LagLlama.cs` around lines 456 - 498, The\nbackward pass is computing gradients w.r.t. point predictions but calling\nBackward with a gradient shaped for the distribution output; adjust by mapping\nthe low-dim gradient returned from _lossFunction.CalculateDerivative (computed\nagainst pointPredictions from ExtractPointPredictions) into a full-size\ndistribution-parameter gradient vector that matches Forward's output shape\nbefore calling Backward. Specifically, build a Vector<T> or array of the same\nlength as the original predictions (the output of Forward), fill zeros for\nnon-mu parameters, and insert the per-horizon gradient values into the mu\npositions (e.g., every Nth index matching how distribution params are laid out),\nthen call Tensor<T>.FromVector(...) with that full-sized gradient so Backward\nreceives gradients aligned to the distribution head; update LastLoss usage\nunchanged.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commits d89ea34 to d4345dc"}]}},{"id":"PRRT_kwDOKSXUF85r2gM7","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/LagLlama.cs","line":633,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**CreateNewInstance drops ONNX mode.**\n\nWhen the current instance is ONNX-backed, cloning via `CreateNewInstance()` returns a native model without weights, which changes behavior.  \n\n\n<details>\n<summary>‚úÖ Suggested fix</summary>\n\n```diff\nreturn new LagLlama<T>(Architecture, options);\n+// Preserve ONNX mode when applicable\n+return _useNativeMode\n+    ? new LagLlama<T>(Architecture, options)\n+    : new LagLlama<T>(Architecture, OnnxModelPath!, options);\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/LagLlama.cs` around lines 552 - 569,\nCreateNewInstance currently builds a new native LagLlama<T> from LagLlamaOptions\nand thus drops ONNX-backed mode and weights; modify CreateNewInstance to detect\nwhen the current instance is ONNX-backed (e.g., a flag or existing ONNX model\nreference on this instance) and, in that case, construct a new ONNX-backed\ninstance (or clone the ONNX model) instead of the native constructor, preserving\nthe Architecture, options (including cloned LagIndices) and copying or reusing\nthe underlying ONNX weights/engine so behavior remains identical to the original\nONNX-backed model; update the logic around CreateNewInstance, LagLlamaOptions,\nand the LagLlama<T> construction paths accordingly.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85r2gM-","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/LagLlama.cs","line":1035,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Point prediction extraction ignores batch dimension.**\n\n`ExtractPointPredictions` always returns shape `[_forecastHorizon]`. If inputs are batched, downstream methods (e.g., `ShiftInputWithPredictions`) expect batched predictions and will misindex.  \n\n\n<details>\n<summary>üß© Suggested approach</summary>\n\n```diff\n-// Output format: [mu, sigma, nu] repeated for each forecast step\n-// Extract just the mu values (every 3rd value starting at index 0)\n-var result = new Tensor<T>(new[] { _forecastHorizon });\n-\n-for (int i = 0; i < _forecastHorizon; i++)\n-{\n-    int idx = i * 3; // mu is at positions 0, 3, 6, ...\n-    if (idx < distributionParams.Length)\n-    {\n-        result.Data.Span[i] = distributionParams.Data.Span[idx];\n-    }\n-}\n+int paramStride = 3; // mu,sigma,nu\n+int batch = distributionParams.Shape.Length > 1 ? distributionParams.Shape[0] : 1;\n+var resultShape = batch == 1 ? new[] { _forecastHorizon } : new[] { batch, _forecastHorizon };\n+var result = new Tensor<T>(resultShape);\n+for (int b = 0; b < batch; b++)\n+{\n+    for (int i = 0; i < _forecastHorizon; i++)\n+    {\n+        int idx = (b * _forecastHorizon + i) * paramStride;\n+        if (idx < distributionParams.Length)\n+            result.Data.Span[b * _forecastHorizon + i] = distributionParams.Data.Span[idx];\n+    }\n+}\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    private Tensor<T> ExtractPointPredictions(Tensor<T> distributionParams)\n    {\n        int paramStride = 3; // mu,sigma,nu\n        int batch = distributionParams.Shape.Length > 1 ? distributionParams.Shape[0] : 1;\n        var resultShape = batch == 1 ? new[] { _forecastHorizon } : new[] { batch, _forecastHorizon };\n        var result = new Tensor<T>(resultShape);\n        for (int b = 0; b < batch; b++)\n        {\n            for (int i = 0; i < _forecastHorizon; i++)\n            {\n                int idx = (b * _forecastHorizon + i) * paramStride;\n                if (idx < distributionParams.Length)\n                    result.Data.Span[b * _forecastHorizon + i] = distributionParams.Data.Span[idx];\n            }\n        }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/LagLlama.cs` around lines 909 - 923,\nExtractPointPredictions currently always returns shape [_forecastHorizon],\ndropping the batch dimension and causing downstream misindexing (e.g., in\nShiftInputWithPredictions). Modify ExtractPointPredictions to preserve the batch\ndimension by reading distributionParams.Shape to determine batchSize (or infer\nwhen rank==2) and return a Tensor<T> with shape [batchSize, _forecastHorizon];\nfor each batch b and step i compute the source index considering 3 params per\nstep (idx = b * (3 * _forecastHorizon) + i * 3) or use the multi-dimensional\nindexing from distributionParams, and copy the mu (every 3rd value) into\nresult[b, i]. Ensure the method works when distributionParams already has rank 2\nor 3 and keep references to _forecastHorizon and the method name\nExtractPointPredictions so downstream callers like ShiftInputWithPredictions\nreceive batched predictions.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commits d89ea34 to d4345dc"}]}},{"id":"PRRT_kwDOKSXUF85r2gNF","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Timer.cs","line":354,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Validate `numFeatures` is positive.**\n\nA non-positive `numFeatures` will propagate into layer shapes and can trigger runtime shape errors later. Add an explicit guard in the native constructor.\n\n<details>\n<summary>üõ°Ô∏è Proposed fix</summary>\n\n```diff\n public Timer(\n     NeuralNetworkArchitecture<T> architecture,\n     TimerOptions<T>? options = null,\n     int numFeatures = 1,\n     IGradientBasedOptimizer<T, Tensor<T>, Tensor<T>>? optimizer = null,\n     ILossFunction<T>? lossFunction = null)\n     : base(architecture, lossFunction ?? new MeanSquaredErrorLoss<T>(), 1.0)\n {\n     options ??= new TimerOptions<T>();\n \n     _useNativeMode = true;\n+    if (numFeatures < 1)\n+        throw new ArgumentOutOfRangeException(nameof(numFeatures), \"Number of features must be at least 1.\");\n \n     _optimizer = optimizer ?? new AdamOptimizer<T, Tensor<T>, Tensor<T>>(this);\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Timer.cs` around lines 318 - 345, The\nTimer constructor currently accepts numFeatures which can be non-positive and\nlater corrupt layer shape computations; add an explicit guard at the start of\nthe Timer(NeuralNetworkArchitecture<T> architecture, ..., int numFeatures = 1,\n...) constructor to validate numFeatures > 0 and throw an\nArgumentOutOfRangeException (or ArgumentException) referencing the parameter\nname \"numFeatures\" if the check fails, then proceed to assign _numFeatures =\nnumFeatures only after the validation; this ensures the Timer class and any uses\nof _numFeatures (e.g., layer shape setup) never receive invalid values.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commits d89ea34 to d4345dc"}]}},{"id":"PRRT_kwDOKSXUF85r2gNH","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Timer.cs","line":597,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Recompute `_numPatches` after deserialization.**\n\n`_numPatches` is derived from context/patch settings but isn‚Äôt recalculated when loading, so metrics can become stale. Recompute it after reading the fields.\n\n<details>\n<summary>üîß Proposed fix</summary>\n\n```diff\n protected override void DeserializeNetworkSpecificData(BinaryReader reader)\n {\n     _contextLength = reader.ReadInt32();\n     _forecastHorizon = reader.ReadInt32();\n     _patchLength = reader.ReadInt32();\n     _patchStride = reader.ReadInt32();\n     _hiddenDimension = reader.ReadInt32();\n     _numLayers = reader.ReadInt32();\n     _numHeads = reader.ReadInt32();\n     _dropout = reader.ReadDouble();\n     _maskRatio = reader.ReadDouble();\n     _useAutoregressiveDecoding = reader.ReadBoolean();\n     _generationTemperature = reader.ReadDouble();\n     _numFeatures = reader.ReadInt32();\n+    _numPatches = (_contextLength - _patchLength) / _patchStride + 1;\n }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    protected override void DeserializeNetworkSpecificData(BinaryReader reader)\n    {\n        _contextLength = reader.ReadInt32();\n        _forecastHorizon = reader.ReadInt32();\n        _patchLength = reader.ReadInt32();\n        _patchStride = reader.ReadInt32();\n        _hiddenDimension = reader.ReadInt32();\n        _numLayers = reader.ReadInt32();\n        _numHeads = reader.ReadInt32();\n        _dropout = reader.ReadDouble();\n        _maskRatio = reader.ReadDouble();\n        _useAutoregressiveDecoding = reader.ReadBoolean();\n        _generationTemperature = reader.ReadDouble();\n        _numFeatures = reader.ReadInt32();\n        _numPatches = (_contextLength - _patchLength) / _patchStride + 1;\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Timer.cs` around lines 569 - 583,\nDeserializeNetworkSpecificData reads fields that determine the derived field\n_numPatches but doesn‚Äôt recompute it, leaving metrics stale; after reading\n_contextLength, _patchLength and _patchStride inside\nDeserializeNetworkSpecificData, recompute _numPatches (e.g. use the same logic\nas the runtime computation: compute floor((_contextLength - _patchLength) /\n_patchStride) + 1 and clamp to zero if negative) or call the existing helper\nmethod that computes patch count so _numPatches is updated on deserialization.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commits d89ea34 to d4345dc"}]}},{"id":"PRRT_kwDOKSXUF85r2gNJ","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Timer.cs","line":977,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Guard against input length mismatches in autoregressive generation.**\n\n`_contextLength` is used for shifting regardless of the flattened input length. If the input isn‚Äôt exactly `_contextLength`, indexing will go out of range. Add a length check after flattening.\n\n<details>\n<summary>üõ°Ô∏è Proposed fix</summary>\n\n```diff\n         else\n         {\n             throw new InvalidOperationException(\n                 $\"Autoregressive generation currently supports a single univariate series with shape [context_length], \" +\n                 $\"[1, context_length], or [1, context_length, 1]. \" +\n                 $\"Got input shape [{string.Join(\", \", input.Shape)}].\");\n         }\n+\n+        if (flatInput.Length != _contextLength)\n+        {\n+            throw new ArgumentException(\n+                $\"Expected input length {_contextLength} but got {flatInput.Length}.\",\n+                nameof(input));\n+        }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Timer.cs` around lines 822 - 883, The\nAutoregressiveGenerate method currently assumes the flattened input length\nequals _contextLength which can cause out-of-range indexing; after creating\nflatInput (and before using _contextLength to shift), validate its length\nagainst _contextLength and handle mismatches by either throwing a clear\nInvalidOperationException referencing AutoregressiveGenerate and input.Shape, or\nexplicitly pad/truncate flatInput to _contextLength (update currentInput\naccordingly) so the subsequent shifting loop that uses _contextLength and\ncurrentInput.Data.Span is safe.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commits d89ea34 to d4345dc"}]}},{"id":"PRRT_kwDOKSXUF85r2gNN","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Timer.cs","line":1083,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Validate quantile inputs and output length before indexing.**\n\nNegative quantiles produce negative indices, and if `Forward` returns fewer than `_forecastHorizon` steps, `values` can be empty and indexing will fail. Validate quantiles and output length up front.\n\n<details>\n<summary>üõ°Ô∏è Proposed fix</summary>\n\n```diff\n private Tensor<T> GenerateQuantilePredictions(Tensor<T> input, double[] quantiles)\n {\n+    if (quantiles.Any(q => q < 0 || q > 1))\n+        throw new ArgumentOutOfRangeException(nameof(quantiles), \"Quantiles must be between 0 and 1.\");\n+\n     int numSamples = 100;\n     var samples = new List<Tensor<T>>();\n     var rand = RandomHelper.CreateSecureRandom();\n \n     // Generate samples with temperature variation\n     for (int s = 0; s < numSamples; s++)\n     {\n         // Vary temperature for diversity\n         double temp = 0.5 + rand.NextDouble() * 1.5; // Range [0.5, 2.0]\n \n         // Use dropout for additional diversity\n         SetTrainingMode(true);\n         var sample = Forward(input);\n         SetTrainingMode(false);\n+        if (sample.Length < _forecastHorizon)\n+            throw new InvalidOperationException(\n+                $\"Forecast output length ({sample.Length}) is –º–µ–Ω—å—à–µ than forecast horizon ({_forecastHorizon}).\");\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Timer.cs` around lines 900 - 949,\nGenerateQuantilePredictions: validate inputs and guard indexing by first\nchecking quantiles is non-null/non-empty and each quantile q is within [0,1]\n(throw ArgumentException if not), and ensure you handle cases where Forward\nreturns fewer than _forecastHorizon (e.g., treat missing steps as NaN/zero or\nskip them) by verifying values.Count>0 before accessing values[idx]; compute idx\nusing a safe clamp (0..values.Count-1) instead of raw cast from quantile*Count\nso negative or out-of-range quantiles can't produce bad indices, and ensure\nresult assignment only happens when values has entries (otherwise set a sensible\ndefault or propagate NaN) ‚Äî reference GenerateQuantilePredictions, Forward,\n_forecastHorizon, quantiles in your changes.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commits d89ea34 to d4345dc"}]}},{"id":"PRRT_kwDOKSXUF85r2gNS","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Timer.cs","line":1187,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Validate input length before shifting.**\n\n`ShiftInputWithPredictions` assumes `input.Length == _contextLength`. Add an explicit check to avoid out-of-range access when upstream inputs differ.\n\n<details>\n<summary>üõ°Ô∏è Proposed fix</summary>\n\n```diff\n         if (input.Shape.Length != 1 || _numFeatures != 1)\n         {\n             throw new InvalidOperationException(\n                 $\"ShiftInputWithPredictions currently supports a single univariate series with shape [context_length]. \" +\n                 $\"Got input shape [{string.Join(\", \", input.Shape)}] with numFeatures={_numFeatures}.\");\n         }\n+        if (input.Length != _contextLength)\n+            throw new ArgumentException(\n+                $\"Expected input length {_contextLength} but got {input.Length}.\",\n+                nameof(input));\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Timer.cs` around lines 1027 - 1045, Add an\nexplicit validation at the start of ShiftInputWithPredictions to ensure the\nprovided input length matches the expected _contextLength (i.e., input.Length ==\n_contextLength) before performing the shift; if it does not match, throw an\nInvalidOperationException with a clear message including the actual input.Length\nand expected _contextLength. Place this check after the existing univariate\nguard in the ShiftInputWithPredictions method so the subsequent creation of\nresult and the for-loop that accesses input.Data.Span cannot run with a\nmismatched length.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commits d89ea34 to d4345dc"}]}},{"id":"PRRT_kwDOKSXUF85r2gNT","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepState.cs","line":null,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Add defensive checks for ONNX model structure.**\n\n`inputMeta.Keys.First()` (Line 898) and `results.First()` (Line 906) will throw `InvalidOperationException` if the ONNX model has no inputs or produces no outputs. Consider validating the model structure before accessing.\n\n\n\n<details>\n<summary>üõ°Ô∏è Proposed defensive checks</summary>\n\n```diff\n         var inputMeta = OnnxSession.InputMetadata;\n+        if (!inputMeta.Any())\n+            throw new InvalidOperationException(\"ONNX model has no input metadata.\");\n         string inputName = inputMeta.Keys.First();\n\n         var inputs = new List<NamedOnnxValue>\n         {\n             NamedOnnxValue.CreateFromTensor(inputName, onnxInput)\n         };\n\n         using var results = OnnxSession.Run(inputs);\n+        if (!results.Any())\n+            throw new InvalidOperationException(\"ONNX model produced no output.\");\n         var outputTensor = results.First().AsTensor<float>();\n```\n\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n        var inputMeta = OnnxSession.InputMetadata;\n        if (!inputMeta.Any())\n            throw new InvalidOperationException(\"ONNX model has no input metadata.\");\n        string inputName = inputMeta.Keys.First();\n\n        var inputs = new List<NamedOnnxValue>\n        {\n            NamedOnnxValue.CreateFromTensor(inputName, onnxInput)\n        };\n\n        using var results = OnnxSession.Run(inputs);\n        if (!results.Any())\n            throw new InvalidOperationException(\"ONNX model produced no output.\");\n        var outputTensor = results.First().AsTensor<float>();\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepState.cs` around lines 897 - 906, The code\nassumes the ONNX model has inputs/outputs and calls\nOnnxSession.InputMetadata.Keys.First() and results.First() unguarded; add\ndefensive checks: verify OnnxSession.InputMetadata is not null/empty before\ngetting inputName (use a clear exception or error message referencing inputMeta\n/ inputName), and after calling OnnxSession.Run(inputs) ensure results is not\nnull/empty and that the expected output exists before accessing results.First()\nor converting to a tensor (reference results and outputTensor); fail fast with\ndescriptive errors mentioning OnnxSession.InputMetadata, inputName,\nOnnxSession.Run, results, and outputTensor so consumers know the model is\nmalformed.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commits d89ea34 to d4345dc"}]}},{"id":"PRRT_kwDOKSXUF85r7K9p","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/AutoML/FinancialSearchSpace.cs","line":88,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Use `_domain` (or remove it) to avoid unused-field warnings.**  \n`_domain` is stored but never read, which can trigger CS0414 in warnings-as-errors builds and misses domain-aware defaults. Consider using it in the fallback selection. One lightweight option:\n\n<details>\n<summary>üõ†Ô∏è Minimal change to consume `_domain` in the default branch</summary>\n\n```diff\n-            _ => GetDefaultSearchSpace()\n+            _ => _domain == FinancialDomain.Risk\n+                ? GetCommonRiskSearchSpace()\n+                : GetDefaultSearchSpace()\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/AutoML/FinancialSearchSpace.cs` around lines 53 - 67, The private\nfield _domain is assigned but never used, causing unused-field warnings; update\nGetSearchSpace (the switch fallback that calls GetDefaultSearchSpace) to consume\n_domain by selecting a domain-aware default (e.g., call a new overload\nGetDefaultSearchSpace(_domain) or branch on _domain inside\nGetDefaultSearchSpace) so the field is read, or if domain behavior is\nunnecessary remove the _domain field entirely; modify the related methods\nGetDefaultSearchSpace, GetPatchTSTSearchSpace, etc., only as needed to accept\nand use the domain input so the warning is resolved and defaults can be\ndomain-aware.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7K9s","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Base/FinancialNLPModelBase.cs","line":133,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Validate NLP dimension arguments to avoid invalid state.**  \nFail fast on zero/negative sizes to prevent invalid tensor sizes or allocations later.  \n\n<details>\n<summary>üêõ Proposed fix</summary>\n\n```diff\n protected FinancialNLPModelBase(\n     NeuralNetworkArchitecture<T> architecture,\n     int maxSequenceLength,\n     int vocabularySize,\n     int hiddenDimension,\n     int numSentimentClasses = 3,\n     ILossFunction<T>? lossFunction = null)\n     : base(architecture, maxSequenceLength, 1, architecture.InputSize, lossFunction)\n {\n+    ValidateNlpConfig(maxSequenceLength, vocabularySize, hiddenDimension, numSentimentClasses);\n     _baseMaxSequenceLength = maxSequenceLength;\n     _baseVocabularySize = vocabularySize;\n     _baseHiddenDimension = hiddenDimension;\n     _baseNumSentimentClasses = numSentimentClasses;\n }\n\n protected FinancialNLPModelBase(\n     NeuralNetworkArchitecture<T> architecture,\n     string onnxModelPath,\n     int maxSequenceLength,\n     int vocabularySize,\n     int hiddenDimension,\n     int numSentimentClasses = 3)\n     : base(architecture, onnxModelPath, maxSequenceLength, 1, architecture.InputSize)\n {\n+    ValidateNlpConfig(maxSequenceLength, vocabularySize, hiddenDimension, numSentimentClasses);\n     _baseMaxSequenceLength = maxSequenceLength;\n     _baseVocabularySize = vocabularySize;\n     _baseHiddenDimension = hiddenDimension;\n     _baseNumSentimentClasses = numSentimentClasses;\n }\n+\n+private static void ValidateNlpConfig(\n+    int maxSequenceLength,\n+    int vocabularySize,\n+    int hiddenDimension,\n+    int numSentimentClasses)\n+{\n+    if (maxSequenceLength <= 0) throw new ArgumentOutOfRangeException(nameof(maxSequenceLength));\n+    if (vocabularySize <= 0) throw new ArgumentOutOfRangeException(nameof(vocabularySize));\n+    if (hiddenDimension <= 0) throw new ArgumentOutOfRangeException(nameof(hiddenDimension));\n+    if (numSentimentClasses <= 0) throw new ArgumentOutOfRangeException(nameof(numSentimentClasses));\n+}\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Base/FinancialNLPModelBase.cs` around lines 72 - 115, The two\nFinancialNLPModelBase constructors (the training ctor and the ONNX ctor) must\nvalidate numeric dimension arguments and fail fast: check maxSequenceLength,\nvocabularySize, and hiddenDimension are > 0 and numSentimentClasses is >= 2 (or\n> 0 if 1-class allowed) and throw ArgumentOutOfRangeException with clear param\nnames when invalid; perform these checks at the start of each ctor (the\noverloads that call base(architecture, ...) and base(architecture,\nonnxModelPath, ...)) so invalid tensor sizes are rejected immediately.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85r7K9u","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Base/FinancialNLPModelBase.cs","line":181,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Add a null guard for `texts`.**  \nAvoids a null-reference crash and clarifies the API contract.  \n\n<details>\n<summary>üõ°Ô∏è Proposed fix</summary>\n\n```diff\n public virtual SentimentResult<T>[] AnalyzeSentiment(string[] texts)\n {\n+    if (texts is null) throw new ArgumentNullException(nameof(texts));\n     var results = new SentimentResult<T>[texts.Length];\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    public virtual SentimentResult<T>[] AnalyzeSentiment(string[] texts)\n    {\n        if (texts is null) throw new ArgumentNullException(nameof(texts));\n        var results = new SentimentResult<T>[texts.Length];\n        for (int i = 0; i < texts.Length; i++)\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Base/FinancialNLPModelBase.cs` around lines 157 - 160, Add a null\nguard at the start of AnalyzeSentiment so it doesn't NRE on a null texts\nparameter: check if texts is null and throw an\nArgumentNullException(nameof(texts)) (or use your project's preferred\nargument-check helper) before creating the results array; this makes the\ncontract explicit for the AnalyzeSentiment method and prevents later\ndereferencing of texts in the loop that fills SentimentResult<T>[].\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7K90","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Chronos.cs","line":335,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Custom-layer path doesn't wire layer references.**\nWhen custom layers are supplied, internal references stay null and Forward/Backward can become no-ops. Call ExtractLayerReferences after validating.\n\n<details>\n<summary>üîß Suggested fix</summary>\n\n```diff\n         if (Architecture.Layers is not null && Architecture.Layers.Count > 0)\n         {\n             Layers.AddRange(Architecture.Layers);\n             ValidateCustomLayers(Layers);\n+            ExtractLayerReferences();\n         }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    protected override void InitializeLayers()\n    {\n        if (Architecture.Layers is not null && Architecture.Layers.Count > 0)\n        {\n            Layers.AddRange(Architecture.Layers);\n            ValidateCustomLayers(Layers);\n            ExtractLayerReferences();\n        }\n        else if (_useNativeMode)\n        {\n            Layers.AddRange(LayerHelper<T>.CreateDefaultChronosLayers(\n                Architecture, _contextLength, _forecastHorizon, _numTokens,\n                _hiddenDimension, _numLayers, _numHeads, _intermediateSize, _dropout));\n\n            ExtractLayerReferences();\n        }\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Chronos.cs` around lines 318 - 333, When\ncustom layers are provided in InitializeLayers (i.e., Architecture.Layers is not\nnull/empty), the code adds them and calls ValidateCustomLayers(Layers) but never\nwires up internal references; call ExtractLayerReferences() immediately after\nValidateCustomLayers(Layers) so the layer references used by Forward/Backward\nare populated; update InitializeLayers to invoke ExtractLayerReferences() in the\nbranch that handles Architecture.Layers, referencing the methods\nInitializeLayers, ValidateCustomLayers, ExtractLayerReferences and the\nLayers/Architecture.Layers collection.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7K93","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Chronos.cs","line":912,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n<details>\n<summary>üß© Analysis chain</summary>\n\nüèÅ Script executed:\n\n```shell\n# First, let's examine the file to understand the context\ncat -n src/Finance/Forecasting/Foundation/Chronos.cs | sed -n '870,920p'\n```\n\nRepository: ooples/AiDotNet\n\nLength of output: 277\n\n---\n\nüèÅ Script executed:\n\n```shell\n# Check what ONNX library is being used and its namespace\nrg \"using.*Onnx|using.*ONNX\" src/Finance/Forecasting/Foundation/Chronos.cs\n```\n\nRepository: ooples/AiDotNet\n\nLength of output: 277\n\n---\n\nüèÅ Script executed:\n\n```shell\n# Look for other usages of OnnxSession in the codebase to understand patterns\nrg \"OnnxSession\" src/ -A 2 -B 2 | head -100\n```\n\nRepository: ooples/AiDotNet\n\nLength of output: 277\n\n---\n\nüèÅ Script executed:\n\n```shell\n# Check if InputMetadata is accessed elsewhere\nrg \"InputMetadata\" src/ -B 2 -A 2\n```\n\nRepository: ooples/AiDotNet\n\nLength of output: 277\n\n---\n\nüåê Web query:\n\n`ONNX Runtime C# InputMetadata.Keys.First() exception behavior`\n\nüí° Result:\n\n`session.InputMetadata.Keys.First()` is just LINQ‚Äôs `Enumerable.First()` applied to the dictionary‚Äôs key collection. It will throw **`System.InvalidOperationException`** if there are **no keys** (i.e., the sequence is empty). This is standard LINQ behavior. [1]\n\nIn ONNX Runtime C#, `InferenceSession.InputMetadata` is an `IReadOnlyDictionary<string, NodeMetadata>` keyed by input name, and ONNX Runtime also exposes `InputNames` as an **ordered** list of input names. [2]\n\nPractical guidance:\n\n- If you ‚Äúassume one input‚Äù, prefer:\n  - `var inputName = session.InputNames[0];` (still fails if there are zero inputs, but is deterministic for >1) [2]\n- If you want to avoid exceptions:\n  - `var inputName = session.InputMetadata.Keys.FirstOrDefault();` then check for `null` (no inputs) [1]\n- If you expect **exactly one** input and want a clearer failure when there are 0 or >1:\n  - `var inputName = session.InputNames.Single();` (throws if not exactly one) [1]\n\n**Sources:**  \n[1] .NET docs on `InvalidOperationException` from calling `Enumerable.First` on an empty sequence. ([learn.microsoft.com](https://learn.microsoft.com/en-us/dotnet/fundamentals/runtime-libraries/system-invalidoperationexception?utm_source=openai))  \n[2] ONNX Runtime C# `InferenceSession` docs for `InputMetadata` and `InputNames`. ([onnxruntime.ai](https://onnxruntime.ai/docs/api/csharp/api/Microsoft.ML.OnnxRuntime.InferenceSession.html))\n\nCitations:\n\n- 1: https://learn.microsoft.com/en-us/dotnet/fundamentals/runtime-libraries/system-invalidoperationexception?utm_source=openai\n- 2: https://onnxruntime.ai/docs/api/csharp/api/Microsoft.ML.OnnxRuntime.InferenceSession.html\n\n---\n\nüåê Web query:\n\n`Microsoft ONNX Runtime C# Session.Run() results empty collection`\n\nüí° Result:\n\nIn ONNX Runtime C#, `InferenceSession.Run(...)` will only return outputs you **request**. If you call an overload that takes `outputNames` and you pass an **empty list / empty array / wrong names**, the returned collection will be **empty** (by design). The docs explicitly say to use `session.OutputNames` to request all outputs (or specific ones). [1] [5]\n\n### Fix / checklist\n\n1. **Verify the model actually has outputs**\n   ```csharp\n   Console.WriteLine($\"#outputs: {session.OutputMetadata.Count}\");\n   Console.WriteLine(string.Join(\", \", session.OutputNames));\n   ```\n   (`OutputMetadata`/`OutputNames` expose the model outputs.) [5]\n\n2. **If you want all outputs, don‚Äôt pass your own empty `outputNames`**\n   Use the ‚Äúfetch all outputs‚Äù overload:\n   ```csharp\n   using var results = session.Run(inputs); // returns all outputs\n   ```\n   [5]\n\n3. **If you use an overload with `outputNames`, pass real output names**\n   Example with the OrtValue API:\n   ```csharp\n   using var output = session.Run(runOptions, inputs, session.OutputNames[0]); // request at least one\n   ```\n   [1] [5]\n\n4. **Don‚Äôt dispose before reading**\n   The result is disposable; read/convert tensors inside the `using` scope. (This usually causes ObjectDisposed-type failures rather than ‚Äúempty‚Äù, but it‚Äôs a common pitfall.) [1]\n\nIf you paste the exact `Run(...)` overload you‚Äôre using (signature + how you build `outputNames`), I can point out exactly why it‚Äôs empty.  \n\n**Sources:** ONNX Runtime C# `InferenceSession.Run` API docs [1], C# API reference and tutorial examples using `session.OutputNames` [5].\n\n---\n\nüåê Web query:\n\n`ONNX Runtime C# API InputMetadata null empty documentation`\n\nüí° Result:\n\n`InferenceSession.InputMetadata` in the ONNX Runtime C# API is **not supposed to be `null`**‚Äîit‚Äôs a read-only dictionary property on `InferenceSession` that provides **(input-name ‚Üí NodeMetadata)** for the model‚Äôs *graph inputs*. ([onnxruntime.ai](https://onnxruntime.ai/docs/api/csharp/api/Microsoft.ML.OnnxRuntime.InferenceSession.html))\n\nIf you see it **empty**, the most common ‚Äúit‚Äôs working as designed‚Äù causes are:\n\n- **The model has no graph inputs** (e.g., it‚Äôs fully constant-folded / produces outputs from initializers/constants only). In that case, `InputNames` will also be empty, and `InputMetadata.Count == 0`. ([onnxruntime.ai](https://onnxruntime.ai/docs/api/csharp/api/Microsoft.ML.OnnxRuntime.InferenceSession.html))\n- **What you think of as an ‚Äúinput‚Äù is actually an initializer** (weights/constants). Only *graph inputs* show up in `InputMetadata`. If the model exposes **overridable initializers**, those appear under `OverridableInitializerMetadata` instead. ([onnxruntime.ai](https://onnxruntime.ai/docs/api/csharp/api/Microsoft.ML.OnnxRuntime.InferenceSession.html))\n\nIf you‚Äôre seeing **`null` at runtime**, that usually points to **your own variable being `null`** (e.g., `session` is `null`, or you‚Äôre debugging a different type/version), because the published API surface documents `InputMetadata` as a non-null property on a valid `InferenceSession` instance. ([onnxruntime.ai](https://onnxruntime.ai/docs/api/csharp/api/Microsoft.ML.OnnxRuntime.InferenceSession.html))\n\nCitations:\n\n- 1: https://onnxruntime.ai/docs/api/csharp/api/Microsoft.ML.OnnxRuntime.InferenceSession.html\n- 2: https://onnxruntime.ai/docs/api/csharp/api/Microsoft.ML.OnnxRuntime.InferenceSession.html\n- 3: https://onnxruntime.ai/docs/api/csharp/api/Microsoft.ML.OnnxRuntime.InferenceSession.html\n- 4: https://onnxruntime.ai/docs/api/csharp/api/Microsoft.ML.OnnxRuntime.InferenceSession.html\n\n---\n\n\n\n</details>\n\n**Consider defensive checks for missing ONNX inputs/outputs.**\n`InputMetadata.Keys.First()` and `results.First()` will throw if the model has no inputs or outputs. Add explicit guards to handle these edge cases with clear errors.\n\n<details>\n<summary>üîß Suggested fix</summary>\n\n```diff\n         var onnxInput = new OnnxTensors.DenseTensor<float>(inputData, input.Shape);\n         var inputMeta = OnnxSession.InputMetadata;\n+        if (inputMeta.Count == 0)\n+            throw new InvalidOperationException(\"ONNX model has no inputs.\");\n         string inputName = inputMeta.Keys.First();\n\n         var inputs = new List<NamedOnnxValue>\n         {\n             NamedOnnxValue.CreateFromTensor(inputName, onnxInput)\n         };\n\n         using var results = OnnxSession.Run(inputs);\n+        if (!results.Any())\n+            throw new InvalidOperationException(\"ONNX model produced no outputs.\");\n         var outputTensor = results.First().AsTensor<float>();\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Chronos.cs` around lines 879 - 910, In\nForecastOnnx, add defensive guards around the ONNX session inputs/outputs:\nverify OnnxSession.InputMetadata has at least one key before calling\nInputMetadata.Keys.First() (throw a clear InvalidOperationException like \"ONNX\nmodel has no inputs\"), validate the computed inputName exists in InputMetadata,\nand after running the session ensure results.Any() and that results.First() is\nnot null and .AsTensor<float>() returns a tensor (throw clear errors such as\n\"ONNX model produced no outputs\" or \"ONNX output tensor is null\"); these checks\nshould replace the direct First() calls and provide explicit error messages\nreferencing OnnxSession, InputMetadata and the results collection.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85r7K97","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Chronos.cs","line":1088,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Validate quantiles are within [0,1].**\nOut-of-range values can yield negative or out-of-bounds indices during quantile selection.\n\n<details>\n<summary>üîß Suggested fix</summary>\n\n```diff\n private Tensor<T> GenerateQuantileSamples(Tensor<T> input, double[] quantiles)\n {\n+    if (quantiles.Any(q => q < 0 || q > 1))\n+        throw new ArgumentOutOfRangeException(nameof(quantiles), \"Quantiles must be in [0, 1].\");\n     var allSamples = new List<double[]>();\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\nprivate Tensor<T> GenerateQuantileSamples(Tensor<T> input, double[] quantiles)\n{\n    if (quantiles.Any(q => q < 0 || q > 1))\n        throw new ArgumentOutOfRangeException(nameof(quantiles), \"Quantiles must be in [0, 1].\");\n    var allSamples = new List<double[]>();\n    var rand = RandomHelper.CreateSecureRandom();\n\n    // Generate multiple samples\n    for (int s = 0; s < _numSamples; s++)\n    {\n        var logits = _useNativeMode ? ForecastNative(input) : ForecastOnnx(input);\n        var sample = new double[_forecastHorizon];\n\n        for (int step = 0; step < _forecastHorizon; step++)\n        {\n            // Sample from softmax distribution with temperature\n            int tokenIdx = SampleFromLogits(logits, step, rand);\n            // Guard against division by zero when _numTokens == 1\n            double scaledValue = _numTokens > 1 ? tokenIdx / (double)(_numTokens - 1) : 0.5;\n\n            if (_hasTokenScale)\n            {\n                double minVal = NumOps.ToDouble(_lastTokenMin);\n                double rangeVal = NumOps.ToDouble(_lastTokenRange);\n                sample[step] = (scaledValue * rangeVal) + minVal;\n            }\n            else\n            {\n                sample[step] = (scaledValue * 2) - 1;\n            }\n        }\n\n        allSamples.Add(sample);\n    }\n\n    // Compute quantiles\n    var result = new Tensor<T>(new[] { _forecastHorizon * quantiles.Length });\n\n    for (int q = 0; q < quantiles.Length; q++)\n    {\n        for (int step = 0; step < _forecastHorizon; step++)\n        {\n            var stepValues = allSamples.Select(s => s[step]).OrderBy(v => v).ToList();\n            int quantileIdx = Math.Min((int)(quantiles[q] * stepValues.Count), stepValues.Count - 1);\n            result.Data.Span[q * _forecastHorizon + step] = NumOps.FromDouble(stepValues[quantileIdx]);\n        }\n    }\n\n    return result;\n}\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Chronos.cs` around lines 1028 - 1075, In\nGenerateQuantileSamples, validate the incoming quantiles array before using it:\ncheck quantiles is not null and iterate quantiles (the quantiles parameter) to\nensure every value is between 0.0 and 1.0 inclusive; if any value is out of\nrange throw an ArgumentOutOfRangeException (include the offending value and\nindex in the message). Add this validation at the top of GenerateQuantileSamples\nto prevent negative or out‚Äëof‚Äëbounds indices when computing quantileIdx (used in\nthe inner loop) and ensure callers receive a clear error instead of producing\ninvalid results.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85r7K-C","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/LagLlama.cs","line":476,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Training doc doesn‚Äôt match the default loss.**\n\nThe remarks state negative log-likelihood, but the default loss is MSE unless the caller supplies an NLL loss. Please align the remarks (or change the default).  \n\n\n<details>\n<summary>‚úçÔ∏è Suggested doc alignment</summary>\n\n```diff\n-/// <b>For Beginners:</b> Training Lag-Llama uses negative log-likelihood loss\n-/// on the predicted distribution. The model learns to predict distribution\n-/// parameters that maximize the probability of observed values.\n+/// <b>For Beginners:</b> Training uses the configured loss function (default MSE).\n+/// To optimize distribution likelihood directly, pass a negative log-likelihood loss.\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/LagLlama.cs` around lines 468 - 474, The\nXML remarks claim training uses negative log-likelihood, but the implementation\nof the LagLlama class uses MSE as the default loss unless an NLL loss is\nexplicitly passed; update the remarks in LagLlama.cs (the LagLlama class XML\ncomments near the constructor/Train method) to state that the default loss is\nMSE and that NLL can be supplied via the loss/lossFunction (or LossFunction)\nparameter, or alternatively change the class default to NLL‚Äîpick one and make\nthe docs and the constructor/default loss behavior consistent.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7K-G","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/LagLlama.cs","line":1143,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Quantile sampling drops the batch dimension.**\n\n`SampleQuantiles` flattens indexing and returns a 1D tensor, so batched inputs interleave outputs and lose per-batch separation. This breaks batched forecasts.  \n\n\n<details>\n<summary>üß© Suggested fix: add batch-aware offsets and output shape</summary>\n\n```diff\n-        var result = new Tensor<T>(new[] { _forecastHorizon * quantiles.Length });\n-        var pointPreds = ExtractPointPredictions(distributionParams);\n+        int paramsPerStep = 3;\n+        int rank = distributionParams.Shape.Length;\n+        int batchSize = rank > 1 ? distributionParams.Shape[0] : 1;\n+        int paramsPerBatch = rank == 1 ? distributionParams.Length : distributionParams.Length / batchSize;\n+\n+        var resultShape = batchSize == 1\n+            ? new[] { _forecastHorizon * quantiles.Length }\n+            : new[] { batchSize, _forecastHorizon * quantiles.Length };\n+        var result = new Tensor<T>(resultShape);\n+        var pointPreds = ExtractPointPredictions(distributionParams);\n@@\n-        for (int q = 0; q < quantiles.Length; q++)\n-        {\n-            double quantile = quantiles[q];\n-\n-            for (int i = 0; i < _forecastHorizon; i++)\n-            {\n-                // Extract mu (mean) for this step - already in pointPreds\n-                T mu = i < pointPreds.Length ? pointPreds.Data.Span[i] : NumOps.Zero;\n-\n-                // Extract sigma (scale) for this step (index 1 in each 3-param group)\n-                int sigmaIdx = i * 3 + 1;\n-                T sigma = sigmaIdx < distributionParams.Length\n-                    ? distributionParams.Data.Span[sigmaIdx]\n-                    : NumOps.FromDouble(1.0);\n+        for (int b = 0; b < batchSize; b++)\n+        {\n+            int batchOffset = b * paramsPerBatch;\n+            int resultBatchOffset = b * (_forecastHorizon * quantiles.Length);\n+\n+            for (int q = 0; q < quantiles.Length; q++)\n+            {\n+                double quantile = quantiles[q];\n+\n+                for (int i = 0; i < _forecastHorizon; i++)\n+                {\n+                    int muIdx = b * _forecastHorizon + i;\n+                    T mu = muIdx < pointPreds.Length ? pointPreds.Data.Span[muIdx] : NumOps.Zero;\n+\n+                    int sigmaIdx = batchOffset + i * paramsPerStep + 1;\n+                    T sigma = sigmaIdx < distributionParams.Length\n+                        ? distributionParams.Data.Span[sigmaIdx]\n+                        : NumOps.FromDouble(1.0);\n@@\n-                int nuIdx = i * 3 + 2;\n+                int nuIdx = batchOffset + i * paramsPerStep + 2;\n@@\n-                result.Data.Span[q * _forecastHorizon + i] = NumOps.Add(mu, adjustment);\n+                int dstIdx = resultBatchOffset + q * _forecastHorizon + i;\n+                result.Data.Span[dstIdx] = NumOps.Add(mu, adjustment);\n+                }\n             }\n         }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/LagLlama.cs` around lines 1044 - 1116,\nSampleQuantiles currently flattens everything into a single 1D result, losing\nthe batch dimension; update SampleQuantiles to be batch-aware by reading\nbatchSize from distributionParams (or pointPreds) shape, allocate result with\nshape [batchSize, _forecastHorizon * quantiles.Length] (or [batchSize,\nquantiles.Length, _forecastHorizon] if you prefer) and add an outer loop over\nbatchIndex; inside use per-batch offsets to index distributionParams and\npointPreds (e.g. batchOffset = batchIndex * paramsPerBatch, pointOffset =\nbatchIndex * _forecastHorizon) when extracting mu, sigma, nu and when writing\ninto result (use result index combining batchIndex, q and i), preserving the\nexisting StudentT/Normal logic in SampleQuantiles. Ensure NumOps and indexing\nuse the batch offsets so outputs for each batch remain contiguous and not\ninterleaved.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7K-I","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Timer.cs","line":1046,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Ensure training mode resets on exceptions during sampling.**  \nIf `Forward` throws, the model can be left in training mode. A `try/finally` keeps state consistent.  \n\n\n<details>\n<summary>üõ°Ô∏è Safe restore with try/finally</summary>\n\n```diff\n-            SetTrainingMode(true);\n-            var sample = Forward(input);\n-            SetTrainingMode(false);\n+            Tensor<T> sample;\n+            SetTrainingMode(true);\n+            try\n+            {\n+                sample = Forward(input);\n+            }\n+            finally\n+            {\n+                SetTrainingMode(false);\n+            }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Timer.cs` around lines 1018 - 1037, The\nsampling loop can leave the model in training mode if Forward(input) throws;\nwrap the training-mode toggle and Forward call in a try/finally so\nSetTrainingMode(false) is always executed. Specifically, around the block that\ncalls SetTrainingMode(true), calls Forward(input) to produce sample, and then\nSetTrainingMode(false), ensure you call SetTrainingMode(false) in a finally\nblock (referencing SetTrainingMode and Forward and the sample generation loop)\nso the model state is restored even on exceptions.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7K-L","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepState.cs","line":350,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Custom-layer path doesn't wire layer references.**\nWhen custom layers are supplied, internal references stay null and Forward/Backward can become no-ops. Call ExtractLayerReferences after validating.\n\n<details>\n<summary>üîß Suggested fix</summary>\n\n```diff\n         if (Architecture.Layers is not null && Architecture.Layers.Count > 0)\n         {\n             Layers.AddRange(Architecture.Layers);\n             ValidateCustomLayers(Layers);\n+            ExtractLayerReferences();\n         }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    protected override void InitializeLayers()\n    {\n        if (Architecture.Layers is not null && Architecture.Layers.Count > 0)\n        {\n            Layers.AddRange(Architecture.Layers);\n            ValidateCustomLayers(Layers);\n            ExtractLayerReferences();\n        }\n        else if (_useNativeMode)\n        {\n            Layers.AddRange(LayerHelper<T>.CreateDefaultDeepStateLayers(\n                Architecture, _lookbackWindow, _forecastHorizon, _numFeatures,\n                _stateDimension, _hiddenDimension, _numRnnLayers, _dropout));\n\n            ExtractLayerReferences();\n        }\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepState.cs` around lines 333 - 348,\nInitializeLayers fails to call ExtractLayerReferences when custom layers are\nprovided, leaving internal references null; after validating and adding custom\nlayers (when Architecture.Layers is not null and Architecture.Layers.Count > 0),\ncall ExtractLayerReferences() so that Layers, ValidateCustomLayers(Layers) and\nExtractLayerReferences() are executed in sequence; update the InitializeLayers\nmethod to invoke ExtractLayerReferences after ValidateCustomLayers when using\ncustom layers.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7K-P","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepState.cs","line":490,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Ensure training mode resets on exceptions.**\nAn exception during Forward/Loss/Backward will skip `SetTrainingMode(false)`. Wrap the training block in try/finally.\n\n<details>\n<summary>üîß Suggested fix</summary>\n\n```diff\n     SetTrainingMode(true);\n-\n-    var predictions = Forward(input);\n-    LastLoss = _lossFunction.CalculateLoss(predictions.ToVector(), target.ToVector());\n-\n-    var gradient = _lossFunction.CalculateDerivative(predictions.ToVector(), target.ToVector());\n-    Backward(Tensor<T>.FromVector(gradient, predictions.Shape));\n-\n-    _optimizer.UpdateParameters(Layers);\n-\n-    SetTrainingMode(false);\n+    try\n+    {\n+        var predictions = Forward(input);\n+        LastLoss = _lossFunction.CalculateLoss(predictions.ToVector(), target.ToVector());\n+\n+        var gradient = _lossFunction.CalculateDerivative(predictions.ToVector(), target.ToVector());\n+        Backward(Tensor<T>.FromVector(gradient, predictions.Shape));\n+\n+        _optimizer.UpdateParameters(Layers);\n+    }\n+    finally\n+    {\n+        SetTrainingMode(false);\n+    }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepState.cs` around lines 468 - 484, The\nTrain method can leave the model in training mode if Forward/Loss/Backward\nthrows; wrap the work after SetTrainingMode(true) in a try/finally so\nSetTrainingMode(false) always runs. In DeepState.cs update the Train(Tensor<T>\ninput, Tensor<T> target) method: call SetTrainingMode(true) then enter try { var\npredictions = Forward(...); compute LastLoss, gradient, Backward(...);\n_optimizer.UpdateParameters(Layers); } finally { SetTrainingMode(false); } so\nexceptions propagate but training mode is reset.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7TDU","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/AutoML/FinancialSearchSpace.cs","line":87,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Domain parameter is unused ‚Äî enforce or remove it.**\n\n`_domain` is stored but never consulted, so a mismatched `modelType` won‚Äôt be caught and the API implies domain-specific behavior that isn‚Äôt applied. At minimum, use `_domain` to influence the fallback space (or add validation for unsupported model/domain combinations).\n\n<details>\n<summary>üí° Minimal fix: use domain-specific defaults in the fallback</summary>\n\n```diff\n public Dictionary<string, ParameterRange> GetSearchSpace(ModelType modelType)\n {\n     return modelType switch\n     {\n         ModelType.PatchTST => GetPatchTSTSearchSpace(),\n         ModelType.ITransformer => GetITransformerSearchSpace(),\n         ModelType.DeepAR => GetDeepARSearchSpace(),\n         ModelType.NBEATS => GetNBEATSSearchSpace(),\n         ModelType.TFT => GetTFTSearchSpace(),\n         ModelType.NeuralVaR => GetNeuralVaRSearchSpace(),\n         ModelType.TabNet => GetTabNetSearchSpace(),\n         ModelType.TabTransformer => GetTabTransformerSearchSpace(),\n-        _ => GetDefaultSearchSpace()\n+        _ => _domain switch\n+        {\n+            FinancialDomain.Forecasting => GetCommonForecastingSearchSpace(),\n+            FinancialDomain.Risk => GetCommonRiskSearchSpace(),\n+            _ => GetDefaultSearchSpace()\n+        }\n     };\n }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/AutoML/FinancialSearchSpace.cs` around lines 24 - 66, The _domain\nfield in FinancialSearchSpace is never used; update GetSearchSpace in the\nFinancialSearchSpace class to enforce or apply domain-specific behavior by\nchecking _domain before or after the modelType switch: either validate that the\nchosen modelType is supported for the current _domain and throw an informative\nArgumentException for unsupported domain/model combinations, or route the\nfallback to a domain-aware default (e.g., call a new\nGetDefaultSearchSpace(FinancialDomain) or GetDomainDefaultSearchSpace() that\nuses _domain) instead of the current GetDefaultSearchSpace(); touch the\nGetDefaultSearchSpace method signature or add a new domain-aware helper and\nensure any model-specific getters (GetPatchTSTSearchSpace,\nGetITransformerSearchSpace, etc.) remain callable.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7TDb","isResolved":false,"comments":{"nodes":[{"path":"src/Finance/Base/PortfolioOptimizerBase.cs","line":290,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Add validation after deserializing `_numAssets`.**\n\nThe constructors enforce `numAssets > 0`, but deserialization bypasses this validation. A corrupted or tampered file could set `_numAssets` to an invalid value, breaking the class invariant.\n\n\n<details>\n<summary>üõ°Ô∏è Proposed fix</summary>\n\n```diff\n protected override void DeserializeModelSpecificData(BinaryReader reader)\n {\n-    _numAssets = reader.ReadInt32();\n+    var numAssets = reader.ReadInt32();\n+    if (numAssets <= 0)\n+    {\n+        throw new InvalidDataException(\n+            $\"Deserialized numAssets ({numAssets}) must be greater than 0.\");\n+    }\n+    _numAssets = numAssets;\n }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    protected override void DeserializeModelSpecificData(BinaryReader reader)\n    {\n        var numAssets = reader.ReadInt32();\n        if (numAssets <= 0)\n        {\n            throw new InvalidDataException(\n                $\"Deserialized numAssets ({numAssets}) must be greater than 0.\");\n        }\n        _numAssets = numAssets;\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Base/PortfolioOptimizerBase.cs` around lines 280 - 283, After\ndeserializing _numAssets in PortfolioOptimizerBase.DeserializeModelSpecificData,\nvalidate that the value is > 0 and throw a clear exception (e.g.,\nInvalidDataException or ArgumentOutOfRangeException) if it is not; this restores\nthe class invariant enforced by the constructors (numAssets > 0) and prevents\ncorrupted/tampered data from producing invalid state. Ensure the exception\nmessage references _numAssets and expected constraint so callers can diagnose\nthe bad serialized input.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85r7TDo","isResolved":false,"comments":{"nodes":[{"path":"src/Finance/Base/RiskModelBase.cs","line":null,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Deserialization validation bounds are inconsistent with constructor.**\n\nThe constructor validates `confidenceLevel <= 0 || confidenceLevel >= 1` (exclusive bounds), but deserialization validates `_confidenceLevel < 0 || _confidenceLevel > 1` (inclusive bounds). This allows deserializing a `confidenceLevel` of exactly 0 or 1, which the constructor would reject.\n\n\n\n<details>\n<summary>üîß Proposed fix to align validation</summary>\n\n```diff\n         // Re-validate invariants after deserialize to prevent corrupt state\n-        if (_confidenceLevel < 0 || _confidenceLevel > 1)\n+        if (_confidenceLevel <= 0 || _confidenceLevel >= 1)\n         {\n             throw new InvalidOperationException(\n-                $\"Deserialized confidenceLevel ({_confidenceLevel}) is invalid. Must be between 0 and 1.\");\n+                $\"Deserialized confidenceLevel ({_confidenceLevel}) is invalid. Must be between 0 and 1 (exclusive).\");\n         }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Base/RiskModelBase.cs` around lines 318 - 327, The\ndeserialization validation for _confidenceLevel is too permissive compared to\nthe constructor (it allows 0 and 1); change the check in the deserialization\nblock to use the same exclusive bounds as the constructor by replacing the\ncondition with (_confidenceLevel <= 0 || _confidenceLevel >= 1) and keep the\nsame InvalidOperationException message; locate the check referencing\n_confidenceLevel in RiskModelBase (the deserialization validation) and update it\nto match the constructor's validation logic.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85r7TDt","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Chronos.cs","line":326,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Custom layers won‚Äôt execute without reference extraction.**  \n`Forward` uses `_tokenEmbedding`, `_transformerLayers`, `_finalNorm`, and `_lmHead`; without `ExtractLayerReferences()` these remain unset for custom layer sets.  \n\n\n<details>\n<summary>üõ†Ô∏è Suggested fix</summary>\n\n```diff\n         if (Architecture.Layers is not null && Architecture.Layers.Count > 0)\n         {\n             Layers.AddRange(Architecture.Layers);\n             ValidateCustomLayers(Layers);\n+            ExtractLayerReferences();\n         }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Chronos.cs` around lines 318 - 324,\nInitializeLayers currently copies Architecture.Layers into Layers and validates\nthem but does not call ExtractLayerReferences(), so Forward's dependencies\n(_tokenEmbedding, _transformerLayers, _finalNorm, _lmHead) remain unset for\ncustom layer sets; after adding and validating custom layers in InitializeLayers\n(when Architecture.Layers is not null/empty) call ExtractLayerReferences() to\npopulate those fields so Forward can execute correctly (i.e., invoke\nExtractLayerReferences() right after ValidateCustomLayers(Layers) or ensure the\nsame initialization path used for default layers is taken).\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7TDv","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/LagLlama.cs","line":443,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Inconsistent validation: \"Normal\" listed as valid but then rejected.**\n\nLine 423 includes \"Normal\" in `validDistributions`, but lines 438-443 explicitly reject it with an error. This creates confusing behavior - the first check passes but the second fails.\n\n\n<details>\n<summary>‚ú® Suggested fix: Remove Normal from valid list or support it</summary>\n\nOption 1 - Remove Normal if not supported:\n```diff\n-var validDistributions = new[] { \"StudentT\", \"Normal\" };\n+var validDistributions = new[] { \"StudentT\" };\n```\n\nOption 2 - Keep the documentation but clarify in error:\n```diff\n-var validDistributions = new[] { \"StudentT\", \"Normal\" };\n+var validDistributions = new[] { \"StudentT\" }; // Normal planned but not yet implemented\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/LagLlama.cs` around lines 421 - 443, The\nvalidation is inconsistent: validDistributions includes \"Normal\" but the later\nbranch for DistributionOutput (\"Normal\" in the else if) adds an error because\nExtractPointPredictions expects a StudentT stride of 3; fix by choosing one\napproach consistently. Either remove \"Normal\" from the validDistributions array\nand adjust the initial error message to only list \"StudentT\", or implement\nproper handling for \"Normal\" (update ExtractPointPredictions/stride logic or add\na separate code path that expects 2 * ForecastHorizon parameters) and keep\n\"Normal\" in validDistributions; update the error messages to reference\noptions.DistributionOutput, ExtractPointPredictions, and ForecastHorizon\naccordingly.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7TDy","isResolved":false,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/LagLlama.cs","line":556,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Missing try/finally around training mode toggle.**\n\nIf an exception occurs during training (e.g., in `Forward`, `Backward`, or optimizer update), `SetTrainingMode(false)` will never be called, leaving the model stuck in training mode.\n\n\n<details>\n<summary>üõ°Ô∏è Suggested fix with try/finally</summary>\n\n```diff\n public override void Train(Tensor<T> input, Tensor<T> target)\n {\n     if (!_useNativeMode)\n         throw new InvalidOperationException(\"Training is only supported in native mode.\");\n\n     SetTrainingMode(true);\n-\n-    var predictions = Forward(input);\n-    ...\n-    _optimizer.UpdateParameters(Layers);\n-\n-    SetTrainingMode(false);\n+    try\n+    {\n+        var predictions = Forward(input);\n+\n+        // Extract point predictions from distribution parameters (use mean)\n+        var pointPredictions = ExtractPointPredictions(predictions);\n+        var predVector = pointPredictions.ToVector();\n+\n+        // ... rest of training logic ...\n+\n+        Backward(Tensor<T>.FromVector(fullGradient, predictions.Shape));\n+\n+        _optimizer.UpdateParameters(Layers);\n+    }\n+    finally\n+    {\n+        SetTrainingMode(false);\n+    }\n }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/LagLlama.cs` around lines 475 - 550, The\nTrain method can leave the model stuck in training mode if an exception occurs;\nwrap the core training sequence (SetTrainingMode(true); Forward(...);\nloss/gradient computation; Backward(...); _optimizer.UpdateParameters(...)) in a\ntry/finally so that SetTrainingMode(false) is always executed. Specifically, in\nLagLlama.Train, call SetTrainingMode(true) before the try, perform Forward,\nloss/gradient mapping, Backward(Tensor.FromVector(..., predictions.Shape)) and\n_optimizer.UpdateParameters(Layers) inside the try, and ensure\nSetTrainingMode(false) runs in the finally block to guarantee mode reset even on\nexceptions.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85r7TD3","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/LagLlama.cs","line":1034,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Potential out-of-bounds or incorrect indexing if tensor shape doesn't match expected layout.**\n\nFor the 2D case, `batchOffset` is calculated as `b * (paramsPerStep * _forecastHorizon)`, but the actual tensor may have a different `totalParams` per batch (read from `distributionParams.Shape[1]`). If the ONNX model or a layer produces a different output shape, the indexing will be incorrect.\n\n\n<details>\n<summary>üîç Suggested validation</summary>\n\n```diff\n // For 1D/2D cases: extract mu values with batch preservation\n+int expectedParamsPerBatch = paramsPerStep * _forecastHorizon;\n+if (rank == 2 && totalParams != expectedParamsPerBatch)\n+{\n+    // Log warning or adjust stride calculation based on actual totalParams\n+    // For now, use actual params per batch from shape\n+}\n+\n var result = new Tensor<T>(batchSize == 1 ? new[] { _forecastHorizon } : new[] { batchSize, _forecastHorizon });\n\n for (int b = 0; b < batchSize; b++)\n {\n-    int batchOffset = b * (paramsPerStep * _forecastHorizon);\n+    int batchOffset = b * totalParams; // Use actual shape, not assumed\n     for (int i = 0; i < _forecastHorizon; i++)\n     {\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/LagLlama.cs` around lines 1013 - 1028, The\nloop assumes each batch's parameters occupy paramsPerStep * _forecastHorizon\nitems and computes batchOffset as b * (paramsPerStep * _forecastHorizon), which\ncan be wrong if distributionParams has a different per-batch stride; fix by\nreading the actual per-batch size from distributionParams.Shape (e.g., use\ndistributionParams.Shape[1] or the appropriate dimension) to compute\nbatchStride, validate that paramsPerStep and batchStride are consistent, and use\nbatchOffset = b * batchStride; also add explicit bounds checks before reading\ndistributionParams.Data.Span[srcIdx] and writing result.Data.Span[dstIdx] to\navoid out-of-range access when shapes differ (reference variables:\ndistributionParams, paramsPerStep, _forecastHorizon, batchSize, result in\nLagLlama.cs).\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7TD5","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/LagLlama.cs","line":1143,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**`SampleQuantiles` doesn't handle batched distribution parameters.**\n\nWhile `ExtractPointPredictions` was updated to handle batched inputs (rank 2/3), `SampleQuantiles` still uses simple indexing (`i * 3 + 1` for sigma, `i * 3 + 2` for nu) that only works for unbatched inputs. If `Forecast` is called with batched data, quantile sampling will produce incorrect results.\n\n\n<details>\n<summary>üîç Suggested approach</summary>\n\nEither:\n1. Document that quantile sampling only supports single-sample (unbatched) inputs\n2. Add batch handling similar to `ExtractPointPredictions`\n\nQuick documentation fix:\n```diff\n private Tensor<T> SampleQuantiles(Tensor<T> distributionParams, double[] quantiles)\n {\n+    // Note: Currently only supports unbatched (rank 1) distribution parameters.\n+    // For batched inputs, quantiles are computed for the first sample only.\n     // Branch on distribution type to use appropriate quantile function\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/LagLlama.cs` around lines 1043 - 1115,\nSampleQuantiles currently assumes unbatched distributionParams by indexing\nsigma/nu with i * 3 + 1 / +2 which breaks when distributionParams is rank-2/3\n(batched) like ExtractPointPredictions now supports; update SampleQuantiles to\neither (a) accept batched inputs by iterating over the batch dimension(s) and\ncomputing per-batch offsets/strides (use distributionParams.Shape and per-batch\nindex = batchIndex * perSeriesStride + i*3 + paramOffset) and compute pointPreds\nper-batch (or call ExtractPointPredictions per-batch) so sigma/nu are read from\nthe correct positions, or (b) explicitly validate the rank/shape of\ndistributionParams at the top of SampleQuantiles and throw a clear\nNotSupportedException if batched inputs are passed (mentioning SampleQuantiles\nand ExtractPointPredictions in the error), ensuring all index calculations use\nTensor shape/stride information rather than fixed i*3 + k math.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7TD9","isResolved":false,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/TimeGPT.cs","line":1067,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Autoregressive helpers drop feature dimensions for multivariate outputs.**  \nBoth `ShiftInputWithPredictions` and `ConcatenatePredictions` assume a single feature, which will corrupt forecasts when `_numFeatures > 1`.  \n\n\n<details>\n<summary>üõ†Ô∏è Suggested fix (feature-aware shift + concat)</summary>\n\n```diff\n-        var result = new Tensor<T>(input.Shape);\n-        // Use effective context length based on actual input size\n-        int effectiveContext = Math.Min(_contextLength, input.Length);\n-        int steps = Math.Min(stepsUsed, effectiveContext);\n-\n-        // Shift old values left - guard against input.Length < _contextLength\n-        for (int i = 0; i < effectiveContext - steps && i + steps < input.Length; i++)\n-        {\n-            result.Data.Span[i] = input.Data.Span[i + steps];\n-        }\n-\n-        // Append predictions - guard against result and predictions bounds\n-        for (int i = 0; i < steps && i < predictions.Length; i++)\n-        {\n-            int targetIdx = effectiveContext - steps + i;\n-            if (targetIdx >= 0 && targetIdx < result.Length)\n-            {\n-                result.Data.Span[targetIdx] = predictions.Data.Span[i];\n-            }\n-        }\n+        int batchSize = input.Shape.Length > 1 ? input.Shape[0] : 1;\n+        int contextLen = input.Shape.Length > 1 ? input.Shape[1] : _contextLength;\n+        int features = input.Shape.Length > 2 ? input.Shape[2] : Math.Max(1, _numFeatures);\n+        int steps = Math.Min(stepsUsed, contextLen);\n+\n+        var result = new Tensor<T>(input.Shape);\n+\n+        int predSteps = predictions.Shape.Length > 1\n+            ? predictions.Shape[1]\n+            : predictions.Length / Math.Max(1, batchSize);\n+        int predFeatures = predictions.Shape.Length > 2 ? predictions.Shape[2] : 1;\n+        int featureCopy = Math.Min(features, predFeatures);\n+\n+        for (int b = 0; b < batchSize; b++)\n+        {\n+            for (int t = 0; t < contextLen - steps; t++)\n+            {\n+                for (int f = 0; f < features; f++)\n+                {\n+                    int srcIdx = b * contextLen * features + (t + steps) * features + f;\n+                    int dstIdx = b * contextLen * features + t * features + f;\n+                    if (srcIdx < input.Length && dstIdx < result.Length)\n+                    {\n+                        result.Data.Span[dstIdx] = input.Data.Span[srcIdx];\n+                    }\n+                }\n+            }\n+\n+            for (int t = 0; t < steps && t < predSteps; t++)\n+            {\n+                for (int f = 0; f < featureCopy; f++)\n+                {\n+                    int predIdx = predFeatures > 1\n+                        ? b * predSteps * predFeatures + t * predFeatures + f\n+                        : b * predSteps + t;\n+                    int dstIdx = b * contextLen * features + (contextLen - steps + t) * features + f;\n+                    if (predIdx < predictions.Length && dstIdx < result.Length)\n+                    {\n+                        result.Data.Span[dstIdx] = predictions.Data.Span[predIdx];\n+                    }\n+                }\n+            }\n+        }\n@@\n-        var result = new Tensor<T>(new[] { 1, totalSteps, 1 });\n-        int position = 0;\n-\n-        foreach (var pred in predictions)\n-        {\n-            int toCopy = Math.Min(pred.Length, totalSteps - position);\n-            for (int i = 0; i < toCopy; i++)\n-            {\n-                result.Data.Span[position + i] = pred.Data.Span[i];\n-            }\n-            position += toCopy;\n-        }\n+        if (predictions.Count == 0)\n+        {\n+            int emptyFeatures = Math.Max(1, _numFeatures);\n+            return new Tensor<T>(new[] { 1, totalSteps, emptyFeatures });\n+        }\n+\n+        int batchSize = predictions[0].Shape.Length > 1 ? predictions[0].Shape[0] : 1;\n+        int predFeatures = predictions[0].Shape.Length > 2 ? predictions[0].Shape[2] : 1;\n+        int features = Math.Max(_numFeatures, predFeatures);\n+        bool hasFeatureDim = features > 1;\n+        var resultShape = hasFeatureDim\n+            ? new[] { batchSize, totalSteps, features }\n+            : new[] { batchSize, totalSteps };\n+        var result = new Tensor<T>(resultShape);\n+        int position = 0;\n+\n+        foreach (var pred in predictions)\n+        {\n+            int predSteps = pred.Shape.Length > 1 ? pred.Shape[1] : pred.Length / Math.Max(1, batchSize);\n+            int predFeat = pred.Shape.Length > 2 ? pred.Shape[2] : 1;\n+            int featureCopy = Math.Min(features, predFeat);\n+            int toCopy = Math.Min(predSteps, totalSteps - position);\n+\n+            for (int b = 0; b < batchSize; b++)\n+            {\n+                for (int t = 0; t < toCopy; t++)\n+                {\n+                    if (hasFeatureDim)\n+                    {\n+                        for (int f = 0; f < featureCopy; f++)\n+                        {\n+                            int srcIdx = predFeat > 1\n+                                ? b * predSteps * predFeat + t * predFeat + f\n+                                : b * predSteps + t;\n+                            int dstIdx = b * totalSteps * features + (position + t) * features + f;\n+                            if (srcIdx < pred.Length && dstIdx < result.Length)\n+                            {\n+                                result.Data.Span[dstIdx] = pred.Data.Span[srcIdx];\n+                            }\n+                        }\n+                    }\n+                    else\n+                    {\n+                        int srcIdx = b * predSteps + t;\n+                        int dstIdx = b * totalSteps + position + t;\n+                        if (srcIdx < pred.Length && dstIdx < result.Length)\n+                        {\n+                            result.Data.Span[dstIdx] = pred.Data.Span[srcIdx];\n+                        }\n+                    }\n+                }\n+            }\n+\n+            position += toCopy;\n+            if (position >= totalSteps)\n+                break;\n+        }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/TimeGPT.cs` around lines 988 - 1041,\nShiftInputWithPredictions and ConcatenatePredictions drop the feature dimension\n(assume single feature) and must be made feature-aware: use the tensor shape or\n_numFeatures to determine featureCount, preserve the feature dimension when\ncreating result tensors (e.g., create result with shape [1, contextLength,\nfeatureCount] and [1, totalSteps, featureCount]) and adjust loops to iterate\nover time steps and features (copy time slices for all features rather than\nsingle scalar positions). In ShiftInputWithPredictions update\neffectiveContext/steps logic to operate on time indices and copy feature vectors\nby computing per-time offsets (timeIndex * featureCount + featureIndex) into\nresult.Data.Span/result lengths; in ConcatenatePredictions compute toCopy in\ntime-steps and for each time step copy all feature elements from pred (using\npred.Shape[2] or featureCount) into result at position*featureCount offset, and\nadvance position by the number of time steps copied. Ensure bounds checks\naccount for time*featureCount lengths.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85r7TEB","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Timer.cs","line":478,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Ensure training mode is always reset on failure.**  \nIf `Forward`, loss, or backward throws, the model can remain in training mode and poison subsequent inference.\n\n\n<details>\n<summary>üîß Proposed fix (guaranteed reset)</summary>\n\n```diff\n     public override void Train(Tensor<T> input, Tensor<T> target)\n     {\n         if (!_useNativeMode)\n             throw new InvalidOperationException(\"Training is only supported in native mode.\");\n \n-        SetTrainingMode(true);\n-\n-        var output = Forward(input);\n-\n-        // Compute loss\n-        LastLoss = _lossFunction.CalculateLoss(output.ToVector(), target.ToVector());\n-\n-        // Backward pass\n-        var gradient = _lossFunction.CalculateDerivative(output.ToVector(), target.ToVector());\n-        Backward(Tensor<T>.FromVector(gradient, output.Shape));\n-\n-        _optimizer.UpdateParameters(Layers);\n-\n-        SetTrainingMode(false);\n+        SetTrainingMode(true);\n+        try\n+        {\n+            var output = Forward(input);\n+\n+            // Compute loss\n+            LastLoss = _lossFunction.CalculateLoss(output.ToVector(), target.ToVector());\n+\n+            // Backward pass\n+            var gradient = _lossFunction.CalculateDerivative(output.ToVector(), target.ToVector());\n+            Backward(Tensor<T>.FromVector(gradient, output.Shape));\n+\n+            _optimizer.UpdateParameters(Layers);\n+        }\n+        finally\n+        {\n+            SetTrainingMode(false);\n+        }\n     }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Timer.cs` around lines 459 - 478, Train\ncurrently sets training mode via SetTrainingMode(true) but does not guarantee\nreset on exceptions from Forward, loss computations, Backward, or\n_optimizer.UpdateParameters; wrap the training sequence in a try/finally so\nSetTrainingMode(false) always runs, move the existing logic (Forward, LastLoss\nassignment, gradient/Backward, _optimizer.UpdateParameters) into the try block\nand call SetTrainingMode(false) in finally, ensuring Train, SetTrainingMode,\nForward, Backward, LastLoss and _optimizer.UpdateParameters are referenced and\npreserved.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7TEC","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Foundation/Timer.cs","line":1037,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Training mode can remain enabled if sampling fails mid-loop.**  \nIf `Forward` throws once, `SetTrainingMode(false)` is skipped and the model stays in training mode.\n\n\n<details>\n<summary>üîß Proposed fix (try/finally per sample)</summary>\n\n```diff\n         for (int s = 0; s < numSamples; s++)\n         {\n             // Vary temperature for diversity\n             double temp = 0.5 + rand.NextDouble() * 1.5; // Range [0.5, 2.0]\n \n             // Use dropout for additional diversity\n-            SetTrainingMode(true);\n-            var sample = Forward(input);\n-            SetTrainingMode(false);\n+            SetTrainingMode(true);\n+            Tensor<T> sample;\n+            try\n+            {\n+                sample = Forward(input);\n+            }\n+            finally\n+            {\n+                SetTrainingMode(false);\n+            }\n \n             // Apply temperature scaling\n             var scaled = new Tensor<T>(sample.Shape);\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Foundation/Timer.cs` around lines 1021 - 1030, The\nloop that samples (using numSamples, rand and temp) enables training mode then\ncalls Forward(input) but if Forward throws the SetTrainingMode(false) call is\nskipped; wrap the per-sample work so SetTrainingMode(true) is followed by a\ntry/finally that ensures SetTrainingMode(false) in the finally block (keep temp\ncomputed before the try), e.g. for each sample set temp, call\nSetTrainingMode(true) then in try call Forward(input) and any sampling logic,\nand in finally call SetTrainingMode(false) to guarantee training mode is always\nreset.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7TEF","isResolved":false,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepAR.cs","line":null,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Orphaned XML documentation comment.**\n\nLine 190 has an empty XML summary tag with no associated property definition following it. This appears to be leftover from a removed property or incomplete documentation.\n\n<details>\n<summary>üßπ Suggested fix</summary>\n\n```diff\n     /// <summary>\n     /// Gets the name of the model architecture.\n     /// </summary>\n-\n     `#endregion`\n```\n\nEither remove the orphaned XML comment or add the intended property (e.g., `public override string ModelName => \"DeepAR\";`).\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepAR.cs` around lines 187 - 191, There is an\norphaned XML <summary> comment in the DeepAR class; either remove that empty XML\ndocumentation block or implement the intended property in the DeepAR class by\nadding an override for ModelName that returns \"DeepAR\" (e.g., implement public\noverride string ModelName that returns \"DeepAR\") and ensure the XML summary\ncorrectly documents that property.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85r7TEK","isResolved":false,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepAR.cs","line":447,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Training mode not restored on exception.**\n\nIf `Backward` or `_optimizer.UpdateParameters` throws an exception, `SetTrainingMode(false)` won't be called, leaving the model in an inconsistent state.\n\n<details>\n<summary>üõ†Ô∏è Suggested fix using try/finally</summary>\n\n```diff\n     protected override void TrainCore(Tensor<T> input, Tensor<T> target, Tensor<T> output)\n     {\n         SetTrainingMode(true);\n-\n-        // Backward pass\n-        var gradient = ComputeGradient(output, target);\n-        Backward(gradient);\n-\n-        // Update weights via optimizer\n-        _optimizer.UpdateParameters(Layers);\n-\n-        SetTrainingMode(false);\n+        try\n+        {\n+            // Backward pass\n+            var gradient = ComputeGradient(output, target);\n+            Backward(gradient);\n+\n+            // Update weights via optimizer\n+            _optimizer.UpdateParameters(Layers);\n+        }\n+        finally\n+        {\n+            SetTrainingMode(false);\n+        }\n     }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    protected override void TrainCore(Tensor<T> input, Tensor<T> target, Tensor<T> output)\n    {\n        SetTrainingMode(true);\n        try\n        {\n            // Backward pass\n            var gradient = ComputeGradient(output, target);\n            Backward(gradient);\n\n            // Update weights via optimizer\n            _optimizer.UpdateParameters(Layers);\n        }\n        finally\n        {\n            SetTrainingMode(false);\n        }\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepAR.cs` around lines 435 - 447, TrainCore\ncurrently sets training mode true but calls Backward and\n_optimizer.UpdateParameters without guaranteeing SetTrainingMode(false) on\nexceptions; wrap the bodies that perform ComputeGradient, Backward, and\n_optimizer.UpdateParameters in a try/finally so that SetTrainingMode(false) is\nalways executed, leaving the model state consistent even if Backward or\n_optimizer.UpdateParameters throws; update the TrainCore method (referencing\nTrainCore, ComputeGradient, Backward, _optimizer.UpdateParameters, and\nSetTrainingMode) to set training mode true, perform work in try, and call\nSetTrainingMode(false) in finally.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85r7TEO","isResolved":false,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepAR.cs","line":528,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Empty string fallback for ONNX model path may cause issues.**\n\nWhen `OnnxModelPath` is null, passing an empty string to the constructor could cause problems if the ONNX constructor tries to load from that path. Consider validating this case or using a more explicit approach.\n\n<details>\n<summary>üõ†Ô∏è Suggested fix</summary>\n\n```diff\n         else\n         {\n+            if (string.IsNullOrEmpty(OnnxModelPath))\n+                throw new InvalidOperationException(\"Cannot clone ONNX-mode model without a valid OnnxModelPath.\");\n             return new DeepAR<T>(Architecture, OnnxModelPath ?? string.Empty, options, _optimizer, LossFunction);\n         }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepAR.cs` around lines 519 - 523, The code\npasses an empty string when OnnxModelPath is null which can break the DeepAR<T>\nONNX constructor; update the factory/creator method to explicitly validate\nOnnxModelPath before calling the DeepAR<T> constructor: if OnnxModelPath is null\nor whitespace, either throw a clear ArgumentException (or ArgumentNullException)\nmentioning OnnxModelPath or choose the appropriate overload/flag that indicates\n‚Äúno ONNX model‚Äù instead of passing string.Empty; also consider verifying the\nfile exists (File.Exists) when a non-empty path is provided so\nDeepAR<T>(Architecture, OnnxModelPath, options, _optimizer, LossFunction) always\nreceives a valid, non-empty path or an explicit null/exception.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:ocelot -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85r7TER","isResolved":false,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepFactor.cs","line":511,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Ensure training mode resets on exceptions.**  \nIf `Forward`/loss/backward throws, the model can remain in training mode. Wrap with try/finally.  \n\n\n<details>\n<summary>üõ†Ô∏è Suggested fix</summary>\n\n```diff\n-        SetTrainingMode(true);\n-\n-        var predictions = Forward(input);\n-        LastLoss = _lossFunction.CalculateLoss(predictions.ToVector(), target.ToVector());\n-\n-        var gradient = _lossFunction.CalculateDerivative(predictions.ToVector(), target.ToVector());\n-        Backward(Tensor<T>.FromVector(gradient, predictions.Shape));\n-\n-        _optimizer.UpdateParameters(Layers);\n-\n-        SetTrainingMode(false);\n+        SetTrainingMode(true);\n+        try\n+        {\n+            var predictions = Forward(input);\n+            LastLoss = _lossFunction.CalculateLoss(predictions.ToVector(), target.ToVector());\n+\n+            var gradient = _lossFunction.CalculateDerivative(predictions.ToVector(), target.ToVector());\n+            Backward(Tensor<T>.FromVector(gradient, predictions.Shape));\n+\n+            _optimizer.UpdateParameters(Layers);\n+        }\n+        finally\n+        {\n+            SetTrainingMode(false);\n+        }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    public override void Train(Tensor<T> input, Tensor<T> target)\n    {\n        if (!_useNativeMode)\n            throw new InvalidOperationException(\"Training is only supported in native mode.\");\n\n        SetTrainingMode(true);\n        try\n        {\n            var predictions = Forward(input);\n            LastLoss = _lossFunction.CalculateLoss(predictions.ToVector(), target.ToVector());\n\n            var gradient = _lossFunction.CalculateDerivative(predictions.ToVector(), target.ToVector());\n            Backward(Tensor<T>.FromVector(gradient, predictions.Shape));\n\n            _optimizer.UpdateParameters(Layers);\n        }\n        finally\n        {\n            SetTrainingMode(false);\n        }\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepFactor.cs` around lines 491 - 507, The\nTrain method may leave the model stuck in training mode if\nForward/CalculateLoss/Backward throws; modify Neural.DeepFactor.Train to call\nSetTrainingMode(true) then execute Forward, loss calculation, Backward and\n_optimizer.UpdateParameters(Layers) inside a try block and ensure\nSetTrainingMode(false) is invoked in a finally block so training mode is always\nreset even on exceptions; preserve setting LastLoss from\n_lossFunction.CalculateLoss and still rethrow or allow exceptions to propagate\nafter cleanup as appropriate.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}},{"id":"PRRT_kwDOKSXUF85r7TEb","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepState.cs","line":341,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Custom layers are ignored without reference extraction.**  \n`Forward`/`Backward` rely on `_inputProjection`, `_rnnLayers`, etc. Without `ExtractLayerReferences()`, custom layers won‚Äôt execute.  \n\n\n<details>\n<summary>üõ†Ô∏è Suggested fix</summary>\n\n```diff\n         if (Architecture.Layers is not null && Architecture.Layers.Count > 0)\n         {\n             Layers.AddRange(Architecture.Layers);\n             ValidateCustomLayers(Layers);\n+            ExtractLayerReferences();\n         }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepState.cs` around lines 333 - 339,\nInitializeLayers adds Architecture.Layers and calls ValidateCustomLayers but\ndoesn‚Äôt call ExtractLayerReferences, so Forward/Backward won‚Äôt find\n_inputProjection/_rnnLayers and custom layers are never wired; after\nLayers.AddRange(Architecture.Layers) and ValidateCustomLayers(Layers) call\nExtractLayerReferences() to populate internal references (e.g.,\n_inputProjection, _rnnLayers, etc.) so Forward and Backward can execute custom\nlayers correctly.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7TEd","isResolved":true,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepState.cs","line":null,"body":"_‚ö†Ô∏è Potential issue_ | _üü° Minor_\n\n**Reset training mode even when training fails.**  \nWrap the training block in try/finally to avoid getting stuck in training mode.  \n\n\n<details>\n<summary>üõ†Ô∏è Suggested fix</summary>\n\n```diff\n-        SetTrainingMode(true);\n-\n-        var predictions = Forward(input);\n-        LastLoss = _lossFunction.CalculateLoss(predictions.ToVector(), target.ToVector());\n-\n-        var gradient = _lossFunction.CalculateDerivative(predictions.ToVector(), target.ToVector());\n-        Backward(Tensor<T>.FromVector(gradient, predictions.Shape));\n-\n-        _optimizer.UpdateParameters(Layers);\n-\n-        SetTrainingMode(false);\n+        SetTrainingMode(true);\n+        try\n+        {\n+            var predictions = Forward(input);\n+            LastLoss = _lossFunction.CalculateLoss(predictions.ToVector(), target.ToVector());\n+\n+            var gradient = _lossFunction.CalculateDerivative(predictions.ToVector(), target.ToVector());\n+            Backward(Tensor<T>.FromVector(gradient, predictions.Shape));\n+\n+            _optimizer.UpdateParameters(Layers);\n+        }\n+        finally\n+        {\n+            SetTrainingMode(false);\n+        }\n```\n</details>\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n    public override void Train(Tensor<T> input, Tensor<T> target)\n    {\n        if (!_useNativeMode)\n            throw new InvalidOperationException(\"Training is only supported in native mode.\");\n\n        SetTrainingMode(true);\n        try\n        {\n            var predictions = Forward(input);\n            LastLoss = _lossFunction.CalculateLoss(predictions.ToVector(), target.ToVector());\n\n            var gradient = _lossFunction.CalculateDerivative(predictions.ToVector(), target.ToVector());\n            Backward(Tensor<T>.FromVector(gradient, predictions.Shape));\n\n            _optimizer.UpdateParameters(Layers);\n        }\n        finally\n        {\n            SetTrainingMode(false);\n        }\n    }\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepState.cs` around lines 468 - 483, The\nTrain method can leave the model stuck in training mode on exceptions; wrap the\nmain training sequence between SetTrainingMode(true) and SetTrainingMode(false)\nin a try/finally so SetTrainingMode(false) always runs. Concretely, after\nchecking _useNativeMode and calling SetTrainingMode(true), execute Forward,\nloss/gradient calculation (LastLoss,\n_lossFunction.CalculateLoss/CalculateDerivative), Backward, and\n_optimizer.UpdateParameters(Layers) inside the try block and move\nSetTrainingMode(false) into the finally block to guarantee reset even if\nForward/Backward/UpdateParameters throws.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->\n\n‚úÖ Addressed in commit ddc8139"}]}},{"id":"PRRT_kwDOKSXUF85r7TEi","isResolved":false,"comments":{"nodes":[{"path":"src/Finance/Forecasting/Neural/DeepState.cs","line":1114,"body":"_‚ö†Ô∏è Potential issue_ | _üü† Major_\n\n**Autoregressive helpers drop feature dimensions for multivariate outputs.**  \n`ShiftInputWithPredictions` writes only one value per step and `ConcatenatePredictions` allocates `[batch,totalSteps]`, which truncates feature channels when `_numFeatures > 1`.  \n\n\n<details>\n<summary>üõ†Ô∏è Suggested fix (feature-aware shift + concat)</summary>\n\n```diff\n         int predSteps = predictions.Shape.Length > 1\n             ? predictions.Shape[1]\n             : predictions.Length / Math.Max(1, batchSize);\n+        int predFeatures = predictions.Shape.Length > 2 ? predictions.Shape[2] : 1;\n+        int featureCopy = Math.Min(_numFeatures, predFeatures);\n\n         for (int b = 0; b < batchSize; b++)\n         {\n             int baseOffset = b * totalElements;\n@@\n-            for (int i = 0; i < steps && i < predSteps; i++)\n-            {\n-                int predIdx = b * predSteps + i;\n-                int targetIdx = baseOffset + (totalElements - shift) + i * _numFeatures;\n-                if (predIdx < predictions.Length && targetIdx < newInput.Length)\n-                {\n-                    newInput.Data.Span[targetIdx] = predictions.Data.Span[predIdx];\n-                }\n-            }\n+            for (int step = 0; step < steps && step < predSteps; step++)\n+            {\n+                for (int f = 0; f < featureCopy; f++)\n+                {\n+                    int predIdx = predFeatures > 1\n+                        ? b * predSteps * predFeatures + step * predFeatures + f\n+                        : b * predSteps + step;\n+                    int targetIdx = baseOffset + (totalElements - shift) + step * _numFeatures + f;\n+                    if (predIdx < predictions.Length && targetIdx < newInput.Length)\n+                    {\n+                        newInput.Data.Span[targetIdx] = predictions.Data.Span[predIdx];\n+                    }\n+                }\n+            }\n         }\n@@\n-        if (predictions.Count == 0)\n-        {\n-            return new Tensor<T>(new[] { 1, totalSteps });\n-        }\n-\n-        int batchSize = predictions[0].Shape.Length > 1 ? predictions[0].Shape[0] : 1;\n-        var result = new Tensor<T>(new[] { batchSize, totalSteps });\n+        if (predictions.Count == 0)\n+        {\n+            int emptyFeatures = Math.Max(1, _numFeatures);\n+            var emptyShape = emptyFeatures > 1\n+                ? new[] { 1, totalSteps, emptyFeatures }\n+                : new[] { 1, totalSteps };\n+            return new Tensor<T>(emptyShape);\n+        }\n+\n+        int batchSize = predictions[0].Shape.Length > 1 ? predictions[0].Shape[0] : 1;\n+        int predFeatures = predictions[0].Shape.Length > 2 ? predictions[0].Shape[2] : 1;\n+        int features = Math.Max(_numFeatures, predFeatures);\n+        bool hasFeatureDim = features > 1;\n+        var resultShape = hasFeatureDim\n+            ? new[] { batchSize, totalSteps, features }\n+            : new[] { batchSize, totalSteps };\n+        var result = new Tensor<T>(resultShape);\n         int currentStep = 0;\n\n         foreach (var pred in predictions)\n         {\n-            int predSteps = pred.Shape.Length > 1 ? pred.Shape[1] : pred.Length / batchSize;\n-            int stepsToCopy = Math.Min(predSteps, totalSteps - currentStep);\n-\n-            for (int b = 0; b < batchSize; b++)\n-            {\n-                for (int t = 0; t < stepsToCopy; t++)\n-                {\n-                    int srcIdx = b * predSteps + t;\n-                    int dstIdx = b * totalSteps + currentStep + t;\n-                    if (srcIdx < pred.Length && dstIdx < result.Length)\n-                    {\n-                        result.Data.Span[dstIdx] = pred.Data.Span[srcIdx];\n-                    }\n-                }\n-            }\n+            int predSteps = pred.Shape.Length > 1 ? pred.Shape[1] : pred.Length / Math.Max(1, batchSize);\n+            int predFeat = pred.Shape.Length > 2 ? pred.Shape[2] : 1;\n+            int featureCopy = Math.Min(features, predFeat);\n+            int stepsToCopy = Math.Min(predSteps, totalSteps - currentStep);\n+\n+            for (int b = 0; b < batchSize; b++)\n+            {\n+                for (int t = 0; t < stepsToCopy; t++)\n+                {\n+                    if (hasFeatureDim)\n+                    {\n+                        for (int f = 0; f < featureCopy; f++)\n+                        {\n+                            int srcIdx = predFeat > 1\n+                                ? b * predSteps * predFeat + t * predFeat + f\n+                                : b * predSteps + t;\n+                            int dstIdx = b * totalSteps * features + (currentStep + t) * features + f;\n+                            if (srcIdx < pred.Length && dstIdx < result.Length)\n+                            {\n+                                result.Data.Span[dstIdx] = pred.Data.Span[srcIdx];\n+                            }\n+                        }\n+                    }\n+                    else\n+                    {\n+                        int srcIdx = b * predSteps + t;\n+                        int dstIdx = b * totalSteps + currentStep + t;\n+                        if (srcIdx < pred.Length && dstIdx < result.Length)\n+                        {\n+                            result.Data.Span[dstIdx] = pred.Data.Span[srcIdx];\n+                        }\n+                    }\n+                }\n+            }\n```\n</details>\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn `@src/Finance/Forecasting/Neural/DeepState.cs` around lines 1016 - 1101,\nShiftInputWithPredictions and ConcatenatePredictions currently assume scalar\noutputs per time step and drop feature channels when _numFeatures > 1; update\nboth to copy/concatenate full feature vectors. In ShiftInputWithPredictions\n(method ShiftInputWithPredictions) change the inner copy loops to move blocks of\n_numFeatures (add a loop over feature f from 0.._numFeatures-1 and adjust\nsrcIdx/dstIdx by +f) and when writing predictions write all features for each\npredicted step (compute prediction feature offset and copy _numFeatures values).\nIn ConcatenatePredictions (method ConcatenatePredictions) allocate result for\nall features for each step (use shape [batch, totalSteps * _numFeatures] or\nequivalent flat length), and when copying from each pred tensor copy\n_numFeatures values per time step (loop over features f and adjust srcIdx/dstIdx\naccordingly); ensure predSteps and indexing account for per-step feature\nchannels rather than assuming one value per step.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:medusa:eagle -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->"}]}}]}}}}}