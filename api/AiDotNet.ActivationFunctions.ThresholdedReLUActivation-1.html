<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class ThresholdedReLUActivation&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class ThresholdedReLUActivation&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Implements the Thresholded ReLU activation function, a variant of the standard ReLU function with an adjustable threshold.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1.md&amp;value=---%0Auid%3A%20AiDotNet.ActivationFunctions.ThresholdedReLUActivation%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1">



  <h1 id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1" class="text-break">
Class ThresholdedReLUActivation&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/ThresholdedReLUActivation.cs/#L26"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.ActivationFunctions.html">ActivationFunctions</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Implements the Thresholded ReLU activation function, a variant of the standard ReLU function with an adjustable threshold.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class ThresholdedReLUActivation&lt;T&gt; : ActivationFunctionBase&lt;T&gt;, IActivationFunction&lt;T&gt;, IVectorActivationFunction&lt;T&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for calculations (e.g., float, double).</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html">ActivationFunctionBase</a>&lt;T&gt;</div>
      <div><span class="xref">ThresholdedReLUActivation&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.Interfaces.IActivationFunction-1.html">IActivationFunction</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IVectorActivationFunction-1.html">IVectorActivationFunction</a>&lt;T&gt;</div>
    </dd>
  </dl>


  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_NumOps">ActivationFunctionBase&lt;T&gt;.NumOps</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Engine">ActivationFunctionBase&lt;T&gt;.Engine</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Activate_AiDotNet_Tensors_LinearAlgebra_Vector__0__">ActivationFunctionBase&lt;T&gt;.Activate(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Derivative_AiDotNet_Tensors_LinearAlgebra_Vector__0__">ActivationFunctionBase&lt;T&gt;.Derivative(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Activate_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">ActivationFunctionBase&lt;T&gt;.Activate(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Derivative_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">ActivationFunctionBase&lt;T&gt;.Derivative(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">ActivationFunctionBase&lt;T&gt;.Backward(Tensor&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_SupportsGpuTraining">ActivationFunctionBase&lt;T&gt;.SupportsGpuTraining</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_ForwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">ActivationFunctionBase&lt;T&gt;.ForwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_BackwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">ActivationFunctionBase&lt;T&gt;.BackwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
<b>For Beginners:</b> The Thresholded ReLU (Rectified Linear Unit) is a variation of the standard ReLU activation function.
<p>While a standard ReLU outputs the input value when it's positive and zero when it's negative (f(x) = max(0, x)),
the Thresholded ReLU adds an additional parameter called &quot;theta&quot; (?) that acts as a threshold.</p>
<p>The Thresholded ReLU only activates (returns the input value) when the input exceeds this threshold.
Otherwise, it returns zero. The formula is:</p>
<p>f(x) = x if x &gt; ?, otherwise f(x) = 0</p>
<p>This allows the neural network to ignore small positive activations that might be noise, potentially
creating more robust models. By adjusting the threshold value, you can control how sensitive the
activation function is to input signals.</p>

</div>


  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1__ctor_" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1.#ctor*"></a>

  <h3 id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1__ctor_System_Double_" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1.#ctor(System.Double)">
  ThresholdedReLUActivation(double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/ThresholdedReLUActivation.cs/#L53"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the ThresholdedReLUActivation class with the specified threshold value.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public ThresholdedReLUActivation(double theta = 1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>theta</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The threshold value. Default is 1.0.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1__ctor_System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
<b>For Beginners:</b> The theta parameter controls how "picky" the activation function is.
<ul>
<li>With a higher theta value (e.g., 2.0), the function will only activate for stronger input signals,
ignoring weaker ones.</li>
<li>With a lower theta value (e.g., 0.1), the function will activate for most positive inputs,
behaving more like a standard ReLU.</li>
</ul>
<p>The default value of 1.0 provides a moderate threshold that works well for many applications.
You can adjust this value during experimentation to see what works best for your specific problem.</p>

</div>




  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_SupportsJitCompilation_" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1.SupportsJitCompilation*"></a>

  <h3 id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_SupportsJitCompilation" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1.SupportsJitCompilation">
  SupportsJitCompilation
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/ThresholdedReLUActivation.cs/#L145"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this activation function supports JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsJitCompilation { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True because TensorOperations.ThresholdedReLU provides full forward and backward pass support.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_SupportsJitCompilation_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
ThresholdedReLU supports JIT compilation with full gradient computation.
The backward pass correctly computes gradients: 1 for inputs above threshold, 0 otherwise.
</p>
</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_Activate_" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1.Activate*"></a>

  <h3 id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_Activate__0_" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1.Activate(`0)">
  Activate(T)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/ThresholdedReLUActivation.cs/#L84"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Thresholded ReLU activation function to an input value.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override T Activate(T input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <span class="xref">T</span></dt>
    <dd><p>The input value.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><span class="xref">T</span></dt>
    <dd><p>The input value if it's greater than the threshold, otherwise zero.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_Activate__0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
<b>For Beginners:</b> This method implements the core functionality of the Thresholded ReLU:
<ul>
<li>If the input is greater than the threshold (theta), it returns the input unchanged</li>
<li>If the input is less than or equal to the threshold, it returns zero</li>
</ul>
<p>For example, with the default threshold of 1.0:</p>
<ul>
<li>An input of 2.5 would return 2.5</li>
<li>An input of 0.8 would return 0</li>
<li>An input of -3.0 would return 0</li>
</ul>
<p>This creates a &quot;step&quot; in the activation function at the threshold value.</p>

</div>




  <a id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_ApplyToGraph_" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1.ApplyToGraph*"></a>

  <h3 id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_ApplyToGraph_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1.ApplyToGraph(AiDotNet.Autodiff.ComputationNode{`0})">
  ApplyToGraph(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/ThresholdedReLUActivation.cs/#L159"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies this activation function to a computation graph node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override ComputationNode&lt;T&gt; ApplyToGraph(ComputationNode&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The computation node to apply the activation to.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with ThresholdedReLU activation applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_ApplyToGraph_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method maps to TensorOperations&lt;T&gt;.ThresholdedReLU(input) which handles both
forward and backward passes for JIT compilation.
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></dt>
    <dd><p>Thrown if input is null.</p>
</dd>
  </dl>



  <a id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_Derivative_" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1.Derivative*"></a>

  <h3 id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_Derivative__0_" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1.Derivative(`0)">
  Derivative(T)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/ThresholdedReLUActivation.cs/#L110"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Calculates the derivative of the Thresholded ReLU function for a given input.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override T Derivative(T input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <span class="xref">T</span></dt>
    <dd><p>The input value.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><span class="xref">T</span></dt>
    <dd><p>1 if the input is greater than the threshold, otherwise 0.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_Derivative__0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
<b>For Beginners:</b> The derivative tells us how the output changes when the input changes slightly.
This is crucial for training neural networks through backpropagation.
<p>For Thresholded ReLU:</p>
<ul>
<li>If the input is greater than the threshold, the derivative is 1, meaning the function passes
changes in the input directly to the output.</li>
<li>If the input is less than or equal to the threshold, the derivative is 0, meaning small changes
in the input have no effect on the output.</li>
</ul>
<p>Note that technically, the derivative is undefined exactly at the threshold point, but for
practical purposes in neural networks, we define it as 0 at that point.</p>

</div>




  <a id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_SupportsScalarOperations_" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1.SupportsScalarOperations*"></a>

  <h3 id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_SupportsScalarOperations" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1.SupportsScalarOperations">
  SupportsScalarOperations()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/ThresholdedReLUActivation.cs/#L62"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Indicates whether this activation function supports operations on individual scalar values.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected override bool SupportsScalarOperations()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Always returns true as Thresholded ReLU can operate on individual values.</p>
</dd>
  </dl>











  <a id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_UpdateTheta_" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1.UpdateTheta*"></a>

  <h3 id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_UpdateTheta__0_" data-uid="AiDotNet.ActivationFunctions.ThresholdedReLUActivation`1.UpdateTheta(`0)">
  UpdateTheta(T)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/ThresholdedReLUActivation.cs/#L129"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Updates the threshold value used by the activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void UpdateTheta(T newTheta)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>newTheta</code> <span class="xref">T</span></dt>
    <dd><p>The new threshold value to use.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_ActivationFunctions_ThresholdedReLUActivation_1_UpdateTheta__0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method allows you to change the threshold parameter after the activation function has been created.
This can be useful for experimentation or for implementing adaptive activation functions that change
their behavior during training.
</p>
</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/ThresholdedReLUActivation.cs/#L26" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
