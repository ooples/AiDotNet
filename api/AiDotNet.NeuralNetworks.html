<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Namespace AiDotNet.NeuralNetworks | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Namespace AiDotNet.NeuralNetworks | AiDotNet Documentation ">
      
      
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.NeuralNetworks">

  <h1 id="AiDotNet_NeuralNetworks" data-uid="AiDotNet.NeuralNetworks" class="text-break">Namespace AiDotNet.NeuralNetworks</h1>
  <div class="markdown level0 summary"></div>
  <div class="markdown level0 conceptual"></div>
  <div class="markdown level0 remarks"></div>

    <h3 id="namespaces">
Namespaces
</h3>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.Attention.html">AiDotNet.NeuralNetworks.Attention</a></dt>
      <dd></dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.Diffusion.html">AiDotNet.NeuralNetworks.Diffusion</a></dt>
      <dd></dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.Layers.html">AiDotNet.NeuralNetworks.Layers</a></dt>
      <dd></dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.Metrics.html">AiDotNet.NeuralNetworks.Metrics</a></dt>
      <dd></dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.Tasks.Graph.html">AiDotNet.NeuralNetworks.Tasks.Graph</a></dt>
      <dd></dd>
    </dl>
    <h3 id="classes">
Classes
</h3>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.ACGAN-1.html">ACGAN&lt;T&gt;</a></dt>
      <dd><p>Represents an Auxiliary Classifier Generative Adversarial Network (AC-GAN), which extends
conditional GANs by having the discriminator also predict the class label of the input.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.AttentionNetwork-1.html">AttentionNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a neural network that utilizes attention mechanisms for sequence processing.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.AudioVisualCorrespondenceNetwork-1.html">AudioVisualCorrespondenceNetwork&lt;T&gt;</a></dt>
      <dd><p>Audio-visual correspondence learning network for cross-modal understanding.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.AudioVisualEventLocalizationNetwork-1.html">AudioVisualEventLocalizationNetwork&lt;T&gt;</a></dt>
      <dd><p>Neural network for audio-visual event localization - identifying WHEN and WHERE events occur
in video by jointly analyzing audio and visual streams with precise temporal boundaries.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.Autoencoder-1.html">Autoencoder&lt;T&gt;</a></dt>
      <dd><p>Represents an autoencoder neural network that can compress data into a lower-dimensional representation and reconstruct it.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.BGE-1.html">BGE&lt;T&gt;</a></dt>
      <dd><p>BGE (BAAI General Embedding) neural network implementation.
A state-of-the-art retrieval model known for its high accuracy across diverse benchmarks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.BigGAN-1.html">BigGAN&lt;T&gt;</a></dt>
      <dd><p>BigGAN implementation for large-scale high-fidelity image generation.</p>
<p>For Beginners:
BigGAN is a state-of-the-art GAN architecture that generates extremely high-quality
images by scaling up training in several ways:</p>
<ol>
<li>Using very large batch sizes (256-2048 images at once)</li>
<li>Increasing model capacity (more parameters and feature maps)</li>
<li>Using class information to generate specific types of images</li>
</ol>
<p>Think of it like training an artist:</p>
<ul>
<li>Small batch = showing the artist 1-2 examples at a time</li>
<li>BigGAN batch = showing 256+ examples at once for better learning</li>
<li>Class conditioning = telling the artist exactly what to draw (&quot;draw a cat&quot; vs &quot;draw something&quot;)</li>
</ul>
<p>Key innovations:</p>
<ol>
<li>Large Batch Training: Uses batch sizes of 256-2048 (vs typical 32-128)</li>
<li>Spectral Normalization: Stabilizes training for both G and D</li>
<li>Self-Attention: Helps model long-range dependencies in images</li>
<li>Class Conditioning: Uses class embeddings for controlled generation</li>
<li>Truncation Trick: Trade diversity for quality at generation time</li>
<li>Orthogonal Initialization: Better weight initialization</li>
<li>Skip Connections: Direct paths in generator architecture</li>
</ol>
<p>Based on &quot;Large Scale GAN Training for High Fidelity Natural Image Synthesis&quot;
by Brock et al. (2019)</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.Blip2NeuralNetwork-1.html">Blip2NeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>BLIP-2 (Bootstrapped Language-Image Pre-training 2) neural network for vision-language tasks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.BlipNeuralNetwork-1.html">BlipNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>BLIP (Bootstrapped Language-Image Pre-training) neural network for vision-language tasks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.CapsuleNetwork-1.html">CapsuleNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Capsule Network, a type of neural network that preserves spatial relationships between features.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.ClipModelConfig.html">ClipModelConfig</a></dt>
      <dd><p>Configuration for a CLIP model variant.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.ClipModelLoader.html">ClipModelLoader</a></dt>
      <dd><p>Loads CLIP models from HuggingFace Hub or local directories.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.ClipNeuralNetwork-1.html">ClipNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>CLIP (Contrastive Language-Image Pre-training) neural network that encodes both text
and images into a shared embedding space, enabling cross-modal similarity and zero-shot classification.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.ColBERT-1.html">ColBERT&lt;T&gt;</a></dt>
      <dd><p>ColBERT (Contextualized Late Interaction over BERT) neural network implementation.
Uses token-level representations for high-precision document retrieval.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.ConditionalGAN-1.html">ConditionalGAN&lt;T&gt;</a></dt>
      <dd><p>Represents a Conditional Generative Adversarial Network (cGAN), which generates data conditioned
on additional information such as class labels, attributes, or other contextual data.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.Connection-1.html">Connection&lt;T&gt;</a></dt>
      <dd><p>Represents a connection between two nodes in a neural network, particularly used in evolving neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.ConvolutionalNeuralNetwork-1.html">ConvolutionalNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Convolutional Neural Network (CNN) that processes multi-dimensional data.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.CycleGAN-1.html">CycleGAN&lt;T&gt;</a></dt>
      <dd><p>Represents a CycleGAN for unpaired image-to-image translation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.DCGAN-1.html">DCGAN&lt;T&gt;</a></dt>
      <dd><p>Represents a Deep Convolutional Generative Adversarial Network (DCGAN), an architecture that uses
convolutional and transposed convolutional layers with specific design guidelines for stable training.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.DeepBeliefNetwork-1.html">DeepBeliefNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Deep Belief Network, a generative graphical model composed of multiple layers of Restricted Boltzmann Machines.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.DeepBoltzmannMachine-1.html">DeepBoltzmannMachine&lt;T&gt;</a></dt>
      <dd><p>Represents a Deep Boltzmann Machine (DBM), a hierarchical generative model consisting of multiple layers of stochastic neurons.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.DeepQNetwork-1.html">DeepQNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Deep Q-Network (DQN), a reinforcement learning algorithm that combines Q-learning with deep neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.DenseNetNetwork-1.html">DenseNetNetwork&lt;T&gt;</a></dt>
      <dd><p>Implements the DenseNet (Densely Connected Convolutional Network) architecture.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.DifferentiableNeuralComputer-1.html">DifferentiableNeuralComputer&lt;T&gt;</a></dt>
      <dd><p>Represents a Differentiable Neural Computer (DNC), a neural network architecture that combines neural networks with external memory resources.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.EchoStateNetwork-1.html">EchoStateNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents an Echo State Network (ESN), a type of recurrent neural network with a sparsely connected hidden layer called a reservoir.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.EfficientNetNetwork-1.html">EfficientNetNetwork&lt;T&gt;</a></dt>
      <dd><p>Implements the EfficientNet architecture with compound scaling.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.ExtremeLearningMachine-1.html">ExtremeLearningMachine&lt;T&gt;</a></dt>
      <dd><p>Represents an Extreme Learning Machine (ELM), a type of feedforward neural network with a unique training approach.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.FastText-1.html">FastText&lt;T&gt;</a></dt>
      <dd><p>FastText neural network implementation, an extension of Word2Vec that considers subword information.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.FeedForwardNeuralNetwork-1.html">FeedForwardNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Feed-Forward Neural Network (FFNN) for processing data in a forward path.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.FlamingoNeuralNetwork-1.html">FlamingoNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Flamingo neural network for in-context visual learning and few-shot tasks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.GRUNeuralNetwork-1.html">GRUNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Gated Recurrent Unit (GRU) Neural Network for processing sequential data.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.GenerativeAdversarialNetwork-1.html">GenerativeAdversarialNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Generative Adversarial Network (GAN), a deep learning architecture that consists of two neural networks
(a generator and a discriminator) competing against each other in a zero-sum game.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.Genome-1.html">Genome&lt;T&gt;</a></dt>
      <dd><p>Represents a genome in a neuroevolutionary algorithm, containing a collection of connections between nodes.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.GloVe-1.html">GloVe&lt;T&gt;</a></dt>
      <dd><p>GloVe (Global Vectors for Word Representation) neural network implementation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.Gpt4VisionNeuralNetwork-1.html">Gpt4VisionNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>GPT-4V-style neural network that combines vision understanding with large language model capabilities.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.GraphAttentionNetwork-1.html">GraphAttentionNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Graph Attention Network (GAT) that uses attention mechanisms to process graph-structured data.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.GraphGenerationModel-1.html">GraphGenerationModel&lt;T&gt;</a></dt>
      <dd><p>Represents a Graph Generation Model using Variational Autoencoder (VAE) architecture.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.GraphIsomorphismNetwork-1.html">GraphIsomorphismNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Graph Isomorphism Network (GIN) for powerful graph representation learning.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.GraphNeuralNetwork-1.html">GraphNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Graph Neural Network that can process data represented as graphs.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.GraphSAGENetwork-1.html">GraphSAGENetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a GraphSAGE (Graph Sample and Aggregate) Network for inductive learning on graphs.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.HTMNetwork-1.html">HTMNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Hierarchical Temporal Memory (HTM) network, a biologically-inspired sequence learning algorithm.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.HopeNetwork-1.html">HopeNetwork&lt;T&gt;</a></dt>
      <dd><p>Hope architecture - a self-modifying recurrent neural network variant of Titans
with unbounded levels of in-context learning.
Core innovation of Google's Nested Learning paradigm.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.HopfieldNetwork-1.html">HopfieldNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Hopfield Network, a recurrent neural network designed for pattern storage and retrieval.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.HyperbolicNeuralNetwork-1.html">HyperbolicNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Hyperbolic Neural Network for learning hierarchical representations in Poincare ball space.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.ImageBindNeuralNetwork-1.html">ImageBindNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>ImageBind neural network for binding multiple modalities (6+) into a shared embedding space.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.InfoGAN-1.html">InfoGAN&lt;T&gt;</a></dt>
      <dd><p>Represents an Information Maximizing Generative Adversarial Network (InfoGAN), which learns
disentangled representations in an unsupervised manner by maximizing mutual information
between latent codes and generated observations.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.InstructorEmbedding-1.html">InstructorEmbedding&lt;T&gt;</a></dt>
      <dd><p>Instructor/E5 (Instruction-Tuned) embedding model implementation.
Uses task-specific instructions to adapt embeddings for different use cases.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.LLaVANeuralNetwork-1.html">LLaVANeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>LLaVA (Large Language and Vision Assistant) neural network for visual instruction following.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.LSTMNeuralNetwork-1.html">LSTMNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Long Short-Term Memory (LSTM) Neural Network, which is specialized for processing
sequential data like text, time series, or audio.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.LiquidStateMachine-1.html">LiquidStateMachine&lt;T&gt;</a></dt>
      <dd><p>Represents a Liquid State Machine (LSM), a type of reservoir computing neural network.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.MatryoshkaEmbedding-1.html">MatryoshkaEmbedding&lt;T&gt;</a></dt>
      <dd><p>Matryoshka Representation Learning (MRL) neural network implementation.
Learns nested embeddings where smaller prefixes of the full vector are valid representations.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.MemoryNetwork-1.html">MemoryNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Memory Network, a neural network architecture designed with explicit memory components
for improved reasoning and question answering capabilities.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.MeshCNN-1.html">MeshCNN&lt;T&gt;</a></dt>
      <dd><p>Implements the MeshCNN architecture for processing 3D triangle meshes.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.MixtureOfExpertsNeuralNetwork-1.html">MixtureOfExpertsNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Mixture-of-Experts (MoE) neural network that routes inputs through multiple specialist networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.MobileNetV2Network-1.html">MobileNetV2Network&lt;T&gt;</a></dt>
      <dd><p>Implements the MobileNetV2 architecture for efficient mobile inference.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.MobileNetV3Network-1.html">MobileNetV3Network&lt;T&gt;</a></dt>
      <dd><p>Implements the MobileNetV3 architecture for efficient mobile inference.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.NEAT-1.html">NEAT&lt;T&gt;</a></dt>
      <dd><p>Represents a NeuroEvolution of Augmenting Topologies (NEAT) algorithm implementation, which evolves
neural networks through genetic algorithms.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html">NeuralNetworkArchitecture&lt;T&gt;</a></dt>
      <dd><p>Defines the structure and configuration of a neural network, including its layers, input/output dimensions, and task-specific properties.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkBase-1.html">NeuralNetworkBase&lt;T&gt;</a></dt>
      <dd><p>Base class for all neural network implementations in AiDotNet.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetwork-1.html">NeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>A neural network implementation that processes data through multiple layers to make predictions.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.NeuralTuringMachine-1.html">NeuralTuringMachine&lt;T&gt;</a></dt>
      <dd><p>Represents a Neural Turing Machine, which is a neural network architecture that combines a neural network with external memory.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.OccupancyNeuralNetwork-1.html">OccupancyNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Neural Network specialized for occupancy detection and prediction in spaces.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.OctonionNeuralNetwork-1.html">OctonionNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents an Octonion-valued Neural Network for processing data in 8-dimensional hypercomplex space.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.Pix2Pix-1.html">Pix2Pix&lt;T&gt;</a></dt>
      <dd><p>Represents a Pix2Pix GAN for paired image-to-image translation tasks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.ProgressiveGAN-1.html">ProgressiveGAN&lt;T&gt;</a></dt>
      <dd><p>Production-ready Progressive GAN (ProGAN) implementation that generates high-resolution images
by progressively growing the generator and discriminator during training.</p>
<p>For Beginners:
Progressive GAN is a technique for training GANs that can generate very high-resolution
images (e.g., 1024x1024 pixels). Instead of trying to generate high-resolution images
from the start, it begins by generating small images (e.g., 4x4) and progressively
adds new layers to both the generator and discriminator to increase the resolution
(4x4 → 8x8 → 16x16 → 32x32 → 64x64 → 128x128 → 256x256 → 1024x1024).</p>
<p>Key innovations:</p>
<ol>
<li>Progressive Growing: Start with low resolution and gradually add layers</li>
<li>Smooth Fade-in: New layers are faded in smoothly using a blending parameter (alpha)</li>
<li>Minibatch Standard Deviation: Helps prevent mode collapse by adding diversity</li>
<li>Equalized Learning Rate: Normalizes weights at runtime for better training dynamics</li>
<li>Pixel Normalization: Normalizes feature vectors in generator to prevent escalation</li>
</ol>
<p>Based on &quot;Progressive Growing of GANs for Improved Quality, Stability, and Variation&quot;
by Karras et al. (2018)</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.QuantumNeuralNetwork-1.html">QuantumNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Quantum Neural Network, which combines quantum computing principles with neural network architecture.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.RadialBasisFunctionNetwork-1.html">RadialBasisFunctionNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Radial Basis Function Network, which is a type of neural network that uses radial basis functions as activation functions.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.RecurrentNeuralNetwork-1.html">RecurrentNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Recurrent Neural Network, which is a type of neural network designed to process sequential data by maintaining an internal state.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.ResNetNetwork-1.html">ResNetNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a ResNet (Residual Network) neural network architecture for image classification.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.ResidualNeuralNetwork-1.html">ResidualNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Residual Neural Network, which is a type of neural network that uses skip connections to address the vanishing gradient problem in deep networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.RestrictedBoltzmannMachine-1.html">RestrictedBoltzmannMachine&lt;T&gt;</a></dt>
      <dd><p>Represents a Restricted Boltzmann Machine, which is a type of neural network that learns probability distributions over its inputs.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.SAGAN-1.html">SAGAN&lt;T&gt;</a></dt>
      <dd><p>Self-Attention GAN (SAGAN) implementation that uses self-attention mechanisms
to model long-range dependencies in generated images.</p>
<p>For Beginners:
Traditional CNNs in GANs only look at nearby pixels (local receptive fields).
This works well for textures and local patterns, but struggles with global
structure and long-range relationships (like making sure both eyes of a face
look similar, or ensuring consistent geometric patterns).</p>
<p>Self-Attention solves this by letting each pixel &quot;attend to&quot; all other pixels,
similar to how Transformers work in NLP. Think of it as:</p>
<ul>
<li>CNN: &quot;I can only see my immediate neighbors&quot;</li>
<li>Self-Attention: &quot;I can see the entire image and decide what's important&quot;</li>
</ul>
<p>Example: When generating a dog's face:</p>
<ul>
<li>CNN: Might make one ear pointy and one floppy (inconsistent)</li>
<li>SAGAN: Notices both ears and makes them match (consistent)</li>
</ul>
<p>Key innovations:</p>
<ol>
<li>Self-Attention Layers: Allow modeling of long-range dependencies</li>
<li>Spectral Normalization: Stabilizes training for both G and D</li>
<li>Hinge Loss: More stable than standard GAN loss</li>
<li>Two Time-Scale Update Rule (TTUR): Different learning rates for G and D</li>
<li>Conditional Batch Normalization: For class-conditional generation</li>
</ol>
<p>Based on &quot;Self-Attention Generative Adversarial Networks&quot; by Zhang et al. (2019)</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.SGPT-1.html">SGPT&lt;T&gt;</a></dt>
      <dd><p>SGPT (Sentence GPT) neural network implementation using decoder-only transformer architectures.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.SPLADE-1.html">SPLADE&lt;T&gt;</a></dt>
      <dd><p>SPLADE (Sparse Lexical and Expansion Model) neural network implementation.
Maps text to a high-dimensional sparse vector in the vocabulary space.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.SelfOrganizingMap-1.html">SelfOrganizingMap&lt;T&gt;</a></dt>
      <dd><p>Represents a Self-Organizing Map, which is an unsupervised neural network that produces a low-dimensional representation of input data.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.SiameseNetwork-1.html">SiameseNetwork&lt;T&gt;</a></dt>
      <dd><p>Implements a Siamese Neural Network for comparing pairs of inputs and determining their similarity.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.SiameseNeuralNetwork-1.html">SiameseNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Siamese Neural Network implementation for dual-encoder comparison and similarity learning.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.SimCSE-1.html">SimCSE&lt;T&gt;</a></dt>
      <dd><p>SimCSE (Simple Contrastive Learning of Sentence Embeddings) neural network implementation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.SparseNeuralNetwork-1.html">SparseNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Sparse Neural Network with efficient sparse weight matrices.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.SpikingNeuralNetwork-1.html">SpikingNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a Spiking Neural Network, which is a type of neural network that more closely models biological neurons with temporal dynamics.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.SpiralNet-1.html">SpiralNet&lt;T&gt;</a></dt>
      <dd><p>Implements the SpiralNet++ architecture for mesh-based deep learning.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.StyleGAN-1.html">StyleGAN&lt;T&gt;</a></dt>
      <dd><p>Represents a StyleGAN (Style-Based Generator Architecture for GANs) that generates
high-quality images with fine-grained control over image style at different levels.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.SuperNet-1.html">SuperNet&lt;T&gt;</a></dt>
      <dd><p>SuperNet implementation for gradient-based neural architecture search (DARTS).
Implements a differentiable architecture search by maintaining architecture parameters (alpha)
and network weights simultaneously.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.TransformerArchitecture-1.html">TransformerArchitecture&lt;T&gt;</a></dt>
      <dd><p>Defines the architecture configuration for a Transformer neural network.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.TransformerEmbeddingNetwork-1.html">TransformerEmbeddingNetwork&lt;T&gt;</a></dt>
      <dd><p>A customizable Transformer-based embedding network.
This serves as the high-performance foundation for modern sentence and document encoders.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.Transformer-1.html">Transformer&lt;T&gt;</a></dt>
      <dd><p>Represents a Transformer neural network architecture, which is particularly effective for
sequence-based tasks like natural language processing.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.UNet3D-1.html">UNet3D&lt;T&gt;</a></dt>
      <dd><p>Represents a 3D U-Net neural network for volumetric semantic segmentation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.UnifiedMultimodalNetwork-1.html">UnifiedMultimodalNetwork&lt;T&gt;</a></dt>
      <dd><p>Unified multimodal network that handles text, images, audio, and video
in a single architecture with cross-modal attention and any-to-any generation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.VGGNetwork-1.html">VGGNetwork&lt;T&gt;</a></dt>
      <dd><p>Represents a VGG (Visual Geometry Group) neural network architecture for image classification.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.VariationalAutoencoder-1.html">VariationalAutoencoder&lt;T&gt;</a></dt>
      <dd><p>Represents a Variational Autoencoder (VAE) neural network architecture, which is used for
generating new data similar to the training data and learning compressed representations.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.VideoCLIPNeuralNetwork-1.html">VideoCLIPNeuralNetwork&lt;T&gt;</a></dt>
      <dd><p>VideoCLIP neural network for video-text alignment and temporal understanding.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.VisionTransformer-1.html">VisionTransformer&lt;T&gt;</a></dt>
      <dd><p>Implements the Vision Transformer (ViT) architecture for image classification tasks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.VoxelCNN-1.html">VoxelCNN&lt;T&gt;</a></dt>
      <dd><p>Represents a Voxel-based 3D Convolutional Neural Network for processing volumetric data.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.WGANGP-1.html">WGANGP&lt;T&gt;</a></dt>
      <dd><p>Represents a Wasserstein GAN with Gradient Penalty (WGAN-GP), an improved version of WGAN
that uses gradient penalty instead of weight clipping to enforce the Lipschitz constraint.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.WGAN-1.html">WGAN&lt;T&gt;</a></dt>
      <dd><p>Represents a Wasserstein Generative Adversarial Network (WGAN), which uses the Wasserstein distance
(Earth Mover's distance) to measure the difference between the generated and real data distributions.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.Word2Vec-1.html">Word2Vec&lt;T&gt;</a></dt>
      <dd><p>Word2Vec neural network implementation supporting both Skip-Gram and CBOW architectures.</p>
</dd>
    </dl>
    <h3 id="enums">
Enums
</h3>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.NeuralNetworks.TransformerEmbeddingNetwork-1.PoolingStrategy.html">TransformerEmbeddingNetwork&lt;T&gt;.PoolingStrategy</a></dt>
      <dd><p>Defines the available pooling strategies for creating a single sentence embedding.</p>
</dd>
    </dl>


</article>

        <div class="contribution d-print-none">
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
