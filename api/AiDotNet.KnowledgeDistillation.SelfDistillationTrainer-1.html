<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class SelfDistillationTrainer&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class SelfDistillationTrainer&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Implements self-distillation where a model acts as its own teacher to improve calibration and generalization.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1.md&amp;value=---%0Auid%3A%20AiDotNet.KnowledgeDistillation.SelfDistillationTrainer%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.KnowledgeDistillation.SelfDistillationTrainer`1">



  <h1 id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1" data-uid="AiDotNet.KnowledgeDistillation.SelfDistillationTrainer`1" class="text-break">
Class SelfDistillationTrainer&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/KnowledgeDistillation/SelfDistillationTrainer.cs/#L51"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.KnowledgeDistillation.html">KnowledgeDistillation</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Implements self-distillation where a model acts as its own teacher to improve calibration and generalization.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class SelfDistillationTrainer&lt;T&gt; : KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;, IKnowledgeDistillationTrainer&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type for calculations (e.g., double, float).</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html">KnowledgeDistillationTrainerBase</a>&lt;T, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;&gt;</div>
      <div><span class="xref">SelfDistillationTrainer&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.Interfaces.IKnowledgeDistillationTrainer-3.html">IKnowledgeDistillationTrainer</a>&lt;T, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;&gt;</div>
    </dd>
  </dl>


  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_NumOps">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.NumOps</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_Random">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.Random</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_Teacher">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.Teacher</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_DistillationStrategy">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.DistillationStrategy</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_TrainBatch_System_Func__1__2__System_Action__2__AiDotNet_Tensors_LinearAlgebra_Vector__1__AiDotNet_Tensors_LinearAlgebra_Vector__2__">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.TrainBatch(Func&lt;Vector&lt;T&gt;, Vector&lt;T&gt;&gt;, Action&lt;Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_Train_System_Func__1__2__System_Action__2__AiDotNet_Tensors_LinearAlgebra_Vector__1__AiDotNet_Tensors_LinearAlgebra_Vector__2__System_Int32_System_Int32_AiDotNet_Tensors_LinearAlgebra_Vector__1__AiDotNet_Tensors_LinearAlgebra_Vector__2__AiDotNet_Interfaces_ICheckpointableModel_System_Action_System_Int32__0__">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.Train(Func&lt;Vector&lt;T&gt;, Vector&lt;T&gt;&gt;, Action&lt;Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;, int, int, Vector&lt;Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;, ICheckpointableModel, Action&lt;int, T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_Train_System_Func__1__2__System_Action__2__AiDotNet_Tensors_LinearAlgebra_Vector__1__AiDotNet_Tensors_LinearAlgebra_Vector__2__System_Int32_System_Int32_System_Action_System_Int32__0__">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.Train(Func&lt;Vector&lt;T&gt;, Vector&lt;T&gt;&gt;, Action&lt;Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;, int, int, Action&lt;int, T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_Evaluate_System_Func__1__2__AiDotNet_Tensors_LinearAlgebra_Vector__1__AiDotNet_Tensors_LinearAlgebra_Vector__2__">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.Evaluate(Func&lt;Vector&lt;T&gt;, Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_ShuffleData_AiDotNet_Tensors_LinearAlgebra_Vector__1__AiDotNet_Tensors_LinearAlgebra_Vector__2__">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.ShuffleData(Vector&lt;Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_FisherYatesShuffle_System_Int32_">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.FisherYatesShuffle(int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_GetTeacherPredictions__1_System_Int32_">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.GetTeacherPredictions(Vector&lt;T&gt;, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_IsCorrectPrediction__2__2_">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.IsCorrectPrediction(Vector&lt;T&gt;, Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_ArgMax_AiDotNet_Tensors_LinearAlgebra_Vector__0__">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.ArgMax(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_OnTrainingStart_AiDotNet_Tensors_LinearAlgebra_Vector__1__AiDotNet_Tensors_LinearAlgebra_Vector__2__">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.OnTrainingStart(Vector&lt;Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_OnTrainingEnd_AiDotNet_Tensors_LinearAlgebra_Vector__1__AiDotNet_Tensors_LinearAlgebra_Vector__2__">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.OnTrainingEnd(Vector&lt;Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_OnEpochStart_System_Int32_AiDotNet_Tensors_LinearAlgebra_Vector__1__AiDotNet_Tensors_LinearAlgebra_Vector__2__">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.OnEpochStart(int, Vector&lt;Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_OnEpochEnd_System_Int32__0_">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.OnEpochEnd(int, T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.KnowledgeDistillation.KnowledgeDistillationTrainerBase-3.html#AiDotNet_KnowledgeDistillation_KnowledgeDistillationTrainerBase_3_OnValidationComplete_System_Int32_System_Double_">KnowledgeDistillationTrainerBase&lt;T, Vector&lt;T&gt;, Vector&lt;T&gt;&gt;.OnValidationComplete(int, double)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p><b>For Beginners:</b> Self-distillation is a clever technique where a model learns from itself!
Instead of using a separate larger teacher, you train a model normally, then use it as a teacher
to train itself again. This often improves:
- **Calibration**: Model confidence matches actual accuracy
- **Generalization**: Better performance on unseen data
- **Robustness**: Less sensitive to noisy labels or adversarial examples</p>
<p><b>How It Works:</b>
1. Train model normally on hard labels (standard training)
2. Save the trained model's predictions
3. Retrain the model using its own soft predictions as teacher
4. Repeat for multiple generations if desired</p>
<p><b>Real-world Analogy:</b>
Imagine studying for an exam, then teaching the material to yourself as if you were a student.
By explaining concepts in your own words, you deepen your understanding and identify gaps
in your knowledge. Self-distillation works similarly for neural networks.</p>
<p><b>Variants:</b>
- **Iterative Self-Distillation**: Multiple rounds of self-teaching
- **Born-Again Networks**: Same architecture, trained from scratch with self as teacher
- **Online Self-Distillation**: Student learns from earlier checkpoints of itself</p>
<p><b>Benefits:</b>
- No need for a separate teacher model
- Improves calibration without model compression
- Can be combined with data augmentation for better regularization
- Often provides 1-3% accuracy improvement for free</p>
<p><b>When to Use:</b>
- You want better calibrated predictions
- You have limited model capacity (can't afford a larger teacher)
- You want to improve an existing trained model
- You're training on noisy or imperfect labels</p>
<p><b>References:</b>
- Furlanello, T., et al. (2018). Born Again Neural Networks. ICML.
- Zhang, L., et al. (2019). Be Your Own Teacher: Improve the Performance of Convolutional Neural Networks via Self-Distillation.</p>
</div>


  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1__ctor_" data-uid="AiDotNet.KnowledgeDistillation.SelfDistillationTrainer`1.#ctor*"></a>

  <h3 id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1__ctor_AiDotNet_Interfaces_IDistillationStrategy__0__System_Int32_System_Nullable_System_Int32__" data-uid="AiDotNet.KnowledgeDistillation.SelfDistillationTrainer`1.#ctor(AiDotNet.Interfaces.IDistillationStrategy{`0},System.Int32,System.Nullable{System.Int32})">
  SelfDistillationTrainer(IDistillationStrategy&lt;T&gt;, int, int?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/KnowledgeDistillation/SelfDistillationTrainer.cs/#L104"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the SelfDistillationTrainer class.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public SelfDistillationTrainer(IDistillationStrategy&lt;T&gt; distillationStrategy, int generations = 1, int? seed = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>distillationStrategy</code> <a class="xref" href="AiDotNet.Interfaces.IDistillationStrategy-1.html">IDistillationStrategy</a>&lt;T&gt;</dt>
    <dd><p>The strategy for computing distillation loss.</p>
</dd>
    <dt><code>generations</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Number of self-distillation generations (default 1).
More generations can improve performance but take longer to train.</p>
</dd>
    <dt><code>seed</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>?</dt>
    <dd><p>Optional random seed for reproducibility.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1__ctor_AiDotNet_Interfaces_IDistillationStrategy__0__System_Int32_System_Nullable_System_Int32___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Beginners:</b> Generations control how many times the model relearns from itself:
- 1 generation: Train normally (standard training, no self-distillation)
- 2 generations: Train, then retrain using self as teacher (first self-distillation)
- 3 generations: Train → self-teach → self-teach again
- More generations: Diminishing returns, usually not worth it beyond 2-3</p>
<p>Example:
<pre><code class="lang-csharp">var distillationLoss = new DistillationLoss&lt;double&gt;(temperature: 3.0, alpha: 0.5);
var selfTrainer = new SelfDistillationTrainer&lt;double&gt;(distillationLoss, generations: 2);</code></pre>

</div>




  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1_EMADecay_" data-uid="AiDotNet.KnowledgeDistillation.SelfDistillationTrainer`1.EMADecay*"></a>

  <h3 id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1_EMADecay" data-uid="AiDotNet.KnowledgeDistillation.SelfDistillationTrainer`1.EMADecay">
  EMADecay
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/KnowledgeDistillation/SelfDistillationTrainer.cs/#L70"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the EMA decay rate (default 0.99). Higher values give more weight to history.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double EMADecay { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd></dd>
  </dl>





  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentoutofrangeexception">ArgumentOutOfRangeException</a></dt>
    <dd><p>Thrown when value is not between 0 and 1.</p>
</dd>
  </dl>



  <a id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1_UseEMA_" data-uid="AiDotNet.KnowledgeDistillation.SelfDistillationTrainer`1.UseEMA*"></a>

  <h3 id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1_UseEMA" data-uid="AiDotNet.KnowledgeDistillation.SelfDistillationTrainer`1.UseEMA">
  UseEMA
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/KnowledgeDistillation/SelfDistillationTrainer.cs/#L64"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets whether to use exponential moving average for teacher predictions.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public bool UseEMA { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1_UseEMA_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Beginners:</b> EMA smooths out the teacher's predictions over time,
making them more stable and reliable. This can improve training stability.</p>
</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1_GetTeacherPredictions_" data-uid="AiDotNet.KnowledgeDistillation.SelfDistillationTrainer`1.GetTeacherPredictions*"></a>

  <h3 id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1_GetTeacherPredictions_AiDotNet_Tensors_LinearAlgebra_Vector__0__System_Int32_" data-uid="AiDotNet.KnowledgeDistillation.SelfDistillationTrainer`1.GetTeacherPredictions(AiDotNet.Tensors.LinearAlgebra.Vector{`0},System.Int32)">
  GetTeacherPredictions(Vector&lt;T&gt;, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/KnowledgeDistillation/SelfDistillationTrainer.cs/#L134"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets teacher predictions from the cached predictions dictionary (for self-distillation).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected override Vector&lt;T&gt; GetTeacherPredictions(Vector&lt;T&gt; input, int index)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The input data to look up cached predictions for.</p>
</dd>
    <dt><code>index</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The index in the training batch (unused - we use input for lookup).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>Cached teacher prediction for this input.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1_GetTeacherPredictions_AiDotNet_Tensors_LinearAlgebra_Vector__0__System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Self-Distillation:</b> Instead of calling a separate teacher model,
we return predictions that were cached from the previous generation. We use the input
itself as the key (via reference equality) to handle shuffled batches correctly.</p>
<p><b>Generation 0 Handling:</b> When no cached predictions exist (first generation),
we use the student's own predictions as the teacher. This makes distillation a no-op for
generation 0, effectively training normally. This avoids dimension mismatches since the
placeholder teacher has OutputDimension = 0.</p>
</div>




  <a id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1_TrainMultipleGenerations_" data-uid="AiDotNet.KnowledgeDistillation.SelfDistillationTrainer`1.TrainMultipleGenerations*"></a>

  <h3 id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1_TrainMultipleGenerations_System_Func_AiDotNet_Tensors_LinearAlgebra_Vector__0__AiDotNet_Tensors_LinearAlgebra_Vector__0___System_Action_AiDotNet_Tensors_LinearAlgebra_Vector__0___AiDotNet_Tensors_LinearAlgebra_Vector_AiDotNet_Tensors_LinearAlgebra_Vector__0___AiDotNet_Tensors_LinearAlgebra_Vector_AiDotNet_Tensors_LinearAlgebra_Vector__0___System_Int32_System_Int32_System_Action_System_Int32__0__" data-uid="AiDotNet.KnowledgeDistillation.SelfDistillationTrainer`1.TrainMultipleGenerations(System.Func{AiDotNet.Tensors.LinearAlgebra.Vector{`0},AiDotNet.Tensors.LinearAlgebra.Vector{`0}},System.Action{AiDotNet.Tensors.LinearAlgebra.Vector{`0}},AiDotNet.Tensors.LinearAlgebra.Vector{AiDotNet.Tensors.LinearAlgebra.Vector{`0}},AiDotNet.Tensors.LinearAlgebra.Vector{AiDotNet.Tensors.LinearAlgebra.Vector{`0}},System.Int32,System.Int32,System.Action{System.Int32,`0})">
  TrainMultipleGenerations(Func&lt;Vector&lt;T&gt;, Vector&lt;T&gt;&gt;, Action&lt;Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;, Vector&lt;Vector&lt;T&gt;&gt;, int, int, Action&lt;int, T&gt;?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/KnowledgeDistillation/SelfDistillationTrainer.cs/#L193"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs self-distillation training for the specified number of generations.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void TrainMultipleGenerations(Func&lt;Vector&lt;T&gt;, Vector&lt;T&gt;&gt; modelForward, Action&lt;Vector&lt;T&gt;&gt; modelBackward, Vector&lt;Vector&lt;T&gt;&gt; trainInputs, Vector&lt;Vector&lt;T&gt;&gt; trainLabels, int epochs, int batchSize = 32, Action&lt;int, T&gt;? onGenerationComplete = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>modelForward</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.func-2">Func</a>&lt;<a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;&gt;</dt>
    <dd><p>Function to perform forward pass and get logits.</p>
</dd>
    <dt><code>modelBackward</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.action-1">Action</a>&lt;<a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;&gt;</dt>
    <dd><p>Function to perform backward pass with gradients.</p>
</dd>
    <dt><code>trainInputs</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;<a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;&gt;</dt>
    <dd><p>Training input data.</p>
</dd>
    <dt><code>trainLabels</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;<a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;&gt;</dt>
    <dd><p>Training labels.</p>
</dd>
    <dt><code>epochs</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Number of epochs per generation.</p>
</dd>
    <dt><code>batchSize</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Batch size for training.</p>
</dd>
    <dt><code>onGenerationComplete</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.action-2">Action</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>, T&gt;</dt>
    <dd><p>Optional callback invoked after each generation with (generation, avgLoss).</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_KnowledgeDistillation_SelfDistillationTrainer_1_TrainMultipleGenerations_System_Func_AiDotNet_Tensors_LinearAlgebra_Vector__0__AiDotNet_Tensors_LinearAlgebra_Vector__0___System_Action_AiDotNet_Tensors_LinearAlgebra_Vector__0___AiDotNet_Tensors_LinearAlgebra_Vector_AiDotNet_Tensors_LinearAlgebra_Vector__0___AiDotNet_Tensors_LinearAlgebra_Vector_AiDotNet_Tensors_LinearAlgebra_Vector__0___System_Int32_System_Int32_System_Action_System_Int32__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Beginners:</b> This method runs the complete self-distillation process:
1. **Generation 0**: Train model normally (if starting from scratch)
2. **Generation 1**: Retrain using self as teacher
3. **Generation 2+**: Continue if requested</p>
<p>Each generation:
- Saves current model predictions as "teacher"
- Retrains model to match both teacher predictions and true labels
- Typically sees 0.5-2% improvement per generation</p>
<p><b>Training Tips:</b>
- Use temperature 2-4 (lower than standard distillation)
- Set alpha = 0.5 (equal weight to self and labels)
- Train for fewer epochs in later generations (half of first)
- Watch for overfitting in later generations</p>
</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/KnowledgeDistillation/SelfDistillationTrainer.cs/#L51" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
