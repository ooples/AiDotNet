<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class VideoUNetPredictor&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class VideoUNetPredictor&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="3D U-Net architecture for video noise prediction in diffusion models.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1.md&amp;value=---%0Auid%3A%20AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1">



  <h1 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1" class="text-break">
Class VideoUNetPredictor&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L53"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.Diffusion.html">Diffusion</a>.<a class="xref" href="AiDotNet.Diffusion.NoisePredictors.html">NoisePredictors</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>3D U-Net architecture for video noise prediction in diffusion models.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class VideoUNetPredictor&lt;T&gt; : NoisePredictorBase&lt;T&gt;, INoisePredictor&lt;T&gt;, IFullModel&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;, IModel&lt;Tensor&lt;T&gt;, Tensor&lt;T&gt;, ModelMetadata&lt;T&gt;&gt;, IModelSerializer, ICheckpointableModel, IParameterizable&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;, IFeatureAware, IFeatureImportance&lt;T&gt;, ICloneable&lt;IFullModel&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;&gt;, IGradientComputable&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;, IJitCompilable&lt;T&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for calculations.</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html">NoisePredictorBase</a>&lt;T&gt;</div>
      <div><span class="xref">VideoUNetPredictor&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.Interfaces.INoisePredictor-1.html">INoisePredictor</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IFullModel-3.html">IFullModel</a>&lt;T, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IModel-3.html">IModel</a>&lt;<a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;, <a class="xref" href="AiDotNet.Models.ModelMetadata-1.html">ModelMetadata</a>&lt;T&gt;&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IModelSerializer.html">IModelSerializer</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.ICheckpointableModel.html">ICheckpointableModel</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.IParameterizable-3.html">IParameterizable</a>&lt;T, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IFeatureAware.html">IFeatureAware</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.IFeatureImportance-1.html">IFeatureImportance</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.ICloneable-1.html">ICloneable</a>&lt;<a class="xref" href="AiDotNet.Interfaces.IFullModel-3.html">IFullModel</a>&lt;T, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;&gt;&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IGradientComputable-3.html">IGradientComputable</a>&lt;T, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IJitCompilable-1.html">IJitCompilable</a>&lt;T&gt;</div>
    </dd>
  </dl>


  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_NumOps">NoisePredictorBase&lt;T&gt;.NumOps</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_RandomGenerator">NoisePredictorBase&lt;T&gt;.RandomGenerator</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_LossFunction">NoisePredictorBase&lt;T&gt;.LossFunction</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_DefaultLossFunction">NoisePredictorBase&lt;T&gt;.DefaultLossFunction</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_SupportsJitCompilation">NoisePredictorBase&lt;T&gt;.SupportsJitCompilation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_GetTimestepEmbedding_System_Int32_">NoisePredictorBase&lt;T&gt;.GetTimestepEmbedding(int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_Train_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">NoisePredictorBase&lt;T&gt;.Train(Tensor&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_Predict_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">NoisePredictorBase&lt;T&gt;.Predict(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_GetModelMetadata">NoisePredictorBase&lt;T&gt;.GetModelMetadata()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_WithParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__">NoisePredictorBase&lt;T&gt;.WithParameters(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_Serialize">NoisePredictorBase&lt;T&gt;.Serialize()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_Deserialize_System_Byte___">NoisePredictorBase&lt;T&gt;.Deserialize(byte[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_SaveModel_System_String_">NoisePredictorBase&lt;T&gt;.SaveModel(string)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_LoadModel_System_String_">NoisePredictorBase&lt;T&gt;.LoadModel(string)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_SaveState_System_IO_Stream_">NoisePredictorBase&lt;T&gt;.SaveState(Stream)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_LoadState_System_IO_Stream_">NoisePredictorBase&lt;T&gt;.LoadState(Stream)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_GetActiveFeatureIndices">NoisePredictorBase&lt;T&gt;.GetActiveFeatureIndices()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_SetActiveFeatureIndices_System_Collections_Generic_IEnumerable_System_Int32__">NoisePredictorBase&lt;T&gt;.SetActiveFeatureIndices(IEnumerable&lt;int&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_IsFeatureUsed_System_Int32_">NoisePredictorBase&lt;T&gt;.IsFeatureUsed(int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_GetFeatureImportance">NoisePredictorBase&lt;T&gt;.GetFeatureImportance()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_ComputeGradients_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Interfaces_ILossFunction__0__">NoisePredictorBase&lt;T&gt;.ComputeGradients(Tensor&lt;T&gt;, Tensor&lt;T&gt;, ILossFunction&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_ApplyGradients_AiDotNet_Tensors_LinearAlgebra_Vector__0___0_">NoisePredictorBase&lt;T&gt;.ApplyGradients(Vector&lt;T&gt;, T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0___">NoisePredictorBase&lt;T&gt;.ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Diffusion.NoisePredictors.NoisePredictorBase-1.html#AiDotNet_Diffusion_NoisePredictors_NoisePredictorBase_1_SampleNoise_System_Int32___System_Random_">NoisePredictorBase&lt;T&gt;.SampleNoise(int[], Random)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>

  <dl class="typelist extensionMethods">
    <dt>Extension Methods</dt>
    <dd>
  <div>
      <a class="xref" href="AiDotNet.DistributedTraining.DistributedExtensions.html#AiDotNet_DistributedTraining_DistributedExtensions_AsDistributedForHighBandwidth__3_AiDotNet_Interfaces_IFullModel___0___1___2__AiDotNet_DistributedTraining_ICommunicationBackend___0__">DistributedExtensions.AsDistributedForHighBandwidth&lt;T, TInput, TOutput&gt;(IFullModel&lt;T, TInput, TOutput&gt;, ICommunicationBackend&lt;T&gt;)</a>
  </div>
  <div>
      <a class="xref" href="AiDotNet.DistributedTraining.DistributedExtensions.html#AiDotNet_DistributedTraining_DistributedExtensions_AsDistributedForLowBandwidth__3_AiDotNet_Interfaces_IFullModel___0___1___2__AiDotNet_DistributedTraining_ICommunicationBackend___0__">DistributedExtensions.AsDistributedForLowBandwidth&lt;T, TInput, TOutput&gt;(IFullModel&lt;T, TInput, TOutput&gt;, ICommunicationBackend&lt;T&gt;)</a>
  </div>
  <div>
      <a class="xref" href="AiDotNet.DistributedTraining.DistributedExtensions.html#AiDotNet_DistributedTraining_DistributedExtensions_AsDistributed__3_AiDotNet_Interfaces_IFullModel___0___1___2__AiDotNet_DistributedTraining_ICommunicationBackend___0__">DistributedExtensions.AsDistributed&lt;T, TInput, TOutput&gt;(IFullModel&lt;T, TInput, TOutput&gt;, ICommunicationBackend&lt;T&gt;)</a>
  </div>
  <div>
      <a class="xref" href="AiDotNet.DistributedTraining.DistributedExtensions.html#AiDotNet_DistributedTraining_DistributedExtensions_AsDistributed__3_AiDotNet_Interfaces_IFullModel___0___1___2__AiDotNet_DistributedTraining_IShardingConfiguration___0__">DistributedExtensions.AsDistributed&lt;T, TInput, TOutput&gt;(IFullModel&lt;T, TInput, TOutput&gt;, IShardingConfiguration&lt;T&gt;)</a>
  </div>
  </dd></dl>



  <h2 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
The VideoUNetPredictor extends the standard U-Net architecture to handle
video data by incorporating 3D convolutions and temporal attention.
This is the core noise prediction network used in video diffusion models
like Stable Video Diffusion.
</p>
<p>
<b>For Beginners:</b> While a regular U-Net processes single images,
VideoUNet processes sequences of frames as a 3D volume:
<p>Regular U-Net:</p>
<ul>
<li>Input: [batch, channels, height, width]</li>
<li>2D convolutions across spatial dimensions only</li>
<li>Each image processed independently</li>
</ul>
<p>Video U-Net:</p>
<ul>
<li>Input: [batch, channels, frames, height, width]</li>
<li>3D convolutions across space AND time</li>
<li>Frames are processed together, understanding motion</li>
</ul>
<p>Key features:</p>
<ul>
<li>Temporal convolutions capture motion patterns</li>
<li>Temporal attention for long-range frame relationships</li>
<li>Skip connections across both space and time</li>
<li>Image conditioning for image-to-video generation</li>
</ul>
<p>Used in: Stable Video Diffusion, ModelScope, VideoCrafter</p>

<p>
Architecture details:
- Encoder: 3D ResBlocks with temporal + spatial attention
- Middle: Multiple 3D attention blocks
- Decoder: 3D ResBlocks with skip connections
- Temporal convolutions with kernel size 3 across frames
</p>
</div>


  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1__ctor_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.#ctor*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1__ctor_System_Int32_System_Nullable_System_Int32__System_Int32_System_Int32___System_Int32_System_Int32___System_Int32_System_Int32_System_Int32_System_Boolean_AiDotNet_Interfaces_ILossFunction__0__System_Nullable_System_Int32__" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.#ctor(System.Int32,System.Nullable{System.Int32},System.Int32,System.Int32[],System.Int32,System.Int32[],System.Int32,System.Int32,System.Int32,System.Boolean,AiDotNet.Interfaces.ILossFunction{`0},System.Nullable{System.Int32})">
  VideoUNetPredictor(int, int?, int, int[]?, int, int[]?, int, int, int, bool, ILossFunction&lt;T&gt;?, int?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L200"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the VideoUNetPredictor class.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public VideoUNetPredictor(int inputChannels = 4, int? outputChannels = null, int baseChannels = 320, int[]? channelMultipliers = null, int numResBlocks = 2, int[]? attentionResolutions = null, int numTemporalLayers = 1, int contextDim = 1024, int numHeads = 8, bool supportsImageConditioning = true, ILossFunction&lt;T&gt;? lossFunction = null, int? seed = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputChannels</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Number of input channels (default: 4 for latent diffusion).</p>
</dd>
    <dt><code>outputChannels</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>?</dt>
    <dd><p>Number of output channels (default: same as input).</p>
</dd>
    <dt><code>baseChannels</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Base channel count (default: 320).</p>
</dd>
    <dt><code>channelMultipliers</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>Channel multipliers per level (default: [1, 2, 4, 4]).</p>
</dd>
    <dt><code>numResBlocks</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Number of residual blocks per level (default: 2).</p>
</dd>
    <dt><code>attentionResolutions</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>Resolution indices for attention (default: [1, 2, 3]).</p>
</dd>
    <dt><code>numTemporalLayers</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Number of temporal transformer layers (default: 1).</p>
</dd>
    <dt><code>contextDim</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Context dimension for cross-attention (default: 1024).</p>
</dd>
    <dt><code>numHeads</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Number of attention heads (default: 8).</p>
</dd>
    <dt><code>supportsImageConditioning</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Whether to support image conditioning (default: true).</p>
</dd>
    <dt><code>lossFunction</code> <a class="xref" href="AiDotNet.Interfaces.ILossFunction-1.html">ILossFunction</a>&lt;T&gt;</dt>
    <dd><p>Optional loss function (default: MSE).</p>
</dd>
    <dt><code>seed</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>?</dt>
    <dd><p>Optional random seed for reproducibility.</p>
</dd>
  </dl>












  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_BaseChannels_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.BaseChannels*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_BaseChannels" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.BaseChannels">
  BaseChannels
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L158"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the base channel count used in the network architecture.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override int BaseChannels { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_BaseChannels_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This determines the model capacity. Common values:
- 320 for Stable Diffusion 1.x and 2.x
- 384 for Stable Diffusion XL (base)
- 1024 for large DiT models
</p>
</div>




  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_ContextDimension_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.ContextDimension*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_ContextDimension" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.ContextDimension">
  ContextDimension
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L173"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the expected context dimension for cross-attention conditioning.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override int ContextDimension { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_ContextDimension_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
For CLIP-conditioned models, this is typically 768 or 1024.
For T5-conditioned models (like SD3), this is typically 2048.
Returns 0 if cross-attention is not supported.
</p>
</div>




  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_InputChannels_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.InputChannels*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_InputChannels" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.InputChannels">
  InputChannels
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L152"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the number of input channels the predictor expects.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override int InputChannels { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_InputChannels_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
For image models, this is typically:
- 4 for latent diffusion models (VAE latent channels)
- 3 for pixel-space RGB models
- Higher for models with additional conditioning channels
</p>
</div>




  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_NumTemporalLayers_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.NumTemporalLayers*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_NumTemporalLayers" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.NumTemporalLayers">
  NumTemporalLayers
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L183"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the number of temporal transformer layers.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int NumTemporalLayers { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>








  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_OutputChannels_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.OutputChannels*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_OutputChannels" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.OutputChannels">
  OutputChannels
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L155"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the number of output channels the predictor produces.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override int OutputChannels { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_OutputChannels_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Usually matches InputChannels since we predict noise of the same shape as input.
Some architectures may predict additional outputs like variance.
</p>
</div>




  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_ParameterCount_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.ParameterCount*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_ParameterCount" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.ParameterCount">
  ParameterCount
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L164"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the number of parameters in the model.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override int ParameterCount { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_ParameterCount_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This property returns the total count of trainable parameters in the model.
It's useful for understanding model complexity and memory requirements.</p>
</div>




  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_SupportsCFG_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.SupportsCFG*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_SupportsCFG" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.SupportsCFG">
  SupportsCFG
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L167"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this noise predictor supports classifier-free guidance.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsCFG { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_SupportsCFG_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Classifier-free guidance allows steering generation toward the conditioning
(e.g., text prompt) without a separate classifier. Most modern models support this.
</p>
</div>




  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_SupportsCrossAttention_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.SupportsCrossAttention*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_SupportsCrossAttention" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.SupportsCrossAttention">
  SupportsCrossAttention
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L170"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this noise predictor supports cross-attention conditioning.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsCrossAttention { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_SupportsCrossAttention_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Cross-attention allows the model to attend to conditioning tokens (like text embeddings).
This is how text-to-image models incorporate the prompt.
</p>
</div>




  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_SupportsImageConditioning_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.SupportsImageConditioning*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_SupportsImageConditioning" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.SupportsImageConditioning">
  SupportsImageConditioning
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L178"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this predictor supports image conditioning for image-to-video.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public bool SupportsImageConditioning { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>








  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_TimeEmbeddingDim_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.TimeEmbeddingDim*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_TimeEmbeddingDim" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.TimeEmbeddingDim">
  TimeEmbeddingDim
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L161"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the dimension of the time/timestep embedding.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override int TimeEmbeddingDim { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_TimeEmbeddingDim_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The timestep is embedded into a high-dimensional vector before being
injected into the network. Typical values: 256, 512, 1024.
</p>
</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_Clone_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.Clone*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_Clone" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.Clone">
  Clone()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L1011"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Creates a deep copy of the noise predictor.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override INoisePredictor&lt;T&gt; Clone()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Interfaces.INoisePredictor-1.html">INoisePredictor</a>&lt;T&gt;</dt>
    <dd><p>A new instance with the same parameters.</p>
</dd>
  </dl>











  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_DeepCopy_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.DeepCopy*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_DeepCopy" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.DeepCopy">
  DeepCopy()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L1031"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Creates a deep copy of this object.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override IFullModel&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt; DeepCopy()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Interfaces.IFullModel-3.html">IFullModel</a>&lt;T, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;&gt;</dt>
    <dd></dd>
  </dl>











  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_GetParameters_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.GetParameters*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_GetParameters" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.GetParameters">
  GetParameters()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L905"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the parameters that can be optimized.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Vector&lt;T&gt; GetParameters()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>











  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_PredictNoise_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.PredictNoise*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_PredictNoise_AiDotNet_Tensors_LinearAlgebra_Tensor__0__System_Int32_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.PredictNoise(AiDotNet.Tensors.LinearAlgebra.Tensor{`0},System.Int32,AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  PredictNoise(Tensor&lt;T&gt;, int, Tensor&lt;T&gt;?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L367"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Predicts the noise in a noisy sample at a given timestep.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; PredictNoise(Tensor&lt;T&gt; noisySample, int timestep, Tensor&lt;T&gt;? conditioning = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>noisySample</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The noisy input sample [batch, channels, height, width].</p>
</dd>
    <dt><code>timestep</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The current timestep in the diffusion process.</p>
</dd>
    <dt><code>conditioning</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Optional conditioning tensor (e.g., text embeddings).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The predicted noise tensor with the same shape as noisySample.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_PredictNoise_AiDotNet_Tensors_LinearAlgebra_Tensor__0__System_Int32_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This is the main forward pass of the noise predictor. Given a noisy sample
at timestep t, it predicts what noise was added.
</p>
<p>
<b>For Beginners:</b> This is where the actual denoising happens:
1. The network looks at the noisy image
2. It considers how noisy it should be at this timestep
3. It predicts the noise pattern
4. This prediction is subtracted to get a cleaner image
</p>
</div>




  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_PredictNoiseWithEmbedding_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.PredictNoiseWithEmbedding*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_PredictNoiseWithEmbedding_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.PredictNoiseWithEmbedding(AiDotNet.Tensors.LinearAlgebra.Tensor{`0},AiDotNet.Tensors.LinearAlgebra.Tensor{`0},AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  PredictNoiseWithEmbedding(Tensor&lt;T&gt;, Tensor&lt;T&gt;, Tensor&lt;T&gt;?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L380"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Predicts noise with explicit timestep embedding (for batched different timesteps).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; PredictNoiseWithEmbedding(Tensor&lt;T&gt; noisySample, Tensor&lt;T&gt; timeEmbedding, Tensor&lt;T&gt;? conditioning = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>noisySample</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The noisy input sample [batch, channels, height, width].</p>
</dd>
    <dt><code>timeEmbedding</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Pre-computed timestep embeddings [batch, timeEmbeddingDim].</p>
</dd>
    <dt><code>conditioning</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Optional conditioning tensor (e.g., text embeddings).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The predicted noise tensor with the same shape as noisySample.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_PredictNoiseWithEmbedding_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This overload is useful when you want to use different timesteps per sample
in a batch, or when you have pre-computed timestep embeddings for efficiency.
</p>
</div>




  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_PredictNoiseWithImageCondition_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.PredictNoiseWithImageCondition*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_PredictNoiseWithImageCondition_AiDotNet_Tensors_LinearAlgebra_Tensor__0__System_Int32_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.PredictNoiseWithImageCondition(AiDotNet.Tensors.LinearAlgebra.Tensor{`0},System.Int32,AiDotNet.Tensors.LinearAlgebra.Tensor{`0},AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  PredictNoiseWithImageCondition(Tensor&lt;T&gt;, int, Tensor&lt;T&gt;, Tensor&lt;T&gt;?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L396"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Predicts noise for image-to-video generation with image conditioning.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public Tensor&lt;T&gt; PredictNoiseWithImageCondition(Tensor&lt;T&gt; noisySample, int timestep, Tensor&lt;T&gt; imageCondition, Tensor&lt;T&gt;? textConditioning = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>noisySample</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The noisy video latent.</p>
</dd>
    <dt><code>timestep</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The current timestep.</p>
</dd>
    <dt><code>imageCondition</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The conditioning image (first frame).</p>
</dd>
    <dt><code>textConditioning</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Optional text conditioning.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The predicted noise.</p>
</dd>
  </dl>











  <a id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_SetParameters_" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.SetParameters*"></a>

  <h3 id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_SetParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.Diffusion.NoisePredictors.VideoUNetPredictor`1.SetParameters(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  SetParameters(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L956"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sets the model parameters.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void SetParameters(Vector&lt;T&gt; parameters)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>parameters</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The parameter vector to set.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_Diffusion_NoisePredictors_VideoUNetPredictor_1_SetParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This method allows direct modification of the model's internal parameters.
This is useful for optimization algorithms that need to update parameters iteratively.
If the length of <code class="paramref">parameters</code> does not match <a class="xref" href="AiDotNet.Interfaces.IParameterizable-3.html#AiDotNet_Interfaces_IParameterizable_3_ParameterCount">ParameterCount</a>,
an <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a> should be thrown.</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a></dt>
    <dd><p>Thrown when the length of <code class="paramref">parameters</code> does not match <a class="xref" href="AiDotNet.Interfaces.IParameterizable-3.html#AiDotNet_Interfaces_IParameterizable_3_ParameterCount">ParameterCount</a>.</p>
</dd>
  </dl>




</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/Diffusion/NoisePredictors/VideoUNetPredictor.cs/#L53" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
