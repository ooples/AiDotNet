<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Namespace AiDotNet.ReinforcementLearning.Policies | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Namespace AiDotNet.ReinforcementLearning.Policies | AiDotNet Documentation ">
      
      
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.ReinforcementLearning.Policies">

  <h1 id="AiDotNet_ReinforcementLearning_Policies" data-uid="AiDotNet.ReinforcementLearning.Policies" class="text-break">Namespace AiDotNet.ReinforcementLearning.Policies</h1>
  <div class="markdown level0 summary"></div>
  <div class="markdown level0 conceptual"></div>
  <div class="markdown level0 remarks"></div>

    <h3 id="namespaces">
Namespaces
</h3>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.Exploration.html">AiDotNet.ReinforcementLearning.Policies.Exploration</a></dt>
      <dd></dd>
    </dl>
    <h3 id="classes">
Classes
</h3>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.BetaPolicyOptions-1.html">BetaPolicyOptions&lt;T&gt;</a></dt>
      <dd><p>Configuration options for Beta distribution policies.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.BetaPolicy-1.html">BetaPolicy&lt;T&gt;</a></dt>
      <dd><p>Policy using Beta distribution for bounded continuous action spaces.
Network outputs alpha and beta parameters for each action dimension.
Actions are naturally bounded to [0, 1] and can be scaled to any [min, max] range.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.ContinuousPolicyOptions-1.html">ContinuousPolicyOptions&lt;T&gt;</a></dt>
      <dd><p>Configuration options for continuous action space policies in reinforcement learning.
Continuous policies output actions as real-valued vectors using Gaussian (normal) distributions.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.ContinuousPolicy-1.html">ContinuousPolicy&lt;T&gt;</a></dt>
      <dd><p>Policy for continuous action spaces using a neural network to output Gaussian parameters.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.DeterministicPolicyOptions-1.html">DeterministicPolicyOptions&lt;T&gt;</a></dt>
      <dd><p>Configuration options for deterministic policies.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.DeterministicPolicy-1.html">DeterministicPolicy&lt;T&gt;</a></dt>
      <dd><p>Deterministic policy for continuous action spaces.
Directly outputs actions without sampling from a distribution.
Commonly used in DDPG, TD3, and other deterministic policy gradient methods.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.DiscretePolicyOptions-1.html">DiscretePolicyOptions&lt;T&gt;</a></dt>
      <dd><p>Configuration options for discrete action space policies in reinforcement learning.
Discrete policies select from a finite set of actions using categorical (softmax) distributions.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.DiscretePolicy-1.html">DiscretePolicy&lt;T&gt;</a></dt>
      <dd><p>Policy for discrete action spaces using a neural network to output action logits.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.MixedPolicyOptions-1.html">MixedPolicyOptions&lt;T&gt;</a></dt>
      <dd><p>Configuration options for mixed discrete and continuous policies.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.MixedPolicy-1.html">MixedPolicy&lt;T&gt;</a></dt>
      <dd><p>Policy for environments with both discrete and continuous action spaces.
Outputs both categorical distribution for discrete actions and Gaussian for continuous actions.
Common in robotics where you have discrete mode selection and continuous parameter control.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.MultiModalPolicyOptions-1.html">MultiModalPolicyOptions&lt;T&gt;</a></dt>
      <dd><p>Configuration options for multi-modal mixture of Gaussians policies.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.MultiModalPolicy-1.html">MultiModalPolicy&lt;T&gt;</a></dt>
      <dd><p>Multi-modal policy using mixture of Gaussians for complex action distributions.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.PolicyBase-1.html">PolicyBase&lt;T&gt;</a></dt>
      <dd><p>Abstract base class for policy implementations.
Provides common functionality for numeric operations, random number generation, and resource management.</p>
</dd>
    </dl>
    <h3 id="interfaces">
Interfaces
</h3>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ReinforcementLearning.Policies.IPolicy-1.html">IPolicy&lt;T&gt;</a></dt>
      <dd><p>Core interface for RL policies - defines how to select actions.</p>
</dd>
    </dl>


</article>

        <div class="contribution d-print-none">
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
