<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Enum FusedActivationType | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Enum FusedActivationType | AiDotNet Documentation ">
      
      <meta name="description" content="Specifies the activation function to use in fused operations.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_Tensors_Engines_FusedActivationType.md&amp;value=---%0Auid%3A%20AiDotNet.Tensors.Engines.FusedActivationType%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.Tensors.Engines.FusedActivationType">




  <h1 id="AiDotNet_Tensors_Engines_FusedActivationType" data-uid="AiDotNet.Tensors.Engines.FusedActivationType" class="text-break">
Enum FusedActivationType  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/AiDotNet.Tensors/Engines/FusedActivationType.cs/#L23"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.Tensors.html">Tensors</a>.<a class="xref" href="AiDotNet.Tensors.Engines.html">Engines</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.Tensors.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Specifies the activation function to use in fused operations.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public enum FusedActivationType</code></pre>
  </div>









  <h2 id="fields">Fields
</h2>
  <dl class="parameters">
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_ELU"><code>ELU = 8</code></dt>
  
  <dd><p>Exponential Linear Unit: f(x) = x if x &gt; 0, else alpha * (exp(x) - 1)
Smoother version of ReLU that avoids dead neurons.</p>
</dd>
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_GELU"><code>GELU = 2</code></dt>
  
  <dd><p>Gaussian Error Linear Unit: f(x) = 0.5 * x * (1 + tanh(sqrt(2/pi) * (x + 0.044715 * x^3)))
Popular in transformer architectures (BERT, GPT).</p>
</dd>
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_HardSigmoid"><code>HardSigmoid = 13</code></dt>
  
  <dd><p>HardSigmoid: f(x) = clip((x + 3) / 6, 0, 1)
Efficient approximation of Sigmoid for mobile/edge deployment.</p>
</dd>
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_HardSwish"><code>HardSwish = 12</code></dt>
  
  <dd><p>HardSwish: f(x) = x * clip((x + 3) / 6, 0, 1)
Efficient approximation of Swish for mobile/edge deployment.</p>
</dd>
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_HardTanh"><code>HardTanh = 14</code></dt>
  
  <dd><p>HardTanh: f(x) = clip(x, -1, 1)
Efficient approximation of Tanh with bounded outputs.</p>
</dd>
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_LeakyReLU"><code>LeakyReLU = 5</code></dt>
  
  <dd><p>Leaky ReLU: f(x) = x if x &gt; 0, else alpha * x
Prevents &quot;dying ReLU&quot; problem by allowing small gradients for negative inputs.</p>
</dd>
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_Mish"><code>Mish = 11</code></dt>
  
  <dd><p>Mish: f(x) = x * tanh(softplus(x)) = x * tanh(log(1 + exp(x)))
Self-regularized activation that often outperforms Swish.</p>
</dd>
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_None"><code>None = 0</code></dt>
  
  <dd><p>No activation function applied (identity).
Output = Linear transformation only.</p>
</dd>
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_ReLU"><code>ReLU = 1</code></dt>
  
  <dd><p>Rectified Linear Unit: f(x) = max(0, x)
Fast and effective, most common choice for hidden layers.</p>
</dd>
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_SELU"><code>SELU = 9</code></dt>
  
  <dd><p>Scaled Exponential Linear Unit: f(x) = scale * (x if x &gt; 0, else alpha * (exp(x) - 1))
Self-normalizing activation for deep networks.</p>
</dd>
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_Sigmoid"><code>Sigmoid = 3</code></dt>
  
  <dd><p>Sigmoid: f(x) = 1 / (1 + exp(-x))
Maps output to range (0, 1), useful for binary classification and gates.</p>
</dd>
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_Softmax"><code>Softmax = 7</code></dt>
  
  <dd><p>Softmax: exp(x_i) / sum(exp(x_j))
Normalizes outputs to probability distribution, used for classification.</p>
</dd>
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_Softplus"><code>Softplus = 10</code></dt>
  
  <dd><p>Softplus: f(x) = log(1 + exp(x))
Smooth approximation of ReLU.</p>
</dd>
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_Swish"><code>Swish = 6</code></dt>
  
  <dd><p>Swish/SiLU: f(x) = x * sigmoid(x)
Self-gated activation, often outperforms ReLU in deep networks.</p>
</dd>
    <dt id="AiDotNet_Tensors_Engines_FusedActivationType_Tanh"><code>Tanh = 4</code></dt>
  
  <dd><p>Hyperbolic Tangent: f(x) = tanh(x)
Maps output to range (-1, 1), useful for hidden layers in RNNs.</p>
</dd>
  </dl>


  <h2 id="AiDotNet_Tensors_Engines_FusedActivationType_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p><b>Purpose:</b></p>
<p>
This enum provides type-safe selection of activation functions for fused operations
in IEngine. The engine implementation decides whether to use GPU fused kernels or
CPU sequential operations based on hardware availability and operation size.
</p>
<p><b>Performance Benefits:</b></p>
<p>
Fused operations combine multiple steps (e.g., MatMul + Bias + Activation) into a
single operation, eliminating intermediate memory allocations and transfers.
On GPU, this can provide 20-50% speedup over separate operations.
</p>
</div>

</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/AiDotNet.Tensors/Engines/FusedActivationType.cs/#L23" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
