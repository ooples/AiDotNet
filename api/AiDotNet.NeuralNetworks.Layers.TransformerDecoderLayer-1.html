<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class TransformerDecoderLayer&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class TransformerDecoderLayer&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Represents a transformer decoder layer that processes sequences using self-attention, cross-attention, and feed-forward networks.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1.md&amp;value=---%0Auid%3A%20AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1">



  <h1 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1" class="text-break">
Class TransformerDecoderLayer&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L34"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.NeuralNetworks.html">NeuralNetworks</a>.<a class="xref" href="AiDotNet.NeuralNetworks.Layers.html">Layers</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Represents a transformer decoder layer that processes sequences using self-attention, cross-attention, and feed-forward networks.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class TransformerDecoderLayer&lt;T&gt; : LayerBase&lt;T&gt;, ILayer&lt;T&gt;, IJitCompilable&lt;T&gt;, IWeightLoadable&lt;T&gt;, IDisposable, IAuxiliaryLossLayer&lt;T&gt;, IDiagnosticsProvider</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for calculations, typically float or double.</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html">LayerBase</a>&lt;T&gt;</div>
      <div><span class="xref">TransformerDecoderLayer&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IJitCompilable-1.html">IJitCompilable</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IWeightLoadable-1.html">IWeightLoadable</a>&lt;T&gt;</div>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.idisposable">IDisposable</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.IAuxiliaryLossLayer-1.html">IAuxiliaryLossLayer</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IDiagnosticsProvider.html">IDiagnosticsProvider</a></div>
    </dd>
  </dl>


  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Engine">LayerBase&lt;T&gt;.Engine</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ScalarActivation">LayerBase&lt;T&gt;.ScalarActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_VectorActivation">LayerBase&lt;T&gt;.VectorActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UsingVectorActivation">LayerBase&lt;T&gt;.UsingVectorActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_NumOps">LayerBase&lt;T&gt;.NumOps</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Random">LayerBase&lt;T&gt;.Random</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Parameters">LayerBase&lt;T&gt;.Parameters</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ParameterGradients">LayerBase&lt;T&gt;.ParameterGradients</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShape">LayerBase&lt;T&gt;.InputShape</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShapes">LayerBase&lt;T&gt;.InputShapes</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateInputShape_System_Int32___">LayerBase&lt;T&gt;.UpdateInputShape(int[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_OutputShape">LayerBase&lt;T&gt;.OutputShape</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsTrainingMode">LayerBase&lt;T&gt;.IsTrainingMode</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationStrategy">LayerBase&lt;T&gt;.InitializationStrategy</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsInitialized">LayerBase&lt;T&gt;.IsInitialized</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationLock">LayerBase&lt;T&gt;.InitializationLock</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_EnsureInitialized">LayerBase&lt;T&gt;.EnsureInitialized()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UseAutodiff">LayerBase&lt;T&gt;.UseAutodiff</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetTrainingMode_System_Boolean_">LayerBase&lt;T&gt;.SetTrainingMode(bool)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterGradients">LayerBase&lt;T&gt;.GetParameterGradients()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ClearGradients">LayerBase&lt;T&gt;.ClearGradients()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShape">LayerBase&lt;T&gt;.GetInputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShapes">LayerBase&lt;T&gt;.GetInputShapes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetOutputShape">LayerBase&lt;T&gt;.GetOutputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetWeights">LayerBase&lt;T&gt;.GetWeights()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetBiases">LayerBase&lt;T&gt;.GetBiases()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_MapActivationToFused">LayerBase&lt;T&gt;.MapActivationToFused()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuTraining">LayerBase&lt;T&gt;.SupportsGpuTraining</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanExecuteOnGpu">LayerBase&lt;T&gt;.CanExecuteOnGpu</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanTrainOnGpu">LayerBase&lt;T&gt;.CanTrainOnGpu</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UploadWeightsToGpu">LayerBase&lt;T&gt;.UploadWeightsToGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_DownloadWeightsFromGpu">LayerBase&lt;T&gt;.DownloadWeightsFromGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ZeroGradientsGpu">LayerBase&lt;T&gt;.ZeroGradientsGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetActivationTypes">LayerBase&lt;T&gt;.GetActivationTypes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0____">LayerBase&lt;T&gt;.Forward(params Tensor&lt;T&gt;[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ApplyActivation(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ApplyActivation(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ActivateTensor(IActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IVectorActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ActivateTensor(IVectorActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateInputShape_System_Int32_System_Int32_System_Int32_">LayerBase&lt;T&gt;.CalculateInputShape(int, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateOutputShape_System_Int32_System_Int32_System_Int32_">LayerBase&lt;T&gt;.CalculateOutputShape(int, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Clone">LayerBase&lt;T&gt;.Clone()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_DerivativeTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.DerivativeTensor(IActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative__0__0_">LayerBase&lt;T&gt;.ApplyActivationDerivative(T, T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ApplyActivationDerivative(Tensor&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ComputeActivationJacobian_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ComputeActivationJacobian(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Vector__0__AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ApplyActivationDerivative(Vector&lt;T&gt;, Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.UpdateParameters(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Serialize_System_IO_BinaryWriter_">LayerBase&lt;T&gt;.Serialize(BinaryWriter)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Deserialize_System_IO_BinaryReader_">LayerBase&lt;T&gt;.Deserialize(BinaryReader)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.SetParameters(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationToGraph_AiDotNet_Autodiff_ComputationNode__0__">LayerBase&lt;T&gt;.ApplyActivationToGraph(ComputationNode&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanActivationBeJitted">LayerBase&lt;T&gt;.CanActivationBeJitted()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_RegisterTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_Engines_PersistentTensorRole_">LayerBase&lt;T&gt;.RegisterTrainableParameter(Tensor&lt;T&gt;, PersistentTensorRole)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InvalidateTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.InvalidateTrainableParameter(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_HasGpuActivation">LayerBase&lt;T&gt;.HasGpuActivation()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationForwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">LayerBase&lt;T&gt;.ApplyActivationForwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationBackwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">LayerBase&lt;T&gt;.ApplyActivationBackwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetFusedActivationType">LayerBase&lt;T&gt;.GetFusedActivationType()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivation_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_">LayerBase&lt;T&gt;.ApplyGpuActivation(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int, FusedActivationType)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivationBackward_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_System_Single_">LayerBase&lt;T&gt;.ApplyGpuActivationBackward(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int, FusedActivationType, float)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose">LayerBase&lt;T&gt;.Dispose()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose_System_Boolean_">LayerBase&lt;T&gt;.Dispose(bool)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_WeightParameterName">LayerBase&lt;T&gt;.WeightParameterName</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_BiasParameterName">LayerBase&lt;T&gt;.BiasParameterName</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetWeights_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetWeights(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetBiases_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetBiases(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterNames">LayerBase&lt;T&gt;.GetParameterNames()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_TryGetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___">LayerBase&lt;T&gt;.TryGetParameter(string, out Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetParameter(string, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterShape_System_String_">LayerBase&lt;T&gt;.GetParameterShape(string)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_NamedParameterCount">LayerBase&lt;T&gt;.NamedParameterCount</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ValidateWeights_System_Collections_Generic_IEnumerable_System_String__System_Func_System_String_System_String__">LayerBase&lt;T&gt;.ValidateWeights(IEnumerable&lt;string&gt;, Func&lt;string, string&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_LoadWeights_System_Collections_Generic_Dictionary_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___System_Func_System_String_System_String__System_Boolean_">LayerBase&lt;T&gt;.LoadWeights(Dictionary&lt;string, Tensor&lt;T&gt;&gt;, Func&lt;string, string&gt;, bool)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
A transformer decoder layer is a fundamental building block of transformer-based models for sequence-to-sequence tasks.
It consists of three main components: a masked self-attention mechanism that processes the target sequence, a cross-attention
mechanism that attends to the encoder's output, and a feed-forward network for additional transformation. Each component
is followed by layer normalization and residual connections to facilitate training of deep networks.
</p>
<p><b>For Beginners:</b> This layer helps the network generate sequences while considering both what it has generated so far and input from another source.
<p>Think of it like a writer who is translating a book:</p>
<ul>
<li>First, the writer looks at what they've translated so far to maintain consistency (self-attention)</li>
<li>Then they look at the original text to understand what to translate next (cross-attention)</li>
<li>Finally, they process all this information to produce the next part of the translation (feed-forward network)</li>
</ul>
<p>For example, in machine translation, the decoder generates each word of the target language by:</p>
<ul>
<li>Looking at the words it has already generated (to maintain grammatical coherence)</li>
<li>Looking at the encoded source sentence (to understand what content to translate)</li>
<li>Combining this information to produce the most appropriate next word</li>
</ul>
<p>This architecture is powerful for tasks like translation, summarization, and text generation.</p>

</div>


  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1__ctor_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.#ctor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1__ctor_System_Int32_System_Int32_System_Int32_System_Int32_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_Engines_IEngine_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.#ctor(System.Int32,System.Int32,System.Int32,System.Int32,AiDotNet.Interfaces.IActivationFunction{`0},AiDotNet.Tensors.Engines.IEngine)">
  TransformerDecoderLayer(int, int, int, int, IActivationFunction&lt;T&gt;?, IEngine?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L539"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the <a class="xref" href="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer-1.html">TransformerDecoderLayer&lt;T&gt;</a> class with scalar activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public TransformerDecoderLayer(int embeddingSize = 512, int numHeads = 8, int feedForwardDim = 2048, int sequenceLength = 512, IActivationFunction&lt;T&gt;? ffnActivation = null, IEngine? engine = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>embeddingSize</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The size of the embeddings. Default is 512.</p>
</dd>
    <dt><code>numHeads</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of attention heads. Default is 8.</p>
</dd>
    <dt><code>feedForwardDim</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The dimension of the feed-forward network. Default is 2048.</p>
</dd>
    <dt><code>sequenceLength</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The maximum sequence length. Default is 512.</p>
</dd>
    <dt><code>ffnActivation</code> <a class="xref" href="AiDotNet.Interfaces.IActivationFunction-1.html">IActivationFunction</a>&lt;T&gt;</dt>
    <dd><p>The activation function for the feed-forward network. Default is GELU.</p>
</dd>
    <dt><code>engine</code> <a class="xref" href="AiDotNet.Tensors.Engines.IEngine.html">IEngine</a></dt>
    <dd></dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1__ctor_System_Int32_System_Int32_System_Int32_System_Int32_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_Engines_IEngine__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This constructor creates a transformer decoder layer with the specified dimensions and a scalar activation function
for the feed-forward network. It initializes all the sublayers needed for the transformer decoder architecture.
</p>
<p><b>For Beginners:</b> This constructor creates a new transformer decoder layer with standard settings.
<p>The parameters you provide determine:</p>
<ul>
<li>embeddingSize: How rich the representation of each token is (more = more expressive)</li>
<li>numHeads: How many different &quot;perspectives&quot; the attention mechanism can have</li>
<li>feedForwardDim: How much processing capacity the feed-forward network has</li>
<li>sequenceLength: The maximum number of tokens the model can process</li>
<li>ffnActivation: The mathematical function used in the feed-forward network</li>
</ul>
<p>These settings control the capacity, expressiveness, and computational requirements of the decoder.
The default values (512 embedding size, 8 heads, etc.) are similar to those used in the original
transformer paper and work well for many language tasks.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1__ctor_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.#ctor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1__ctor_System_Int32_System_Int32_System_Int32_System_Int32_AiDotNet_Interfaces_IVectorActivationFunction__0__AiDotNet_Tensors_Engines_IEngine_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.#ctor(System.Int32,System.Int32,System.Int32,System.Int32,AiDotNet.Interfaces.IVectorActivationFunction{`0},AiDotNet.Tensors.Engines.IEngine)">
  TransformerDecoderLayer(int, int, int, int, IVectorActivationFunction&lt;T&gt;?, IEngine?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L597"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the <a class="xref" href="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer-1.html">TransformerDecoderLayer&lt;T&gt;</a> class with vector activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public TransformerDecoderLayer(int embeddingSize = 512, int numHeads = 8, int feedForwardDim = 2048, int sequenceLength = 512, IVectorActivationFunction&lt;T&gt;? ffnVectorActivation = null, IEngine? engine = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>embeddingSize</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The size of the embeddings. Default is 512.</p>
</dd>
    <dt><code>numHeads</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of attention heads. Default is 8.</p>
</dd>
    <dt><code>feedForwardDim</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The dimension of the feed-forward network. Default is 2048.</p>
</dd>
    <dt><code>sequenceLength</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The maximum sequence length. Default is 512.</p>
</dd>
    <dt><code>ffnVectorActivation</code> <a class="xref" href="AiDotNet.Interfaces.IVectorActivationFunction-1.html">IVectorActivationFunction</a>&lt;T&gt;</dt>
    <dd><p>The vector activation function for the feed-forward network. Default is GELU.</p>
</dd>
    <dt><code>engine</code> <a class="xref" href="AiDotNet.Tensors.Engines.IEngine.html">IEngine</a></dt>
    <dd></dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1__ctor_System_Int32_System_Int32_System_Int32_System_Int32_AiDotNet_Interfaces_IVectorActivationFunction__0__AiDotNet_Tensors_Engines_IEngine__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This constructor creates a transformer decoder layer with the specified dimensions and a vector activation function
for the feed-forward network. It initializes all the sublayers needed for the transformer decoder architecture.
</p>
<p><b>For Beginners:</b> This constructor is similar to the previous one, but uses vector activations.
<p>Vector activations:</p>
<ul>
<li>Process entire groups of numbers at once, rather than one at a time</li>
<li>Can capture relationships between different elements</li>
<li>Allow for more complex transformations</li>
</ul>
<p>This version is useful when you need more sophisticated processing that considers
how different features relate to each other, rather than treating each feature independently.</p>

</div>




  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_AuxiliaryLossWeight_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.AuxiliaryLossWeight*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_AuxiliaryLossWeight" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.AuxiliaryLossWeight">
  AuxiliaryLossWeight
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L77"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the weight for the auxiliary loss contribution.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public T AuxiliaryLossWeight { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><span class="xref">T</span></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_AuxiliaryLossWeight_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This value determines how much the aggregated auxiliary losses contribute to the total loss.
The default value of 0.005 provides a good balance between the main task and regularization.
</p>
<p><b>For Beginners:</b> This controls how much importance to give to the attention regularization.
<p>The weight affects training:</p>
<ul>
<li>Higher values (e.g., 0.01) make the network prioritize better attention patterns more strongly</li>
<li>Lower values (e.g., 0.001) make the regularization less important</li>
<li>The default (0.005) works well for most transformer tasks</li>
</ul>
<p>If your attention is collapsing (all heads learning the same thing), you might increase this value.
If the main task is more important, you might decrease it.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ParameterCount_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.ParameterCount*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ParameterCount" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.ParameterCount">
  ParameterCount
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L503"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the total number of trainable parameters in this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override int ParameterCount { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ParameterCount_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This returns the sum of all parameters from sublayers: self-attention, cross-attention,
layer norms, feed-forward layer, and feed-forward projection layer.</p>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_SupportsGpuExecution_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.SupportsGpuExecution*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_SupportsGpuExecution" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.SupportsGpuExecution">
  SupportsGpuExecution
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L494"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets a value indicating whether this layer can execute on GPU.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected override bool SupportsGpuExecution { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>








  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_SupportsJitCompilation_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.SupportsJitCompilation*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_SupportsJitCompilation" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.SupportsJitCompilation">
  SupportsJitCompilation
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L1492"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this transformer decoder layer supports JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsJitCompilation { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if all sublayers support JIT compilation.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_SupportsJitCompilation_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property indicates whether the layer can be JIT compiled. As a composite layer,
it supports JIT if all its sublayers support JIT:
- Masked self-attention layer
- Cross-attention layer (attends to encoder output)
- Layer normalization layers (3 total)
- Feed-forward layer
</p>
<p><b>For Beginners:</b> This tells you if this composite layer can use JIT compilation.
<p>The transformer decoder layer can be JIT compiled if:</p>
<ul>
<li>All sublayers are properly initialized</li>
<li>Each sublayer supports JIT compilation</li>
</ul>
<p>Composite layer JIT optimization:</p>
<ul>
<li>Each sublayer can be independently JIT compiled</li>
<li>Future optimization: fuse operations across sublayers</li>
<li>Residual connections and layer norms are fast operations</li>
</ul>
<p>The bottleneck in decoder layers:</p>
<ul>
<li>Self-attention: O(nÂ²) for target sequence</li>
<li>Cross-attention: O(n*m) where n=target length, m=source length</li>
<li>Feed-forward: matrix multiplications</li>
</ul>
<p>All benefit significantly from JIT compilation (5-10x speedup).</p>
<p>GPT models use decoder-only architecture (no cross-attention, only self-attention).
T5 and other seq2seq models use both encoder and decoder layers.
GPT-3 has 96 decoder layers, making JIT optimization critical for performance.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_SupportsTraining_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.SupportsTraining*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_SupportsTraining" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.SupportsTraining">
  SupportsTraining
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L489"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets a value indicating whether this layer supports training.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsTraining { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p><code>true</code> for this layer, as it contains trainable parameters.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_SupportsTraining_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property indicates whether the transformer decoder layer can be trained through backpropagation.
Since this layer has trainable parameters in its sublayers, it supports training.
</p>
<p><b>For Beginners:</b> This property tells you if the layer can learn from data.
<p>A value of true means:</p>
<ul>
<li>The layer has internal values that can be adjusted during training</li>
<li>It will improve its performance as it sees more data</li>
<li>It participates in the learning process</li>
</ul>
<p>For this layer, the value is always true because it contains multiple sublayers
with trainable parameters that need to be optimized during training.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_UseAuxiliaryLoss_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.UseAuxiliaryLoss*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_UseAuxiliaryLoss" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.UseAuxiliaryLoss">
  UseAuxiliaryLoss
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L56"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets a value indicating whether auxiliary loss is enabled for this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public bool UseAuxiliaryLoss { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_UseAuxiliaryLoss_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
When enabled, the layer aggregates auxiliary losses from its attention sublayers (both self-attention and cross-attention).
This helps regularize attention patterns and prevents issues like attention collapse.
</p>
<p><b>For Beginners:</b> This setting controls whether the layer uses additional learning signals.
<p>When enabled (true):</p>
<ul>
<li>The layer collects extra penalties from both self-attention and cross-attention mechanisms</li>
<li>This helps the attention heads learn diverse and focused patterns</li>
<li>Training may be more stable and produce better results</li>
</ul>
<p>When disabled (false):</p>
<ul>
<li>Only the main task loss is used for training</li>
<li>This is the default setting</li>
</ul>

</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_Backward_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.Backward*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.Backward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Backward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L898"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the backward pass of the transformer decoder layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; Backward(Tensor&lt;T&gt; outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>outputGradient</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The gradient of the loss with respect to the layer's output.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The gradient of the loss with respect to the layer's input.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method implements the backward pass of the transformer decoder layer, which is used during training to
propagate error gradients back through the network. It computes gradients for each sublayer in reverse order
of the forward pass, ensuring that residual connections are properly handled.
</p>
<p><b>For Beginners:</b> This method calculates how the layer's inputs should change to reduce errors.
<p>During the backward pass, we go through the same steps as the forward pass, but in reverse order:</p>
<ol>
<li><p>Final Layer Normalization:</p>
<ul>
<li>Compute how the normalization's input should change based on output errors</li>
</ul>
</li>
<li><p>Feed-Forward Network:</p>
<ul>
<li>Determine how the feed-forward network's input should change</li>
<li>Account for the residual connection by adding gradients</li>
</ul>
</li>
<li><p>Second Layer Normalization:</p>
<ul>
<li>Compute how the second normalization's input should change</li>
</ul>
</li>
<li><p>Cross-Attention:</p>
<ul>
<li>Determine how the cross-attention's inputs should change</li>
<li>Account for the residual connection</li>
</ul>
</li>
<li><p>First Layer Normalization:</p>
<ul>
<li>Compute how the first normalization's input should change</li>
</ul>
</li>
<li><p>Self-Attention:</p>
<ul>
<li>Determine how the self-attention's input should change</li>
<li>Account for the final residual connection</li>
</ul>
</li>
</ol>
<p>This reverse flow of gradients allows each component to learn how it contributed to any errors.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_BackwardGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.BackwardGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_BackwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.BackwardGpu(AiDotNet.Tensors.Engines.Gpu.IGpuTensor{`0})">
  BackwardGpu(IGpuTensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L797"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the gradient of the loss with respect to the decoder input on the GPU.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override IGpuTensor&lt;T&gt; BackwardGpu(IGpuTensor&lt;T&gt; outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>outputGradient</code> <a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;</dt>
    <dd><p>The gradient of the loss with respect to the layer's output.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;</dt>
    <dd><p>The gradient of the loss with respect to the decoder input.</p>
</dd>
  </dl>











  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ComputeAuxiliaryLoss_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.ComputeAuxiliaryLoss*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ComputeAuxiliaryLoss" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.ComputeAuxiliaryLoss">
  ComputeAuxiliaryLoss()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L1144"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the auxiliary loss for this layer by aggregating losses from sublayers.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public T ComputeAuxiliaryLoss()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><span class="xref">T</span></dt>
    <dd><p>The computed auxiliary loss value.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ComputeAuxiliaryLoss_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method computes the auxiliary loss by aggregating losses from sublayers that implement IAuxiliaryLossLayer.
For the decoder layer, this includes both self-attention and cross-attention mechanisms, which provide
attention entropy and head diversity regularization.
</p>
<p><b>For Beginners:</b> This method collects additional learning signals from the layer's components.
<p>Auxiliary loss aggregation:</p>
<ul>
<li>Checks each attention sublayer to see if it has auxiliary losses</li>
<li>Collects those losses from both self-attention and cross-attention</li>
<li>Combines them and returns the total for use in training</li>
</ul>
<p>Why this is useful:</p>
<ul>
<li>Both attention mechanisms benefit from regularization to prevent all heads from learning the same patterns</li>
<li>Self-attention regularization helps the decoder maintain coherent generation patterns</li>
<li>Cross-attention regularization helps the decoder focus on relevant parts of the source</li>
<li>Aggregating losses at the decoder level provides a unified view of attention quality</li>
</ul>
<p>Example: If the self-attention has an entropy loss (to keep attention focused) and a diversity loss
(to prevent heads from being redundant), and the cross-attention has similar losses, this method
adds all of them together and returns the total.</p>
<p>The aggregated loss helps ensure:</p>
<ul>
<li>Both attention mechanisms learn diverse patterns</li>
<li>Attention is focused rather than diffuse</li>
<li>The decoder uses its capacity efficiently for both understanding context and attending to source</li>
</ul>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ExportComputationGraph_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.ExportComputationGraph*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0___" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.ExportComputationGraph(System.Collections.Generic.List{AiDotNet.Autodiff.ComputationNode{`0}})">
  ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L1302"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Exports the transformer decoder layer as a computation graph for JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override ComputationNode&lt;T&gt; ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt; inputNodes)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputNodes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.list-1">List</a>&lt;<a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;&gt;</dt>
    <dd><p>List to which the input node will be added.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The output computation node representing the transformer decoder operation.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method creates a symbolic computation graph for JIT compilation:
1. Creates a symbolic input node (decoder input)
2. Applies masked self-attention with residual connection and norm
3. Applies cross-attention to encoder output with residual and norm
4. Applies feed-forward network with residual connection and norm
5. Returns the final output
</p>
<p><b>For Beginners:</b> This method builds a symbolic representation of a transformer decoder layer for JIT.
<p>The transformer decoder layer is a composite layer combining:</p>
<ul>
<li>Masked self-attention (prevents looking ahead in target sequence)</li>
<li>Cross-attention (attends to encoder output, connects source and target)</li>
<li>Layer normalization (stabilizes training)</li>
<li>Feed-forward network (processes each position independently)</li>
<li>Residual connections (helps gradient flow in deep networks)</li>
</ul>
<p>The forward pass:</p>
<ol>
<li>x' = LayerNorm(x + MaskedSelfAttention(x))</li>
<li>x'' = LayerNorm(x' + CrossAttention(x', encoder_output))</li>
<li>output = LayerNorm(x'' + FeedForward(x''))</li>
</ol>
<p>JIT optimization for composite layers:</p>
<ul>
<li>For now, composite layers note their structure but may delegate to sublayers</li>
<li>Future optimization could fuse operations across sublayers</li>
<li>Each sublayer (self-attention, cross-attention, feed-forward, norm) can be independently JIT compiled</li>
</ul>
<p>This is the core building block of GPT (decoder-only) and encoder-decoder models like T5.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></dt>
    <dd><p>Thrown when inputNodes is null.</p>
</dd>
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown when sublayers are not initialized.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_Forward_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.Forward*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.Forward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Forward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L652"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Not supported for this layer. Use Forward(Tensor&lt;T&gt; input, Tensor&lt;T&gt; encoderOutput) instead.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; Forward(Tensor&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The input tensor.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Never returns as this method throws an exception.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method is not supported for the transformer decoder layer, as it requires both a decoder input and an encoder output.
Use the overloaded Forward method that accepts both inputs instead.
</p>
<p><b>For Beginners:</b> This method is a placeholder that shows an error if used incorrectly.
<p>The transformer decoder needs two inputs:</p>
<ul>
<li>The decoder's own input (what it has generated so far)</li>
<li>The encoder's output (information from the source sequence)</li>
</ul>
<p>This method exists only to satisfy the base class requirements, but will show an error
if someone tries to use it. The correct method to use is the one that accepts both inputs.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Always thrown, as this method is not supported for this layer.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_Forward_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.Forward*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.Forward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0},AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Forward(Tensor&lt;T&gt;, Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L694"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the forward pass of the transformer decoder layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public Tensor&lt;T&gt; Forward(Tensor&lt;T&gt; input, Tensor&lt;T&gt; encoderOutput)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The decoder input tensor.</p>
</dd>
    <dt><code>encoderOutput</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The encoder output tensor.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The output tensor after processing through the transformer decoder layer.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method implements the forward pass of the transformer decoder layer. It processes the decoder input through
the self-attention mechanism, applies layer normalization and a residual connection, then passes the result through
the cross-attention mechanism (attending to the encoder output), applies another layer normalization and residual
connection, and finally processes the result through the feed-forward network followed by a final layer normalization
and residual connection.
</p>
<p><b>For Beginners:</b> This method processes the inputs through all components of the decoder layer.
<p>The forward pass follows these steps:</p>
<ol>
<li><p>Self-Attention:</p>
<ul>
<li>The decoder looks at its own input to understand the context of what it has generated so far</li>
<li>The result is added to the original input (residual connection)</li>
<li>Layer normalization is applied to stabilize the values</li>
</ul>
</li>
<li><p>Cross-Attention:</p>
<ul>
<li>The decoder looks at the encoder output to gather information from the source sequence</li>
<li>The result is added to the output from step 1 (residual connection)</li>
<li>Layer normalization is applied again</li>
</ul>
</li>
<li><p>Feed-Forward Network:</p>
<ul>
<li>The output from step 2 is processed through a feed-forward network</li>
<li>The result is added to the output from step 2 (residual connection)</li>
<li>A final layer normalization is applied</li>
</ul>
</li>
</ol>
<p>These steps allow the decoder to generate output that is coherent with both
what it has generated so far and the information from the source sequence.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ForwardGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.ForwardGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ForwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0____" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.ForwardGpu(AiDotNet.Tensors.Engines.Gpu.IGpuTensor{`0}[])">
  ForwardGpu(params IGpuTensor&lt;T&gt;[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L735"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>GPU-resident forward pass for the transformer decoder layer.
Performs self-attention, cross-attention, and feed-forward operations entirely on GPU.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override IGpuTensor&lt;T&gt; ForwardGpu(params IGpuTensor&lt;T&gt;[] inputs)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputs</code> <a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;[]</dt>
    <dd><p>Array containing [decoderInput, encoderOutput] GPU tensors.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;</dt>
    <dd><p>GPU-resident output tensor.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ForwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0_____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs the entire transformer decoder forward pass on the GPU without downloading
intermediate results to CPU. All sublayer operations (self-attention, cross-attention, layer normalization,
feed-forward networks, residual connections) remain GPU-resident for maximum performance.
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a></dt>
    <dd><p>Thrown when inputs array doesn't contain exactly 2 tensors.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_GetAuxiliaryLossDiagnostics_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.GetAuxiliaryLossDiagnostics*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_GetAuxiliaryLossDiagnostics" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.GetAuxiliaryLossDiagnostics">
  GetAuxiliaryLossDiagnostics()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L1210"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets diagnostic information about the auxiliary loss computation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public Dictionary&lt;string, string&gt; GetAuxiliaryLossDiagnostics()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.dictionary-2">Dictionary</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>, <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>A dictionary containing diagnostic information about the auxiliary loss.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_GetAuxiliaryLossDiagnostics_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method returns diagnostic information that can be used to monitor the auxiliary loss during training.
The diagnostics include the total auxiliary loss, the weight applied to it, whether auxiliary loss is enabled,
and detailed diagnostics from both self-attention and cross-attention sublayers.
</p>
<p><b>For Beginners:</b> This method provides information to help you understand how the auxiliary loss is working.
<p>The diagnostics show:</p>
<ul>
<li>TotalAuxiliaryLoss: The combined penalty from all attention sublayers</li>
<li>AuxiliaryWeight: How much this penalty affects the overall training</li>
<li>UseAuxiliaryLoss: Whether this penalty is currently enabled</li>
<li>SelfAttentionDiagnostics: Detailed information from the self-attention mechanism</li>
<li>CrossAttentionDiagnostics: Detailed information from the cross-attention mechanism</li>
</ul>
<p>You can use this information to:</p>
<ul>
<li>Monitor if attention patterns are healthy (diverse and focused) in both mechanisms</li>
<li>Debug training issues related to attention</li>
<li>Understand how the decoder is learning both context and source information</li>
</ul>
<p>Example: If you see that self-attention entropy is very low, it might mean the decoder isn't
maintaining good coherence with its own generated output. If cross-attention diversity is low,
it might mean all heads are looking at the same part of the source, wasting capacity.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_GetDiagnostics_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.GetDiagnostics*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_GetDiagnostics" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.GetDiagnostics">
  GetDiagnostics()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L1250"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets diagnostic information about this component's state and behavior.
Overrides <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetDiagnostics">GetDiagnostics()</a> to include auxiliary loss diagnostics.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Dictionary&lt;string, string&gt; GetDiagnostics()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.dictionary-2">Dictionary</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>, <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>A dictionary containing diagnostic metrics including both base layer diagnostics and
auxiliary loss diagnostics from <a class="xref" href="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer-1.html#AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_GetAuxiliaryLossDiagnostics">GetAuxiliaryLossDiagnostics()</a>.</p>
</dd>
  </dl>











  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_GetParameters_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.GetParameters*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_GetParameters" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.GetParameters">
  GetParameters()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L1036"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets all trainable parameters of the transformer decoder layer as a single vector.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Vector&lt;T&gt; GetParameters()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>A vector containing all trainable parameters from all sublayers.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_GetParameters_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method retrieves all trainable parameters from all sublayers of the transformer decoder layer and combines
them into a single vector. This is useful for optimization algorithms that operate on all parameters at once,
or for saving and loading model weights.
</p>
<p><b>For Beginners:</b> This method collects all the learnable values from all parts of the decoder.
<p>The parameters:</p>
<ul>
<li>Are the numbers that the neural network learns during training</li>
<li>Include weights from attention mechanisms, normalization layers, and the feed-forward network</li>
<li>Are combined into a single long list (vector)</li>
</ul>
<p>This is useful for:</p>
<ul>
<li>Saving the model to disk</li>
<li>Loading parameters from a previously trained model</li>
<li>Advanced optimization techniques that need access to all parameters</li>
</ul>
<p>A transformer decoder layer typically has millions of parameters, all of which
contribute to its ability to generate high-quality sequences.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ResetState_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.ResetState*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ResetState" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.ResetState">
  ResetState()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L1086"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Resets the internal state of the transformer decoder layer and all its sublayers.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void ResetState()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_ResetState_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method resets the internal state of the transformer decoder layer and all its sublayers. It clears the cached
tensors from the forward pass and delegates the reset operation to each sublayer.
</p>
<p><b>For Beginners:</b> This method clears the layer's memory to start fresh.
<p>When resetting the state:</p>
<ul>
<li>All sublayers are reset to their initial condition</li>
<li>Stored inputs and outputs are cleared</li>
<li>The layer forgets all intermediate results from previous processing</li>
</ul>
<p>This is important for:</p>
<ul>
<li>Processing a new, unrelated sequence</li>
<li>Starting a new training episode</li>
<li>Testing the layer with fresh inputs</li>
</ul>
<p>Think of it like clearing the entire team's mind before starting a completely new task,
ensuring no residual information affects the processing of new inputs.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_UpdateParameters_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.UpdateParameters*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_UpdateParameters__0_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.UpdateParameters(`0)">
  UpdateParameters(T)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L977"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Updates the parameters of all sublayers using the calculated gradients.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void UpdateParameters(T learningRate)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>learningRate</code> <span class="xref">T</span></dt>
    <dd><p>The learning rate to use for parameter updates.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_UpdateParameters__0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method updates the parameters of all sublayers in the transformer decoder layer based on the gradients
calculated during the backward pass. It delegates the update process to each sublayer, passing the learning rate.
</p>
<p><b>For Beginners:</b> This method adjusts all the internal values of the layer to improve its performance.
<p>During parameter updates:</p>
<ul>
<li>The learning rate controls how big each adjustment is</li>
<li>Every sublayer gets updated based on what was learned in the backward pass</li>
<li>This helps the entire decoder layer gradually improve its performance</li>
</ul>
<p>Think of it like fine-tuning all the components of the decoder based on feedback:</p>
<ul>
<li>The self-attention mechanism learns to focus on more relevant parts of what's been generated</li>
<li>The cross-attention mechanism learns to extract more useful information from the source</li>
<li>The feed-forward network learns to better transform this information into the next output</li>
</ul>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_UpdateParametersGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.UpdateParametersGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_UpdateParametersGpu_AiDotNet_Interfaces_IGpuOptimizerConfig_" data-uid="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer`1.UpdateParametersGpu(AiDotNet.Interfaces.IGpuOptimizerConfig)">
  UpdateParametersGpu(IGpuOptimizerConfig)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L998"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Updates layer parameters using GPU-resident optimizer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void UpdateParametersGpu(IGpuOptimizerConfig config)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>config</code> <a class="xref" href="AiDotNet.Interfaces.IGpuOptimizerConfig.html">IGpuOptimizerConfig</a></dt>
    <dd><p>The GPU optimizer configuration.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_TransformerDecoderLayer_1_UpdateParametersGpu_AiDotNet_Interfaces_IGpuOptimizerConfig__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method delegates to each sublayer's UpdateParametersGpu method.
All sublayers (self-attention, cross-attention, layer norms, feed-forward) are updated.
</p>
</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/TransformerDecoderLayer.cs/#L34" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
