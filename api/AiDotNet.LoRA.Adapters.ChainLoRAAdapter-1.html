<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class ChainLoRAAdapter&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class ChainLoRAAdapter&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Chain-of-LoRA adapter that implements sequential composition of multiple LoRA adapters.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1.md&amp;value=---%0Auid%3A%20AiDotNet.LoRA.Adapters.ChainLoRAAdapter%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1">



  <h1 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1" class="text-break">
Class ChainLoRAAdapter&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L100"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.LoRA.html">LoRA</a>.<a class="xref" href="AiDotNet.LoRA.Adapters.html">Adapters</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Chain-of-LoRA adapter that implements sequential composition of multiple LoRA adapters.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class ChainLoRAAdapter&lt;T&gt; : LoRAAdapterBase&lt;T&gt;, IDisposable, ILoRAAdapter&lt;T&gt;, ILayer&lt;T&gt;, IJitCompilable&lt;T&gt;, IDiagnosticsProvider, IWeightLoadable&lt;T&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for calculations, typically float or double.</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html">LayerBase</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html">LoRAAdapterBase</a>&lt;T&gt;</div>
      <div><span class="xref">ChainLoRAAdapter&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.idisposable">IDisposable</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.ILoRAAdapter-1.html">ILoRAAdapter</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IJitCompilable-1.html">IJitCompilable</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IDiagnosticsProvider.html">IDiagnosticsProvider</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.IWeightLoadable-1.html">IWeightLoadable</a>&lt;T&gt;</div>
    </dd>
  </dl>


  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1__baseLayer">LoRAAdapterBase&lt;T&gt;._baseLayer</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1__loraLayer">LoRAAdapterBase&lt;T&gt;._loraLayer</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1__freezeBaseLayer">LoRAAdapterBase&lt;T&gt;._freezeBaseLayer</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_BaseLayer">LoRAAdapterBase&lt;T&gt;.BaseLayer</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_LoRALayer">LoRAAdapterBase&lt;T&gt;.LoRALayer</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_IsBaseLayerFrozen">LoRAAdapterBase&lt;T&gt;.IsBaseLayerFrozen</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Rank">LoRAAdapterBase&lt;T&gt;.Rank</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Alpha">LoRAAdapterBase&lt;T&gt;.Alpha</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_SupportsTraining">LoRAAdapterBase&lt;T&gt;.SupportsTraining</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_CreateLoRALayer_System_Int32_System_Double_">LoRAAdapterBase&lt;T&gt;.CreateLoRALayer(int, double)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_CreateMergedLayerWithClone_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LoRAAdapterBase&lt;T&gt;.CreateMergedLayerWithClone(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_MergeToDenseOrFullyConnected">LoRAAdapterBase&lt;T&gt;.MergeToDenseOrFullyConnected()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_UpdateParametersFromLayers">LoRAAdapterBase&lt;T&gt;.UpdateParametersFromLayers()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_SupportsJitCompilation">LoRAAdapterBase&lt;T&gt;.SupportsJitCompilation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0___">LoRAAdapterBase&lt;T&gt;.ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Engine">LayerBase&lt;T&gt;.Engine</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ScalarActivation">LayerBase&lt;T&gt;.ScalarActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_VectorActivation">LayerBase&lt;T&gt;.VectorActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UsingVectorActivation">LayerBase&lt;T&gt;.UsingVectorActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_NumOps">LayerBase&lt;T&gt;.NumOps</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Random">LayerBase&lt;T&gt;.Random</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Parameters">LayerBase&lt;T&gt;.Parameters</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ParameterGradients">LayerBase&lt;T&gt;.ParameterGradients</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShape">LayerBase&lt;T&gt;.InputShape</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShapes">LayerBase&lt;T&gt;.InputShapes</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateInputShape_System_Int32___">LayerBase&lt;T&gt;.UpdateInputShape(int[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_OutputShape">LayerBase&lt;T&gt;.OutputShape</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsTrainingMode">LayerBase&lt;T&gt;.IsTrainingMode</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationStrategy">LayerBase&lt;T&gt;.InitializationStrategy</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsInitialized">LayerBase&lt;T&gt;.IsInitialized</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationLock">LayerBase&lt;T&gt;.InitializationLock</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_EnsureInitialized">LayerBase&lt;T&gt;.EnsureInitialized()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UseAutodiff">LayerBase&lt;T&gt;.UseAutodiff</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetTrainingMode_System_Boolean_">LayerBase&lt;T&gt;.SetTrainingMode(bool)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterGradients">LayerBase&lt;T&gt;.GetParameterGradients()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ClearGradients">LayerBase&lt;T&gt;.ClearGradients()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShape">LayerBase&lt;T&gt;.GetInputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShapes">LayerBase&lt;T&gt;.GetInputShapes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetOutputShape">LayerBase&lt;T&gt;.GetOutputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetWeights">LayerBase&lt;T&gt;.GetWeights()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetBiases">LayerBase&lt;T&gt;.GetBiases()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_MapActivationToFused">LayerBase&lt;T&gt;.MapActivationToFused()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuExecution">LayerBase&lt;T&gt;.SupportsGpuExecution</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuTraining">LayerBase&lt;T&gt;.SupportsGpuTraining</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanExecuteOnGpu">LayerBase&lt;T&gt;.CanExecuteOnGpu</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanTrainOnGpu">LayerBase&lt;T&gt;.CanTrainOnGpu</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ForwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0____">LayerBase&lt;T&gt;.ForwardGpu(params IGpuTensor&lt;T&gt;[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_BackwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0__">LayerBase&lt;T&gt;.BackwardGpu(IGpuTensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParametersGpu_AiDotNet_Interfaces_IGpuOptimizerConfig_">LayerBase&lt;T&gt;.UpdateParametersGpu(IGpuOptimizerConfig)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UploadWeightsToGpu">LayerBase&lt;T&gt;.UploadWeightsToGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_DownloadWeightsFromGpu">LayerBase&lt;T&gt;.DownloadWeightsFromGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ZeroGradientsGpu">LayerBase&lt;T&gt;.ZeroGradientsGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetActivationTypes">LayerBase&lt;T&gt;.GetActivationTypes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0____">LayerBase&lt;T&gt;.Forward(params Tensor&lt;T&gt;[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ApplyActivation(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ApplyActivation(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ActivateTensor(IActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IVectorActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ActivateTensor(IVectorActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateInputShape_System_Int32_System_Int32_System_Int32_">LayerBase&lt;T&gt;.CalculateInputShape(int, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateOutputShape_System_Int32_System_Int32_System_Int32_">LayerBase&lt;T&gt;.CalculateOutputShape(int, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Clone">LayerBase&lt;T&gt;.Clone()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_DerivativeTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.DerivativeTensor(IActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative__0__0_">LayerBase&lt;T&gt;.ApplyActivationDerivative(T, T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ApplyActivationDerivative(Tensor&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ComputeActivationJacobian_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ComputeActivationJacobian(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Vector__0__AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ApplyActivationDerivative(Vector&lt;T&gt;, Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.UpdateParameters(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Serialize_System_IO_BinaryWriter_">LayerBase&lt;T&gt;.Serialize(BinaryWriter)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Deserialize_System_IO_BinaryReader_">LayerBase&lt;T&gt;.Deserialize(BinaryReader)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetDiagnostics">LayerBase&lt;T&gt;.GetDiagnostics()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationToGraph_AiDotNet_Autodiff_ComputationNode__0__">LayerBase&lt;T&gt;.ApplyActivationToGraph(ComputationNode&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanActivationBeJitted">LayerBase&lt;T&gt;.CanActivationBeJitted()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_RegisterTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_Engines_PersistentTensorRole_">LayerBase&lt;T&gt;.RegisterTrainableParameter(Tensor&lt;T&gt;, PersistentTensorRole)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InvalidateTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.InvalidateTrainableParameter(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_HasGpuActivation">LayerBase&lt;T&gt;.HasGpuActivation()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationForwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">LayerBase&lt;T&gt;.ApplyActivationForwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationBackwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">LayerBase&lt;T&gt;.ApplyActivationBackwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetFusedActivationType">LayerBase&lt;T&gt;.GetFusedActivationType()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivation_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_">LayerBase&lt;T&gt;.ApplyGpuActivation(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int, FusedActivationType)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivationBackward_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_System_Single_">LayerBase&lt;T&gt;.ApplyGpuActivationBackward(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int, FusedActivationType, float)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose">LayerBase&lt;T&gt;.Dispose()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose_System_Boolean_">LayerBase&lt;T&gt;.Dispose(bool)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_WeightParameterName">LayerBase&lt;T&gt;.WeightParameterName</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_BiasParameterName">LayerBase&lt;T&gt;.BiasParameterName</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetWeights_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetWeights(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetBiases_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetBiases(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterNames">LayerBase&lt;T&gt;.GetParameterNames()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_TryGetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___">LayerBase&lt;T&gt;.TryGetParameter(string, out Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetParameter(string, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterShape_System_String_">LayerBase&lt;T&gt;.GetParameterShape(string)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_NamedParameterCount">LayerBase&lt;T&gt;.NamedParameterCount</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ValidateWeights_System_Collections_Generic_IEnumerable_System_String__System_Func_System_String_System_String__">LayerBase&lt;T&gt;.ValidateWeights(IEnumerable&lt;string&gt;, Func&lt;string, string&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_LoadWeights_System_Collections_Generic_Dictionary_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___System_Func_System_String_System_String__System_Boolean_">LayerBase&lt;T&gt;.LoadWeights(Dictionary&lt;string, Tensor&lt;T&gt;&gt;, Func&lt;string, string&gt;, bool)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
Chain-of-LoRA (COLA) is an advanced LoRA technique that enables sequential composition
of multiple LoRA adaptations through an iterative optimization framework. Unlike standard
LoRA which applies a single low-rank adaptation, COLA builds a chain of adaptations where
each adapter is trained, merged into the model, and then a new adapter is initialized for
further refinement.
</p>
<p>
This approach bridges the performance gap between standard LoRA and full fine-tuning by
employing residual learning principles. Each iteration in the chain adds incremental
improvements to the model's task-specific performance without incurring additional
computational costs or memory overhead during inference.
</p>
<p><b>Key Concepts:</b>
<p><b>Sequential Adaptation:</b>
Chain-of-LoRA applies adaptations in sequence (Task A → Task B → Task C), where each
stage builds upon the previous one. This is inspired by the Frank-Wolfe optimization
algorithm, which makes greedy updates along the direction of maximum improvement.</p>
<p><b>Merge and Re-initialize:</b>
After training each LoRA adapter, the learned weights are merged back into the base layer,
and a new LoRA adapter is initialized. This &quot;tying a knot&quot; process allows the model to
consolidate learned knowledge before adding new adaptations.</p>
<p><b>Knowledge Preservation:</b>
By freezing the base layer and only training the LoRA components, the chain preserves
previously learned knowledge while allowing new task-specific adaptations. Each adapter
in the chain captures a specific aspect of the task or a refinement step.</p>
<p><b>Incremental Fine-tuning Pipeline:</b>
COLA enables continual learning scenarios where tasks are presented sequentially, and
the model must adapt to new tasks while maintaining performance on previous ones.</p>

<p><b>Benefits of Chain-of-LoRA:</b>
<ul>
<li><b>Better Performance:</b> Achieves up to 6.47% relative accuracy gain over standard LoRA</li>
<li><b>No Extra Overhead:</b> After merging, inference cost is identical to the base model</li>
<li><b>Modular Adaptation:</b> Each adapter can be trained, tested, and validated independently</li>
<li><b>Catastrophic Forgetting Mitigation:</b> Sequential merging helps preserve prior knowledge</li>
<li><b>Task Chaining:</b> Naturally supports multi-task learning and transfer learning scenarios</li>
<li><b>Flexible Deployment:</b> Can deploy the full chain or selected adapters as needed</li>
</ul>

<p><b>For Beginners:</b>
<p>Imagine you're learning a complex skill in stages:</p>
<ol>
<li>First, you learn the basics (Adapter 1)</li>
<li>Then you practice and the basics become automatic (Merge)</li>
<li>Next, you learn intermediate techniques on top of the basics (Adapter 2)</li>
<li>Again, you practice until they're automatic (Merge)</li>
<li>Finally, you learn advanced skills building on everything before (Adapter 3)</li>
</ol>
<p>Chain-of-LoRA works the same way: each adapter learns something new, then it's consolidated
into the model, and the next adapter can focus on the next refinement. This stepwise approach
often achieves better results than trying to learn everything at once.</p>

<p><b>Research Reference:</b>
<p>Based on &quot;Chain of LoRA: Efficient Fine-tuning of Language Models via Residual Learning&quot;
(arXiv:2401.04151, January 2024). The paper demonstrates that sequential low-rank adaptations
can significantly improve task performance compared to single-stage LoRA, especially on
complex reasoning and multi-step tasks.</p>

<p><b>Usage Example:</b>
<pre><code class="lang-csharp">// Create a chain with 3 sequential adaptations
var chain = new ChainLoRAAdapter&lt;double&gt;(baseLayer, rank: 8, chainLength: 3);

// Train first adapter on Task A
chain.SetActiveAdapterIndex(0);
TrainModel(chain, taskAData);
chain.FreezeActiveAdapter(); // Freeze Task A adapter

// Train second adapter on Task B
chain.SetActiveAdapterIndex(1);
TrainModel(chain, taskBData);
chain.FreezeActiveAdapter(); // Freeze Task B adapter

// Train third adapter on Task C
chain.SetActiveAdapterIndex(2);
TrainModel(chain, taskCData);

// Deploy: merge all adapters into base layer for optimized inference
ILayer&lt;double&gt; finalLayer = chain.MergeToOriginalLayer();</code></pre>

</div>


  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1__ctor_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.#ctor*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1__ctor_AiDotNet_Interfaces_ILayer__0__System_Int32_System_Int32_System_Double_System_Boolean_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.#ctor(AiDotNet.Interfaces.ILayer{`0},System.Int32,System.Int32,System.Double,System.Boolean)">
  ChainLoRAAdapter(ILayer&lt;T&gt;, int, int, double, bool)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L198"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new Chain-of-LoRA adapter with the specified configuration.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public ChainLoRAAdapter(ILayer&lt;T&gt; baseLayer, int rank, int chainLength = 3, double alpha = -1, bool freezeBaseLayer = true)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>baseLayer</code> <a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</dt>
    <dd><p>The layer to adapt with the LoRA chain.</p>
</dd>
    <dt><code>rank</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The rank of each LoRA decomposition in the chain.</p>
</dd>
    <dt><code>chainLength</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of sequential adapters in the chain (default: 3).</p>
</dd>
    <dt><code>alpha</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The LoRA scaling factor for each adapter (defaults to rank if negative).</p>
</dd>
    <dt><code>freezeBaseLayer</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Whether to freeze the base layer's parameters during training (default: true).</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1__ctor_AiDotNet_Interfaces_ILayer__0__System_Int32_System_Int32_System_Double_System_Boolean__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Creates a chain of LoRA adapters for sequential fine-tuning. Each adapter in the chain
can be trained independently, merged into the model, and then the next adapter can be
activated for further refinement.
</p>
<p><b>For Beginners:</b>
<p>Parameters:</p>
<ul>
<li>baseLayer: The layer you want to adapt (e.g., a dense or convolutional layer)</li>
<li>rank: How compressed each adapter is (lower = fewer parameters per stage)</li>
<li>chainLength: How many sequential adaptation stages you want (typical: 2-5)</li>
<li>alpha: Controls adaptation strength (usually equals rank)</li>
<li>freezeBaseLayer: Lock base weights to preserve pre-trained knowledge (recommended: true)</li>
</ul>
<p>Example: chainLength=3 means you can do three rounds of training and merging,
allowing the model to incrementally improve on complex tasks.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></dt>
    <dd><p>Thrown when baseLayer is null.</p>
</dd>
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a></dt>
    <dd><p>Thrown when chainLength is less than 1.</p>
</dd>
  </dl>



  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_ActiveAdapterIndex_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.ActiveAdapterIndex*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_ActiveAdapterIndex" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.ActiveAdapterIndex">
  ActiveAdapterIndex
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L148"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the index of the currently active adapter (0-based).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int ActiveAdapterIndex { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_ActiveAdapterIndex_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>The active adapter is the one currently being trained. Other adapters in the chain
are either waiting to be trained (higher indices) or have been merged (lower indices).</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_AdapterChain_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.AdapterChain*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_AdapterChain" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.AdapterChain">
  AdapterChain
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L157"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the list of LoRA adapters in the chain.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public IReadOnlyList&lt;LoRALayer&lt;T&gt;&gt; AdapterChain { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ireadonlylist-1">IReadOnlyList</a>&lt;<a class="xref" href="AiDotNet.LoRA.LoRALayer-1.html">LoRALayer</a>&lt;T&gt;&gt;</dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_AdapterChain_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>Each adapter in the chain represents one stage of sequential adaptation.
Adapters are applied in order during forward passes.</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_ChainLength_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.ChainLength*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_ChainLength" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.ChainLength">
  ChainLength
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L139"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the total number of adapters in the chain.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int ChainLength { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_ChainLength_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This represents the maximum number of sequential adaptation stages that can be applied.
Each adapter can be trained independently and then merged before proceeding to the next.</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_FrozenStatus_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.FrozenStatus*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_FrozenStatus" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.FrozenStatus">
  FrozenStatus
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L167"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the frozen status of each adapter in the chain.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public IReadOnlyList&lt;bool&gt; FrozenStatus { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ireadonlylist-1">IReadOnlyList</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a>&gt;</dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_FrozenStatus_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>True indicates that an adapter has been frozen and should no longer contribute
trainable parameters. Frozen adapters still contribute to forward/backward passes
until the entire chain is merged via MergeToOriginalLayer().</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_ParameterCount_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.ParameterCount*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_ParameterCount" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.ParameterCount">
  ParameterCount
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L330"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the total number of parameters in the chain (base layer + all unfrozen adapters).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override int ParameterCount { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_ParameterCount_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This count includes parameters from the base layer (if not frozen) plus all unfrozen adapters in the chain.
Frozen adapters don't contribute to the parameter count since they no longer receive gradient updates.
Returns the cached _currentParameterCount once the chain is initialized, or computes it on-the-fly
during construction to handle base class initialization.</p>
</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_Backward_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.Backward*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.Backward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Backward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L433"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the backward pass through all layers in the chain.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; Backward(Tensor&lt;T&gt; outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>outputGradient</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Gradient flowing back from the next layer.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Gradient to pass to the previous layer.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Gradients flow through all adapters and the base layer. Only unfrozen adapters
and the base layer (if not frozen) receive parameter updates.
</p>
<p><b>For Beginners:</b>
During learning, this figures out how to improve each adapter. Only the active,
unfrozen adapter gets updated - the frozen ones preserve their learned knowledge.
</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_Forward_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.Forward*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.Forward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Forward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L398"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the forward pass through the base layer and all adapters in the chain.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; Forward(Tensor&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Input tensor.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Output with all adapter contributions summed.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The forward pass computes:
output = base_layer(input) + adapter_0(input) + adapter_1(input) + ... + adapter_n(input)
</p>
<p>
IMPORTANT: All adapters contribute to the output, regardless of frozen status.
Frozen adapters continue to be computed in every forward pass. They are only
"frozen" in the sense that they don't receive gradient updates during training.
True inference optimization (eliminating frozen adapter computation) only occurs
after calling MergeToOriginalLayer().
</p>
<p><b>For Beginners:</b>
During inference or training, the input goes through the base layer and ALL adapters
in the chain (both frozen and unfrozen). Their outputs are added together to get the
final result. Freezing an adapter stops it from training, but it still contributes
to every prediction.
</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_FreezeActiveAdapter_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.FreezeActiveAdapter*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_FreezeActiveAdapter" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.FreezeActiveAdapter">
  FreezeActiveAdapter()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L279"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Freezes the currently active adapter to prevent further training.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void FreezeActiveAdapter()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_FreezeActiveAdapter_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This "ties a knot" in the chain by marking the active adapter as frozen.
The adapter continues to contribute to forward passes but will no longer receive
gradient updates, allowing the next adapter in the chain to build upon this
consolidated knowledge.
</p>
<p>
IMPORTANT: This method does NOT merge weights into the base layer. All adapters
(frozen or not) remain active during forward/backward passes. True weight merging
only occurs when MergeToOriginalLayer() is called at the end of training.
</p>
<p><b>For Beginners:</b>
After training an adapter stage, call this to "lock it in" before moving to the
next stage. The adapter's learned knowledge is preserved and it stops training,
but it still contributes to the model's output. Think of it like finishing one
chapter before starting the next - the previous chapter's knowledge remains active.
</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_GetFrozenCount_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.GetFrozenCount*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_GetFrozenCount" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.GetFrozenCount">
  GetFrozenCount()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L316"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the number of adapters that have been frozen.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int GetFrozenCount()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Count of frozen adapters.</p>
</dd>
  </dl>











  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_GetParameters_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.GetParameters*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_GetParameters" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.GetParameters">
  GetParameters()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L497"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the current parameters as a vector.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Vector&lt;T&gt; GetParameters()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>Vector containing parameters from base layer (if not frozen) and all unfrozen adapters.</p>
</dd>
  </dl>











  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_GetTrainableAdapterCount_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.GetTrainableAdapterCount*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_GetTrainableAdapterCount" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.GetTrainableAdapterCount">
  GetTrainableAdapterCount()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L369"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the number of adapters that are still trainable (not frozen).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int GetTrainableAdapterCount()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Count of unfrozen adapters.</p>
</dd>
  </dl>











  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_MergeToOriginalLayer_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.MergeToOriginalLayer*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_MergeToOriginalLayer" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.MergeToOriginalLayer">
  MergeToOriginalLayer()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L535"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Merges all adapters in the chain into the original base layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override ILayer&lt;T&gt; MergeToOriginalLayer()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</dt>
    <dd><p>A new layer with all LoRA adaptations merged into the base weights.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_MergeToOriginalLayer_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This creates a single layer that includes all the sequential adaptations from the chain.
The resulting layer has the same computational cost as the original base layer but
includes all the learned improvements from each stage of the chain.
</p>
<p><b>For Beginners:</b>
After training all stages of the chain, call this to create a final optimized layer.
The result is a regular layer (no LoRA overhead) that performs as well as the full chain.
Perfect for deployment when you want maximum speed with all the learned adaptations.
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown when the base layer type is not DenseLayer or FullyConnectedLayer.</p>
</dd>
  </dl>



  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_ResetState_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.ResetState*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_ResetState" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.ResetState">
  ResetState()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L579"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Resets the internal state of the base layer and all adapters in the chain.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void ResetState()</code></pre>
  </div>













  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_SetActiveAdapterIndex_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.SetActiveAdapterIndex*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_SetActiveAdapterIndex_System_Int32_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.SetActiveAdapterIndex(System.Int32)">
  SetActiveAdapterIndex(int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L247"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sets which adapter in the chain is currently active for training.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void SetActiveAdapterIndex(int index)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>index</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The 0-based index of the adapter to activate.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_SetActiveAdapterIndex_System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Only the active adapter receives gradient updates during training. Other adapters
are either frozen (already merged) or inactive (waiting to be trained).
</p>
<p><b>For Beginners:</b>
This is like choosing which stage of learning you're currently working on.
Set to 0 for the first stage, 1 for the second, etc. Only that stage's adapter
will be trained while the others remain frozen.
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentoutofrangeexception">ArgumentOutOfRangeException</a></dt>
    <dd><p>Thrown when index is out of range.</p>
</dd>
  </dl>



  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_SetParameters_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.SetParameters*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_SetParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.SetParameters(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  SetParameters(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L507"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sets the layer parameters from a vector.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void SetParameters(Vector&lt;T&gt; parameters)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>parameters</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>Vector containing parameters.</p>
</dd>
  </dl>









  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a></dt>
    <dd><p>Thrown when parameter count doesn't match.</p>
</dd>
  </dl>



  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_UnfreezeAdapter_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.UnfreezeAdapter*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_UnfreezeAdapter_System_Int32_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.UnfreezeAdapter(System.Int32)">
  UnfreezeAdapter(int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L301"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Unfreezes a previously frozen adapter, making it trainable again.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void UnfreezeAdapter(int index)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>index</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The index of the adapter to unfreeze.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_UnfreezeAdapter_System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This allows re-training a previously frozen adapter if needed for iterative refinement.
Useful for scenarios where you want to go back and adjust an earlier stage.
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentoutofrangeexception">ArgumentOutOfRangeException</a></dt>
    <dd><p>Thrown when index is out of range.</p>
</dd>
  </dl>



  <a id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_UpdateParameters_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.UpdateParameters*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_UpdateParameters__0_" data-uid="AiDotNet.LoRA.Adapters.ChainLoRAAdapter`1.UpdateParameters(`0)">
  UpdateParameters(T)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L475"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Updates parameters using the specified learning rate.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void UpdateParameters(T learningRate)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>learningRate</code> <span class="xref">T</span></dt>
    <dd><p>The learning rate for parameter updates.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_LoRA_Adapters_ChainLoRAAdapter_1_UpdateParameters__0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>Only the active unfrozen adapter receives updates. Frozen adapters and the base layer
(if frozen) do not receive parameter updates.</p>
</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/ChainLoRAAdapter.cs/#L100" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
