<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class SphericalSoftmaxActivation&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class SphericalSoftmaxActivation&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Implements the Spherical Softmax activation function, which normalizes inputs to the unit sphere before applying softmax.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1.md&amp;value=---%0Auid%3A%20AiDotNet.ActivationFunctions.SphericalSoftmaxActivation%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.ActivationFunctions.SphericalSoftmaxActivation`1">



  <h1 id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1" data-uid="AiDotNet.ActivationFunctions.SphericalSoftmaxActivation`1" class="text-break">
Class SphericalSoftmaxActivation&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/SphericalSoftmaxActivation.cs/#L31"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.ActivationFunctions.html">ActivationFunctions</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Implements the Spherical Softmax activation function, which normalizes inputs to the unit sphere before applying softmax.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class SphericalSoftmaxActivation&lt;T&gt; : ActivationFunctionBase&lt;T&gt;, IActivationFunction&lt;T&gt;, IVectorActivationFunction&lt;T&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric data type used for calculations.</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html">ActivationFunctionBase</a>&lt;T&gt;</div>
      <div><span class="xref">SphericalSoftmaxActivation&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.Interfaces.IActivationFunction-1.html">IActivationFunction</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IVectorActivationFunction-1.html">IVectorActivationFunction</a>&lt;T&gt;</div>
    </dd>
  </dl>


  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_NumOps">ActivationFunctionBase&lt;T&gt;.NumOps</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Engine">ActivationFunctionBase&lt;T&gt;.Engine</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Activate__0_">ActivationFunctionBase&lt;T&gt;.Activate(T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Derivative__0_">ActivationFunctionBase&lt;T&gt;.Derivative(T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Activate_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">ActivationFunctionBase&lt;T&gt;.Activate(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Derivative_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">ActivationFunctionBase&lt;T&gt;.Derivative(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">ActivationFunctionBase&lt;T&gt;.Backward(Tensor&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_SupportsGpuTraining">ActivationFunctionBase&lt;T&gt;.SupportsGpuTraining</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_ForwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">ActivationFunctionBase&lt;T&gt;.ForwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_BackwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">ActivationFunctionBase&lt;T&gt;.BackwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
Spherical Softmax is a variation of the standard Softmax function that first normalizes the input vector
to have unit length (projects it onto the unit sphere) before applying the exponential and normalization steps.
This can help improve numerical stability and performance in certain neural network architectures.
</p>
<p>
<b>For Beginners:</b> Spherical Softmax is a special version of the Softmax function that's often used in the
output layer of neural networks for classification tasks. 
<p>The standard Softmax converts a vector of numbers into probabilities that sum to 1, but it can sometimes
have numerical issues with very large or very small numbers. Spherical Softmax adds an extra step by first
&quot;normalizing&quot; the input vector (making its length equal to 1) before applying the regular Softmax steps.</p>
<p>Think of it like this:</p>
<ol>
<li>First, we adjust all the input values so that they form a point on a sphere with radius 1</li>
<li>Then we apply the regular Softmax calculation to these adjusted values</li>
</ol>
<p>This approach can make the neural network training more stable and sometimes leads to better performance,
especially when dealing with high-dimensional data or when the input values can vary widely in magnitude.</p>

</div>


  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_SupportsJitCompilation_" data-uid="AiDotNet.ActivationFunctions.SphericalSoftmaxActivation`1.SupportsJitCompilation*"></a>

  <h3 id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_SupportsJitCompilation" data-uid="AiDotNet.ActivationFunctions.SphericalSoftmaxActivation`1.SupportsJitCompilation">
  SupportsJitCompilation
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/SphericalSoftmaxActivation.cs/#L181"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this activation function supports JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsJitCompilation { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True because TensorOperations.SphericalSoftmax provides full forward and backward pass support.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_SupportsJitCompilation_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
SphericalSoftmax supports JIT compilation by composing L2 normalization with softmax.
The backward pass correctly applies the chain rule through both operations.
</p>
<p>
Note: Currently implemented for 2D tensors (batch, features) along axis=-1.
</p>
</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_Activate_" data-uid="AiDotNet.ActivationFunctions.SphericalSoftmaxActivation`1.Activate*"></a>

  <h3 id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_Activate_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.ActivationFunctions.SphericalSoftmaxActivation`1.Activate(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  Activate(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/SphericalSoftmaxActivation.cs/#L85"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Spherical Softmax activation function to a vector of inputs.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Vector&lt;T&gt; Activate(Vector&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The input vector.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>A vector where all elements are positive and sum to 1.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_Activate_AiDotNet_Tensors_LinearAlgebra_Vector__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The Spherical Softmax function performs the following steps:
1. Normalizes the input vector to have unit length (L2 norm = 1)
2. Applies the exponential function to each element
3. Divides each element by the sum of all exponential values
</p>
<p>
<b>For Beginners:</b> This method transforms a vector of numbers (like scores for different classes) into 
probabilities that add up to 1. Here's how it works step by step:
<ol>
<li><p>First, it calculates the &quot;length&quot; of the input vector (called the L2 norm)</p>
<ul>
<li>This is like finding the distance from the origin to a point in multi-dimensional space</li>
<li>Mathematically, it's the square root of the sum of squares of all elements</li>
</ul>
</li>
<li><p>Then it divides each input value by this length</p>
<ul>
<li>This &quot;normalizes&quot; the vector so its length becomes exactly 1</li>
<li>The direction of the vector stays the same, but its magnitude is now 1</li>
</ul>
</li>
<li><p>Next, it applies the exponential function (e^x) to each normalized value</p>
<ul>
<li>This makes all values positive and emphasizes larger values</li>
</ul>
</li>
<li><p>Finally, it divides each exponential value by the sum of all exponential values</p>
<ul>
<li>This ensures all values are between 0 and 1 and sum to exactly 1</li>
<li>These values can now be interpreted as probabilities</li>
</ul>
</li>
</ol>
<p>The result is a probability distribution where higher input values get higher probabilities,
but the initial normalization step helps prevent numerical issues that can occur with regular Softmax.</p>

</div>




  <a id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_ApplyToGraph_" data-uid="AiDotNet.ActivationFunctions.SphericalSoftmaxActivation`1.ApplyToGraph*"></a>

  <h3 id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_ApplyToGraph_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.ActivationFunctions.SphericalSoftmaxActivation`1.ApplyToGraph(AiDotNet.Autodiff.ComputationNode{`0})">
  ApplyToGraph(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/SphericalSoftmaxActivation.cs/#L195"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies this activation function to a computation graph node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override ComputationNode&lt;T&gt; ApplyToGraph(ComputationNode&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The computation node to apply the activation to.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with SphericalSoftmax activation applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_ApplyToGraph_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method maps to TensorOperations&lt;T&gt;.SphericalSoftmax(input) which handles both
forward and backward passes for JIT compilation.
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></dt>
    <dd><p>Thrown if input is null.</p>
</dd>
  </dl>



  <a id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_Derivative_" data-uid="AiDotNet.ActivationFunctions.SphericalSoftmaxActivation`1.Derivative*"></a>

  <h3 id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_Derivative_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.ActivationFunctions.SphericalSoftmaxActivation`1.Derivative(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  Derivative(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/SphericalSoftmaxActivation.cs/#L137"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Calculates the Jacobian matrix of the Spherical Softmax function for a given input vector.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Matrix&lt;T&gt; Derivative(Vector&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The input vector.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Matrix-1.html">Matrix</a>&lt;T&gt;</dt>
    <dd><p>A matrix representing the partial derivatives of each output with respect to each input.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_Derivative_AiDotNet_Tensors_LinearAlgebra_Vector__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The Jacobian matrix contains the partial derivatives of each output element with respect to each input element.
For Spherical Softmax, the Jacobian combines the derivatives of both the normalization step and the softmax step.
</p>
<p>
<b>For Beginners:</b> The derivative of Spherical Softmax is quite complex because it involves two transformations:
first normalizing the vector to the unit sphere, and then applying softmax.
<p>This method returns a &quot;Jacobian matrix&quot; which shows how each output value changes when each input value changes.
It's used during the training process of neural networks to determine how to adjust the weights.</p>
<p>The calculation has two main parts:</p>
<ol>
<li>How the softmax output changes with respect to the normalized input</li>
<li>How the normalized input changes with respect to the original input</li>
</ol>
<p>For diagonal elements (when i=j):</p>
<ul>
<li>term1: How the softmax output changes if its own input increases</li>
<li>term2: How the normalization affects this relationship</li>
</ul>
<p>For off-diagonal elements (when i?j):</p>
<ul>
<li>term1: How one output changes when a different input increases</li>
<li>term2: How the normalization creates interdependencies between inputs</li>
</ul>
<p>Don't worry if the math seems complex - the neural network library handles these calculations automatically.
The important thing to understand is that this function helps the network learn by showing how changes in
the input affect the output probabilities.</p>

</div>




  <a id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_SupportsScalarOperations_" data-uid="AiDotNet.ActivationFunctions.SphericalSoftmaxActivation`1.SupportsScalarOperations*"></a>

  <h3 id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_SupportsScalarOperations" data-uid="AiDotNet.ActivationFunctions.SphericalSoftmaxActivation`1.SupportsScalarOperations">
  SupportsScalarOperations()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/SphericalSoftmaxActivation.cs/#L48"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Indicates whether this activation function supports scalar operations.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected override bool SupportsScalarOperations()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Always returns false as Spherical Softmax requires a vector of values.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_ActivationFunctions_SphericalSoftmaxActivation_1_SupportsScalarOperations_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Unlike functions like ReLU that can operate on individual values, Spherical Softmax needs to consider
all elements in a vector together to compute the probability distribution.
</p>
<p>
<b>For Beginners:</b> This method returning false means that Spherical Softmax cannot work on just one number at a time.
It needs to see all the values together (like all scores for different classes) to normalize them properly
and convert them into probabilities.
</p>
</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/SphericalSoftmaxActivation.cs/#L31" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
