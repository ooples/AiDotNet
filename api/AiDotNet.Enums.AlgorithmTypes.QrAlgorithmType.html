<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Enum QrAlgorithmType | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Enum QrAlgorithmType | AiDotNet Documentation ">
      
      <meta name="description" content="Represents different algorithm types for computing the QR decomposition of matrices.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_Enums_AlgorithmTypes_QrAlgorithmType.md&amp;value=---%0Auid%3A%20AiDotNet.Enums.AlgorithmTypes.QrAlgorithmType%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.Enums.AlgorithmTypes.QrAlgorithmType">




  <h1 id="AiDotNet_Enums_AlgorithmTypes_QrAlgorithmType" data-uid="AiDotNet.Enums.AlgorithmTypes.QrAlgorithmType" class="text-break">
Enum QrAlgorithmType  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Enums/AlgorithmTypes/QrAlgorithmType.cs/#L36"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.Enums.html">Enums</a>.<a class="xref" href="AiDotNet.Enums.AlgorithmTypes.html">AlgorithmTypes</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Represents different algorithm types for computing the QR decomposition of matrices.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public enum QrAlgorithmType</code></pre>
  </div>









  <h2 id="fields">Fields
</h2>
  <dl class="parameters">
    <dt id="AiDotNet_Enums_AlgorithmTypes_QrAlgorithmType_Givens"><code>Givens = 2</code></dt>
  <dd><p>Uses Givens rotations to compute the QR decomposition.</p>
<p>
<b>For Beginners:</b> The Givens method uses a series of simple rotations to gradually transform a matrix 
into triangular form.
<p>Think of it like carefully turning a combination lock: you make one precise rotation at a time, each
affecting just two numbers, until the whole lock reaches the correct position.</p>
<p>The method works by:</p>
<ol>
<li>Identifying two elements in a column</li>
<li>Creating a rotation that makes one of these elements zero</li>
<li>Applying this rotation to the entire matrix</li>
<li>Repeating until all elements below the diagonal are zero</li>
</ol>
<p>The Givens rotation method:</p>
<ol>
<li><p>Is very precise and numerically stable</p>
</li>
<li><p>Works on just two rows at a time, making it ideal for sparse matrices</p>
</li>
<li><p>Can be easily parallelized for certain matrix structures</p>
</li>
<li><p>Is excellent for making targeted changes to matrices</p>
</li>
<li><p>Is particularly useful when you only need to zero out specific elements</p>
</li>
</ol>
<p>In machine learning applications, Givens rotations might be used when working with sparse data matrices,
when updating existing QR decompositions after small changes to the data, or in specialized algorithms
that process streaming data where the matrix is built up row by row.</p>

</dd>
  
    <dt id="AiDotNet_Enums_AlgorithmTypes_QrAlgorithmType_GramSchmidt"><code>GramSchmidt = 0</code></dt>
  <dd><p>Uses the classical Gram-Schmidt process to compute the QR decomposition.</p>
<p>
<b>For Beginners:</b> The Gram-Schmidt process is like creating a set of perfectly perpendicular directions 
from a set of possibly overlapping directions.
<p>Imagine you're in a room and want to describe locations using &quot;forward/backward,&quot; &quot;left/right,&quot; and
&quot;up/down.&quot; If your initial directions aren't perfectly aligned with the room's walls (they're skewed),
Gram-Schmidt helps you straighten them out to get clean, perpendicular directions.</p>
<p>The process works by:</p>
<ol>
<li>Taking the first vector as is</li>
<li>For each subsequent vector, removing any components that point in the same direction as previous vectors</li>
<li>Then normalizing each vector (making its length equal to 1)</li>
</ol>
<p>The classical Gram-Schmidt method:</p>
<ol>
<li><p>Is conceptually simple and easy to understand</p>
</li>
<li><p>Works well for small matrices and educational purposes</p>
</li>
<li><p>Is less numerically stable than other methods when used with floating-point arithmetic</p>
</li>
<li><p>Has a straightforward implementation</p>
</li>
</ol>
<p>In machine learning applications, understanding Gram-Schmidt helps in feature engineering when you want
to create independent features from correlated ones, or when implementing certain types of neural network
layers that benefit from orthogonal weights.</p>

</dd>
  
    <dt id="AiDotNet_Enums_AlgorithmTypes_QrAlgorithmType_Householder"><code>Householder = 1</code></dt>
  <dd><p>Uses Householder reflections to compute the QR decomposition.</p>
<p>
<b>For Beginners:</b> The Householder method uses special transformations called "reflections" to gradually 
transform a matrix into triangular form.
<p>Imagine you have a mirror and you're using it to reflect light onto specific targets. A Householder
reflection is like perfectly positioning a mirror to transform multiple points at once in a very
specific way.</p>
<p>For each column of the matrix:</p>
<ol>
<li>The method creates a special &quot;mirror&quot; (Householder reflector)</li>
<li>This mirror is positioned to reflect the column in such a way that all elements below the diagonal become zero</li>
<li>This reflection is applied to the remaining columns as well</li>
</ol>
<p>The Householder method:</p>
<ol>
<li><p>Is numerically very stable (much more so than classical Gram-Schmidt)</p>
</li>
<li><p>Is efficient for medium to large matrices</p>
</li>
<li><p>Requires fewer arithmetic operations than Givens rotations for dense matrices</p>
</li>
<li><p>Is the method of choice in many professional numerical libraries</p>
</li>
<li><p>Transforms entire columns at once rather than working element by element</p>
</li>
</ol>
<p>In machine learning, this stable QR decomposition is often used behind the scenes in algorithms that
require reliable numerical linear algebra, such as in training certain types of models, in dimensionality
reduction techniques, or when solving least squares problems with many features.</p>

</dd>
  
    <dt id="AiDotNet_Enums_AlgorithmTypes_QrAlgorithmType_IterativeGramSchmidt"><code>IterativeGramSchmidt = 4</code></dt>
  <dd><p>Uses an iterative version of the Gram-Schmidt process that repeats the orthogonalization step to achieve higher accuracy.</p>
<p>
<b>For Beginners:</b> The Iterative Gram-Schmidt method takes the modified Gram-Schmidt process and repeats it 
multiple times to achieve even better numerical accuracy.
<p>Think of it like cleaning a window: the first pass removes most of the dirt, but you might go over it
again to catch the spots you missed and make it truly spotless.</p>
<p>The process works by:</p>
<ol>
<li>Performing a complete Modified Gram-Schmidt orthogonalization</li>
<li>Checking if the resulting vectors are sufficiently orthogonal</li>
<li>If not, applying the orthogonalization process again to further refine the results</li>
<li>Repeating until a desired level of orthogonality is achieved</li>
</ol>
<p>The Iterative Gram-Schmidt method:</p>
<ol>
<li><p>Provides the highest numerical accuracy among Gram-Schmidt variants</p>
</li>
<li><p>Is useful for very ill-conditioned matrices where even Modified Gram-Schmidt might not be sufficient</p>
</li>
<li><p>Requires more computational time due to the repeated orthogonalization</p>
</li>
<li><p>Can achieve results comparable to Householder reflections in terms of stability</p>
</li>
<li><p>Allows for a trade-off between speed and accuracy by adjusting the number of iterations</p>
</li>
</ol>
<p>In machine learning applications, this high-precision orthogonalization might be used when working with
extremely sensitive models, when the data has many highly correlated features, or in specialized scientific
applications where even small numerical errors could propagate and affect results significantly.</p>

</dd>
  
    <dt id="AiDotNet_Enums_AlgorithmTypes_QrAlgorithmType_ModifiedGramSchmidt"><code>ModifiedGramSchmidt = 3</code></dt>
  <dd><p>Uses the Modified Gram-Schmidt process to compute the QR decomposition with improved numerical stability.</p>
<p>
<b>For Beginners:</b> The Modified Gram-Schmidt process is an improved version of the classical Gram-Schmidt 
that addresses numerical stability issues.
<p>Imagine you're building a house: the classical Gram-Schmidt is like measuring and cutting all your lumber
at the beginning (which might lead to accumulated errors), while the modified version is like measuring
and cutting each piece just before you use it (reducing error buildup).</p>
<p>The key difference is:</p>
<ul>
<li>Classical: Computes all projections using the original vectors</li>
<li>Modified: Updates the vectors after each projection, using the most recent versions</li>
</ul>
<p>The Modified Gram-Schmidt method:</p>
<ol>
<li><p>Is much more numerically stable than the classical version</p>
</li>
<li><p>Produces more accurate results, especially for ill-conditioned matrices</p>
</li>
<li><p>Has the same computational complexity as the classical version</p>
</li>
<li><p>Is still conceptually straightforward to understand</p>
</li>
<li><p>Is suitable for practical applications, not just educational purposes</p>
</li>
</ol>
<p>In machine learning, this improved stability is important when working with real-world data that might
have nearly linearly dependent features, when implementing algorithms that require orthogonal bases,
or when the precision of the decomposition directly affects the quality of predictions or classifications.</p>

</dd>
  
  </dl>


  <h2 id="AiDotNet_Enums_AlgorithmTypes_QrAlgorithmType_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
<b>For Beginners:</b> QR decomposition is a fundamental technique in linear algebra that breaks down a matrix into 
two components: Q (an orthogonal matrix) and R (an upper triangular matrix).
<p>Think of it like breaking down a complex movement (like throwing a ball) into two simpler movements:</p>
<ol>
<li>First, rotating your body to face the right direction (the Q part)</li>
<li>Then, moving your arm forward in a straight line (the R part)</li>
</ol>
<p>In matrix terms:</p>
<ul>
<li>If A is your original matrix, QR decomposition gives you A = QR</li>
<li>Q has perpendicular columns with unit length (orthogonal)</li>
<li>R is upper triangular (has zeros below the diagonal)</li>
</ul>
<p>Why is QR decomposition important in AI and machine learning?</p>
<ol>
<li><p>Solving Linear Systems: Helps solve equations more efficiently and stably</p>
</li>
<li><p>Least Squares Problems: Essential for finding the best-fit line or curve through data points</p>
</li>
<li><p>Eigenvalue Calculations: Used in dimensionality reduction techniques like PCA</p>
</li>
<li><p>Feature Extraction: Helps identify important patterns in high-dimensional data</p>
</li>
<li><p>Numerical Stability: Makes many calculations more reliable, especially with nearly dependent data</p>
</li>
</ol>
<p>This enum specifies which specific algorithm to use for computing the QR decomposition, as different
methods have different performance characteristics depending on the matrix properties.</p>

</div>

</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/Enums/AlgorithmTypes/QrAlgorithmType.cs/#L36" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
