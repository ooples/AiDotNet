<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class SqueezeAndExcitationLayer&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class SqueezeAndExcitationLayer&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Represents a Squeeze-and-Excitation layer that recalibrates channel-wise feature responses adaptively.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1.md&amp;value=---%0Auid%3A%20AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1">



  <h1 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1" class="text-break">
Class SqueezeAndExcitationLayer&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L34"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.NeuralNetworks.html">NeuralNetworks</a>.<a class="xref" href="AiDotNet.NeuralNetworks.Layers.html">Layers</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Represents a Squeeze-and-Excitation layer that recalibrates channel-wise feature responses adaptively.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class SqueezeAndExcitationLayer&lt;T&gt; : LayerBase&lt;T&gt;, ILayer&lt;T&gt;, IJitCompilable&lt;T&gt;, IWeightLoadable&lt;T&gt;, IDisposable, IAuxiliaryLossLayer&lt;T&gt;, IDiagnosticsProvider, IChainableComputationGraph&lt;T&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for calculations, typically float or double.</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html">LayerBase</a>&lt;T&gt;</div>
      <div><span class="xref">SqueezeAndExcitationLayer&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IJitCompilable-1.html">IJitCompilable</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IWeightLoadable-1.html">IWeightLoadable</a>&lt;T&gt;</div>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.idisposable">IDisposable</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.IAuxiliaryLossLayer-1.html">IAuxiliaryLossLayer</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IDiagnosticsProvider.html">IDiagnosticsProvider</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.IChainableComputationGraph-1.html">IChainableComputationGraph</a>&lt;T&gt;</div>
    </dd>
  </dl>


  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Engine">LayerBase&lt;T&gt;.Engine</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ScalarActivation">LayerBase&lt;T&gt;.ScalarActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_VectorActivation">LayerBase&lt;T&gt;.VectorActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UsingVectorActivation">LayerBase&lt;T&gt;.UsingVectorActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_NumOps">LayerBase&lt;T&gt;.NumOps</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Random">LayerBase&lt;T&gt;.Random</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Parameters">LayerBase&lt;T&gt;.Parameters</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ParameterGradients">LayerBase&lt;T&gt;.ParameterGradients</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShape">LayerBase&lt;T&gt;.InputShape</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShapes">LayerBase&lt;T&gt;.InputShapes</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateInputShape_System_Int32___">LayerBase&lt;T&gt;.UpdateInputShape(int[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_OutputShape">LayerBase&lt;T&gt;.OutputShape</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsTrainingMode">LayerBase&lt;T&gt;.IsTrainingMode</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationStrategy">LayerBase&lt;T&gt;.InitializationStrategy</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsInitialized">LayerBase&lt;T&gt;.IsInitialized</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationLock">LayerBase&lt;T&gt;.InitializationLock</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_EnsureInitialized">LayerBase&lt;T&gt;.EnsureInitialized()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UseAutodiff">LayerBase&lt;T&gt;.UseAutodiff</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetTrainingMode_System_Boolean_">LayerBase&lt;T&gt;.SetTrainingMode(bool)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterGradients">LayerBase&lt;T&gt;.GetParameterGradients()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ClearGradients">LayerBase&lt;T&gt;.ClearGradients()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShape">LayerBase&lt;T&gt;.GetInputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShapes">LayerBase&lt;T&gt;.GetInputShapes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetOutputShape">LayerBase&lt;T&gt;.GetOutputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetWeights">LayerBase&lt;T&gt;.GetWeights()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetBiases">LayerBase&lt;T&gt;.GetBiases()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_MapActivationToFused">LayerBase&lt;T&gt;.MapActivationToFused()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuTraining">LayerBase&lt;T&gt;.SupportsGpuTraining</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanExecuteOnGpu">LayerBase&lt;T&gt;.CanExecuteOnGpu</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanTrainOnGpu">LayerBase&lt;T&gt;.CanTrainOnGpu</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_BackwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0__">LayerBase&lt;T&gt;.BackwardGpu(IGpuTensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParametersGpu_AiDotNet_Interfaces_IGpuOptimizerConfig_">LayerBase&lt;T&gt;.UpdateParametersGpu(IGpuOptimizerConfig)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UploadWeightsToGpu">LayerBase&lt;T&gt;.UploadWeightsToGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_DownloadWeightsFromGpu">LayerBase&lt;T&gt;.DownloadWeightsFromGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ZeroGradientsGpu">LayerBase&lt;T&gt;.ZeroGradientsGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetActivationTypes">LayerBase&lt;T&gt;.GetActivationTypes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0____">LayerBase&lt;T&gt;.Forward(params Tensor&lt;T&gt;[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ApplyActivation(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ApplyActivation(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ActivateTensor(IActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IVectorActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ActivateTensor(IVectorActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateInputShape_System_Int32_System_Int32_System_Int32_">LayerBase&lt;T&gt;.CalculateInputShape(int, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateOutputShape_System_Int32_System_Int32_System_Int32_">LayerBase&lt;T&gt;.CalculateOutputShape(int, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Clone">LayerBase&lt;T&gt;.Clone()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_DerivativeTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.DerivativeTensor(IActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative__0__0_">LayerBase&lt;T&gt;.ApplyActivationDerivative(T, T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ApplyActivationDerivative(Tensor&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ComputeActivationJacobian_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ComputeActivationJacobian(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Vector__0__AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ApplyActivationDerivative(Vector&lt;T&gt;, Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.UpdateParameters(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Serialize_System_IO_BinaryWriter_">LayerBase&lt;T&gt;.Serialize(BinaryWriter)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Deserialize_System_IO_BinaryReader_">LayerBase&lt;T&gt;.Deserialize(BinaryReader)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationToGraph_AiDotNet_Autodiff_ComputationNode__0__">LayerBase&lt;T&gt;.ApplyActivationToGraph(ComputationNode&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanActivationBeJitted">LayerBase&lt;T&gt;.CanActivationBeJitted()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_RegisterTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_Engines_PersistentTensorRole_">LayerBase&lt;T&gt;.RegisterTrainableParameter(Tensor&lt;T&gt;, PersistentTensorRole)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InvalidateTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.InvalidateTrainableParameter(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_HasGpuActivation">LayerBase&lt;T&gt;.HasGpuActivation()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationForwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">LayerBase&lt;T&gt;.ApplyActivationForwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationBackwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">LayerBase&lt;T&gt;.ApplyActivationBackwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetFusedActivationType">LayerBase&lt;T&gt;.GetFusedActivationType()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivation_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_">LayerBase&lt;T&gt;.ApplyGpuActivation(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int, FusedActivationType)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivationBackward_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_System_Single_">LayerBase&lt;T&gt;.ApplyGpuActivationBackward(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int, FusedActivationType, float)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose">LayerBase&lt;T&gt;.Dispose()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose_System_Boolean_">LayerBase&lt;T&gt;.Dispose(bool)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_WeightParameterName">LayerBase&lt;T&gt;.WeightParameterName</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_BiasParameterName">LayerBase&lt;T&gt;.BiasParameterName</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetWeights_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetWeights(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetBiases_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetBiases(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterNames">LayerBase&lt;T&gt;.GetParameterNames()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_TryGetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___">LayerBase&lt;T&gt;.TryGetParameter(string, out Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetParameter(string, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterShape_System_String_">LayerBase&lt;T&gt;.GetParameterShape(string)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_NamedParameterCount">LayerBase&lt;T&gt;.NamedParameterCount</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ValidateWeights_System_Collections_Generic_IEnumerable_System_String__System_Func_System_String_System_String__">LayerBase&lt;T&gt;.ValidateWeights(IEnumerable&lt;string&gt;, Func&lt;string, string&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_LoadWeights_System_Collections_Generic_Dictionary_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___System_Func_System_String_System_String__System_Boolean_">LayerBase&lt;T&gt;.LoadWeights(Dictionary&lt;string, Tensor&lt;T&gt;&gt;, Func&lt;string, string&gt;, bool)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
A Squeeze-and-Excitation layer enhances the representational power of a network by explicitly modeling the 
interdependencies between channels. It does this by performing two operations:
1. "Squeeze" - aggregating feature maps across spatial dimensions to produce a channel descriptor
2. "Excitation" - using this descriptor to recalibrate the original feature maps channel-wise
</p>
<p><b>For Beginners:</b> This layer helps the neural network focus on the most important features.
<p>Think of it like how your brain works when looking at a picture:</p>
<ul>
<li>First, you get a rough idea of what's in the image (the &quot;squeeze&quot; step)</li>
<li>Then, you decide which parts to pay more attention to (the &quot;excitation&quot; step)</li>
<li>Finally, you look at the image again with this focused attention</li>
</ul>
<p>For example, if the network is processing an image of a cat, the Squeeze-and-Excitation layer might:</p>
<ul>
<li>First compress all the information to understand &quot;this is probably a cat&quot;</li>
<li>Then decide to pay more attention to features that look like ears, whiskers, and fur</li>
<li>Finally enhance those important features in the original image data</li>
</ul>
<p>This helps the network become more accurate and efficient by focusing on what matters most.</p>

</div>


  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1__ctor_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.#ctor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1__ctor_System_Int32_System_Int32_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Interfaces_IActivationFunction__0__" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.#ctor(System.Int32,System.Int32,AiDotNet.Interfaces.IActivationFunction{`0},AiDotNet.Interfaces.IActivationFunction{`0})">
  SqueezeAndExcitationLayer(int, int, IActivationFunction&lt;T&gt;?, IActivationFunction&lt;T&gt;?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L519"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the <a class="xref" href="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer-1.html">SqueezeAndExcitationLayer&lt;T&gt;</a> class with scalar activation functions.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public SqueezeAndExcitationLayer(int channels, int reductionRatio, IActivationFunction&lt;T&gt;? firstActivation = null, IActivationFunction&lt;T&gt;? secondActivation = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>channels</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of input and output channels.</p>
</dd>
    <dt><code>reductionRatio</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The ratio by which to reduce the number of channels in the bottleneck.</p>
</dd>
    <dt><code>firstActivation</code> <a class="xref" href="AiDotNet.Interfaces.IActivationFunction-1.html">IActivationFunction</a>&lt;T&gt;</dt>
    <dd><p>The activation function for the first fully connected layer. Defaults to ReLU if not specified.</p>
</dd>
    <dt><code>secondActivation</code> <a class="xref" href="AiDotNet.Interfaces.IActivationFunction-1.html">IActivationFunction</a>&lt;T&gt;</dt>
    <dd><p>The activation function for the second fully connected layer. Defaults to Sigmoid if not specified.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1__ctor_System_Int32_System_Int32_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Interfaces_IActivationFunction__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This constructor creates a Squeeze-and-Excitation layer with the specified number of channels and reduction ratio.
The reduction ratio determines how much the channel dimension is compressed in the bottleneck.
The activation functions control the non-linearities applied after each fully connected layer.
</p>
<p><b>For Beginners:</b> This constructor creates a new Squeeze-and-Excitation layer.
<p>The parameters you provide determine:</p>
<ul>
<li>channels: How many different feature types the layer will process</li>
<li>reductionRatio: How much to compress the information (higher means more compression)</li>
<li>firstActivation: How to process information after the first step (defaults to ReLU, which keeps only positive values)</li>
<li>secondActivation: How to determine importance of each feature (defaults to Sigmoid, which outputs values between 0 and 1)</li>
</ul>
<p>Think of it like this: if you have 64 channels (different types of features) and a reduction ratio of 16,
the layer will compress those 64 channels down to just 4 during the middle step, forcing it to focus
on only the most important patterns.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1__ctor_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.#ctor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1__ctor_System_Int32_System_Int32_AiDotNet_Interfaces_IVectorActivationFunction__0__AiDotNet_Interfaces_IVectorActivationFunction__0__" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.#ctor(System.Int32,System.Int32,AiDotNet.Interfaces.IVectorActivationFunction{`0},AiDotNet.Interfaces.IVectorActivationFunction{`0})">
  SqueezeAndExcitationLayer(int, int, IVectorActivationFunction&lt;T&gt;?, IVectorActivationFunction&lt;T&gt;?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L566"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the <a class="xref" href="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer-1.html">SqueezeAndExcitationLayer&lt;T&gt;</a> class with vector activation functions.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public SqueezeAndExcitationLayer(int channels, int reductionRatio, IVectorActivationFunction&lt;T&gt;? firstVectorActivation = null, IVectorActivationFunction&lt;T&gt;? secondVectorActivation = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>channels</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of input and output channels.</p>
</dd>
    <dt><code>reductionRatio</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The ratio by which to reduce the number of channels in the bottleneck.</p>
</dd>
    <dt><code>firstVectorActivation</code> <a class="xref" href="AiDotNet.Interfaces.IVectorActivationFunction-1.html">IVectorActivationFunction</a>&lt;T&gt;</dt>
    <dd><p>The vector activation function for the first fully connected layer. Defaults to ReLU if not specified.</p>
</dd>
    <dt><code>secondVectorActivation</code> <a class="xref" href="AiDotNet.Interfaces.IVectorActivationFunction-1.html">IVectorActivationFunction</a>&lt;T&gt;</dt>
    <dd><p>The vector activation function for the second fully connected layer. Defaults to Sigmoid if not specified.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1__ctor_System_Int32_System_Int32_AiDotNet_Interfaces_IVectorActivationFunction__0__AiDotNet_Interfaces_IVectorActivationFunction__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This constructor creates a Squeeze-and-Excitation layer with the specified number of channels and reduction ratio.
It uses vector activation functions, which operate on entire vectors rather than individual elements.
The reduction ratio determines how much the channel dimension is compressed in the bottleneck.
</p>
<p><b>For Beginners:</b> This constructor is similar to the previous one, but uses vector activations.
<p>Vector activations:</p>
<ul>
<li>Process entire groups of numbers at once, rather than one at a time</li>
<li>Can capture relationships between different elements</li>
<li>Allow for more complex transformations</li>
</ul>
<p>This version is useful when you need more sophisticated processing that considers
how different features relate to each other, rather than treating each feature independently.</p>

</div>




  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_AuxiliaryLossWeight_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.AuxiliaryLossWeight*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_AuxiliaryLossWeight" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.AuxiliaryLossWeight">
  AuxiliaryLossWeight
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L77"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the weight for the auxiliary loss contribution.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public T AuxiliaryLossWeight { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><span class="xref">T</span></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_AuxiliaryLossWeight_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This value determines how much the channel attention regularization contributes to the total loss.
The default value of 0.01 provides a good balance between the main task and regularization.
</p>
<p><b>For Beginners:</b> This controls how much importance to give to the channel attention regularization.
<p>The weight affects training:</p>
<ul>
<li>Higher values (e.g., 0.05) make the network prioritize balanced channel attention more strongly</li>
<li>Lower values (e.g., 0.001) make the regularization less important</li>
<li>The default (0.01) works well for most computer vision tasks</li>
</ul>
<p>If your network is over-fitting to specific channels, increase this value.
If the main task is more important, you might decrease it.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ParameterCount_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.ParameterCount*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ParameterCount" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.ParameterCount">
  ParameterCount
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L487"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the total number of trainable parameters in this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override int ParameterCount { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ParameterCount_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This returns the total count of weights and biases in both fully connected layers.</p>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_SparsityWeight_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.SparsityWeight*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_SparsityWeight" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.SparsityWeight">
  SparsityWeight
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L365"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the weight for L1 sparsity regularization on attention weights.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public T SparsityWeight { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><span class="xref">T</span></dt>
    <dd><p>The weight to apply to the L1 sparsity loss. Default is 0.0001.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_SparsityWeight_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property controls the strength of L1 sparsity regularization applied to
the channel attention weights. Higher values encourage more sparse attention
(fewer active channels), while lower values allow more distributed attention.
</p>
<p><b>For Beginners:</b> This controls how strongly to encourage sparse attention.
<p>Sparsity regularization:</p>
<ul>
<li>Encourages the network to focus on fewer, more important channels</li>
<li>Helps prevent overfitting by reducing model complexity</li>
<li>Can improve interpretability by making channel selection clearer</li>
</ul>
<p>Typical values range from 0.0001 to 0.01. Set to 0 to disable sparsity regularization.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_SupportsGpuExecution_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.SupportsGpuExecution*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_SupportsGpuExecution" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.SupportsGpuExecution">
  SupportsGpuExecution
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L479"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets a value indicating whether this layer supports GPU execution.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected override bool SupportsGpuExecution { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>








  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_SupportsJitCompilation_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.SupportsJitCompilation*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_SupportsJitCompilation" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.SupportsJitCompilation">
  SupportsJitCompilation
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L1904"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this layer supports JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsJitCompilation { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if the layer can be JIT compiled, false otherwise.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_SupportsJitCompilation_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property indicates whether the layer has implemented ExportComputationGraph()
and can benefit from JIT compilation. All layers MUST implement this property.
</p>
<p><b>For Beginners:</b> JIT compilation can make inference 5-10x faster by converting
the layer's operations into optimized native code.
<p>Layers should return false if they:</p>
<ul>
<li>Have not yet implemented a working ExportComputationGraph()</li>
<li>Use dynamic operations that change based on input data</li>
<li>Are too simple to benefit from JIT compilation</li>
</ul>
<p>When false, the layer will use the standard Forward() method instead.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_SupportsTraining_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.SupportsTraining*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_SupportsTraining" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.SupportsTraining">
  SupportsTraining
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L474"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets a value indicating whether this layer supports training.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsTraining { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p><code>true</code> for this layer, as it contains trainable parameters (weights and biases).</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_SupportsTraining_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property indicates whether the Squeeze-and-Excitation layer can be trained through backpropagation.
Since this layer has trainable parameters (weights and biases), it supports training.
</p>
<p><b>For Beginners:</b> This property tells you if the layer can learn from data.
<p>A value of true means:</p>
<ul>
<li>The layer has internal values (weights and biases) that can be adjusted during training</li>
<li>It will improve its performance as it sees more data</li>
<li>It participates in the learning process</li>
</ul>
<p>For this layer, the value is always true because it needs to learn which features
are most important to pay attention to.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_UseAuxiliaryLoss_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.UseAuxiliaryLoss*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_UseAuxiliaryLoss" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.UseAuxiliaryLoss">
  UseAuxiliaryLoss
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L56"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets a value indicating whether auxiliary loss is enabled for this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public bool UseAuxiliaryLoss { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_UseAuxiliaryLoss_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
When enabled, the layer computes a channel attention regularization loss that encourages balanced
channel importance. This helps prevent the layer from over-relying on specific channels.
</p>
<p><b>For Beginners:</b> This setting controls whether the layer uses an additional learning signal.
<p>When enabled (true):</p>
<ul>
<li>The layer encourages balanced attention across channels</li>
<li>This helps prevent over-reliance on specific features</li>
<li>Training may be more stable and produce more robust representations</li>
</ul>
<p>When disabled (false):</p>
<ul>
<li>Only the main task loss is used for training</li>
<li>This is the default setting</li>
</ul>

</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_Backward_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.Backward*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.Backward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Backward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L1227"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the backward pass of the Squeeze-and-Excitation layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; Backward(Tensor&lt;T&gt; outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>outputGradient</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The gradient of the loss with respect to the layer's output.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The gradient of the loss with respect to the layer's input.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method implements the backward pass of the Squeeze-and-Excitation layer, which is used during training to propagate
error gradients back through the network. It calculates gradients for the input and for all trainable parameters
(weights and biases).
</p>
<p><b>For Beginners:</b> This method is used during training to calculate how the layer's input
and parameters should change to reduce errors.
<p>During the backward pass:</p>
<ol>
<li>The layer receives information about how its output should change (outputGradient)</li>
<li>It calculates how the original input should change to reduce error (inputGradient)</li>
<li>It calculates how its internal weights and biases should change to reduce error</li>
</ol>
<p>This process follows the chain rule of calculus, working backward from the output to the input.
It's essential for the &quot;learning&quot; part of deep learning, allowing the network to gradually
improve its performance based on examples.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown when trying to perform a backward pass before a forward pass.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_BuildComputationGraph_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.BuildComputationGraph*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_BuildComputationGraph_AiDotNet_Autodiff_ComputationNode__0__System_String_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.BuildComputationGraph(AiDotNet.Autodiff.ComputationNode{`0},System.String)">
  BuildComputationGraph(ComputationNode&lt;T&gt;, string)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L1854"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Builds the computation graph for this layer using the provided input node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public ComputationNode&lt;T&gt; BuildComputationGraph(ComputationNode&lt;T&gt; inputNode, string namePrefix)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputNode</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node from the parent layer.</p>
</dd>
    <dt><code>namePrefix</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>Prefix for naming internal nodes (for debugging/visualization).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The output computation node representing this layer's computation.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_BuildComputationGraph_AiDotNet_Autodiff_ComputationNode__0__System_String__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Unlike ILayer&lt;T&gt;.ExportComputationGraph, this method does NOT create a new
input variable. Instead, it uses the provided <code class="paramref">inputNode</code> as its input,
allowing the parent layer to chain multiple sub-layers together in a single computation graph.
</p>
<p>
The <code class="paramref">namePrefix</code> parameter should be used to prefix all internal node names
to avoid naming conflicts when multiple instances of the same layer type are used.
</p>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ComputeAuxiliaryLoss_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.ComputeAuxiliaryLoss*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ComputeAuxiliaryLoss" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.ComputeAuxiliaryLoss">
  ComputeAuxiliaryLoss()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L1741"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the auxiliary loss for this layer based on channel attention regularization.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public T ComputeAuxiliaryLoss()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><span class="xref">T</span></dt>
    <dd><p>The computed auxiliary loss value.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ComputeAuxiliaryLoss_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method computes a channel attention regularization loss. In a full implementation, this would encourage
balanced channel attention by penalizing extreme attention values (all attention on one channel or uniform
attention across all channels). The regularization can use L2 norm or entropy-based measures.
</p>
<p><b>For Beginners:</b> This method calculates a penalty to encourage balanced feature importance.
<p>Channel attention regularization:</p>
<ul>
<li>Prevents the layer from relying too heavily on specific channels</li>
<li>Encourages the network to use information from multiple features</li>
<li>Helps create more robust and generalizable models</li>
</ul>
<p>Why this is useful:</p>
<ul>
<li>In complex tasks, multiple types of features are usually important</li>
<li>Over-relying on one type of feature can lead to poor generalization</li>
<li>Balanced attention helps the network learn richer representations</li>
</ul>
<p>Example: In image classification, instead of only looking at edges (one channel),
the network should also consider colors, textures, and shapes (other channels).</p>
<p><b>Note:</b> This is a placeholder implementation. For full functionality, the layer would need to
cache the excitation weights (channel attention scores) during the forward pass. The formula would
compute a regularization term based on these attention weights, such as:</p>
<ul>
<li>L2 regularization: L = ||excitation||</li>
<li>Entropy regularization: L = -(p * log(p)) for normalized excitation weights</li>
<li>Variance penalty: encouraging variance in attention across channels</li>
</ul>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ExportComputationGraph_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.ExportComputationGraph*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0___" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.ExportComputationGraph(System.Collections.Generic.List{AiDotNet.Autodiff.ComputationNode{`0}})">
  ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L1833"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Exports the layer's computation graph for JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override ComputationNode&lt;T&gt; ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt; inputNodes)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputNodes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.list-1">List</a>&lt;<a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;&gt;</dt>
    <dd><p>List to populate with input computation nodes.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The output computation node representing the layer's operation.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method constructs a computation graph representation of the layer's forward pass
that can be JIT compiled for faster inference. All layers MUST implement this method
to support JIT compilation.
</p>
<p><b>For Beginners:</b> JIT (Just-In-Time) compilation converts the layer's operations
into optimized native code for 5-10x faster inference.
<p>To support JIT compilation, a layer must:</p>
<ol>
<li>Implement this method to export its computation graph</li>
<li>Set SupportsJitCompilation to true</li>
<li>Use ComputationNode and TensorOperations to build the graph</li>
</ol>
<p>All layers are required to implement this method, even if they set SupportsJitCompilation = false.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_Forward_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.Forward*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.Forward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Forward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L681"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the forward pass of the Squeeze-and-Excitation layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; Forward(Tensor&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The input tensor to process.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The output tensor after Squeeze-and-Excitation processing.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method implements the forward pass of the Squeeze-and-Excitation layer. It first applies global average pooling
to "squeeze" spatial information into a channel descriptor. Then it passes this descriptor through two fully connected
layers with activations to produce channel-wise scaling factors. Finally, it multiplies the original input by these
scaling factors to recalibrate the feature maps.
</p>
<p><b>For Beginners:</b> This method processes the input data through the Squeeze-and-Excitation steps.
<p>The process works in three main steps:</p>
<ol>
<li><p>Squeeze: Compresses all spatial information into a single value per channel</p>
<ul>
<li>For each channel, all values are averaged together</li>
<li>This creates a &quot;summary&quot; of each feature type</li>
</ul>
</li>
<li><p>Excitation: Determines the importance of each channel</p>
<ul>
<li>The summary passes through two neural layers with activations</li>
<li>This produces an &quot;importance score&quot; between 0 and 1 for each channel</li>
</ul>
</li>
<li><p>Scaling: Adjusts the original input based on importance</p>
<ul>
<li>Each feature map is multiplied by its importance score</li>
<li>Important features are kept or enhanced</li>
<li>Less important features are reduced</li>
</ul>
</li>
</ol>
<p>This helps the network focus attention on the most useful features for the current input.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ForwardGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.ForwardGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ForwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0____" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.ForwardGpu(AiDotNet.Tensors.Engines.Gpu.IGpuTensor{`0}[])">
  ForwardGpu(params IGpuTensor&lt;T&gt;[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L803"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the forward pass of the Squeeze-and-Excitation layer on GPU tensors.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override IGpuTensor&lt;T&gt; ForwardGpu(params IGpuTensor&lt;T&gt;[] inputs)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputs</code> <a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;[]</dt>
    <dd><p>GPU tensor inputs.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;</dt>
    <dd><p>GPU tensor output after SE processing.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ForwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0_____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method implements the GPU-accelerated forward pass of the SE layer.
All tensor ranks are handled natively on GPU using GlobalAvgPool2D for squeeze,
FusedLinearGpu for excitation, and BroadcastMultiplyFirstAxis for scaling.
</p>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_GetAuxiliaryLossDiagnostics_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.GetAuxiliaryLossDiagnostics*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_GetAuxiliaryLossDiagnostics" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.GetAuxiliaryLossDiagnostics">
  GetAuxiliaryLossDiagnostics()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L1801"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets diagnostic information about the auxiliary loss computation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public Dictionary&lt;string, string&gt; GetAuxiliaryLossDiagnostics()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.dictionary-2">Dictionary</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>, <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>A dictionary containing diagnostic information about the auxiliary loss.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_GetAuxiliaryLossDiagnostics_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method returns diagnostic information that can be used to monitor the auxiliary loss during training.
The diagnostics include the total channel attention loss, the weight applied to it, and whether auxiliary loss is enabled.
</p>
<p><b>For Beginners:</b> This method provides information to help you understand how the auxiliary loss is working.
<p>The diagnostics show:</p>
<ul>
<li>TotalChannelAttentionLoss: The computed penalty for imbalanced channel attention</li>
<li>ChannelAttentionWeight: How much this penalty affects the overall training</li>
<li>UseChannelAttention: Whether this penalty is currently enabled</li>
</ul>
<p>You can use this information to:</p>
<ul>
<li>Monitor if channel attention is becoming more balanced over time</li>
<li>Debug training issues related to feature selection</li>
<li>Understand which features the network prioritizes</li>
</ul>
<p>Example: If TotalChannelAttentionLoss is high, it might indicate that the network is over-relying
on specific channels, which could be a sign of overfitting or poor feature diversity.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_GetDiagnostics_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.GetDiagnostics*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_GetDiagnostics" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.GetDiagnostics">
  GetDiagnostics()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L1819"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets diagnostic information about this component's state and behavior.
Overrides <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetDiagnostics">GetDiagnostics()</a> to include auxiliary loss diagnostics.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Dictionary&lt;string, string&gt; GetDiagnostics()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.dictionary-2">Dictionary</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>, <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>A dictionary containing diagnostic metrics including both base layer diagnostics and
auxiliary loss diagnostics from <a class="xref" href="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer-1.html#AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_GetAuxiliaryLossDiagnostics">GetAuxiliaryLossDiagnostics()</a>.</p>
</dd>
  </dl>











  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_GetParameters_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.GetParameters*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_GetParameters" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.GetParameters">
  GetParameters()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L1555"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets all trainable parameters of the layer as a single vector.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Vector&lt;T&gt; GetParameters()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>A vector containing all trainable parameters.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_GetParameters_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method retrieves all trainable parameters (weights and biases) of the layer and combines them into a single vector.
This is useful for optimization algorithms that operate on all parameters at once, or for saving and loading model weights.
</p>
<p><b>For Beginners:</b> This method collects all the learnable values from the layer.
<p>The parameters:</p>
<ul>
<li>Are the numbers that the neural network learns during training</li>
<li>Include all weights and biases from both fully connected layers</li>
<li>Are combined into a single long list (vector)</li>
</ul>
<p>This is useful for:</p>
<ul>
<li>Saving the model to disk</li>
<li>Loading parameters from a previously trained model</li>
<li>Advanced optimization techniques that need access to all parameters</li>
</ul>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ResetState_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.ResetState*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ResetState" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.ResetState">
  ResetState()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L1692"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Resets the internal state of the Squeeze-and-Excitation layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void ResetState()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_ResetState_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method resets the internal state of the Squeeze-and-Excitation layer, including the cached inputs and outputs
from the forward pass and the gradients calculated during the backward pass. This is useful when starting to process
a new input after training or when implementing stateful networks.
</p>
<p><b>For Beginners:</b> This method clears the layer's memory to start fresh.
<p>When resetting the state:</p>
<ul>
<li>Stored inputs and outputs are cleared</li>
<li>Calculated gradients are cleared</li>
<li>The layer forgets any information from previous inputs</li>
</ul>
<p>This is important for:</p>
<ul>
<li>Processing a new, unrelated input</li>
<li>Starting a new training epoch</li>
<li>Preventing information from one input affecting another</li>
</ul>
<p>Think of it like wiping a whiteboard clean before starting a new problem.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_SetParameters_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.SetParameters*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_SetParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.SetParameters(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  SetParameters(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L1623"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sets the trainable parameters of the layer from a single vector.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void SetParameters(Vector&lt;T&gt; parameters)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>parameters</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>A vector containing all parameters to set.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_SetParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method sets the trainable parameters (weights and biases) of the layer from a single vector.
This is useful for loading saved model weights or for implementing optimization algorithms that operate on all parameters at once.
</p>
<p><b>For Beginners:</b> This method updates all the learnable values in the layer.
<p>When setting parameters:</p>
<ul>
<li>The input must be a vector with the correct length</li>
<li>The values are copied back into the layer's weights and biases</li>
</ul>
<p>This is useful for:</p>
<ul>
<li>Loading a previously saved model</li>
<li>Transferring parameters from another model</li>
<li>Testing different parameter values</li>
</ul>
<p>An error is thrown if the input vector doesn't have the expected number of parameters.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a></dt>
    <dd><p>Thrown when the parameters vector has incorrect length.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_UpdateParameters_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.UpdateParameters*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_UpdateParameters__0_" data-uid="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer`1.UpdateParameters(`0)">
  UpdateParameters(T)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L1517"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Updates the layer's parameters using the calculated gradients and the specified learning rate.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void UpdateParameters(T learningRate)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>learningRate</code> <span class="xref">T</span></dt>
    <dd><p>The learning rate that controls the size of the parameter updates.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_SqueezeAndExcitationLayer_1_UpdateParameters__0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method updates the weights and biases of the layer based on the gradients calculated during the backward pass.
The learning rate controls the size of the updates, with larger values leading to faster but potentially less stable learning.
</p>
<p><b>For Beginners:</b> This method adjusts the layer's weights and biases to improve performance.
<p>During training:</p>
<ul>
<li>The backward pass calculates how each parameter should change to reduce errors</li>
<li>This method applies those changes to the actual parameters</li>
<li>The learning rate controls how big each adjustment is</li>
</ul>
<p>Think of it like learning to ride a bike:</p>
<ul>
<li>If you make very small adjustments (small learning rate), you learn slowly but steadily</li>
<li>If you make large adjustments (large learning rate), you might learn faster but risk overcorrecting</li>
</ul>
<p>This process of gradual adjustment is how neural networks &quot;learn&quot; from examples.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown when trying to update parameters before calculating gradients.</p>
</dd>
  </dl>




</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/SqueezeAndExcitationLayer.cs/#L34" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
