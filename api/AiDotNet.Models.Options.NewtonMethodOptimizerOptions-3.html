<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class NewtonMethodOptimizerOptions&lt;T, TInput, TOutput&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class NewtonMethodOptimizerOptions&lt;T, TInput, TOutput&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Configuration options for Newton&#39;s Method optimizer, an advanced second-order optimization technique that uses both gradient and Hessian information to accelerate convergence in optimization problems.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3.md&amp;value=---%0Auid%3A%20AiDotNet.Models.Options.NewtonMethodOptimizerOptions%603%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.Models.Options.NewtonMethodOptimizerOptions`3">



  <h1 id="AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3" data-uid="AiDotNet.Models.Options.NewtonMethodOptimizerOptions`3" class="text-break">
Class NewtonMethodOptimizerOptions&lt;T, TInput, TOutput&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/NewtonMethodOptimizerOptions.cs/#L41"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.Models.html">Models</a>.<a class="xref" href="AiDotNet.Models.Options.html">Options</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Configuration options for Newton's Method optimizer, an advanced second-order optimization technique
that uses both gradient and Hessian information to accelerate convergence in optimization problems.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class NewtonMethodOptimizerOptions&lt;T, TInput, TOutput&gt; : GradientBasedOptimizerOptions&lt;T, TInput, TOutput&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd></dd>
    <dt><code>TInput</code></dt>
    <dd></dd>
    <dt><code>TOutput</code></dt>
    <dd></dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.Models.Options.ModelOptions.html">ModelOptions</a></div>
      <div><a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html">OptimizationAlgorithmOptions</a>&lt;T, TInput, TOutput&gt;</div>
      <div><a class="xref" href="AiDotNet.Models.Options.GradientBasedOptimizerOptions-3.html">GradientBasedOptimizerOptions</a>&lt;T, TInput, TOutput&gt;</div>
      <div><span class="xref">NewtonMethodOptimizerOptions&lt;T, TInput, TOutput&gt;</span></div>
    </dd>
  </dl>



  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.GradientBasedOptimizerOptions-3.html#AiDotNet_Models_Options_GradientBasedOptimizerOptions_3_GradientCache">GradientBasedOptimizerOptions&lt;T, TInput, TOutput&gt;.GradientCache</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.GradientBasedOptimizerOptions-3.html#AiDotNet_Models_Options_GradientBasedOptimizerOptions_3_LossFunction">GradientBasedOptimizerOptions&lt;T, TInput, TOutput&gt;.LossFunction</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.GradientBasedOptimizerOptions-3.html#AiDotNet_Models_Options_GradientBasedOptimizerOptions_3_Regularization">GradientBasedOptimizerOptions&lt;T, TInput, TOutput&gt;.Regularization</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.GradientBasedOptimizerOptions-3.html#AiDotNet_Models_Options_GradientBasedOptimizerOptions_3_DataSampler">GradientBasedOptimizerOptions&lt;T, TInput, TOutput&gt;.DataSampler</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.GradientBasedOptimizerOptions-3.html#AiDotNet_Models_Options_GradientBasedOptimizerOptions_3_ShuffleData">GradientBasedOptimizerOptions&lt;T, TInput, TOutput&gt;.ShuffleData</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.GradientBasedOptimizerOptions-3.html#AiDotNet_Models_Options_GradientBasedOptimizerOptions_3_DropLastBatch">GradientBasedOptimizerOptions&lt;T, TInput, TOutput&gt;.DropLastBatch</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.GradientBasedOptimizerOptions-3.html#AiDotNet_Models_Options_GradientBasedOptimizerOptions_3_RandomSeed">GradientBasedOptimizerOptions&lt;T, TInput, TOutput&gt;.RandomSeed</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.GradientBasedOptimizerOptions-3.html#AiDotNet_Models_Options_GradientBasedOptimizerOptions_3_EnableGradientClipping">GradientBasedOptimizerOptions&lt;T, TInput, TOutput&gt;.EnableGradientClipping</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.GradientBasedOptimizerOptions-3.html#AiDotNet_Models_Options_GradientBasedOptimizerOptions_3_GradientClippingMethod">GradientBasedOptimizerOptions&lt;T, TInput, TOutput&gt;.GradientClippingMethod</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.GradientBasedOptimizerOptions-3.html#AiDotNet_Models_Options_GradientBasedOptimizerOptions_3_MaxGradientNorm">GradientBasedOptimizerOptions&lt;T, TInput, TOutput&gt;.MaxGradientNorm</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.GradientBasedOptimizerOptions-3.html#AiDotNet_Models_Options_GradientBasedOptimizerOptions_3_MaxGradientValue">GradientBasedOptimizerOptions&lt;T, TInput, TOutput&gt;.MaxGradientValue</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.GradientBasedOptimizerOptions-3.html#AiDotNet_Models_Options_GradientBasedOptimizerOptions_3_LearningRateScheduler">GradientBasedOptimizerOptions&lt;T, TInput, TOutput&gt;.LearningRateScheduler</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.GradientBasedOptimizerOptions-3.html#AiDotNet_Models_Options_GradientBasedOptimizerOptions_3_SchedulerStepMode">GradientBasedOptimizerOptions&lt;T, TInput, TOutput&gt;.SchedulerStepMode</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_MaxIterations">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.MaxIterations</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_UseEarlyStopping">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.UseEarlyStopping</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_EarlyStoppingPatience">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.EarlyStoppingPatience</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_BadFitPatience">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.BadFitPatience</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_MinimumFeatures">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.MinimumFeatures</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_MaximumFeatures">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.MaximumFeatures</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_UseExpressionTrees">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.UseExpressionTrees</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_InitialLearningRate">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.InitialLearningRate</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_UseAdaptiveLearningRate">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.UseAdaptiveLearningRate</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_LearningRateDecay">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.LearningRateDecay</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_MinLearningRate">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.MinLearningRate</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_MaxLearningRate">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.MaxLearningRate</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_UseAdaptiveMomentum">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.UseAdaptiveMomentum</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_InitialMomentum">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.InitialMomentum</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_MomentumIncreaseFactor">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.MomentumIncreaseFactor</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_MomentumDecreaseFactor">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.MomentumDecreaseFactor</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_MinMomentum">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.MinMomentum</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_MaxMomentum">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.MaxMomentum</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_ExplorationRate">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.ExplorationRate</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_MinExplorationRate">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.MinExplorationRate</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_MaxExplorationRate">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.MaxExplorationRate</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_Tolerance">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.Tolerance</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_OptimizationMode">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.OptimizationMode</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_ParameterAdjustmentScale">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.ParameterAdjustmentScale</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_SignFlipProbability">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.SignFlipProbability</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_FeatureSelectionProbability">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.FeatureSelectionProbability</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_ParameterAdjustmentProbability">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.ParameterAdjustmentProbability</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_PredictionOptions">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.PredictionOptions</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_ModelStatsOptions">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.ModelStatsOptions</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_ModelEvaluator">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.ModelEvaluator</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_FitDetector">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.FitDetector</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_FitnessCalculator">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.FitnessCalculator</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_ModelCache">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.ModelCache</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html#AiDotNet_Models_Options_OptimizationAlgorithmOptions_3_CreateDefaults_AiDotNet_Enums_OptimizerType_">OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt;.CreateDefaults(OptimizerType)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Models.Options.ModelOptions.html#AiDotNet_Models_Options_ModelOptions_Seed">ModelOptions.Seed</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
Newton's Method is a powerful optimization algorithm that leverages second-order derivatives 
(Hessian matrix) in addition to first-order gradients to determine optimal step directions and sizes. 
This approach can achieve faster convergence than first-order methods, particularly near the optimum 
and for well-conditioned problems. The method approximates the objective function locally as a quadratic 
function and steps directly toward the minimum of this approximation. This class provides configuration 
options to control the learning rate dynamics of the Newton optimizer, allowing for adaptive step sizing 
that can improve stability and convergence speed across different optimization landscapes.
</p>
<p><b>For Beginners:</b> Newton's Method is an advanced technique for helping AI models learn faster and more efficiently.
<p>Imagine you're trying to find the lowest point in a valley while blindfolded:</p>
<ul>
<li>First-order methods (like regular gradient descent) only tell you which direction is downhill</li>
<li>Newton's Method tells you both the downhill direction AND how curved the terrain is</li>
</ul>
<p>This extra information about curvature helps the optimizer:</p>
<ul>
<li>Take larger steps when the terrain is relatively flat</li>
<li>Take smaller, more careful steps when the terrain is highly curved</li>
<li>Often reach the lowest point in fewer steps</li>
</ul>
<p>Think of it like having a more intelligent navigation system:</p>
<ul>
<li>Regular gradient descent says &quot;go downhill&quot;</li>
<li>Newton's Method says &quot;go downhill, but adjust your stride based on the terrain&quot;</li>
</ul>
<p>This method typically excels when:</p>
<ul>
<li>The optimization problem is well-behaved (smooth, not too many bumps)</li>
<li>You need fast convergence and can afford the extra computation</li>
<li>The problem isn't too high-dimensional</li>
</ul>
<p>The settings in this class let you control how the learning rate adapts during optimization,
balancing between speed and stability.</p>

</div>


  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3_BatchSize_" data-uid="AiDotNet.Models.Options.NewtonMethodOptimizerOptions`3.BatchSize*"></a>

  <h3 id="AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3_BatchSize" data-uid="AiDotNet.Models.Options.NewtonMethodOptimizerOptions`3.BatchSize">
  BatchSize
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/NewtonMethodOptimizerOptions.cs/#L53"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the batch size for gradient computation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int BatchSize { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>A positive integer, defaulting to -1 (full batch).</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3_BatchSize_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Beginners:</b> The batch size controls how many examples are used to calculate gradients.
Newton's Method uses full-batch gradients (batch size -1) because it requires computing the Hessian
matrix, which depends on consistent gradient and second derivative information from the entire dataset.
Using mini-batches would introduce noise that makes the Hessian approximation unreliable.</p>
</div>




  <a id="AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3_InitialLearningRate_" data-uid="AiDotNet.Models.Options.NewtonMethodOptimizerOptions`3.InitialLearningRate*"></a>

  <h3 id="AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3_InitialLearningRate" data-uid="AiDotNet.Models.Options.NewtonMethodOptimizerOptions`3.InitialLearningRate">
  InitialLearningRate
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/NewtonMethodOptimizerOptions.cs/#L95"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the initial learning rate used by the Newton's Method optimizer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double InitialLearningRate { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The initial learning rate, defaulting to 0.1.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3_InitialLearningRate_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This parameter determines the initial step size for the Newton method optimization process. Despite 
Newton's Method theoretically being able to determine optimal step sizes automatically, in practice, 
a learning rate is often applied to the Newton step to improve stability, especially when far from 
the optimum or when the Hessian approximation is imperfect. The default value of 0.1 provides a 
conservative starting point that balances convergence speed with numerical stability. This property 
overrides the base class implementation with a value more appropriate for Newton's Method.
</p>
<p><b>For Beginners:</b> This setting controls how big the initial steps are
when the optimizer starts searching for the best solution.
<p>The default value of 0.1 means:</p>
<ul>
<li>The algorithm takes modest initial steps</li>
<li>This provides a balance between speed and stability</li>
</ul>
<p>Think of it like exploring an unfamiliar area:</p>
<ul>
<li>Too small steps (like 0.01) would be cautious but very slow</li>
<li>Too large steps (like 1.0) might overshoot important details</li>
<li>The default 0.1 is like a moderate walking pace - reasonable for most situations</li>
</ul>
<p>You might want a higher value (like 0.5) if:</p>
<ul>
<li>You're confident the function is well-behaved</li>
<li>Initial progress seems too slow</li>
<li>You have good Hessian estimates</li>
</ul>
<p>You might want a lower value (like 0.05) if:</p>
<ul>
<li>The optimization is unstable or diverging</li>
<li>The problem is known to be challenging</li>
<li>You're working with a poorly conditioned problem</li>
</ul>
<p>Unlike in regular gradient descent, Newton's Method theoretically shouldn't need
a learning rate at all, but in practice, this damping factor helps prevent
instability when the quadratic approximation isn't perfect.</p>

</div>




  <a id="AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3_LearningRateDecreaseFactor_" data-uid="AiDotNet.Models.Options.NewtonMethodOptimizerOptions`3.LearningRateDecreaseFactor*"></a>

  <h3 id="AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3_LearningRateDecreaseFactor" data-uid="AiDotNet.Models.Options.NewtonMethodOptimizerOptions`3.LearningRateDecreaseFactor">
  LearningRateDecreaseFactor
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/NewtonMethodOptimizerOptions.cs/#L181"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the factor by which the learning rate is decreased when the algorithm
is not making good progress.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double LearningRateDecreaseFactor { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The learning rate decrease factor, defaulting to 0.95.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3_LearningRateDecreaseFactor_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This parameter controls how quickly the learning rate is reduced when the optimization
algorithm encounters difficulties or does not improve the objective function. A value
of 0.95 means the learning rate decreases by 5% when progress stalls, allowing the
algorithm to take more cautious steps in challenging regions of the parameter space.
This adaptive behavior is particularly important for Newton's Method when encountering
non-quadratic regions, ill-conditioned Hessians, or saddle points, where the standard
Newton step might be too aggressive or point in unhelpful directions.
</p>
<p><b>For Beginners:</b> This setting controls how much the step size decreases
when the algorithm stops making progress or moves in the wrong direction.
<p>The default value of 0.95 means:</p>
<ul>
<li>After an unsuccessful step, the learning rate shrinks by 5%</li>
<li>This makes the algorithm more cautious when it encounters difficulties</li>
</ul>
<p>Continuing our navigation analogy:</p>
<ul>
<li>When the terrain becomes tricky or you start going the wrong way</li>
<li>You slow down and take smaller, more careful steps</li>
</ul>
<p>You might want a lower value (like 0.8) if:</p>
<ul>
<li>The optimization frequently becomes unstable</li>
<li>You want to quickly reduce step size after poor steps</li>
<li>The function has many difficult regions that require careful navigation</li>
</ul>
<p>You might want a higher value (closer to 1.0) if:</p>
<ul>
<li>You want to maintain faster progress even through challenging regions</li>
<li>Minor setbacks shouldn't dramatically slow the optimization</li>
<li>You're confident in the overall stability of your approach</li>
</ul>
<p>This adaptive decrease helps Newton's Method remain stable and effective
even when the theoretical assumptions of the method aren't fully met in
practical optimization problems.</p>

</div>




  <a id="AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3_LearningRateIncreaseFactor_" data-uid="AiDotNet.Models.Options.NewtonMethodOptimizerOptions`3.LearningRateIncreaseFactor*"></a>

  <h3 id="AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3_LearningRateIncreaseFactor" data-uid="AiDotNet.Models.Options.NewtonMethodOptimizerOptions`3.LearningRateIncreaseFactor">
  LearningRateIncreaseFactor
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/NewtonMethodOptimizerOptions.cs/#L138"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the factor by which the learning rate is increased when the algorithm
is making good progress.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double LearningRateIncreaseFactor { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The learning rate increase factor, defaulting to 1.05.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_NewtonMethodOptimizerOptions_3_LearningRateIncreaseFactor_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This parameter controls how rapidly the learning rate can grow when consecutive iterations
show improvements in the optimization objective. A value of 1.05 means the learning rate 
can increase by 5% per successful iteration, gradually accelerating the optimization process
when moving in promising directions. While Newton's Method has theoretical guarantees for 
quadratic functions, adaptive learning rates help handle non-quadratic regions of the objective 
function and imperfect Hessian approximations. Higher values enable more aggressive acceleration 
but may reduce stability.
</p>
<p><b>For Beginners:</b> This setting determines how much the step size increases
when the algorithm is successfully moving toward better solutions.
<p>The default value of 1.05 means:</p>
<ul>
<li>After each successful step, the learning rate grows by 5%</li>
<li>This allows the algorithm to gradually speed up when things are going well</li>
</ul>
<p>Using our navigation analogy:</p>
<ul>
<li>When you're confident you're on the right path, you gradually walk faster</li>
<li>This adaptive pace helps you reach your destination more efficiently</li>
</ul>
<p>You might want a higher value (like 1.1) if:</p>
<ul>
<li>The optimization seems to be progressing too slowly</li>
<li>You're confident in the stability of your problem</li>
<li>You want to reach convergence more quickly</li>
</ul>
<p>You might want a lower value (closer to 1.0) if:</p>
<ul>
<li>The optimization becomes unstable with larger steps</li>
<li>You prefer a more cautious approach</li>
<li>The problem has delicate features that require careful exploration</li>
</ul>
<p>This adaptive increase helps Newton's Method balance between taking advantage
of its powerful second-order information while maintaining stability in
real-world optimization problems.</p>

</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/NewtonMethodOptimizerOptions.cs/#L41" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
