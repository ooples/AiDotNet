<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class SparsemaxActivation&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class SparsemaxActivation&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Implements the Sparsemax activation function, which is an alternative to Softmax that can produce sparse probability distributions.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_ActivationFunctions_SparsemaxActivation_1.md&amp;value=---%0Auid%3A%20AiDotNet.ActivationFunctions.SparsemaxActivation%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.ActivationFunctions.SparsemaxActivation`1">



  <h1 id="AiDotNet_ActivationFunctions_SparsemaxActivation_1" data-uid="AiDotNet.ActivationFunctions.SparsemaxActivation`1" class="text-break">
Class SparsemaxActivation&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/SparsemaxActivation.cs/#L27"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.ActivationFunctions.html">ActivationFunctions</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Implements the Sparsemax activation function, which is an alternative to Softmax that can produce sparse probability distributions.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class SparsemaxActivation&lt;T&gt; : ActivationFunctionBase&lt;T&gt;, IActivationFunction&lt;T&gt;, IVectorActivationFunction&lt;T&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric data type used for calculations.</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html">ActivationFunctionBase</a>&lt;T&gt;</div>
      <div><span class="xref">SparsemaxActivation&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.Interfaces.IActivationFunction-1.html">IActivationFunction</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IVectorActivationFunction-1.html">IVectorActivationFunction</a>&lt;T&gt;</div>
    </dd>
  </dl>


  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_NumOps">ActivationFunctionBase&lt;T&gt;.NumOps</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Engine">ActivationFunctionBase&lt;T&gt;.Engine</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Activate__0_">ActivationFunctionBase&lt;T&gt;.Activate(T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Derivative__0_">ActivationFunctionBase&lt;T&gt;.Derivative(T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Activate_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">ActivationFunctionBase&lt;T&gt;.Activate(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Derivative_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">ActivationFunctionBase&lt;T&gt;.Derivative(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">ActivationFunctionBase&lt;T&gt;.Backward(Tensor&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_SupportsGpuTraining">ActivationFunctionBase&lt;T&gt;.SupportsGpuTraining</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_ForwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">ActivationFunctionBase&lt;T&gt;.ForwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html#AiDotNet_ActivationFunctions_ActivationFunctionBase_1_BackwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">ActivationFunctionBase&lt;T&gt;.BackwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
Sparsemax maps input vectors to probability distributions, similar to Softmax, but with the key difference
that Sparsemax can assign exactly zero probability to low-scoring classes, creating sparse outputs.
</p>
<p>
<b>For Beginners:</b> Sparsemax is an advanced activation function used primarily in the output layer of 
neural networks for classification tasks. While Softmax always gives some probability to every possible 
class (even if very small), Sparsemax can assign exactly zero probability to unlikely classes.
<p>Think of it like this:</p>
<ul>
<li>Softmax is like saying &quot;I'm 80% sure it's a dog, 15% sure it's a cat, and 5% sure it's something else&quot;</li>
<li>Sparsemax might say &quot;I'm 90% sure it's a dog, 10% sure it's a cat, and 0% sure it's anything else&quot;</li>
</ul>
<p>This &quot;sparsity&quot; (having many zeros) can be useful when you have many possible classes but only a few
are likely to be correct. It makes the model's predictions more focused and interpretable.</p>

</div>


  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_SupportsJitCompilation_" data-uid="AiDotNet.ActivationFunctions.SparsemaxActivation`1.SupportsJitCompilation*"></a>

  <h3 id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_SupportsJitCompilation" data-uid="AiDotNet.ActivationFunctions.SparsemaxActivation`1.SupportsJitCompilation">
  SupportsJitCompilation
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/SparsemaxActivation.cs/#L174"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this activation function supports JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsJitCompilation { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True because TensorOperations.Sparsemax provides full forward and backward pass support.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_SupportsJitCompilation_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Sparsemax supports JIT compilation with support set tracking for correct gradient computation.
The backward pass routes gradients only through the support set (non-zero outputs),
computing the mean gradient within the support and subtracting it from each element.
</p>
<p>
Note: Currently implemented for 2D tensors (batch, features) along axis=-1.
</p>
</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_Activate_" data-uid="AiDotNet.ActivationFunctions.SparsemaxActivation`1.Activate*"></a>

  <h3 id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_Activate_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.ActivationFunctions.SparsemaxActivation`1.Activate(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  Activate(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/SparsemaxActivation.cs/#L75"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Sparsemax activation function to a vector of inputs.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Vector&lt;T&gt; Activate(Vector&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The input vector.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>A vector where some elements may be exactly zero, and all elements sum to 1.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_Activate_AiDotNet_Tensors_LinearAlgebra_Vector__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Sparsemax projects the input vector onto the probability simplex, potentially setting some values to exactly zero.
The algorithm finds a threshold value and sets all elements below this threshold to zero,
while shifting the remaining elements to ensure they sum to 1.
</p>
<p>
<b>For Beginners:</b> This method transforms a vector of numbers (like scores for different classes) into 
probabilities that add up to 1. Here's how it works:
<ol>
<li>Sort all the input values from highest to lowest</li>
<li>Find a &quot;threshold&quot; value by checking when the running average becomes greater than the next value</li>
<li>Subtract this threshold from all input values</li>
<li>Set any negative results to zero</li>
</ol>
<p>The result is a probability distribution where:</p>
<ul>
<li>Some values may be exactly zero (unlike Softmax where all values are positive)</li>
<li>All values add up to 1</li>
<li>Higher input values get higher probabilities</li>
</ul>
<p>This creates &quot;sparse&quot; outputs where only the most important classes get non-zero probabilities,
making the model's predictions easier to interpret.</p>

</div>




  <a id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_ApplyToGraph_" data-uid="AiDotNet.ActivationFunctions.SparsemaxActivation`1.ApplyToGraph*"></a>

  <h3 id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_ApplyToGraph_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.ActivationFunctions.SparsemaxActivation`1.ApplyToGraph(AiDotNet.Autodiff.ComputationNode{`0})">
  ApplyToGraph(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/SparsemaxActivation.cs/#L188"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies this activation function to a computation graph node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override ComputationNode&lt;T&gt; ApplyToGraph(ComputationNode&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The computation node to apply the activation to.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with Sparsemax activation applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_ApplyToGraph_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method maps to TensorOperations&lt;T&gt;.Sparsemax(input) which handles both
forward and backward passes for JIT compilation with support set tracking.
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></dt>
    <dd><p>Thrown if input is null.</p>
</dd>
  </dl>



  <a id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_Derivative_" data-uid="AiDotNet.ActivationFunctions.SparsemaxActivation`1.Derivative*"></a>

  <h3 id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_Derivative_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.ActivationFunctions.SparsemaxActivation`1.Derivative(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  Derivative(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/SparsemaxActivation.cs/#L128"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Calculates the Jacobian matrix of the Sparsemax function for a given input vector.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Matrix&lt;T&gt; Derivative(Vector&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The input vector.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Matrix-1.html">Matrix</a>&lt;T&gt;</dt>
    <dd><p>A matrix representing the partial derivatives of each output with respect to each input.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_Derivative_AiDotNet_Tensors_LinearAlgebra_Vector__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The Jacobian matrix contains the partial derivatives of each output element with respect to each input element.
For Sparsemax, the Jacobian has a specific structure based on which outputs are non-zero.
</p>
<p>
<b>For Beginners:</b> The derivative of Sparsemax is more complex than simpler activation functions because
changing one input can affect multiple outputs. This method returns a "Jacobian matrix" which shows
how each output value changes when each input value changes.
<p>Some key points about the Sparsemax derivative:</p>
<ul>
<li>For outputs that are zero, the derivatives are also zero (these outputs don't respond to small input changes)</li>
<li>For non-zero outputs, the derivatives form a specific pattern:
<ul>
<li>When i=j (diagonal elements): the derivative is 1</li>
<li>When i?j: the derivative is negative and depends on the output values</li>
</ul>
</li>
</ul>
<p>During neural network training, this matrix helps determine how to adjust the weights based on errors.
The sparsity of Sparsemax can make training more efficient because many derivatives will be zero.</p>

</div>




  <a id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_SupportsScalarOperations_" data-uid="AiDotNet.ActivationFunctions.SparsemaxActivation`1.SupportsScalarOperations*"></a>

  <h3 id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_SupportsScalarOperations" data-uid="AiDotNet.ActivationFunctions.SparsemaxActivation`1.SupportsScalarOperations">
  SupportsScalarOperations()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/SparsemaxActivation.cs/#L44"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Indicates whether this activation function supports scalar operations.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected override bool SupportsScalarOperations()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Always returns false as Sparsemax requires a vector of values.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_ActivationFunctions_SparsemaxActivation_1_SupportsScalarOperations_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Unlike functions like ReLU that can operate on individual values, Sparsemax needs to consider
all elements in a vector together to compute the probability distribution.
</p>
<p>
<b>For Beginners:</b> This method returning false means that Sparsemax cannot work on just one number at a time.
It needs to see all the values together (like all scores for different classes) to determine
which ones should get non-zero probabilities.
</p>
</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/ActivationFunctions/SparsemaxActivation.cs/#L27" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
