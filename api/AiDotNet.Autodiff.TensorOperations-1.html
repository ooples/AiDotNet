<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class TensorOperations&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class TensorOperations&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Provides automatic differentiation support for tensor operations.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_Autodiff_TensorOperations_1.md&amp;value=---%0Auid%3A%20AiDotNet.Autodiff.TensorOperations%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.Autodiff.TensorOperations`1">



  <h1 id="AiDotNet_Autodiff_TensorOperations_1" data-uid="AiDotNet.Autodiff.TensorOperations`1" class="text-break">
Class TensorOperations&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L48"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.Autodiff.html">Autodiff</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Provides automatic differentiation support for tensor operations.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static class TensorOperations&lt;T&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for calculations.</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><span class="xref">TensorOperations&lt;T&gt;</span></div>
    </dd>
  </dl>



  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_Autodiff_TensorOperations_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
TensorOperations is a helper class that integrates automatic differentiation with tensor operations.
It records operations performed on tensors to an active GradientTape (if present) and creates
the computation graph needed for backpropagation.
</p>
<p>
This class follows the opt-in pattern: tensor operations only record to the gradient tape
when explicitly used within a GradientTape context. Outside of a GradientTape context,
operations work normally without any overhead.
</p>
<p><b>For Beginners:</b> This class bridges regular tensor operations with automatic differentiation.
<p>Think of it like adding a &quot;recording mode&quot; to your calculations:</p>
<ul>
<li>When you're inside a GradientTape context, operations are recorded</li>
<li>The recording remembers how each value was computed</li>
<li>Later, you can &quot;play it backwards&quot; to compute gradients</li>
<li>When not recording, operations work exactly as before</li>
</ul>
<p>This enables features like:</p>
<ul>
<li>Automatic gradient computation for neural network training</li>
<li>Computing derivatives without writing manual backward passes</li>
<li>Building complex computational graphs automatically</li>
</ul>
<p>Example usage:</p>
<pre><code class="lang-csharp">using (var tape = new GradientTape&lt;double&gt;())
{
    var x = TensorOperations&lt;double&gt;.Variable(inputTensor, "x");
    var y = TensorOperations&lt;double&gt;.Variable(parameterTensor, "y");
    tape.Watch(x);
    tape.Watch(y);

    var z = TensorOperations&lt;double&gt;.Add(x, y); // Recorded to tape
    var gradients = tape.Gradient(z, new[] { x, y });
}</code></pre>

</div>


  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_Autodiff_TensorOperations_1_Abs_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Abs*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Abs_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Abs(AiDotNet.Autodiff.ComputationNode{`0})">
  Abs(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L922"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the absolute value of each element in a computation node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Abs(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the absolute values.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Abs_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method computes |x| for each element and records the operation.
The backward function uses the sign of the original values for gradient computation.
</p>
<p><b>For Beginners:</b> This makes all values positive (removes the sign).
<p>For absolute value (c = |a|):</p>
<ul>
<li>The forward pass removes the sign of each element</li>
<li>The backward pass uses sign(a) to route gradients correctly</li>
<li>For positive values, gradient passes through unchanged</li>
<li>For negative values, gradient is negated</li>
</ul>
<p>Note: At x = 0, the gradient is technically undefined, but we use 0 as a convention.</p>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Add_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Add*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Add_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Add(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  Add(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L142"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs element-wise addition of two computation nodes.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Add(ComputationNode&lt;T&gt; a, ComputationNode&lt;T&gt; b)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The first node.</p>
</dd>
    <dt><code>b</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The second node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the sum.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Add_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs element-wise addition and records the operation to any active GradientTape.
The backward function distributes gradients equally to both inputs (since ∂(a+b)/∂a = 1 and ∂(a+b)/∂b = 1).
</p>
<p><b>For Beginners:</b> This adds two tensors together and remembers how to compute gradients.
<p>For addition (c = a + b):</p>
<ul>
<li>The forward pass computes the sum element-wise</li>
<li>The backward pass sends gradients to both inputs unchanged</li>
<li>This is because changing 'a' by 1 changes the sum by 1, same for 'b'</li>
</ul>
<p>Example:
If the gradient flowing back to c is [1, 2, 3], then both 'a' and 'b' receive [1, 2, 3]</p>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_AffineGrid_" data-uid="AiDotNet.Autodiff.TensorOperations`1.AffineGrid*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_AffineGrid_AiDotNet_Autodiff_ComputationNode__0__System_Int32_System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.AffineGrid(AiDotNet.Autodiff.ComputationNode{`0},System.Int32,System.Int32)">
  AffineGrid(ComputationNode&lt;T&gt;, int, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L6621"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Generates a sampling grid for spatial transformer networks using affine transformation matrices.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; AffineGrid(ComputationNode&lt;T&gt; theta, int outputHeight, int outputWidth)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>theta</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Affine transformation matrices of shape [batch, 2, 3]</p>
</dd>
    <dt><code>outputHeight</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Height of the output grid</p>
</dd>
    <dt><code>outputWidth</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Width of the output grid</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Sampling grid of shape [batch, outputHeight, outputWidth, 2] with (x, y) coordinates</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_AffineGrid_AiDotNet_Autodiff_ComputationNode__0__System_Int32_System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This operation generates a grid of sampling coordinates for spatial transformations.
The output grid starts as a regular grid in normalized coordinates [-1, 1], then
each point is transformed using the affine matrix.
</p>
<p>
Forward pass:
1. Generate base grid in [-1, 1] normalized space
2. For each point (x_out, y_out) in output space:
   x_in = theta[0,0]*x_out + theta[0,1]*y_out + theta[0,2]
   y_in = theta[1,0]*x_out + theta[1,1]*y_out + theta[1,2]
</p>
<p>
Backward pass:
- ∂L/∂theta[i,j] = sum over all grid points of (∂L/∂grid * ∂grid/∂theta)
</p>
<p><b>For Beginners:</b> This creates a map showing where each output pixel should sample from.
The affine matrix controls rotation, scaling, translation, and shearing of the grid.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_AnomalyScore_" data-uid="AiDotNet.Autodiff.TensorOperations`1.AnomalyScore*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_AnomalyScore_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.AnomalyScore(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  AnomalyScore(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L9412"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Anomaly score computation using reconstruction error or density estimation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; AnomalyScore(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; reconstruction)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input tensor.</p>
</dd>
    <dt><code>reconstruction</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Reconstructed input (e.g., from autoencoder).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Anomaly scores (higher = more anomalous).</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_ApplyActivation_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ApplyActivation*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_ApplyActivation_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Interfaces_IActivationFunction__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.ApplyActivation(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Interfaces.IActivationFunction{`0})">
  ApplyActivation(ComputationNode&lt;T&gt;, IActivationFunction&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L7382"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies a generic activation function (scalar or element-wise) with automatic differentiation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; ApplyActivation(ComputationNode&lt;T&gt; input, IActivationFunction&lt;T&gt; activation)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>activation</code> <a class="xref" href="AiDotNet.Interfaces.IActivationFunction-1.html">IActivationFunction</a>&lt;T&gt;</dt>
    <dd><p>The activation function to apply.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with the activation applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_ApplyActivation_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Interfaces_IActivationFunction__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method provides generic autodiff support for ANY activation function that implements
IActivationFunction{T}. It works by applying the activation function element-wise during
the forward pass, then using the activation's ComputeDerivative method during backpropagation.
</p>
<p>
This means ALL 39 built-in activation functions automatically work with autodiff,
and only truly custom user-defined activations (that don't inherit from ActivationFunctionBase)
would fail.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_AvgPool2D_" data-uid="AiDotNet.Autodiff.TensorOperations`1.AvgPool2D*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_AvgPool2D_AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.AvgPool2D(AiDotNet.Autodiff.ComputationNode{`0},System.Int32[],System.Int32[])">
  AvgPool2D(ComputationNode&lt;T&gt;, int[], int[]?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L3031"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs 2D average pooling on a 4D tensor (batch, channels, height, width).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; AvgPool2D(ComputationNode&lt;T&gt; a, int[] poolSize, int[]? strides = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node with shape [batch, channels, height, width].</p>
</dd>
    <dt><code>poolSize</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The size of the pooling window [poolH, poolW].</p>
</dd>
    <dt><code>strides</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The stride for the pooling operation [strideH, strideW]. If null, uses poolSize.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the average pooled result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_AvgPool2D_AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs average pooling over 2D spatial dimensions.
The backward function distributes gradients equally across the pooling window.
</p>
<p><b>For Beginners:</b> AvgPool downsamples by taking the average value in each window.
<p>For average pooling:</p>
<ul>
<li>The forward pass slides a window and computes the average</li>
<li>This smoothly reduces spatial dimensions</li>
<li>The backward pass distributes gradients equally to all elements in the window</li>
<li>Each element gets gradient / pool_area</li>
</ul>
<p>Used in:</p>
<ul>
<li>CNNs for smoother downsampling than max pooling</li>
<li>Global average pooling (replacing fully connected layers)</li>
<li>Reducing overfitting</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_BatchMatrixMultiply_" data-uid="AiDotNet.Autodiff.TensorOperations`1.BatchMatrixMultiply*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_BatchMatrixMultiply_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.BatchMatrixMultiply(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  BatchMatrixMultiply(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1081"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs batched matrix multiplication of two 3D computation nodes.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; BatchMatrixMultiply(ComputationNode&lt;T&gt; a, ComputationNode&lt;T&gt; b)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The first 3D tensor with shape [Batch, M, K].</p>
</dd>
    <dt><code>b</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The second 3D tensor with shape [Batch, K, N].</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node representing the batched matrix multiplication with shape [Batch, M, N].</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_BatchMatrixMultiply_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
For 3D tensors, performs element-wise matrix multiplication across the batch dimension:
result[i] = a[i] @ b[i] for each batch index i.
</p>
<p><b>Gradient computation:</b>
- ∂(A·B)/∂A = gradOut·B^T (batch-wise)
- ∂(A·B)/∂B = A^T·gradOut (batch-wise)
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_BatchNorm_" data-uid="AiDotNet.Autodiff.TensorOperations`1.BatchNorm*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_BatchNorm_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__System_Boolean_System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.BatchNorm(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Tensors.LinearAlgebra.Tensor{`0},AiDotNet.Tensors.LinearAlgebra.Tensor{`0},System.Boolean,System.Double)">
  BatchNorm(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;?, ComputationNode&lt;T&gt;?, Tensor&lt;T&gt;?, Tensor&lt;T&gt;?, bool, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L3480"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies batch normalization to a computation node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; BatchNorm(ComputationNode&lt;T&gt; a, ComputationNode&lt;T&gt;? gamma = null, ComputationNode&lt;T&gt;? beta = null, Tensor&lt;T&gt;? runningMean = null, Tensor&lt;T&gt;? runningVar = null, bool training = true, double epsilon = 1E-05)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node with shape [batch, features].</p>
</dd>
    <dt><code>gamma</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional scale parameter (learnable). If null, uses ones.</p>
</dd>
    <dt><code>beta</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional shift parameter (learnable). If null, uses zeros.</p>
</dd>
    <dt><code>runningMean</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Running mean for inference (not updated during this operation).</p>
</dd>
    <dt><code>runningVar</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Running variance for inference (not updated during this operation).</p>
</dd>
    <dt><code>training</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Whether in training mode (uses batch statistics) or inference mode (uses running statistics).</p>
</dd>
    <dt><code>epsilon</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Small constant for numerical stability. Default is 1e-5.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the batch normalized result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_BatchNorm_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__System_Boolean_System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Batch normalization normalizes inputs across the batch dimension.
During training: Uses batch statistics (mean and variance computed from current batch).
During inference: Uses running statistics (accumulated during training).
</p>
<p><b>For Beginners:</b> BatchNorm standardizes features across the batch.
<p>For batch normalization:</p>
<ul>
<li>Training mode: Uses current batch's mean and variance</li>
<li>Inference mode: Uses running mean/variance from training</li>
<li>Normalizes: (x - mean) / sqrt(variance)</li>
<li>Scales and shifts: result * gamma + beta</li>
</ul>
<p>Benefits:</p>
<ul>
<li>Stabilizes training (reduces internal covariate shift)</li>
<li>Allows higher learning rates</li>
<li>Acts as regularization</li>
</ul>
<p>Used in:</p>
<ul>
<li>CNNs (after convolutional layers)</li>
<li>Deep feedforward networks</li>
<li>GANs and many other architectures</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_BentIdentity_" data-uid="AiDotNet.Autodiff.TensorOperations`1.BentIdentity*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_BentIdentity_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.BentIdentity(AiDotNet.Autodiff.ComputationNode{`0})">
  BentIdentity(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L2402"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Bent Identity activation function element-wise.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; BentIdentity(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with BentIdentity applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_BentIdentity_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
BentIdentity is defined as: f(x) = (sqrt(x² + 1) - 1) / 2 + x
The gradient is: x / (2 * sqrt(x² + 1)) + 1
</p>
<p><b>For Beginners:</b> BentIdentity is a smooth alternative to ReLU with
non-zero gradient everywhere, preventing dead neurons during training.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Broadcast_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Broadcast*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Broadcast_AiDotNet_Autodiff_ComputationNode__0__System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.Broadcast(AiDotNet.Autodiff.ComputationNode{`0},System.Int32[])">
  Broadcast(ComputationNode&lt;T&gt;, int[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1476"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Broadcasts a 1D tensor to a 2D tensor by tiling along the batch dimension.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Broadcast(ComputationNode&lt;T&gt; a, int[] targetShape)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input 1D tensor node with shape [N].</p>
</dd>
    <dt><code>targetShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The target 2D shape [batchSize, N].</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with the broadcasted tensor.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Broadcast_AiDotNet_Autodiff_ComputationNode__0__System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This operation broadcasts a 1D tensor (e.g., biases with shape [outputSize]) to a 2D tensor
(e.g., [batchSize, outputSize]) by replicating values along the batch dimension.
The backward pass correctly sums gradients along the broadcasted dimension.
</p>
<p><b>For Beginners:</b> Broadcasting is like copying a row multiple times to create a matrix.
<p>For example, if you have biases [b1, b2, b3] and need to add them to a batch of outputs:</p>
<ul>
<li>Input: [b1, b2, b3] (shape [3])</li>
<li>Target shape: [batchSize=2, 3]</li>
<li>Output: [[b1, b2, b3], [b1, b2, b3]] (each row is a copy)</li>
</ul>
<p>During backpropagation, gradients from all rows are summed back to the original biases,
because each bias contributed to all batch elements.</p>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_CELU_" data-uid="AiDotNet.Autodiff.TensorOperations`1.CELU*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_CELU_AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.CELU(AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  CELU(ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L2276"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the CELU (Continuously Differentiable ELU) activation function element-wise.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; CELU(ComputationNode&lt;T&gt; a, double alpha = 1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>alpha</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The alpha parameter controlling negative saturation. Default is 1.0.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with CELU applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_CELU_AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
CELU is defined as: max(0, x) + min(0, α * (exp(x/α) - 1))
The gradient is: 1 if x &gt;= 0, otherwise exp(x/α)
</p>
<p><b>For Beginners:</b> CELU is an improved version of ELU that is continuously
differentiable everywhere, which can help with optimization and training stability.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_CRFForward_" data-uid="AiDotNet.Autodiff.TensorOperations`1.CRFForward*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_CRFForward_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.CRFForward(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  CRFForward(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;?, ComputationNode&lt;T&gt;?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L9221"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>CRF forward algorithm for sequence labeling.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; CRFForward(ComputationNode&lt;T&gt; emissions, ComputationNode&lt;T&gt; transitions, ComputationNode&lt;T&gt;? startScores = null, ComputationNode&lt;T&gt;? endScores = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>emissions</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Emission scores [seq_len, num_tags].</p>
</dd>
    <dt><code>transitions</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Transition matrix [num_tags, num_tags].</p>
</dd>
    <dt><code>startScores</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional start scores [num_tags].</p>
</dd>
    <dt><code>endScores</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional end scores [num_tags].</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Log partition function (normalizer).</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_CRFForward_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Computes the log partition function using the forward-backward algorithm.
This is differentiable and returns proper gradients for emissions, transitions,
start scores, and end scores.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_ComplexMatMul_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ComplexMatMul*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_ComplexMatMul_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_String_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ComplexMatMul(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.String)">
  ComplexMatMul(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, string)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L8113"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs complex matrix multiplication on tensors representing complex numbers as [real, imag] pairs.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; ComplexMatMul(ComputationNode&lt;T&gt; a, ComputationNode&lt;T&gt; b, string format = &quot;split&quot;)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>First complex matrix [batch, m, 2*k] where dimensions are [real, imag] interleaved or concatenated.</p>
</dd>
    <dt><code>b</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Second complex matrix [batch, 2*k, n].</p>
</dd>
    <dt><code>format</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>Whether complex numbers are &quot;interleaved&quot; ([r,i,r,i,...]) or &quot;split&quot; ([r,r,...,i,i,...]).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Complex matrix product [batch, m, 2*n].</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_ComplexMatMul_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_String__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Complex multiplication: (a + bi)(c + di) = (ac - bd) + (ad + bc)i
</p>
<p><b>For Beginners:</b> This multiplies matrices of complex numbers.
<p>Complex numbers are represented as pairs of real numbers [real_part, imaginary_part].
This operation implements the full complex matrix multiplication formula.</p>
<p>Used in quantum computing layers where quantum gates are unitary matrices.</p>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_ComplexMultiply_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ComplexMultiply*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_ComplexMultiply_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_String_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ComplexMultiply(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.String)">
  ComplexMultiply(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, string)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L8497"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs element-wise complex multiplication.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; ComplexMultiply(ComputationNode&lt;T&gt; a, ComputationNode&lt;T&gt; b, string format = &quot;split&quot;)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>First complex tensor with last dimension of size 2*n.</p>
</dd>
    <dt><code>b</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Second complex tensor with last dimension of size 2*n.</p>
</dd>
    <dt><code>format</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>Whether complex numbers are &quot;split&quot; ([r,r,...,i,i,...]).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Element-wise complex product.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_ComplexMultiply_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_String__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Complex multiplication: (a + bi)(c + di) = (ac - bd) + (ad + bc)i
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Concat_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Concat*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Concat_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0___System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Concat(System.Collections.Generic.List{AiDotNet.Autodiff.ComputationNode{`0}},System.Int32)">
  Concat(List&lt;ComputationNode&lt;T&gt;&gt;, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L2600"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Concatenates multiple computation nodes along a specified axis.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Concat(List&lt;ComputationNode&lt;T&gt;&gt; nodes, int axis = 0)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>nodes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.list-1">List</a>&lt;<a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;&gt;</dt>
    <dd><p>The list of nodes to concatenate.</p>
</dd>
    <dt><code>axis</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The axis along which to concatenate. Default is 0.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the concatenated result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Concat_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0___System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method concatenates tensors along the specified axis.
All tensors must have the same shape except along the concatenation axis.
The backward function splits the gradient and sends each portion to the corresponding input.
</p>
<p><b>For Beginners:</b> Concat stacks tensors together along a dimension.
<p>For concatenation:</p>
<ul>
<li>The forward pass combines multiple tensors into one larger tensor</li>
<li>The backward pass splits the gradient back to each input</li>
<li>Think of it like gluing arrays together end-to-end</li>
</ul>
<p>Used in:</p>
<ul>
<li>Skip connections (concatenating features from different layers)</li>
<li>Multi-input architectures</li>
<li>Feature fusion in neural networks</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Constant_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Constant*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Constant_AiDotNet_Tensors_LinearAlgebra_Tensor__0__System_String_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Constant(AiDotNet.Tensors.LinearAlgebra.Tensor{`0},System.String)">
  Constant(Tensor&lt;T&gt;, string?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L110"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Creates a constant computation node from a tensor value.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Constant(Tensor&lt;T&gt; value, string? name = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>value</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The tensor value.</p>
</dd>
    <dt><code>name</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>Optional name for the node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node that doesn't require gradients.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Constant_AiDotNet_Tensors_LinearAlgebra_Tensor__0__System_String__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method creates a constant node - a value that won't have gradients computed.
Use this for constants, hyperparameters, or intermediate values you don't need gradients for.
</p>
<p><b>For Beginners:</b> This creates a value that won't be adjusted during training.
<p>Use this for:</p>
<ul>
<li>Constants (like pi, e, or fixed multipliers)</li>
<li>Hyperparameters that don't change during training</li>
<li>Any value you don't need gradients for (saves memory)</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Conv2D_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Conv2D*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Conv2D_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.Conv2D(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Int32[],System.Int32[])">
  Conv2D(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;?, int[]?, int[]?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L4464"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs 2D convolution on a 4D tensor (batch, channels, height, width).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Conv2D(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; kernel, ComputationNode&lt;T&gt;? bias = null, int[]? stride = null, int[]? padding = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node with shape [batch, inChannels, height, width].</p>
</dd>
    <dt><code>kernel</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The kernel/filter with shape [outChannels, inChannels, kernelH, kernelW].</p>
</dd>
    <dt><code>bias</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional bias with shape [outChannels]. If null, no bias is added.</p>
</dd>
    <dt><code>stride</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The stride [strideH, strideW]. Default is [1, 1].</p>
</dd>
    <dt><code>padding</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The padding [padH, padW]. Default is [0, 0].</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the convolution result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Conv2D_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs 2D convolution, the fundamental operation in CNNs.
Forward: Slides the kernel over the input computing dot products.
Backward: Computes gradients for both input and kernel using transposed convolutions.
</p>
<p><b>For Beginners:</b> Conv2D is the core operation of convolutional neural networks.
<p>For 2D convolution:</p>
<ul>
<li>The kernel &quot;slides&quot; over the input, computing weighted sums</li>
<li>Each output position is a dot product of the kernel with input patch</li>
<li>Stride controls how far the kernel moves each step</li>
<li>Padding adds borders to control output size</li>
</ul>
<p>Gradient computation:</p>
<ul>
<li>Gradient w.r.t. input: &quot;full&quot; convolution with flipped kernel</li>
<li>Gradient w.r.t. kernel: cross-correlation between input and output gradient</li>
</ul>
<p>Used in:</p>
<ul>
<li>All CNNs (image classification, object detection, segmentation)</li>
<li>Feature extraction in vision models</li>
<li>Learning spatial hierarchies</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Conv3D_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Conv3D*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Conv3D_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.Conv3D(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Int32[],System.Int32[])">
  Conv3D(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;?, int[]?, int[]?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L4609"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs 3D convolution on a 5D tensor (batch, channels, depth, height, width).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Conv3D(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; kernel, ComputationNode&lt;T&gt;? bias = null, int[]? stride = null, int[]? padding = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node with shape [batch, inChannels, depth, height, width].</p>
</dd>
    <dt><code>kernel</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The kernel/filter with shape [outChannels, inChannels, kernelD, kernelH, kernelW].</p>
</dd>
    <dt><code>bias</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional bias with shape [outChannels]. If null, no bias is added.</p>
</dd>
    <dt><code>stride</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The stride [strideD, strideH, strideW]. Default is [1, 1, 1].</p>
</dd>
    <dt><code>padding</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The padding [padD, padH, padW]. Default is [0, 0, 0].</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the 3D convolution result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Conv3D_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs 3D convolution, the fundamental operation for volumetric data processing.
Forward: Slides the kernel over the input computing dot products across all three spatial dimensions.
Backward: Computes gradients for both input and kernel using transposed 3D convolutions.
</p>
<p><b>For Beginners:</b> Conv3D is the 3D extension of Conv2D for volumetric data.
<p>For 3D convolution:</p>
<ul>
<li>The kernel &quot;slides&quot; over depth, height, and width dimensions</li>
<li>Each output position is a dot product of the kernel with an input volume</li>
<li>Stride controls how far the kernel moves each step in each dimension</li>
<li>Padding adds borders to control output size</li>
</ul>
<p>Gradient computation:</p>
<ul>
<li>Gradient w.r.t. input: &quot;full&quot; 3D convolution with flipped kernel</li>
<li>Gradient w.r.t. kernel: 3D cross-correlation between input and output gradient</li>
</ul>
<p>Used in:</p>
<ul>
<li>3D object recognition from voxel grids (VoxNet, VoxelCNN)</li>
<li>Medical image analysis (CT/MRI volumetric scans)</li>
<li>Video understanding (treating time as depth dimension)</li>
<li>Point cloud processing after voxelization</li>
</ul>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a></dt>
    <dd><p>Thrown when input or kernel have invalid dimensions.</p>
</dd>
  </dl>



  <a id="AiDotNet_Autodiff_TensorOperations_1_ConvTranspose2D_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ConvTranspose2D*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_ConvTranspose2D_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32___System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.ConvTranspose2D(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Int32[],System.Int32[],System.Int32[])">
  ConvTranspose2D(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;?, int[]?, int[]?, int[]?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L4905"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs 2D transposed convolution (deconvolution) on a 4D tensor.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; ConvTranspose2D(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; kernel, ComputationNode&lt;T&gt;? bias = null, int[]? stride = null, int[]? padding = null, int[]? outputPadding = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node with shape [batch, inChannels, height, width].</p>
</dd>
    <dt><code>kernel</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The kernel with shape [inChannels, outChannels, kernelH, kernelW] (note: reversed from Conv2D).</p>
</dd>
    <dt><code>bias</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional bias with shape [outChannels]. If null, no bias is added.</p>
</dd>
    <dt><code>stride</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The stride [strideH, strideW]. Default is [1, 1].</p>
</dd>
    <dt><code>padding</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The padding [padH, padW]. Default is [0, 0].</p>
</dd>
    <dt><code>outputPadding</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>Output padding [outPadH, outPadW] for size adjustment. Default is [0, 0].</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the transposed convolution result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_ConvTranspose2D_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32___System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Transposed convolution (often called deconvolution) upsamples the input.
It's the gradient of Conv2D with respect to its input, used as a forward operation.
</p>
<p><b>For Beginners:</b> ConvTranspose2D upsamples spatial dimensions.
<p>For transposed convolution:</p>
<ul>
<li>Inserts zeros between input elements according to stride</li>
<li>Applies regular convolution to the expanded input</li>
<li>Results in larger spatial dimensions (upsampling)</li>
</ul>
<p>Used in:</p>
<ul>
<li>Image generation (GANs, VAEs)</li>
<li>Semantic segmentation (U-Net decoder)</li>
<li>Super-resolution</li>
<li>Any task requiring upsampling</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Crop_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Crop*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Crop_AiDotNet_Autodiff_ComputationNode__0__System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.Crop(AiDotNet.Autodiff.ComputationNode{`0},System.Int32[])">
  Crop(ComputationNode&lt;T&gt;, int[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L5393"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Crops a tensor by removing elements from the edges.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Crop(ComputationNode&lt;T&gt; a, int[] cropping)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>cropping</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>Array of [top, bottom, left, right] cropping amounts for 4D tensors.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node representing the cropped tensor.</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_DeformableConv2D_" data-uid="AiDotNet.Autodiff.TensorOperations`1.DeformableConv2D*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_DeformableConv2D_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32___System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.DeformableConv2D(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Int32[],System.Int32[],System.Int32[])">
  DeformableConv2D(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;?, ComputationNode&lt;T&gt;?, int[]?, int[]?, int[]?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L6112"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs 2D deformable convolution with learnable offsets and optional modulation mask.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; DeformableConv2D(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; kernel, ComputationNode&lt;T&gt; offset, ComputationNode&lt;T&gt;? mask = null, ComputationNode&lt;T&gt;? bias = null, int[]? stride = null, int[]? padding = null, int[]? dilation = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input tensor [batch, inChannels, height, width].</p>
</dd>
    <dt><code>kernel</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Convolution kernel [outChannels, inChannels, kernelH, kernelW].</p>
</dd>
    <dt><code>offset</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Spatial offsets [batch, 2<em>kernelH</em>kernelW, outH, outW].</p>
</dd>
    <dt><code>mask</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional modulation mask [batch, kernelH*kernelW, outH, outW]. If null, uses uniform weights.</p>
</dd>
    <dt><code>bias</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional bias [outChannels]. If null, no bias is added.</p>
</dd>
    <dt><code>stride</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>Stride [strideH, strideW]. Default is [1, 1].</p>
</dd>
    <dt><code>padding</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>Padding [padH, padW]. Default is [0, 0].</p>
</dd>
    <dt><code>dilation</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>Dilation [dilationH, dilationW]. Default is [1, 1].</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Output tensor [batch, outChannels, outH, outW].</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_DeformableConv2D_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32___System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Deformable convolution augments standard convolution with learnable 2D offsets for each
sampling position in the kernel. This allows the network to adaptively adjust its receptive
field based on the input, enabling better modeling of geometric transformations.
</p>
<p><b>For Beginners:</b> Standard convolution samples at fixed grid positions.
Deformable convolution learns where to sample, allowing it to handle objects of various
shapes and scales more effectively.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_DepthwiseConv2D_" data-uid="AiDotNet.Autodiff.TensorOperations`1.DepthwiseConv2D*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_DepthwiseConv2D_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.DepthwiseConv2D(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Int32[],System.Int32[])">
  DepthwiseConv2D(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;?, int[]?, int[]?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L5724"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs depthwise 2D convolution where each input channel is convolved with its own set of filters.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; DepthwiseConv2D(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; kernel, ComputationNode&lt;T&gt;? bias = null, int[]? stride = null, int[]? padding = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input tensor of shape [batch, in_channels, height, width]</p>
</dd>
    <dt><code>kernel</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Kernel tensor of shape [in_channels, multiplier, kernel_height, kernel_width]</p>
</dd>
    <dt><code>bias</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional bias tensor of shape [in_channels * multiplier]</p>
</dd>
    <dt><code>stride</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>Stride for the convolution, defaults to [1, 1]</p>
</dd>
    <dt><code>padding</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>Padding for the convolution, defaults to [0, 0]</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Output tensor of shape [batch, in_channels * multiplier, out_height, out_width]</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_DepthwiseConv2D_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Depthwise convolution applies a separate filter to each input channel independently, with no mixing
across channels. This is in contrast to standard convolution which mixes all input channels.
Each input channel gets 'multiplier' filters applied to it, producing 'multiplier' output channels.
The total output channels is in_channels * multiplier.
</p>
<p>
This operation is commonly used in MobileNets and other efficient architectures, often followed
by a pointwise (1x1) convolution to mix channels. The combination dramatically reduces
computational cost compared to standard convolution.
</p>
<p>
Forward pass computes the depthwise convolution by applying each filter only to its corresponding
input channel. Backward pass computes gradients with respect to input, kernel, and bias.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_DilatedConv2D_" data-uid="AiDotNet.Autodiff.TensorOperations`1.DilatedConv2D*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_DilatedConv2D_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32___System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.DilatedConv2D(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Int32[],System.Int32[],System.Int32[])">
  DilatedConv2D(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;?, int[]?, int[]?, int[]?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L5589"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs dilated (atrous) 2D convolution operation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; DilatedConv2D(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; kernel, ComputationNode&lt;T&gt;? bias = null, int[]? stride = null, int[]? padding = null, int[]? dilation = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input tensor with shape [batch, channels, height, width].</p>
</dd>
    <dt><code>kernel</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The convolution kernel with shape [out_channels, in_channels, kernel_height, kernel_width].</p>
</dd>
    <dt><code>bias</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional bias tensor with shape [out_channels].</p>
</dd>
    <dt><code>stride</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The stride for the convolution. Defaults to [1, 1].</p>
</dd>
    <dt><code>padding</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The padding for the convolution. Defaults to [0, 0].</p>
</dd>
    <dt><code>dilation</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The dilation rate for the convolution. Defaults to [1, 1].</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node representing the dilated convolution result.</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_Divide_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Divide*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Divide_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Divide(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  Divide(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L413"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs element-wise division of two computation nodes.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Divide(ComputationNode&lt;T&gt; a, ComputationNode&lt;T&gt; b)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The numerator node.</p>
</dd>
    <dt><code>b</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The denominator node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the element-wise quotient.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Divide_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs element-wise division and records the operation to any active GradientTape.
The backward function uses the quotient rule: ∂(a/b)/∂a = 1/b and ∂(a/b)/∂b = -a/b².
</p>
<p><b>For Beginners:</b> This divides one tensor by another element-wise and tracks gradients.
<p>For element-wise division (c = a / b):</p>
<ul>
<li>The forward pass divides corresponding elements</li>
<li>The backward pass uses the quotient rule from calculus</li>
<li>Gradient to 'a' is: incoming gradient * (1/b)</li>
<li>Gradient to 'b' is: incoming gradient * (-a/b²)</li>
</ul>
<p>Example:
If a=[6,8], b=[2,4], c=[3,2]
If gradient to c is [1,1]:</p>
<ul>
<li>'a' receives [1/2, 1/4] = [0.5, 0.25]</li>
<li>'b' receives [-6/4, -8/16] = [-1.5, -0.5]</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_ELU_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ELU*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_ELU_AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ELU(AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  ELU(ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1616"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Exponential Linear Unit (ELU) activation function to a computation node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; ELU(ComputationNode&lt;T&gt; a, double alpha = 1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>alpha</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The alpha parameter controlling the negative saturation value. Default is 1.0.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with ELU applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_ELU_AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
ELU(x) = x if x &gt; 0, alpha * (exp(x) - 1) otherwise.
ELU helps prevent "dying neurons" and pushes mean activations closer to zero.
</p>
<p><b>Gradient:</b> d(ELU)/dx = 1 if x &gt; 0, alpha * exp(x) = ELU(x) + alpha otherwise.</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_ElementwiseMultiply_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ElementwiseMultiply*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_ElementwiseMultiply_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.ElementwiseMultiply(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  ElementwiseMultiply(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L312"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs element-wise multiplication of two computation nodes.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; ElementwiseMultiply(ComputationNode&lt;T&gt; a, ComputationNode&lt;T&gt; b)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The first node.</p>
</dd>
    <dt><code>b</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The second node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the element-wise product.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_ElementwiseMultiply_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs element-wise (Hadamard) multiplication and records the operation.
The backward function uses the product rule: ∂(a*b)/∂a = b and ∂(a*b)/∂b = a.
</p>
<p><b>For Beginners:</b> This multiplies two tensors element-wise and tracks gradients.
<p>For element-wise multiplication (c = a * b):</p>
<ul>
<li>The forward pass multiplies corresponding elements</li>
<li>The backward pass uses the product rule from calculus</li>
<li>Gradient to 'a' is: incoming gradient * b's value</li>
<li>Gradient to 'b' is: incoming gradient * a's value</li>
</ul>
<p>Example:
If a=[2,3], b=[4,5], c=[8,15]
If gradient to c is [1,1]:</p>
<ul>
<li>'a' receives [1<em>4, 1</em>5] = [4, 5]</li>
<li>'b' receives [1<em>2, 1</em>3] = [2, 3]</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_EmbeddingLookup_" data-uid="AiDotNet.Autodiff.TensorOperations`1.EmbeddingLookup*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_EmbeddingLookup_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.EmbeddingLookup(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  EmbeddingLookup(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L7436"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs embedding lookup operation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; EmbeddingLookup(ComputationNode&lt;T&gt; embeddings, ComputationNode&lt;T&gt; indices)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>embeddings</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The embedding matrix [vocab_size, embedding_dim].</p>
</dd>
    <dt><code>indices</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The indices to lookup [batch_size, sequence_length].</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The looked up embeddings [batch_size, sequence_length, embedding_dim].</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_Exp_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Exp*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Exp_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Exp(AiDotNet.Autodiff.ComputationNode{`0})">
  Exp(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L548"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the exponential function (e^x) for a computation node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Exp(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the exponential result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Exp_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method computes e raised to each element and records the operation.
The backward function uses: ∂(e^a)/∂a = e^a.
</p>
<p><b>For Beginners:</b> This computes e^x for each element and tracks gradients.
<p>For exponential (c = e^a):</p>
<ul>
<li>The forward pass computes e^x for each element</li>
<li>The backward pass has a special property: the derivative equals the output!</li>
<li>Gradient to 'a' is: incoming gradient * e^a (which is just the output)</li>
</ul>
<p>This is used in softmax, sigmoid, and many activation functions.</p>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_FakeQuantize_" data-uid="AiDotNet.Autodiff.TensorOperations`1.FakeQuantize*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_FakeQuantize_AiDotNet_Autodiff_ComputationNode__0__System_Int32__0__0_System_Boolean_" data-uid="AiDotNet.Autodiff.TensorOperations`1.FakeQuantize(AiDotNet.Autodiff.ComputationNode{`0},System.Int32,`0,`0,System.Boolean)">
  FakeQuantize(ComputationNode&lt;T&gt;, int, T?, T?, bool)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L11406"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs fake quantization with Straight-Through Estimator (STE) for differentiable quantization.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; FakeQuantize(ComputationNode&lt;T&gt; input, int numBits = 8, T? scale = default, T? zeroPoint = default, bool symmetric = true)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input tensor to quantize.</p>
</dd>
    <dt><code>numBits</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Number of quantization bits (default: 8).</p>
</dd>
    <dt><code>scale</code> <span class="xref">T</span></dt>
    <dd><p>Scale factor (if null, computed from input range).</p>
</dd>
    <dt><code>zeroPoint</code> <span class="xref">T</span></dt>
    <dd><p>Zero point for asymmetric quantization (default: 0).</p>
</dd>
    <dt><code>symmetric</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Whether to use symmetric quantization (default: true).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Fake-quantized tensor (quantized forward, STE backward).</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_FakeQuantize_AiDotNet_Autodiff_ComputationNode__0__System_Int32__0__0_System_Boolean__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Forward: output = round(input / scale) * scale (clipped to valid range)
Backward: gradient passes through unchanged (Straight-Through Estimator)
</p>
<p><b>For Beginners:</b> This simulates quantization during training while allowing
gradients to flow back for optimization. The forward pass applies real quantization,
but the backward pass pretends it didn't happen - this trick (STE) lets us train
models that will be quantized for deployment.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_GELU_" data-uid="AiDotNet.Autodiff.TensorOperations`1.GELU*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_GELU_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.GELU(AiDotNet.Autodiff.ComputationNode{`0})">
  GELU(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1726"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Gaussian Error Linear Unit (GELU) activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; GELU(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with GELU applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_GELU_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
GELU(x) = x * Φ(x) where Φ is the standard Gaussian cumulative distribution function.
Approximation: 0.5 * x * (1 + tanh(√(2/π) * (x + 0.044715 * x³)))
</p>
<p>
GELU is widely used in transformers (BERT, GPT) and modern architectures.
</p>
<p><b>Gradient:</b> d(GELU)/dx = Φ(x) + x * φ(x) where φ is the Gaussian PDF.</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_GRUCell_" data-uid="AiDotNet.Autodiff.TensorOperations`1.GRUCell*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_GRUCell_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.GRUCell(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  GRUCell(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L7662"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>GRU cell forward pass.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; GRUCell(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; hiddenState, ComputationNode&lt;T&gt; weightIH, ComputationNode&lt;T&gt; weightHH, ComputationNode&lt;T&gt; bias)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input tensor [batch, input_dim].</p>
</dd>
    <dt><code>hiddenState</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Previous hidden state [batch, hidden_dim].</p>
</dd>
    <dt><code>weightIH</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input-to-hidden weights [input_dim, 3*hidden_dim].</p>
</dd>
    <dt><code>weightHH</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Hidden-to-hidden weights [hidden_dim, 3*hidden_dim].</p>
</dd>
    <dt><code>bias</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Bias terms [3*hidden_dim].</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>New hidden state.</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_Gaussian_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Gaussian*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Gaussian_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Gaussian(AiDotNet.Autodiff.ComputationNode{`0})">
  Gaussian(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L2466"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Gaussian activation function element-wise: f(x) = exp(-x²).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Gaussian(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with Gaussian applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Gaussian_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Gaussian is defined as: f(x) = exp(-x²)
The gradient is: -2x * exp(-x²)
</p>
<p><b>For Beginners:</b> Gaussian creates a bell-shaped response curve that is
maximum at zero and approaches zero for large inputs in either direction.
Useful for RBF networks and pattern recognition.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_GraphConv_" data-uid="AiDotNet.Autodiff.TensorOperations`1.GraphConv*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_GraphConv_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.GraphConv(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  GraphConv(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L6981"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs graph convolution operation for graph neural networks.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; GraphConv(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; adjacency, ComputationNode&lt;T&gt; weights, ComputationNode&lt;T&gt;? bias = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input node features of shape [batch, numNodes, inputFeatures]</p>
</dd>
    <dt><code>adjacency</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Adjacency matrix of shape [batch, numNodes, numNodes]</p>
</dd>
    <dt><code>weights</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Weight matrix of shape [inputFeatures, outputFeatures]</p>
</dd>
    <dt><code>bias</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional bias vector of shape [outputFeatures]</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Output node features of shape [batch, numNodes, outputFeatures]</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_GraphConv_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This operation implements graph convolution: output = adjacency @ (input @ weights) + bias.
It aggregates features from neighboring nodes according to the graph structure defined by the adjacency matrix.
</p>
<p>
Forward pass:
1. Transform node features: X' = X @ W
2. Aggregate via graph structure: output = A @ X'
3. Add bias: output = output + b
</p>
<p>
Backward pass gradients:
- ∂L/∂X = A^T @ (∂L/∂out) @ W^T
- ∂L/∂W = X^T @ A^T @ (∂L/∂out)
- ∂L/∂b = sum(∂L/∂out) across batch and nodes
- ∂L/∂A = (∂L/∂out) @ (X @ W)^T
</p>
<p><b>For Beginners:</b> This operation helps neural networks learn from graph-structured data.
<p>Think of it like spreading information through a social network:</p>
<ul>
<li>Each person (node) has certain features</li>
<li>The adjacency matrix shows who is connected to whom</li>
<li>This operation lets each person's features be influenced by their connections</li>
<li>The weights control how features are transformed during this process</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_GridSample_" data-uid="AiDotNet.Autodiff.TensorOperations`1.GridSample*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_GridSample_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.GridSample(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  GridSample(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L6756"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Samples input using bilinear interpolation at grid locations for spatial transformer networks.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; GridSample(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; grid)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input tensor of shape [batch, height, width, channels]</p>
</dd>
    <dt><code>grid</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Sampling grid of shape [batch, out_height, out_width, 2] with normalized coordinates in [-1, 1]</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Sampled output of shape [batch, out_height, out_width, channels]</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_GridSample_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This operation performs differentiable bilinear sampling from the input tensor
using coordinates specified in the grid. Grid coordinates are in normalized [-1, 1] space
where (-1, -1) is top-left and (1, 1) is bottom-right.
</p>
<p>
Forward pass:
1. Convert normalized grid coordinates to input pixel coordinates
2. For each sampling point, find the 4 nearest pixels
3. Compute bilinear interpolation weights
4. Interpolate: out = w00*v00 + w01*v01 + w10*v10 + w11*v11
</p>
<p>
Backward pass:
- ∂L/∂input: Distribute gradients back to the 4 nearest pixels using same weights
- ∂L/∂grid: Compute how grid coordinates affect the sampling result
</p>
<p><b>For Beginners:</b> This samples from an image using smooth interpolation.
Instead of reading exact pixels, it can sample from positions between pixels
by blending nearby pixel values. This enables smooth transformations like rotation.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_GroupNorm_" data-uid="AiDotNet.Autodiff.TensorOperations`1.GroupNorm*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_GroupNorm_AiDotNet_Autodiff_ComputationNode__0__System_Int32_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.GroupNorm(AiDotNet.Autodiff.ComputationNode{`0},System.Int32,AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  GroupNorm(ComputationNode&lt;T&gt;, int, ComputationNode&lt;T&gt;?, ComputationNode&lt;T&gt;?, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L4035"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies group normalization to a computation node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; GroupNorm(ComputationNode&lt;T&gt; a, int numGroups, ComputationNode&lt;T&gt;? gamma = null, ComputationNode&lt;T&gt;? beta = null, double epsilon = 1E-05)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node with shape [batch, channels, ...] where ... can be spatial dimensions.</p>
</dd>
    <dt><code>numGroups</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of groups to divide channels into.</p>
</dd>
    <dt><code>gamma</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional scale parameter per channel. If null, uses ones.</p>
</dd>
    <dt><code>beta</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional shift parameter per channel. If null, uses zeros.</p>
</dd>
    <dt><code>epsilon</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Small constant for numerical stability. Default is 1e-5.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the group normalized result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_GroupNorm_AiDotNet_Autodiff_ComputationNode__0__System_Int32_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Group normalization divides channels into groups and normalizes within each group.
Unlike batch normalization, it doesn't depend on batch size, making it suitable
for small batch sizes or generative models.
</p>
<p><b>For Beginners:</b> GroupNorm is an alternative to BatchNorm that works better
when batch sizes are small.
<p>For group normalization:</p>
<ul>
<li>Divides channels into groups (e.g., 32 groups for 256 channels = 8 channels per group)</li>
<li>Normalizes each group independently: (x - mean) / sqrt(variance + epsilon)</li>
<li>Scales and shifts per channel: result * gamma + beta</li>
<li>Works the same during training and inference (no batch dependency)</li>
</ul>
<p>Key advantages:</p>
<ul>
<li>Works with batch size of 1 (unlike BatchNorm)</li>
<li>More stable for generative models (VAEs, GANs, diffusion models)</li>
<li>Used in modern architectures like Stable Diffusion VAE</li>
</ul>
<p>Typical usage:</p>
<ul>
<li>numGroups=32 for 256+ channels</li>
<li>numGroups=16 for 128 channels</li>
<li>numGroups=8 for 64 channels</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_GumbelSoftmax_" data-uid="AiDotNet.Autodiff.TensorOperations`1.GumbelSoftmax*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_GumbelSoftmax_AiDotNet_Autodiff_ComputationNode__0__System_Double_System_Boolean_" data-uid="AiDotNet.Autodiff.TensorOperations`1.GumbelSoftmax(AiDotNet.Autodiff.ComputationNode{`0},System.Double,System.Boolean)">
  GumbelSoftmax(ComputationNode&lt;T&gt;, double, bool)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L8812"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies Gumbel-Softmax for differentiable discrete sampling approximation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; GumbelSoftmax(ComputationNode&lt;T&gt; logits, double temperature = 1, bool hard = false)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>logits</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input logits.</p>
</dd>
    <dt><code>temperature</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Temperature parameter controlling softness (default 1.0).</p>
</dd>
    <dt><code>hard</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Whether to use straight-through estimator for hard samples.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node containing the soft/hard samples.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_GumbelSoftmax_AiDotNet_Autodiff_ComputationNode__0__System_Double_System_Boolean__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Gumbel-Softmax provides a differentiable approximation to categorical sampling.
As temperature approaches 0, outputs approach one-hot categorical samples.
When hard=true, uses straight-through estimator for discrete outputs with gradient pass-through.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_HardSigmoid_" data-uid="AiDotNet.Autodiff.TensorOperations`1.HardSigmoid*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_HardSigmoid_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.HardSigmoid(AiDotNet.Autodiff.ComputationNode{`0})">
  HardSigmoid(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L2078"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Hard Sigmoid activation function element-wise: f(x) = clip((x + 1) / 2, 0, 1).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; HardSigmoid(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with HardSigmoid applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_HardSigmoid_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
HardSigmoid is a piecewise linear approximation of sigmoid that is computationally efficient.
The gradient is 0.5 when -1 &lt; x &lt; 1, and 0 otherwise.
</p>
<p><b>For Beginners:</b> HardSigmoid uses straight lines instead of curves,
making it faster to compute while still mapping inputs to the [0, 1] range.
It's commonly used in mobile and embedded neural networks.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_HardTanh_" data-uid="AiDotNet.Autodiff.TensorOperations`1.HardTanh*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_HardTanh_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.HardTanh(AiDotNet.Autodiff.ComputationNode{`0})">
  HardTanh(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L2148"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Hard Tanh activation function element-wise: f(x) = clip(x, -1, 1).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; HardTanh(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with HardTanh applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_HardTanh_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
HardTanh is a piecewise linear approximation of tanh that is computationally efficient.
The gradient is 1 when -1 &lt; x &lt; 1, and 0 otherwise.
</p>
<p><b>For Beginners:</b> HardTanh clips values to the range [-1, 1], passing
through values in the middle range unchanged. It's faster than regular tanh
and useful when you need bounded outputs.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_HierarchicalSoftmax_" data-uid="AiDotNet.Autodiff.TensorOperations`1.HierarchicalSoftmax*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_HierarchicalSoftmax_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.HierarchicalSoftmax(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Int32)">
  HierarchicalSoftmax(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L10820"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Hierarchical Softmax activation function for efficient large-vocabulary classification.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; HierarchicalSoftmax(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; nodeWeights, int numClasses)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node (2D: batch × inputDim).</p>
</dd>
    <dt><code>nodeWeights</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The tree node weights (2D: treeDepth × inputDim).</p>
</dd>
    <dt><code>numClasses</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Number of output classes.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with HierarchicalSoftmax applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_HierarchicalSoftmax_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Hierarchical Softmax organizes classes in a binary tree structure.
Each node makes a binary decision using sigmoid, and the final probability
is the product of probabilities along the path to each class.
</p>
<p>
Computational complexity is O(log N) instead of O(N) for standard softmax.
</p>
<p><b>Gradient:</b> Flows through sigmoid derivatives at each tree node.</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_HyperbolicLinear_" data-uid="AiDotNet.Autodiff.TensorOperations`1.HyperbolicLinear*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_HyperbolicLinear_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.HyperbolicLinear(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  HyperbolicLinear(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;?, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L12770"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Hyperbolic linear transformation in the Poincare ball model.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; HyperbolicLinear(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; weights, ComputationNode&lt;T&gt;? biases = null, double curvature = -1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input tensor [batchSize, inputFeatures].</p>
</dd>
    <dt><code>weights</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Weight matrix in tangent space [outputFeatures, inputFeatures].</p>
</dd>
    <dt><code>biases</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Bias points on Poincare ball [outputFeatures, inputFeatures].</p>
</dd>
    <dt><code>curvature</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Negative curvature of hyperbolic space (default -1).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Output tensor [batchSize, outputFeatures] with Poincare distances.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_HyperbolicLinear_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>Performs hyperbolic linear transformation:</p>
<ol>
<li>Project input to Poincare ball</li>
<li>For each output: exp_origin(weight) → Mobius add with input → Mobius add with bias → distance from origin</li>
</ol>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_ISRU_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ISRU*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_ISRU_AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ISRU(AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  ISRU(ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L9555"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Inverse Square Root Unit (ISRU) activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; ISRU(ComputationNode&lt;T&gt; a, double alpha = 1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>alpha</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The scaling parameter (default 1.0).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with ISRU applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_ISRU_AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
ISRU(x) = x / sqrt(1 + alpha * x²)
A smooth, bounded activation function that ranges from -1/sqrt(alpha) to 1/sqrt(alpha).
</p>
<p><b>Gradient:</b> d(ISRU)/dx = (1 + alpha * x²)^(-3/2)</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_LSTMCell_" data-uid="AiDotNet.Autodiff.TensorOperations`1.LSTMCell*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_LSTMCell_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.LSTMCell(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  LSTMCell(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L7602"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>LSTM cell forward pass.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static (ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;) LSTMCell(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; hiddenState, ComputationNode&lt;T&gt; cellState, ComputationNode&lt;T&gt; weightIH, ComputationNode&lt;T&gt; weightHH, ComputationNode&lt;T&gt; bias)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input tensor [batch, input_dim].</p>
</dd>
    <dt><code>hiddenState</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Previous hidden state [batch, hidden_dim].</p>
</dd>
    <dt><code>cellState</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Previous cell state [batch, hidden_dim].</p>
</dd>
    <dt><code>weightIH</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input-to-hidden weights [input_dim, 4*hidden_dim].</p>
</dd>
    <dt><code>weightHH</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Hidden-to-hidden weights [hidden_dim, 4*hidden_dim].</p>
</dd>
    <dt><code>bias</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Bias terms [4*hidden_dim].</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt>(<a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;, <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;)</dt>
    <dd><p>Tuple of (new hidden state, new cell state).</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_LayerNorm_" data-uid="AiDotNet.Autodiff.TensorOperations`1.LayerNorm*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_LayerNorm_AiDotNet_Autodiff_ComputationNode__0__System_Int32___AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.LayerNorm(AiDotNet.Autodiff.ComputationNode{`0},System.Int32[],AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  LayerNorm(ComputationNode&lt;T&gt;, int[], ComputationNode&lt;T&gt;?, ComputationNode&lt;T&gt;?, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L3109"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies layer normalization to a computation node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; LayerNorm(ComputationNode&lt;T&gt; a, int[] normalizedShape, ComputationNode&lt;T&gt;? gamma = null, ComputationNode&lt;T&gt;? beta = null, double epsilon = 1E-05)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node.</p>
</dd>
    <dt><code>normalizedShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The shape over which to normalize (typically the feature dimensions).</p>
</dd>
    <dt><code>gamma</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional scale parameter (learnable). If null, uses ones.</p>
</dd>
    <dt><code>beta</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional shift parameter (learnable). If null, uses zeros.</p>
</dd>
    <dt><code>epsilon</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Small constant for numerical stability. Default is 1e-5.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the layer normalized result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_LayerNorm_AiDotNet_Autodiff_ComputationNode__0__System_Int32___AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Layer normalization normalizes inputs across the feature dimension for each sample independently.
Formula: y = gamma * (x - mean) / sqrt(variance + epsilon) + beta
Unlike batch normalization, this doesn't depend on batch statistics.
</p>
<p><b>For Beginners:</b> LayerNorm standardizes features for each sample independently.
<p>For layer normalization:</p>
<ul>
<li>Computes mean and variance for each sample's features</li>
<li>Normalizes: (x - mean) / sqrt(variance)</li>
<li>Scales and shifts: result * gamma + beta</li>
<li>Works the same during training and inference (no batch dependency)</li>
</ul>
<p>Used in:</p>
<ul>
<li>Transformers (critical component)</li>
<li>RNNs (stabilizes training)</li>
<li>Any architecture needing sample-independent normalization</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_LeakyReLU_" data-uid="AiDotNet.Autodiff.TensorOperations`1.LeakyReLU*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_LeakyReLU_AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.LeakyReLU(AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  LeakyReLU(ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1672"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Leaky Rectified Linear Unit (LeakyReLU) activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; LeakyReLU(ComputationNode&lt;T&gt; a, double alpha = 0.01)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>alpha</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The slope for negative values. Default is 0.01.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with LeakyReLU applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_LeakyReLU_AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
LeakyReLU(x) = x if x &gt; 0, alpha * x otherwise.
Unlike ReLU, LeakyReLU allows a small gradient for negative inputs, preventing dying neurons.
</p>
<p><b>Gradient:</b> d(LeakyReLU)/dx = 1 if x &gt; 0, alpha otherwise.</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_LeakyStateUpdate_" data-uid="AiDotNet.Autodiff.TensorOperations`1.LeakyStateUpdate*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_LeakyStateUpdate_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.LeakyStateUpdate(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  LeakyStateUpdate(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L9175"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Leaky state update for reservoir/echo state networks.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; LeakyStateUpdate(ComputationNode&lt;T&gt; prevState, ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; weights, double leakingRate = 1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>prevState</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Previous hidden state.</p>
</dd>
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Current input.</p>
</dd>
    <dt><code>weights</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Reservoir weight matrix (can be frozen).</p>
</dd>
    <dt><code>leakingRate</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Leaking rate (default 1.0 for full update).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>New hidden state.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_LeakyStateUpdate_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Computes: new_state = (1 - leakingRate) * prevState + leakingRate * tanh(weights @ prevState + input)
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_LiSHT_" data-uid="AiDotNet.Autodiff.TensorOperations`1.LiSHT*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_LiSHT_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.LiSHT(AiDotNet.Autodiff.ComputationNode{`0})">
  LiSHT(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L2343"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the LiSHT (Linearly Scaled Hyperbolic Tangent) activation function element-wise.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; LiSHT(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with LiSHT applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_LiSHT_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
LiSHT is defined as: f(x) = x * tanh(x)
The gradient is: tanh(x) + x * (1 - tanh²(x))
</p>
<p><b>For Beginners:</b> LiSHT combines the input with its tanh, creating a smooth
activation that preserves sign and helps prevent vanishing gradients.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_LocallyConnectedConv2D_" data-uid="AiDotNet.Autodiff.TensorOperations`1.LocallyConnectedConv2D*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_LocallyConnectedConv2D_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.LocallyConnectedConv2D(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Int32[])">
  LocallyConnectedConv2D(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;?, int[]?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L5891"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs locally connected 2D convolution where weights are NOT shared across spatial locations.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; LocallyConnectedConv2D(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; weights, ComputationNode&lt;T&gt;? bias = null, int[]? stride = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input tensor of shape [batch, in_channels, height, width]</p>
</dd>
    <dt><code>weights</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Weight tensor of shape [out_h, out_w, out_channels, in_channels, kernel_h, kernel_w]</p>
</dd>
    <dt><code>bias</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional bias tensor of shape [out_channels]</p>
</dd>
    <dt><code>stride</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>Stride for the convolution, defaults to [1, 1]</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Output tensor of shape [batch, out_channels, out_h, out_w]</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_LocallyConnectedConv2D_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Locally connected convolution is like regular convolution but uses different weights for each
spatial output location. This increases parameters but allows position-specific feature detection.
</p>
<p>
Unlike Conv2D where weights are shared across all positions, LocallyConnectedConv2D uses
unique weights for each (h,w) output position. This is useful when different regions have
fundamentally different characteristics (e.g., face recognition where eyes/nose/mouth are
at specific locations).
</p>
<p>
Forward pass applies position-specific filters at each output location.
Backward pass computes gradients with respect to input, position-specific weights, and bias.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Log_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Log*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Log_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Log(AiDotNet.Autodiff.ComputationNode{`0})">
  Log(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L597"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the natural logarithm for a computation node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Log(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the logarithm result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Log_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method computes the natural logarithm of each element and records the operation.
The backward function uses: ∂(log(a))/∂a = 1/a.
</p>
<p><b>For Beginners:</b> This computes the natural log and tracks gradients.
<p>For logarithm (c = log(a)):</p>
<ul>
<li>The forward pass computes log for each element</li>
<li>The backward pass uses: gradient to 'a' is incoming gradient * (1/a)</li>
</ul>
<p>Logarithms are used in loss functions like cross-entropy.</p>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_LogSoftmax_" data-uid="AiDotNet.Autodiff.TensorOperations`1.LogSoftmax*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_LogSoftmax_AiDotNet_Autodiff_ComputationNode__0__System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.LogSoftmax(AiDotNet.Autodiff.ComputationNode{`0},System.Int32)">
  LogSoftmax(ComputationNode&lt;T&gt;, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L9679"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Log-Softmax function for numerically stable cross-entropy loss computation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; LogSoftmax(ComputationNode&lt;T&gt; a, int axis = -1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>axis</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The axis along which to compute log-softmax (default -1, last axis).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with Log-Softmax applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_LogSoftmax_AiDotNet_Autodiff_ComputationNode__0__System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
LogSoftmax(x) = log(softmax(x)) = x - log(sum(exp(x)))
More numerically stable than computing log(softmax(x)) separately.
</p>
<p><b>Gradient:</b> d(LogSoftmax)/dx_i = 1 - softmax(x)_i for the target class.</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_LogSoftmin_" data-uid="AiDotNet.Autodiff.TensorOperations`1.LogSoftmin*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_LogSoftmin_AiDotNet_Autodiff_ComputationNode__0__System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.LogSoftmin(AiDotNet.Autodiff.ComputationNode{`0},System.Int32)">
  LogSoftmin(ComputationNode&lt;T&gt;, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L9925"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Log-Softmin function for numerically stable computation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; LogSoftmin(ComputationNode&lt;T&gt; a, int axis = -1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>axis</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The axis along which to compute log-softmin (default -1, last axis).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with Log-Softmin applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_LogSoftmin_AiDotNet_Autodiff_ComputationNode__0__System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
LogSoftmin(x) = log(softmin(x)) = -x - log(sum(exp(-x)))
Combines log and softmin for numerical stability.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_MatrixMultiply_" data-uid="AiDotNet.Autodiff.TensorOperations`1.MatrixMultiply*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_MatrixMultiply_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.MatrixMultiply(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  MatrixMultiply(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L985"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs matrix multiplication on two computation nodes.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; MatrixMultiply(ComputationNode&lt;T&gt; a, ComputationNode&lt;T&gt; b)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The left matrix (must be 2D).</p>
</dd>
    <dt><code>b</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The right matrix (must be 2D).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node representing the matrix product.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_MatrixMultiply_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Computes C = A·B where A has shape [m, n] and B has shape [n, p], resulting in C with shape [m, p].
</p>
<p><b>Gradient computation:</b>
- ∂(A·B)/∂A = gradOut·B^T
- ∂(A·B)/∂B = A^T·gradOut
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_MatrixVectorMultiply_" data-uid="AiDotNet.Autodiff.TensorOperations`1.MatrixVectorMultiply*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_MatrixVectorMultiply_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.MatrixVectorMultiply(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  MatrixVectorMultiply(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1031"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs a matrix-vector multiplication (2D x 1D) by reshaping the vector into a column matrix.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; MatrixVectorMultiply(ComputationNode&lt;T&gt; matrix, ComputationNode&lt;T&gt; vector)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>matrix</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The left matrix (must be 2D).</p>
</dd>
    <dt><code>vector</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The right vector (must be 1D).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node representing the vector result.</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_MaxPool2D_" data-uid="AiDotNet.Autodiff.TensorOperations`1.MaxPool2D*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_MaxPool2D_AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.MaxPool2D(AiDotNet.Autodiff.ComputationNode{`0},System.Int32[],System.Int32[])">
  MaxPool2D(ComputationNode&lt;T&gt;, int[], int[]?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L2956"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs 2D max pooling on a 4D tensor (batch, channels, height, width).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; MaxPool2D(ComputationNode&lt;T&gt; a, int[] poolSize, int[]? strides = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node with shape [batch, channels, height, width].</p>
</dd>
    <dt><code>poolSize</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The size of the pooling window [poolH, poolW].</p>
</dd>
    <dt><code>strides</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The stride for the pooling operation [strideH, strideW]. If null, uses poolSize.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the max pooled result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_MaxPool2D_AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs max pooling over 2D spatial dimensions.
During forward pass, it tracks which element was the max for routing gradients during backward pass.
</p>
<p><b>For Beginners:</b> MaxPool downsamples by taking the maximum value in each window.
<p>For max pooling:</p>
<ul>
<li>The forward pass slides a window and takes the max value in each position</li>
<li>This reduces spatial dimensions (downsampling)</li>
<li>The backward pass routes gradients only to the positions that were max</li>
<li>Other positions get zero gradient (they didn't contribute to the output)</li>
</ul>
<p>Used in:</p>
<ul>
<li>CNNs for translation invariance</li>
<li>Reducing spatial resolution</li>
<li>Building hierarchical features</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_MaxPool3D_" data-uid="AiDotNet.Autodiff.TensorOperations`1.MaxPool3D*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_MaxPool3D_AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.MaxPool3D(AiDotNet.Autodiff.ComputationNode{`0},System.Int32[],System.Int32[])">
  MaxPool3D(ComputationNode&lt;T&gt;, int[], int[]?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L4763"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs 3D max pooling on a 5D tensor (batch, channels, depth, height, width).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; MaxPool3D(ComputationNode&lt;T&gt; input, int[] poolSize, int[]? strides = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node with shape [batch, channels, depth, height, width].</p>
</dd>
    <dt><code>poolSize</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The size of the pooling window [poolD, poolH, poolW].</p>
</dd>
    <dt><code>strides</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The stride for the pooling operation [strideD, strideH, strideW]. If null, uses poolSize.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the max pooled result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_MaxPool3D_AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs max pooling over 3D spatial dimensions (depth, height, width).
The backward function routes gradients only to the maximum values in each pooling window.
</p>
<p><b>For Beginners:</b> MaxPool3D downsamples volumetric data by taking the maximum value in each window.
<p>For max pooling:</p>
<ul>
<li>The forward pass slides a 3D window and takes the maximum</li>
<li>This reduces the spatial dimensions while preserving the strongest activations</li>
<li>The backward pass routes gradients only to where the max came from</li>
<li>Non-max elements get zero gradient</li>
</ul>
<p>Used in:</p>
<ul>
<li>Voxel-based 3D CNNs for shape classification</li>
<li>Medical image analysis (CT/MRI)</li>
<li>Video processing</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Maxout_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Maxout*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Maxout_AiDotNet_Autodiff_ComputationNode__0__System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Maxout(AiDotNet.Autodiff.ComputationNode{`0},System.Int32)">
  Maxout(ComputationNode&lt;T&gt;, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L10111"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Maxout activation function which takes maximum over groups of inputs.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Maxout(ComputationNode&lt;T&gt; a, int numPieces = 2)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node (2D: batch × features).</p>
</dd>
    <dt><code>numPieces</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Number of inputs per group (default 2).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with Maxout applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Maxout_AiDotNet_Autodiff_ComputationNode__0__System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Maxout groups consecutive features and outputs the maximum from each group.
Input features must be divisible by numPieces.
Output shape: [batch, features / numPieces].
</p>
<p><b>Gradient:</b> Flows only to the maximum element in each group (sparse gradient).</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Mean_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Mean*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Mean_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Mean(AiDotNet.Autodiff.ComputationNode{`0})">
  Mean(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1307"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the mean of elements in a computation node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Mean(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The computation node to compute mean of.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node representing the mean (scalar).</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Mean_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Computes the average of all elements in the tensor.
</p>
<p><b>Gradient computation:</b>
- ∂(mean(A))/∂A = gradOut / count
- Each element gets an equal share of the gradient, divided by the total count.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Mish_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Mish*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Mish_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Mish(AiDotNet.Autodiff.ComputationNode{`0})">
  Mish(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1863"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Mish activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Mish(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with Mish applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Mish_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))
Mish is a smooth, self-regularizing activation function.
</p>
<p><b>Gradient:</b> d(Mish)/dx = sech²(softplus(x)) * sigmoid(x) + tanh(softplus(x))</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_MobiusAdd_" data-uid="AiDotNet.Autodiff.TensorOperations`1.MobiusAdd*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_MobiusAdd_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.MobiusAdd(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  MobiusAdd(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L12175"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Mobius addition in the Poincare ball model.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; MobiusAdd(ComputationNode&lt;T&gt; x, ComputationNode&lt;T&gt; y, double curvature = -1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>x</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>First point tensor [batchSize, dim] or [dim].</p>
</dd>
    <dt><code>y</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Second point tensor with same shape as x.</p>
</dd>
    <dt><code>curvature</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Negative curvature of hyperbolic space (default -1).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Result of Mobius addition x ⊕ y.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_MobiusAdd_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>Mobius addition is the hyperbolic analog of vector addition:
x ⊕ y = ((1 + 2c⟨x,y⟩ + c||y||²)x + (1 - c||x||²)y) / (1 + 2c⟨x,y⟩ + c²||x||²||y||²)</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_MultiHeadAttention_" data-uid="AiDotNet.Autodiff.TensorOperations`1.MultiHeadAttention*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_MultiHeadAttention_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.MultiHeadAttention(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Int32,AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  MultiHeadAttention(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, int, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L7568"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies multi-head attention mechanism.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; MultiHeadAttention(ComputationNode&lt;T&gt; query, ComputationNode&lt;T&gt; key, ComputationNode&lt;T&gt; value, int numHeads, ComputationNode&lt;T&gt; wQ, ComputationNode&lt;T&gt; wK, ComputationNode&lt;T&gt; wV, ComputationNode&lt;T&gt; wO)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>query</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Query tensor.</p>
</dd>
    <dt><code>key</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Key tensor.</p>
</dd>
    <dt><code>value</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Value tensor.</p>
</dd>
    <dt><code>numHeads</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Number of attention heads.</p>
</dd>
    <dt><code>wQ</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Query projection weights.</p>
</dd>
    <dt><code>wK</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Key projection weights.</p>
</dd>
    <dt><code>wV</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Value projection weights.</p>
</dd>
    <dt><code>wO</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Output projection weights.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Multi-head attention output.</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_Negate_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Negate*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Negate_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Negate(AiDotNet.Autodiff.ComputationNode{`0})">
  Negate(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L870"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Negates a computation node (computes -a).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Negate(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the negated result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Negate_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method negates each element and records the operation.
The backward function simply negates the incoming gradient.
</p>
<p><b>For Beginners:</b> This flips the sign of each element.
<p>For negation (c = -a):</p>
<ul>
<li>The forward pass flips signs (positive becomes negative, vice versa)</li>
<li>The backward pass also flips the gradient sign</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Norm_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Norm*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Norm_AiDotNet_Autodiff_ComputationNode__0__System_Int32_System_Boolean_System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Norm(AiDotNet.Autodiff.ComputationNode{`0},System.Int32,System.Boolean,System.Double)">
  Norm(ComputationNode&lt;T&gt;, int, bool, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L7961"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the L2 norm along a specified axis.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Norm(ComputationNode&lt;T&gt; a, int axis = -1, bool keepDims = false, double epsilon = 1E-12)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node.</p>
</dd>
    <dt><code>axis</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The axis along which to compute the norm. Default is -1 (last axis).</p>
</dd>
    <dt><code>keepDims</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Whether to keep the reduced dimensions. Default is false.</p>
</dd>
    <dt><code>epsilon</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Small value for numerical stability. Default is 1e-12.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the norm along the specified axis.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Norm_AiDotNet_Autodiff_ComputationNode__0__System_Int32_System_Boolean_System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method computes the L2 (Euclidean) norm: sqrt(sum(x²)) along the specified axis.
The gradient is computed as: ∂||x||/∂x = x / ||x||.
</p>
<p><b>For Beginners:</b> The norm measures the "length" of vectors.
<p>For example, with axis=-1:</p>
<ul>
<li>Input shape: [batch, features]</li>
<li>Output shape: [batch] (or [batch, 1] with keepDims=True)</li>
<li>Each output value is sqrt(sum of squares along that row)</li>
</ul>
<p>This is commonly used in capsule networks to compute capsule lengths,
and in normalization operations.</p>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_OctonionMatMul_" data-uid="AiDotNet.Autodiff.TensorOperations`1.OctonionMatMul*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_OctonionMatMul_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.OctonionMatMul(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  OctonionMatMul(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L11669"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs octonion matrix multiplication for OctonionLinearLayer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; OctonionMatMul(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; weights, ComputationNode&lt;T&gt;? biases = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input tensor with shape [batch, inputFeatures * 8] where each group of 8 represents an octonion.</p>
</dd>
    <dt><code>weights</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Weight tensor with shape [outputFeatures, inputFeatures, 8] where last dimension is octonion components.</p>
</dd>
    <dt><code>biases</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional bias tensor with shape [outputFeatures, 8].</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Output tensor with shape [batch, outputFeatures * 8].</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_OctonionMatMul_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Octonions are 8-dimensional numbers that generalize quaternions. They are non-associative
but can capture more complex relationships in data. This operation performs:
output[b, o] = sum_i(input[b, i] * weights[o, i]) + biases[o]
where * is octonion multiplication.
</p>
<p><b>For Beginners:</b> This is like matrix multiplication but using 8-dimensional
octonion numbers instead of regular numbers. Each octonion has 8 components:
(scalar, e1, e2, e3, e4, e5, e6, e7).
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_PReLU_" data-uid="AiDotNet.Autodiff.TensorOperations`1.PReLU*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_PReLU_AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.PReLU(AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  PReLU(ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L9433"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Parametric Rectified Linear Unit (PReLU) activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; PReLU(ComputationNode&lt;T&gt; a, double alpha = 0.01)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>alpha</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The slope for negative values (default 0.01).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with PReLU applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_PReLU_AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
PReLU(x) = x if x &gt; 0, alpha * x otherwise.
Similar to LeakyReLU but alpha is typically learned during training.
</p>
<p><b>Gradient:</b> d(PReLU)/dx = 1 if x &gt; 0, alpha otherwise.</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Pad_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Pad*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Pad_AiDotNet_Autodiff_ComputationNode__0__System_Int32_0__0____0_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Pad(AiDotNet.Autodiff.ComputationNode{`0},System.Int32[0:,0:],`0)">
  Pad(ComputationNode&lt;T&gt;, int[,], T?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L2741"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Pads a tensor with a constant value along specified dimensions.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Pad(ComputationNode&lt;T&gt; a, int[,] padWidth, T? value = default)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node.</p>
</dd>
    <dt><code>padWidth</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[,]</dt>
    <dd><p>Padding width for each dimension as (before, after) pairs.</p>
</dd>
    <dt><code>value</code> <span class="xref">T</span></dt>
    <dd><p>The value to use for padding. Default is zero.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the padded result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Pad_AiDotNet_Autodiff_ComputationNode__0__System_Int32_0__0____0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method adds padding around the tensor.
The backward function simply crops the gradient back to the original size (gradients for padding are zero).
</p>
<p><b>For Beginners:</b> Pad adds extra elements around a tensor.
<p>For padding:</p>
<ul>
<li>The forward pass adds border elements with a constant value</li>
<li>The backward pass removes those border gradients (they don't affect the original tensor)</li>
<li>Think of it like adding margins to an image</li>
</ul>
<p>Used in:</p>
<ul>
<li>Convolutional layers (to maintain spatial dimensions)</li>
<li>Handling variable-length sequences</li>
<li>Data augmentation</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Pad_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Pad*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Pad_AiDotNet_Autodiff_ComputationNode__0__System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.Pad(AiDotNet.Autodiff.ComputationNode{`0},System.Int32[])">
  Pad(ComputationNode&lt;T&gt;, int[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L7211"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Pads a tensor with zeros along specified dimensions.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Pad(ComputationNode&lt;T&gt; a, int[] padding)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node to pad.</p>
</dd>
    <dt><code>padding</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>Array specifying padding amount for each dimension (applied symmetrically on both sides).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the padded tensor.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Pad_AiDotNet_Autodiff_ComputationNode__0__System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method pads the input tensor by adding zeros around each dimension.
The padding array specifies how many zeros to add on BOTH sides of each dimension.
For example, padding[1] = 2 means add 2 zeros on the left AND 2 zeros on the right of dimension 1.
</p>
<p>
The backward function for padding simply extracts the non-padded region from the output gradient,
since ∂(pad(x))/∂x is an extraction operation that removes the padded regions.
</p>
<p><b>For Beginners:</b> Padding adds a border of zeros around your data.
<p>For padding (output = pad(input, [p0, p1, ...])):</p>
<ul>
<li>The forward pass creates a larger tensor and copies input to the center</li>
<li>Padding p on dimension d means: add p zeros on left, p zeros on right</li>
<li>The backward pass extracts the center region from the gradient (removes the padding)</li>
</ul>
<p>This is commonly used in convolutional neural networks to preserve spatial dimensions.</p>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Permute_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Permute*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Permute_AiDotNet_Autodiff_ComputationNode__0__System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.Permute(AiDotNet.Autodiff.ComputationNode{`0},System.Int32[])">
  Permute(ComputationNode&lt;T&gt;, params int[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1411"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Permutes the dimensions of a computation node (general transpose).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Permute(ComputationNode&lt;T&gt; a, params int[] axes)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The computation node to permute.</p>
</dd>
    <dt><code>axes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The new order of dimensions.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node with permuted dimensions.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Permute_AiDotNet_Autodiff_ComputationNode__0__System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Rearranges dimensions according to the axes array.
Equivalent to Transpose but for N dimensions.
</p>
<p><b>Gradient computation:</b>
- ∂(Permute(A))/∂A = Permute(gradOut, inverseAxes)
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_PixelShuffle_" data-uid="AiDotNet.Autodiff.TensorOperations`1.PixelShuffle*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_PixelShuffle_AiDotNet_Autodiff_ComputationNode__0__System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.PixelShuffle(AiDotNet.Autodiff.ComputationNode{`0},System.Int32)">
  PixelShuffle(ComputationNode&lt;T&gt;, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L5529"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs pixel shuffle (depth-to-space) operation for sub-pixel convolution.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; PixelShuffle(ComputationNode&lt;T&gt; a, int upscaleFactor)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node with shape [batch, channels, height, width].</p>
</dd>
    <dt><code>upscaleFactor</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The upscaling factor (r). Channels must be divisible by r².</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node with shape [batch, channels/(r²), height<em>r, width</em>r].</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_PoincareDistance_" data-uid="AiDotNet.Autodiff.TensorOperations`1.PoincareDistance*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_PoincareDistance_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.PoincareDistance(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  PoincareDistance(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L12622"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the Poincare ball distance between two points.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; PoincareDistance(ComputationNode&lt;T&gt; x, ComputationNode&lt;T&gt; y, double curvature = -1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>x</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>First point tensor [batchSize, dim] or [dim].</p>
</dd>
    <dt><code>y</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Second point tensor with same shape as x.</p>
</dd>
    <dt><code>curvature</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Negative curvature of hyperbolic space (default -1).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Distance tensor [batchSize] or scalar.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_PoincareDistance_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>The Poincare distance between points x and y is:
d(x, y) = (2/sqrt(c)) * arctanh(sqrt(c) || -x ⊕ y ||)</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_PoincareExpMap_" data-uid="AiDotNet.Autodiff.TensorOperations`1.PoincareExpMap*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_PoincareExpMap_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.PoincareExpMap(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  PoincareExpMap(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L12309"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Poincare ball exponential map from tangent space at a point.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; PoincareExpMap(ComputationNode&lt;T&gt; point, ComputationNode&lt;T&gt; tangent, double curvature = -1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>point</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Base point on the Poincare ball [batchSize, dim] or [dim].</p>
</dd>
    <dt><code>tangent</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Tangent vector at the point with same shape.</p>
</dd>
    <dt><code>curvature</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Negative curvature of hyperbolic space (default -1).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Point on manifold after following geodesic.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_PoincareExpMap_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>The exponential map takes a tangent vector at point p and returns the point
reached by following the geodesic in that direction:
exp_p(v) = p ⊕ (tanh(sqrt(c)||v||_p / 2) * v / (sqrt(c)||v||))
where ||v||_p = ||v|| * 2 / (1 - c||p||²) is the Poincare norm.</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_PoincareLogMap_" data-uid="AiDotNet.Autodiff.TensorOperations`1.PoincareLogMap*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_PoincareLogMap_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.PoincareLogMap(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  PoincareLogMap(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L12471"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Poincare ball logarithmic map to tangent space at a point.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; PoincareLogMap(ComputationNode&lt;T&gt; point, ComputationNode&lt;T&gt; target, double curvature = -1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>point</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Base point on the Poincare ball [batchSize, dim] or [dim].</p>
</dd>
    <dt><code>target</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Target point on the Poincare ball with same shape.</p>
</dd>
    <dt><code>curvature</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Negative curvature of hyperbolic space (default -1).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Tangent vector at point pointing towards target.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_PoincareLogMap_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>The logarithmic map is the inverse of the exponential map:
log_p(q) = (2 / (sqrt(c) * lambda_p)) * arctanh(sqrt(c) || -p ⊕ q ||) * (-p ⊕ q) / || -p ⊕ q ||</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_PoincareProject_" data-uid="AiDotNet.Autodiff.TensorOperations`1.PoincareProject*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_PoincareProject_AiDotNet_Autodiff_ComputationNode__0__System_Double_System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.PoincareProject(AiDotNet.Autodiff.ComputationNode{`0},System.Double,System.Double)">
  PoincareProject(ComputationNode&lt;T&gt;, double, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L12024"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Projects a point onto the Poincare ball to ensure it stays inside the unit ball.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; PoincareProject(ComputationNode&lt;T&gt; point, double curvature = -1, double epsilon = 1E-05)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>point</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input point tensor [batchSize, dim] or [dim].</p>
</dd>
    <dt><code>curvature</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Negative curvature of hyperbolic space (default -1).</p>
</dd>
    <dt><code>epsilon</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Small value for numerical stability.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Projected point on the Poincare ball.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_PoincareProject_AiDotNet_Autodiff_ComputationNode__0__System_Double_System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>Projects points that are outside or on the boundary of the Poincare ball
back inside by scaling to have norm slightly less than 1/sqrt(|c|).</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Power_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Power*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Power_AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Power(AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  Power(ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L488"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Raises a computation node to a power.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Power(ComputationNode&lt;T&gt; a, double exponent)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The base node.</p>
</dd>
    <dt><code>exponent</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The exponent value.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the power operation result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Power_AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method raises each element to a power and records the operation.
The backward function uses the power rule: ∂(a^n)/∂a = n * a^(n-1).
</p>
<p><b>For Beginners:</b> This raises a tensor to a power and tracks gradients.
<p>For power operation (c = a^n):</p>
<ul>
<li>The forward pass raises each element to the power</li>
<li>The backward pass uses the power rule from calculus</li>
<li>Gradient to 'a' is: incoming gradient * n * a^(n-1)</li>
</ul>
<p>Example:
If a=[2,3], n=2, c=[4,9]
If gradient to c is [1,1]:</p>
<ul>
<li>'a' receives [1<em>2</em>2^1, 1<em>2</em>3^1] = [4, 6]</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_RBFKernel_" data-uid="AiDotNet.Autodiff.TensorOperations`1.RBFKernel*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_RBFKernel_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.RBFKernel(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  RBFKernel(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L6444"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes Gaussian Radial Basis Function (RBF) kernel activations.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; RBFKernel(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; centers, ComputationNode&lt;T&gt; epsilons)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input tensor of shape [batch, inputSize]</p>
</dd>
    <dt><code>centers</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Center points tensor of shape [numCenters, inputSize]</p>
</dd>
    <dt><code>epsilons</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Width parameters tensor of shape [numCenters]</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Output tensor of shape [batch, numCenters] containing RBF activations</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_RBFKernel_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This operation implements the Gaussian RBF: f(r) = exp(-epsilon * r²)
where r is the Euclidean distance between input and center.
</p>
<p>
Forward pass: For each input and center pair, computes:
1. distance = sqrt(sum((input - center)²))
2. output = exp(-epsilon * distance²)
</p>
<p>
Backward pass gradients:
- ∂L/∂input = ∂L/∂output * (-2 * epsilon * distance) * (input - center) / distance
- ∂L/∂centers = -∂L/∂input (opposite direction)
- ∂L/∂epsilon = ∂L/∂output * (-distance²) * output
</p>
<p><b>For Beginners:</b> This operation creates "similarity scores" between inputs and centers.
Each RBF neuron responds strongly (value near 1) when input is close to its center,
and weakly (value near 0) when far away. The epsilon parameter controls how quickly
the response decreases with distance.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_RReLU_" data-uid="AiDotNet.Autodiff.TensorOperations`1.RReLU*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_RReLU_AiDotNet_Autodiff_ComputationNode__0__System_Double_System_Double_System_Boolean_System_Nullable_System_Int32__" data-uid="AiDotNet.Autodiff.TensorOperations`1.RReLU(AiDotNet.Autodiff.ComputationNode{`0},System.Double,System.Double,System.Boolean,System.Nullable{System.Int32})">
  RReLU(ComputationNode&lt;T&gt;, double, double, bool, int?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L10213"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Randomized Leaky ReLU (RReLU) activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; RReLU(ComputationNode&lt;T&gt; a, double lower = 0.125, double upper = 0.333, bool isTraining = false, int? seed = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>lower</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Lower bound for alpha (default 1/8).</p>
</dd>
    <dt><code>upper</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Upper bound for alpha (default 1/3).</p>
</dd>
    <dt><code>isTraining</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>If true, samples random alpha; if false, uses average (default false for JIT).</p>
</dd>
    <dt><code>seed</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>?</dt>
    <dd><p>Optional random seed for reproducibility.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with RReLU applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_RReLU_AiDotNet_Autodiff_ComputationNode__0__System_Double_System_Double_System_Boolean_System_Nullable_System_Int32___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
RReLU(x) = x if x &gt;= 0, alpha * x otherwise.
During training, alpha is sampled uniformly from [lower, upper].
During inference (JIT default), alpha = (lower + upper) / 2.
</p>
<p><b>Gradient:</b> 1 for x &gt;= 0, alpha for x &lt; 0.</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_ReLU_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ReLU*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_ReLU_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.ReLU(AiDotNet.Autodiff.ComputationNode{`0})">
  ReLU(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L817"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the ReLU (Rectified Linear Unit) activation for a computation node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; ReLU(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the ReLU result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_ReLU_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method computes ReLU (max(0, x)) and records the operation.
The backward function uses: ∂ReLU(a)/∂a = 1 if a &gt; 0, else 0.
</p>
<p><b>For Beginners:</b> ReLU is the most popular activation function in deep learning.
<p>For ReLU (c = max(0, a)):</p>
<ul>
<li>The forward pass keeps positive values, zeros out negative values</li>
<li>The backward pass: gradient flows through if input was positive, blocked if negative</li>
</ul>
<p>ReLU is popular because:</p>
<ul>
<li>Very fast to compute</li>
<li>Helps avoid vanishing gradients</li>
<li>Works well in practice for deep networks</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_ReduceLogVariance_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ReduceLogVariance*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_ReduceLogVariance_AiDotNet_Autodiff_ComputationNode__0__System_Int32_System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ReduceLogVariance(AiDotNet.Autodiff.ComputationNode{`0},System.Int32,System.Double)">
  ReduceLogVariance(ComputationNode&lt;T&gt;, int, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L6291"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the natural logarithm of variance along the specified axis.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; ReduceLogVariance(ComputationNode&lt;T&gt; input, int axis, double epsilon = 1E-08)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Input tensor of any shape</p>
</dd>
    <dt><code>axis</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The axis along which to compute variance (must be specified)</p>
</dd>
    <dt><code>epsilon</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Small constant for numerical stability (default: 1e-8)</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Tensor with reduced shape containing log-variance values</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_ReduceLogVariance_AiDotNet_Autodiff_ComputationNode__0__System_Int32_System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This operation computes log(variance + epsilon) along the specified axis. The output shape
has the specified axis dimension removed from the input shape.
</p>
<p>
Forward pass: log(variance + epsilon) where variance = mean((x - mean(x))^2)
</p>
<p>
Backward pass uses chain rule:
∂L/∂x_i = ∂L/∂log_var * (1/variance) * (2/N) * (x_i - mean)
where N is the size of the reduction axis.
</p>
<p><b>For Beginners:</b> This operation measures how spread out values are along an axis,
then takes the logarithm. Commonly used in variational autoencoders and uncertainty estimation.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_ReduceMax_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ReduceMax*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_ReduceMax_AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Boolean_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ReduceMax(AiDotNet.Autodiff.ComputationNode{`0},System.Int32[],System.Boolean)">
  ReduceMax(ComputationNode&lt;T&gt;, int[]?, bool)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L5056"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Reduces a tensor by computing the maximum value along specified axes.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; ReduceMax(ComputationNode&lt;T&gt; a, int[]? axes = null, bool keepDims = false)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>axes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The axes along which to compute the maximum. If null, reduces over all axes.</p>
</dd>
    <dt><code>keepDims</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Whether to keep the reduced dimensions with size 1.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node representing the result of the reduce max operation.</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_ReduceMean_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ReduceMean*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_ReduceMean_AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Boolean_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ReduceMean(AiDotNet.Autodiff.ComputationNode{`0},System.Int32[],System.Boolean)">
  ReduceMean(ComputationNode&lt;T&gt;, int[]?, bool)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L5169"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Reduces a tensor by computing the mean value along specified axes.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; ReduceMean(ComputationNode&lt;T&gt; a, int[]? axes = null, bool keepDims = false)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>axes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The axes along which to compute the mean. If null, reduces over all axes.</p>
</dd>
    <dt><code>keepDims</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Whether to keep the reduced dimensions with size 1.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node representing the result of the reduce mean operation.</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_Reshape_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Reshape*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Reshape_AiDotNet_Autodiff_ComputationNode__0__System_Int32___" data-uid="AiDotNet.Autodiff.TensorOperations`1.Reshape(AiDotNet.Autodiff.ComputationNode{`0},System.Int32[])">
  Reshape(ComputationNode&lt;T&gt;, params int[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1362"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Reshapes a computation node to a new shape.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Reshape(ComputationNode&lt;T&gt; a, params int[] newShape)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The computation node to reshape.</p>
</dd>
    <dt><code>newShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The new shape (must have same total number of elements).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node with the new shape.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Reshape_AiDotNet_Autodiff_ComputationNode__0__System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Changes the shape of the tensor without changing the underlying data.
The total number of elements must remain the same.
</p>
<p><b>Gradient computation:</b>
- ∂(Reshape(A))/∂A = Reshape(gradOut, A.Shape)
- Simply reshape the gradient back to the original shape.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_SELU_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SELU*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_SELU_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.SELU(AiDotNet.Autodiff.ComputationNode{`0})">
  SELU(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L2001"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the SELU (Scaled Exponential Linear Unit) activation function element-wise.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; SELU(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with SELU applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_SELU_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
SELU is defined as: λ * x if x &gt; 0, otherwise λ * α * (e^x - 1)
where λ ≈ 1.0507 and α ≈ 1.6733 are fixed constants for self-normalization.
The gradient is: λ if x &gt; 0, otherwise λ * α * e^x
</p>
<p><b>For Beginners:</b> SELU enables self-normalizing neural networks where
activations converge to zero mean and unit variance, reducing the need for
batch normalization.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_SQRBF_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SQRBF*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_SQRBF_AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SQRBF(AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  SQRBF(ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L10048"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Squared Radial Basis Function (SQRBF) activation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; SQRBF(ComputationNode&lt;T&gt; a, double beta = 1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>beta</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The width parameter controlling the Gaussian bell curve (default 1.0).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with SQRBF applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_SQRBF_AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
SQRBF(x) = exp(-β * x²)
A Gaussian bell-shaped activation with maximum at x=0 and values approaching 0 as |x| increases.
</p>
<p><b>Gradient:</b> d(SQRBF)/dx = -2βx * exp(-β * x²)</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_ScaledDotProductAttention_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ScaledDotProductAttention*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_ScaledDotProductAttention_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.ScaledDotProductAttention(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  ScaledDotProductAttention(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L7515"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes scaled dot-product attention: softmax(Q @ K^T / sqrt(d_k)) @ V.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; ScaledDotProductAttention(ComputationNode&lt;T&gt; query, ComputationNode&lt;T&gt; key, ComputationNode&lt;T&gt; value, ComputationNode&lt;T&gt;? mask = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>query</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Query tensor [batch, seq_len_q, d_k].</p>
</dd>
    <dt><code>key</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Key tensor [batch, seq_len_k, d_k].</p>
</dd>
    <dt><code>value</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Value tensor [batch, seq_len_k, d_v].</p>
</dd>
    <dt><code>mask</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Optional attention mask.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Attention output [batch, seq_len_q, d_v].</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_ScaledTanh_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ScaledTanh*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_ScaledTanh_AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ScaledTanh(AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  ScaledTanh(ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L2527"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Scaled Tanh activation function element-wise.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; ScaledTanh(ComputationNode&lt;T&gt; a, double beta = 1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>beta</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The steepness parameter. Default is 1.0.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with ScaledTanh applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_ScaledTanh_AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
ScaledTanh is defined as: f(x) = (1 - exp(-βx)) / (1 + exp(-βx))
The gradient is: β * (1 - f(x)²)
When β = 2, this equals standard tanh.
</p>
<p><b>For Beginners:</b> ScaledTanh allows you to control the steepness of the
tanh curve, which can be useful for tuning network behavior.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Sigmoid_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Sigmoid*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Sigmoid_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Sigmoid(AiDotNet.Autodiff.ComputationNode{`0})">
  Sigmoid(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L759"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the sigmoid function for a computation node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Sigmoid(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the sigmoid result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Sigmoid_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method computes sigmoid (σ(x) = 1/(1+e^(-x))) and records the operation.
The backward function uses: ∂σ(a)/∂a = σ(a) * (1 - σ(a)).
</p>
<p><b>For Beginners:</b> Sigmoid squashes values to be between 0 and 1.
<p>For sigmoid (c = σ(a)):</p>
<ul>
<li>The forward pass computes 1/(1+e^(-x)) for each element</li>
<li>The backward pass: gradient to 'a' is incoming gradient * output * (1 - output)</li>
</ul>
<p>Sigmoid is used in binary classification and as a gate in LSTM networks.</p>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Sign_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Sign*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Sign_AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Sign(AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  Sign(ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L9615"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"></div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Sign(ComputationNode&lt;T&gt; a, double surrogateBeta = 1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd></dd>
    <dt><code>surrogateBeta</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd></dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_SinusoidalTimeEmbedding_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SinusoidalTimeEmbedding*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_SinusoidalTimeEmbedding_AiDotNet_Autodiff_ComputationNode__0__System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SinusoidalTimeEmbedding(AiDotNet.Autodiff.ComputationNode{`0},System.Int32)">
  SinusoidalTimeEmbedding(ComputationNode&lt;T&gt;, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L11981"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Creates sinusoidal time embeddings for diffusion models.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; SinusoidalTimeEmbedding(ComputationNode&lt;T&gt; timesteps, int embeddingDim)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>timesteps</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The timesteps to embed [batchSize] or [batchSize, 1].</p>
</dd>
    <dt><code>embeddingDim</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The dimension of the output embeddings.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node with sinusoidal embeddings [batchSize, embeddingDim].</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_Slice_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Slice*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Slice_AiDotNet_Autodiff_ComputationNode__0__System_Int32_System_Int32_System_Int32_System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Slice(AiDotNet.Autodiff.ComputationNode{`0},System.Int32,System.Int32,System.Int32,System.Int32)">
  Slice(ComputationNode&lt;T&gt;, int, int, int, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L8668"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Extracts a slice from a tensor along a specified axis.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Slice(ComputationNode&lt;T&gt; a, int start, int length, int step = 1, int axis = 0)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input tensor to slice.</p>
</dd>
    <dt><code>start</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The starting index along the specified axis.</p>
</dd>
    <dt><code>length</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of elements to extract.</p>
</dd>
    <dt><code>step</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The step size between elements (default 1).</p>
</dd>
    <dt><code>axis</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The axis along which to slice (default 0).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the sliced tensor.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Slice_AiDotNet_Autodiff_ComputationNode__0__System_Int32_System_Int32_System_Int32_System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This operation extracts a portion of a tensor along a specified axis, starting at
a given offset and continuing for a specified length. An optional step parameter
allows for strided slicing (e.g., every 2nd element).
</p>
<p><b>For Beginners:</b> Think of this like taking a substring from a string.
<p>For example, if you have a tensor [1, 2, 3, 4, 5, 6] and you slice with start=1, length=3:</p>
<ul>
<li>You get [2, 3, 4]</li>
</ul>
<p>With step=2 and start=0, length=3:</p>
<ul>
<li>You get [1, 3, 5] (every 2nd element)</li>
</ul>
<p>This is useful for extracting specific parts of data, like separating real and
imaginary parts of complex numbers stored in interleaved format.</p>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_SoftKNN_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SoftKNN*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_SoftKNN_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___0_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SoftKNN(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},`0)">
  SoftKNN(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, T?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L11188"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs a soft K-Nearest Neighbors operation for differentiable instance-based learning.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; SoftKNN(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; supportVectors, ComputationNode&lt;T&gt; labels, T? temperature = default)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The query input tensor.</p>
</dd>
    <dt><code>supportVectors</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Matrix of support vectors (training points) [n_samples, n_features].</p>
</dd>
    <dt><code>labels</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Labels for each support vector [n_samples] or [n_samples, n_outputs].</p>
</dd>
    <dt><code>temperature</code> <span class="xref">T</span></dt>
    <dd><p>Temperature for softmax attention (default: 1.0).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Attention-weighted sum of labels.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_SoftKNN_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Computes: distances[i] = ||input - supportVectors[i]||²
          weights = softmax(-distances / temperature)
          output = Σ weights[i] * labels[i]
</p>
<p><b>For Beginners:</b> Instead of finding exactly k nearest neighbors, this
computes attention weights for ALL neighbors based on distance. Closer neighbors
get higher attention. This makes KNN differentiable and JIT-compilable.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_SoftLocallyWeighted_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SoftLocallyWeighted*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_SoftLocallyWeighted_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___0_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SoftLocallyWeighted(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},`0)">
  SoftLocallyWeighted(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, T?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L11376"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs soft locally-weighted regression for differentiable instance-based learning.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; SoftLocallyWeighted(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; xTrain, ComputationNode&lt;T&gt; yTrain, T? bandwidth = default)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The query input tensor.</p>
</dd>
    <dt><code>xTrain</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Training feature matrix [n_samples, n_features].</p>
</dd>
    <dt><code>yTrain</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Training target values [n_samples] or [n_samples, n_outputs].</p>
</dd>
    <dt><code>bandwidth</code> <span class="xref">T</span></dt>
    <dd><p>Bandwidth parameter controlling locality (default: 1.0).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Attention-weighted prediction.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_SoftLocallyWeighted_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Computes: distances[i] = ||input - xTrain[i]||²
          weights = softmax(-distances / bandwidth)
          output = Σ weights[i] * yTrain[i]
</p>
<p><b>For Beginners:</b> This is similar to SoftKNN but specifically designed for
regression with a bandwidth parameter that controls how local the weighting is.
Smaller bandwidth = more local predictions.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_SoftPlus_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SoftPlus*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_SoftPlus_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.SoftPlus(AiDotNet.Autodiff.ComputationNode{`0})">
  SoftPlus(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1931"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the SoftPlus activation function element-wise: f(x) = ln(1 + e^x).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; SoftPlus(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with SoftPlus applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_SoftPlus_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
SoftPlus is a smooth approximation of ReLU. The gradient is the sigmoid function:
d(SoftPlus)/dx = sigmoid(x) = 1 / (1 + e^(-x))
</p>
<p><b>For Beginners:</b> SoftPlus smoothly approaches 0 for negative inputs and
approaches the input value for large positive inputs, similar to ReLU but without
the sharp corner at x=0.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_SoftSign_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SoftSign*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_SoftSign_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.SoftSign(AiDotNet.Autodiff.ComputationNode{`0})">
  SoftSign(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L2214"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the SoftSign activation function element-wise: f(x) = x / (1 + |x|).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; SoftSign(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with SoftSign applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_SoftSign_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
SoftSign is an alternative to tanh with polynomial tails that approach ±1 more slowly.
The gradient is: d(SoftSign)/dx = 1 / (1 + |x|)²
</p>
<p><b>For Beginners:</b> SoftSign maps inputs to (-1, 1) like tanh, but with
a different shape. The slower saturation can help prevent vanishing gradients
in deep networks.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_SoftSplit_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SoftSplit*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_SoftSplit_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32__0__0_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SoftSplit(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0},System.Int32,`0,`0)">
  SoftSplit(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;, int, T, T?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L11057"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs a soft split operation for differentiable decision trees.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; SoftSplit(ComputationNode&lt;T&gt; input, ComputationNode&lt;T&gt; leftValue, ComputationNode&lt;T&gt; rightValue, int featureIndex, T threshold, T? temperature = default)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input features tensor.</p>
</dd>
    <dt><code>leftValue</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The value to return if going left.</p>
</dd>
    <dt><code>rightValue</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The value to return if going right.</p>
</dd>
    <dt><code>featureIndex</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The index of the feature to split on.</p>
</dd>
    <dt><code>threshold</code> <span class="xref">T</span></dt>
    <dd><p>The threshold value for the split.</p>
</dd>
    <dt><code>temperature</code> <span class="xref">T</span></dt>
    <dd><p>Temperature parameter controlling split sharpness (default: 1.0).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A weighted combination of left and right values based on soft split.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_SoftSplit_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__System_Int32__0__0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Computes: p_left = σ((threshold - x[featureIndex]) / temperature)
          output = p_left * leftValue + (1 - p_left) * rightValue
</p>
<p><b>For Beginners:</b> This makes decision tree splits differentiable by using
a smooth sigmoid function instead of a hard if-then-else. Lower temperature makes
the split sharper (more like a hard decision), while higher temperature makes it softer.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Softmax_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Softmax*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Softmax_AiDotNet_Autodiff_ComputationNode__0__System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Softmax(AiDotNet.Autodiff.ComputationNode{`0},System.Int32)">
  Softmax(ComputationNode&lt;T&gt;, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1559"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the softmax function for a computation node along a specified axis.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Softmax(ComputationNode&lt;T&gt; a, int axis = -1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node.</p>
</dd>
    <dt><code>axis</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The axis along which to compute softmax. Default is -1 (last axis).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the softmax result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Softmax_AiDotNet_Autodiff_ComputationNode__0__System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method computes softmax (σ(x_i) = exp(x_i) / Σexp(x_j)) along the specified axis.
Uses numerical stability trick: subtract max before exponentiating.
The backward function uses: ∂softmax/∂x = softmax(x) * (grad - Σ(grad * softmax(x))).
</p>
<p><b>For Beginners:</b> Softmax converts a vector of numbers into probabilities.
<p>For softmax:</p>
<ul>
<li>The forward pass exponentiates each element, then normalizes so they sum to 1</li>
<li>The result is a probability distribution (all values between 0 and 1, summing to 1)</li>
<li>The backward pass is complex but efficient: uses the Jacobian of softmax</li>
</ul>
<p>Softmax is crucial for:</p>
<ul>
<li>Multi-class classification (final layer outputs)</li>
<li>Attention mechanisms (computing attention weights)</li>
<li>Anywhere you need to convert scores to probabilities</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Softmin_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Softmin*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Softmin_AiDotNet_Autodiff_ComputationNode__0__System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Softmin(AiDotNet.Autodiff.ComputationNode{`0},System.Int32)">
  Softmin(ComputationNode&lt;T&gt;, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L9803"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Softmin function, which assigns higher probability to lower values.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Softmin(ComputationNode&lt;T&gt; a, int axis = -1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>axis</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The axis along which to compute softmin (default -1, last axis).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with Softmin applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Softmin_AiDotNet_Autodiff_ComputationNode__0__System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Softmin(x) = softmax(-x) = exp(-x) / sum(exp(-x))
Useful when lower values should have higher probability, e.g., in attention over distances.
</p>
<p><b>Gradient:</b> Same Jacobian structure as softmax but with negated input.</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Sparsemax_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Sparsemax*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Sparsemax_AiDotNet_Autodiff_ComputationNode__0__System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Sparsemax(AiDotNet.Autodiff.ComputationNode{`0},System.Int32)">
  Sparsemax(ComputationNode&lt;T&gt;, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L10643"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Sparsemax activation function which projects onto the probability simplex.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Sparsemax(ComputationNode&lt;T&gt; a, int axis = -1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node (2D: batch × features).</p>
</dd>
    <dt><code>axis</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Axis along which to apply (default -1, last axis).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with Sparsemax applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Sparsemax_AiDotNet_Autodiff_ComputationNode__0__System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Sparsemax produces sparse probability distributions where some outputs are exactly zero.
Unlike softmax which always gives positive probabilities to all classes, sparsemax
can assign exactly zero to low-scoring classes.
</p>
<p><b>Gradient:</b> For support set S (non-zero outputs): grad = upstream - mean(upstream[S])</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_SphericalSoftmax_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SphericalSoftmax*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_SphericalSoftmax_AiDotNet_Autodiff_ComputationNode__0__System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SphericalSoftmax(AiDotNet.Autodiff.ComputationNode{`0},System.Int32)">
  SphericalSoftmax(ComputationNode&lt;T&gt;, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L10294"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Spherical Softmax activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; SphericalSoftmax(ComputationNode&lt;T&gt; a, int axis = -1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node (2D: batch × features).</p>
</dd>
    <dt><code>axis</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Axis along which to apply (default -1, last axis).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with SphericalSoftmax applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_SphericalSoftmax_AiDotNet_Autodiff_ComputationNode__0__System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
SphericalSoftmax = softmax(x / ||x||₂)
First L2-normalizes the input, then applies softmax.
This improves numerical stability for inputs with varying magnitudes.
</p>
<p><b>Gradient:</b> Chain rule through L2 normalization and softmax.</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Split_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Split*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Split_AiDotNet_Autodiff_ComputationNode__0__System_Int32_System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Split(AiDotNet.Autodiff.ComputationNode{`0},System.Int32,System.Int32)">
  Split(ComputationNode&lt;T&gt;, int, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L5298"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Splits a tensor along a specified axis into multiple tensors.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static List&lt;ComputationNode&lt;T&gt;&gt; Split(ComputationNode&lt;T&gt; a, int numSplits, int axis = 0)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>numSplits</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of splits to create.</p>
</dd>
    <dt><code>axis</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The axis along which to split.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.list-1">List</a>&lt;<a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;&gt;</dt>
    <dd><p>A list of computation nodes representing the split tensors.</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_Sqrt_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Sqrt*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Sqrt_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Sqrt(AiDotNet.Autodiff.ComputationNode{`0})">
  Sqrt(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L649"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the square root for a computation node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Sqrt(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the square root result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Sqrt_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method computes the square root of each element and records the operation.
The backward function uses: ∂(√a)/∂a = 1/(2√a).
</p>
<p><b>For Beginners:</b> This computes square root and tracks gradients.
<p>For square root (c = √a):</p>
<ul>
<li>The forward pass computes √x for each element</li>
<li>The backward pass: gradient to 'a' is incoming gradient * 1/(2√a)</li>
<li>Which simplifies to: incoming gradient / (2 * output)</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Square_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Square*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Square_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Square(AiDotNet.Autodiff.ComputationNode{`0})">
  Square(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L7748"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the element-wise square of the input (x²).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Square(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the squared result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Square_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method computes the square of each element (x²) and records the operation.
The backward function uses: ∂(x²)/∂x = 2x.
</p>
<p><b>For Beginners:</b> Square is a common operation in neural networks.
<p>For square (c = a²):</p>
<ul>
<li>The forward pass computes a² for each element</li>
<li>The backward pass: gradient to 'a' is incoming gradient * 2a</li>
</ul>
<p>This is more efficient than using Power(a, 2) and is frequently needed for
operations like computing distances, norms, and variance.</p>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Squash_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Squash*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Squash_AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Squash(AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  Squash(ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L7817"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the squashing function used in capsule networks: s(x) = ||x||² / (1 + ||x||²) * (x / ||x||).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Squash(ComputationNode&lt;T&gt; a, double epsilon = 1E-07)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node representing capsule vectors.</p>
</dd>
    <dt><code>epsilon</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Small value for numerical stability (default: 1e-7).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the squashed result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Squash_AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method computes the squashing nonlinearity used in capsule networks.
The squashing function ensures that short vectors shrink to near zero length
and long vectors shrink to a length slightly below 1.
</p>
<p><b>For Beginners:</b> Squashing is the activation function for capsule layers.
<p>The squashing function:</p>
<ul>
<li>Keeps the direction of the vector unchanged</li>
<li>Scales the length to be between 0 and 1</li>
<li>Short vectors get much shorter (near 0)</li>
<li>Long vectors approach length 1</li>
</ul>
<p>This is crucial for capsule networks where the length represents the probability
that the entity represented by the capsule exists, and the direction represents
its properties.</p>
<p>Formula: s(v) = ||v||² / (1 + ||v||²) * (v / ||v||)</p>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_StraightThroughThreshold_" data-uid="AiDotNet.Autodiff.TensorOperations`1.StraightThroughThreshold*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_StraightThroughThreshold_AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.StraightThroughThreshold(AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  StraightThroughThreshold(ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L9018"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies a straight-through threshold for HTM-style sparse activations.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; StraightThroughThreshold(ComputationNode&lt;T&gt; input, double threshold)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input activations.</p>
</dd>
    <dt><code>threshold</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The threshold value.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Binary activations with straight-through gradients.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_StraightThroughThreshold_AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Forward: output = (input &gt; threshold) ? 1 : 0
Backward: gradients pass through unchanged (straight-through estimator)
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Subtract_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Subtract*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Subtract_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Subtract(AiDotNet.Autodiff.ComputationNode{`0},AiDotNet.Autodiff.ComputationNode{`0})">
  Subtract(ComputationNode&lt;T&gt;, ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L232"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs element-wise subtraction of two computation nodes.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Subtract(ComputationNode&lt;T&gt; a, ComputationNode&lt;T&gt; b)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The node to subtract from.</p>
</dd>
    <dt><code>b</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The node to subtract.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the difference.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Subtract_AiDotNet_Autodiff_ComputationNode__0__AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs element-wise subtraction and records the operation to any active GradientTape.
The backward function sends gradient to 'a' unchanged and negated gradient to 'b'
(since ∂(a-b)/∂a = 1 and ∂(a-b)/∂b = -1).
</p>
<p><b>For Beginners:</b> This subtracts one tensor from another and tracks gradients.
<p>For subtraction (c = a - b):</p>
<ul>
<li>The forward pass computes a minus b element-wise</li>
<li>The backward pass sends the gradient to 'a' unchanged</li>
<li>But sends the <em>negative</em> gradient to 'b'</li>
<li>This is because increasing 'b' by 1 <em>decreases</em> the result by 1</li>
</ul>
<p>Example:
If the gradient flowing to c is [1, 2, 3]:</p>
<ul>
<li>'a' receives [1, 2, 3]</li>
<li>'b' receives [-1, -2, -3]</li>
</ul>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Sum_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Sum*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Sum_AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Boolean_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Sum(AiDotNet.Autodiff.ComputationNode{`0},System.Int32[],System.Boolean)">
  Sum(ComputationNode&lt;T&gt;, int[]?, bool)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1182"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sums elements of a computation node along specified axes.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Sum(ComputationNode&lt;T&gt; a, int[]? axes = null, bool keepDims = false)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The computation node to sum.</p>
</dd>
    <dt><code>axes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The axes along which to sum. If null, sums all elements.</p>
</dd>
    <dt><code>keepDims</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Whether to keep the reduced dimensions with size 1. Default is false.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node representing the sum.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Sum_AiDotNet_Autodiff_ComputationNode__0__System_Int32___System_Boolean__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Reduces the tensor by summing along specified axes.
</p>
<p><b>Gradient computation:</b>
- The gradient is broadcast back to the original shape, as each element contributed equally to the sum.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_SurrogateSpike_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SurrogateSpike*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_SurrogateSpike_AiDotNet_Autodiff_ComputationNode__0__System_Double_System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.SurrogateSpike(AiDotNet.Autodiff.ComputationNode{`0},System.Double,System.Double)">
  SurrogateSpike(ComputationNode&lt;T&gt;, double, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L8948"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies a surrogate spike function for spiking neural network JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; SurrogateSpike(ComputationNode&lt;T&gt; membranePotential, double threshold = 1, double surrogateBeta = 1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>membranePotential</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The membrane potential input.</p>
</dd>
    <dt><code>threshold</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The spike threshold (default 1.0).</p>
</dd>
    <dt><code>surrogateBeta</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Sharpness of the surrogate gradient (default 1.0).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node containing spike outputs with surrogate gradients.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_SurrogateSpike_AiDotNet_Autodiff_ComputationNode__0__System_Double_System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Uses the sigmoid surrogate for gradient computation while producing hard spikes in forward pass.
Forward: spike = (potential &gt; threshold) ? 1 : 0
Backward: uses sigmoid derivative as surrogate gradient
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Swish_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Swish*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Swish_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Swish(AiDotNet.Autodiff.ComputationNode{`0})">
  Swish(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1801"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Swish (SiLU) activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Swish(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with Swish applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Swish_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Swish(x) = x * sigmoid(x) = x / (1 + exp(-x))
Also known as SiLU (Sigmoid Linear Unit).
Used in EfficientNet and other modern architectures.
</p>
<p><b>Gradient:</b> d(Swish)/dx = sigmoid(x) + x * sigmoid(x) * (1 - sigmoid(x)) = Swish(x) + sigmoid(x) * (1 - Swish(x))</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Tanh_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Tanh*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Tanh_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Tanh(AiDotNet.Autodiff.ComputationNode{`0})">
  Tanh(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L704"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the hyperbolic tangent (tanh) for a computation node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Tanh(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the tanh result.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Tanh_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method computes tanh of each element and records the operation.
The backward function uses: ∂(tanh(a))/∂a = 1 - tanh²(a).
</p>
<p><b>For Beginners:</b> Tanh is a common activation function in neural networks.
<p>For tanh (c = tanh(a)):</p>
<ul>
<li>The forward pass computes tanh for each element (outputs between -1 and 1)</li>
<li>The backward pass: gradient to 'a' is incoming gradient * (1 - output²)</li>
</ul>
<p>Tanh is popular because it's centered around 0 (unlike sigmoid which is 0 to 1).</p>

</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_TaylorSoftmax_" data-uid="AiDotNet.Autodiff.TensorOperations`1.TaylorSoftmax*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_TaylorSoftmax_AiDotNet_Autodiff_ComputationNode__0__System_Int32_System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.TaylorSoftmax(AiDotNet.Autodiff.ComputationNode{`0},System.Int32,System.Int32)">
  TaylorSoftmax(ComputationNode&lt;T&gt;, int, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L10473"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Taylor Softmax activation function using Taylor series approximation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; TaylorSoftmax(ComputationNode&lt;T&gt; a, int order = 2, int axis = -1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node (2D: batch × features).</p>
</dd>
    <dt><code>order</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Order of Taylor series expansion (default 2).</p>
</dd>
    <dt><code>axis</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Axis along which to apply (default -1, last axis).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with TaylorSoftmax applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_TaylorSoftmax_AiDotNet_Autodiff_ComputationNode__0__System_Int32_System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
TaylorSoftmax uses Taylor series approximation of exp(x):
exp(x) ≈ 1 + x + x²/2! + x³/3! + ... + xⁿ/n!
Then normalizes like standard softmax.
More computationally efficient than standard softmax for some hardware.
</p>
<p><b>Gradient:</b> Similar to softmax but using polynomial derivatives.</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_ThresholdedReLU_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ThresholdedReLU*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_ThresholdedReLU_AiDotNet_Autodiff_ComputationNode__0__System_Double_" data-uid="AiDotNet.Autodiff.TensorOperations`1.ThresholdedReLU(AiDotNet.Autodiff.ComputationNode{`0},System.Double)">
  ThresholdedReLU(ComputationNode&lt;T&gt;, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L9495"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the Thresholded Rectified Linear Unit activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; ThresholdedReLU(ComputationNode&lt;T&gt; a, double threshold = 1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node.</p>
</dd>
    <dt><code>threshold</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The threshold value (default 1.0).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node with ThresholdedReLU applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_ThresholdedReLU_AiDotNet_Autodiff_ComputationNode__0__System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
ThresholdedReLU(x) = x if x &gt; threshold, 0 otherwise.
Unlike standard ReLU which activates at 0, this activates at a configurable threshold.
</p>
<p><b>Gradient:</b> d(ThresholdedReLU)/dx = 1 if x &gt; threshold, 0 otherwise.</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_TopKSoftmax_" data-uid="AiDotNet.Autodiff.TensorOperations`1.TopKSoftmax*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_TopKSoftmax_AiDotNet_Autodiff_ComputationNode__0__System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.TopKSoftmax(AiDotNet.Autodiff.ComputationNode{`0},System.Int32)">
  TopKSoftmax(ComputationNode&lt;T&gt;, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L9068"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Differentiable Top-K selection for mixture-of-experts routing.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; TopKSoftmax(ComputationNode&lt;T&gt; scores, int k)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>scores</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The routing scores for each expert.</p>
</dd>
    <dt><code>k</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Number of experts to select.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>Sparse routing weights with only top-K non-zero.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_TopKSoftmax_AiDotNet_Autodiff_ComputationNode__0__System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Selects top-K values and normalizes them via softmax.
Gradients flow only to the selected experts.
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Transpose_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Transpose*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Transpose_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.Autodiff.TensorOperations`1.Transpose(AiDotNet.Autodiff.ComputationNode{`0})">
  Transpose(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L1137"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Transposes a 2D computation node (matrix).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Transpose(ComputationNode&lt;T&gt; a)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The matrix to transpose (must be 2D).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node representing the transposed matrix.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Transpose_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
For a 2D tensor, swaps rows and columns: if A has shape [m, n], result has shape [n, m].
</p>
<p><b>Gradient computation:</b>
- ∂(A^T)/∂A = gradOut^T (transpose the gradient back)
</p>
</div>




  <a id="AiDotNet_Autodiff_TensorOperations_1_Upsample_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Upsample*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Upsample_AiDotNet_Autodiff_ComputationNode__0__System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Upsample(AiDotNet.Autodiff.ComputationNode{`0},System.Int32)">
  Upsample(ComputationNode&lt;T&gt;, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L5477"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Upsamples a tensor using nearest neighbor interpolation.
Supports tensors of any rank (at least 2D), treating the last two dimensions as height and width.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Upsample(ComputationNode&lt;T&gt; a, int scale)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>a</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input computation node with at least 2 dimensions.</p>
</dd>
    <dt><code>scale</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The upsampling scale factor.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node representing the upsampled tensor.</p>
</dd>
  </dl>











  <a id="AiDotNet_Autodiff_TensorOperations_1_Upsample3D_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Upsample3D*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Upsample3D_AiDotNet_Autodiff_ComputationNode__0__System_Int32_System_Int32_System_Int32_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Upsample3D(AiDotNet.Autodiff.ComputationNode{`0},System.Int32,System.Int32,System.Int32)">
  Upsample3D(ComputationNode&lt;T&gt;, int, int, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L4832"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs 3D upsampling (nearest neighbor) on a 5D tensor.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Upsample3D(ComputationNode&lt;T&gt; input, int scaleD, int scaleH, int scaleW)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The input node with shape [batch, channels, depth, height, width].</p>
</dd>
    <dt><code>scaleD</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Scale factor for depth dimension.</p>
</dd>
    <dt><code>scaleH</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Scale factor for height dimension.</p>
</dd>
    <dt><code>scaleW</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Scale factor for width dimension.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A new computation node containing the upsampled result with shape
[batch, channels, depth<em>scaleD, height</em>scaleH, width*scaleW].</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Upsample3D_AiDotNet_Autodiff_ComputationNode__0__System_Int32_System_Int32_System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
3D upsampling increases spatial resolution by repeating values. This is the inverse
operation of 3D max pooling and is commonly used in 3D U-Net decoder paths.
</p>
<p><b>For Beginners:</b> Upsample3D makes volumetric data larger by repeating voxels.
If you have a 4x4x4 volume and upsample by 2 in each dimension, you get an 8x8x8 volume
where each original voxel is repeated 2x2x2 times.
</p>
<p><b>Gradient:</b> The gradient is computed by summing gradients that were distributed
to repeated elements back to the original position.</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a></dt>
    <dd><p>Thrown when input is not 5D.</p>
</dd>
  </dl>



  <a id="AiDotNet_Autodiff_TensorOperations_1_Variable_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Variable*"></a>

  <h3 id="AiDotNet_Autodiff_TensorOperations_1_Variable_AiDotNet_Tensors_LinearAlgebra_Tensor__0__System_String_System_Boolean_" data-uid="AiDotNet.Autodiff.TensorOperations`1.Variable(AiDotNet.Tensors.LinearAlgebra.Tensor{`0},System.String,System.Boolean)">
  Variable(Tensor&lt;T&gt;, string?, bool)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L73"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Creates a computation node from a tensor value.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ComputationNode&lt;T&gt; Variable(Tensor&lt;T&gt; value, string? name = null, bool requiresGradient = true)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>value</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The tensor value.</p>
</dd>
    <dt><code>name</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>Optional name for the node.</p>
</dd>
    <dt><code>requiresGradient</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Whether this node requires gradient computation.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>A computation node wrapping the tensor.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Autodiff_TensorOperations_1_Variable_AiDotNet_Tensors_LinearAlgebra_Tensor__0__System_String_System_Boolean__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method creates a leaf node in the computation graph - a node with no parents.
Leaf nodes typically represent inputs or parameters that gradients will be computed with respect to.
</p>
<p><b>For Beginners:</b> This creates a starting point in your calculation graph.
<p>Use this to wrap:</p>
<ul>
<li>Model parameters (weights, biases) that need gradients</li>
<li>Input data that you want to compute gradients for</li>
<li>Constants (with requiresGradient=false)</li>
</ul>
<p>The returned ComputationNode tracks the tensor's value and will accumulate gradients
during backpropagation.</p>

</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/Autodiff/TensorOperations.cs/#L48" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
