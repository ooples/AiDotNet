<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class MixtureOfExpertsOptions&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class MixtureOfExpertsOptions&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Configuration options for the Mixture-of-Experts (MoE) neural network model.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_Models_Options_MixtureOfExpertsOptions_1.md&amp;value=---%0Auid%3A%20AiDotNet.Models.Options.MixtureOfExpertsOptions%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1">



  <h1 id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1" class="text-break">
Class MixtureOfExpertsOptions&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/MixtureOfExpertsOptions.cs/#L35"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.Models.html">Models</a>.<a class="xref" href="AiDotNet.Models.Options.html">Options</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Configuration options for the Mixture-of-Experts (MoE) neural network model.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class MixtureOfExpertsOptions&lt;T&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for calculations (e.g., float, double, decimal).</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><span class="xref">MixtureOfExpertsOptions&lt;T&gt;</span></div>
    </dd>
  </dl>



  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
Mixture-of-Experts is a neural network architecture that employs multiple specialist networks (experts)
and a gating mechanism to route inputs to the most appropriate experts. This approach enables:
- Increased model capacity without proportional compute cost (sparse activation)
- Specialization of different experts on different aspects of the problem
- Improved scalability for large-scale problems
</p>
<p><b>For Beginners:</b> Mixture-of-Experts (MoE) is like having a team of specialists rather than one generalist.
<p>Imagine you're running a hospital:</p>
<ul>
<li>Instead of one doctor handling everything, you have specialists (cardiologist, neurologist, etc.)</li>
<li>A triage system (gating network) decides which specialist(s) should see each patient</li>
<li>Each specialist only handles cases they're best suited for</li>
</ul>
<p>In a MoE neural network:</p>
<ul>
<li>Multiple &quot;expert&quot; networks specialize in different patterns in your data</li>
<li>A &quot;gating network&quot; learns to route each input to the best expert(s)</li>
<li>Only a few experts process each input (sparse activation), making it efficient</li>
<li>The final prediction combines the outputs from the selected experts</li>
</ul>
<p>This class lets you configure:</p>
<ul>
<li>How many expert networks to use</li>
<li>How many experts process each input (Top-K)</li>
<li>Dimensions of the expert networks</li>
<li>Whether to use load balancing to ensure all experts are utilized</li>
</ul>

</div>


  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_HiddenExpansion_" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.HiddenExpansion*"></a>

  <h3 id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_HiddenExpansion" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.HiddenExpansion">
  HiddenExpansion
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/MixtureOfExpertsOptions.cs/#L194"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the hidden layer expansion factor for each expert's feed-forward network.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int HiddenExpansion { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The expansion factor, defaulting to 4.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_HiddenExpansion_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This parameter determines the size of the hidden layer within each expert relative to the input
dimension. Following the Transformer architecture convention, experts typically use a feed-forward
network with a hidden layer that is 4x the input dimension. The hidden layer size equals
InputDim * HiddenExpansion. Larger values increase expert capacity but also increase computational cost.
</p>
<p><b>For Beginners:</b> This controls how much each expert can expand internally for processing.
<p>The default value of 4 means:</p>
<ul>
<li>Each expert has a hidden layer that's 4 times the input size</li>
<li>With InputDim=128, the hidden layer is 512 neurons</li>
<li>This follows the proven Transformer architecture design</li>
</ul>
<p>How it works:</p>
<ul>
<li>Input (128) → Hidden Layer (512) → Output (128)</li>
<li>The expansion allows experts to learn more complex transformations</li>
<li>Then compression back to output size</li>
</ul>
<p>Typical values:</p>
<ul>
<li>4: Standard choice (recommended, from Transformer research)</li>
<li>2-3: More efficient, less capacity</li>
<li>6-8: More capacity, higher cost</li>
</ul>
<p>Most users should keep the default value of 4.</p>

</div>




  <a id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_InputDim_" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.InputDim*"></a>

  <h3 id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_InputDim" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.InputDim">
  InputDim
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/MixtureOfExpertsOptions.cs/#L131"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the input dimension for each expert network.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int InputDim { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The input dimension, defaulting to 128.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_InputDim_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This parameter specifies the dimensionality of the input that each expert receives. For MoE layers
embedded within larger networks, this typically matches the hidden layer size of the network. The
input dimension determines the size of the expert networks and should match the output dimension of
the previous layer in the network architecture.
</p>
<p><b>For Beginners:</b> This is the size of the input data that goes into each expert.
<p>The default value of 128 means:</p>
<ul>
<li>Each expert receives 128-dimensional input vectors</li>
<li>This is a common size for neural network hidden layers</li>
</ul>
<p>This value should match:</p>
<ul>
<li>The output size of the previous layer in your network, OR</li>
<li>The size of your input features if MoE is the first layer</li>
</ul>
<p>Larger dimensions:</p>
<ul>
<li>Can capture more complex patterns</li>
<li>Require more memory and computation</li>
<li>Need more training data</li>
</ul>
<p>Typical values range from 64 to 512 depending on your problem complexity.</p>

</div>




  <a id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_LoadBalancingWeight_" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.LoadBalancingWeight*"></a>

  <h3 id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_LoadBalancingWeight" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.LoadBalancingWeight">
  LoadBalancingWeight
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/MixtureOfExpertsOptions.cs/#L263"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the weight of the auxiliary load balancing loss.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double LoadBalancingWeight { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The load balancing loss weight, defaulting to 0.01.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_LoadBalancingWeight_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This parameter controls the strength of the load balancing regularization. The total loss becomes:
TotalLoss = PrimaryLoss + (LoadBalancingWeight * LoadBalancingLoss). A value of 0.01 provides gentle
encouragement toward balanced expert usage without overwhelming the primary task loss. Values that are
too high can hurt task performance by forcing artificial balance, while values too low may not
effectively prevent expert collapse. Only used when UseLoadBalancing is true.
</p>
<p><b>For Beginners:</b> This controls how strongly the model tries to balance expert usage.
<p>The default value of 0.01 means:</p>
<ul>
<li>Load balancing contributes 1% as much as the main task loss</li>
<li>It gently encourages balance without dominating training</li>
<li>This is a research-proven default from the Switch Transformer paper</li>
</ul>
<p>Think of it like priorities:</p>
<ul>
<li>Main task (99% weight): Make accurate predictions</li>
<li>Load balancing (1% weight): Keep expert usage balanced</li>
</ul>
<p>Typical values:</p>
<ul>
<li>0.001: Very gentle balancing (for when balance isn't critical)</li>
<li>0.01: Standard choice (recommended default)</li>
<li>0.1: Strong balancing (if you notice severe imbalance)</li>
</ul>
<p>If you see in your logs that only 1-2 experts are being used, try increasing this to 0.05 or 0.1.
If training seems unstable, try decreasing to 0.001.</p>
<p>For most applications, the default 0.01 works well.</p>

</div>




  <a id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_NumExperts_" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.NumExperts*"></a>

  <h3 id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_NumExperts" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.NumExperts">
  NumExperts
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/MixtureOfExpertsOptions.cs/#L67"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the number of expert networks in the mixture.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int NumExperts { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of experts, defaulting to 4.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_NumExperts_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This parameter determines how many specialist networks the model contains. More experts allow for
greater specialization and model capacity but increase computational and memory requirements. Research
suggests that 4-16 experts provides a good balance for most applications. The number of experts should
be chosen based on the complexity of the problem domain and available computational resources.
</p>
<p><b>For Beginners:</b> This controls how many specialist networks you want in your model.
<p>The default value of 4 means you'll have 4 different expert networks:</p>
<ul>
<li>Each expert can learn to specialize in different types of patterns</li>
<li>Think of it like having 4 specialists on your team</li>
</ul>
<p>You might want more experts if:</p>
<ul>
<li>Your problem has many distinct types of patterns or sub-tasks</li>
<li>You have a large dataset and lots of computing power</li>
<li>You want maximum model capacity</li>
</ul>
<p>You might want fewer experts if:</p>
<ul>
<li>Your problem is relatively simple</li>
<li>You have limited computing resources or data</li>
<li>You want faster training and inference</li>
</ul>
<p>Typical values range from 2-16 experts. Start with 4-8 for most problems.</p>

</div>




  <a id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_OutputDim_" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.OutputDim*"></a>

  <h3 id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_OutputDim" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.OutputDim">
  OutputDim
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/MixtureOfExpertsOptions.cs/#L161"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the output dimension for each expert network.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int OutputDim { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The output dimension, defaulting to 128.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_OutputDim_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This parameter specifies the dimensionality of the output produced by each expert. In many
architectures, this matches the input dimension to allow for residual connections and easier
stacking of MoE layers. However, it can differ if the MoE layer is designed to change the
dimensionality of the representations.
</p>
<p><b>For Beginners:</b> This is the size of the output from each expert.
<p>The default value of 128 means:</p>
<ul>
<li>Each expert produces 128-dimensional output vectors</li>
<li>Often set equal to InputDim for symmetry</li>
</ul>
<p>Common patterns:</p>
<ul>
<li>Same as InputDim (128→128): Maintains dimension, good for stacking multiple MoE layers</li>
<li>Different size: If you want to compress (128→64) or expand (64→128) the representation</li>
</ul>
<p>This value should match:</p>
<ul>
<li>The input size expected by the next layer in your network, OR</li>
<li>The final output size if MoE is the last hidden layer</li>
</ul>
<p>For most applications, keeping InputDim == OutputDim (both 128) works well.</p>

</div>




  <a id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_RandomSeed_" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.RandomSeed*"></a>

  <h3 id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_RandomSeed" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.RandomSeed">
  RandomSeed
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/MixtureOfExpertsOptions.cs/#L293"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the random seed for expert initialization.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int? RandomSeed { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>?</dt>
    <dd><p>The random seed, defaulting to null for non-deterministic initialization.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_RandomSeed_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
When set, this seed ensures deterministic initialization of expert networks and the gating network,
making training reproducible. When null, initialization uses a non-deterministic seed, leading to
different results across runs. Reproducibility is important for research, debugging, and production
systems where consistent behavior is required.
</p>
<p><b>For Beginners:</b> This controls whether training produces the same results every time.
<p>The default value of null means:</p>
<ul>
<li>Each training run will produce slightly different results</li>
<li>Initial weights are randomly chosen each time</li>
</ul>
<p>Set a specific number (e.g., 42) for reproducibility:</p>
<ul>
<li>Same seed = same initial weights = same training trajectory</li>
<li>Useful for debugging, comparing changes, or research</li>
</ul>
<p>Example usage:</p>
<ul>
<li>RandomSeed = null: Different results each time (fine for production)</li>
<li>RandomSeed = 42: Same results each time (good for debugging/research)</li>
</ul>
<p>Note: This only controls initialization. Other factors like data shuffling may still introduce variability.</p>

</div>




  <a id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_TopK_" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.TopK*"></a>

  <h3 id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_TopK" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.TopK">
  TopK
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/MixtureOfExpertsOptions.cs/#L100"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the number of experts to activate for each input (Top-K routing).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int TopK { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The Top-K value, defaulting to 2.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_TopK_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This parameter determines how many experts process each input in a sparse activation pattern. Only
the K experts with the highest routing probabilities are activated for each input, while others are
skipped. This sparse activation is key to the efficiency of MoE models. The value should typically
be much smaller than the total number of experts. Common choices are 1-2 for efficiency or 2-4 for
better quality. TopK must be less than or equal to NumExperts.
</p>
<p><b>For Beginners:</b> This determines how many experts actually process each input.
<p>The default value of 2 means:</p>
<ul>
<li>For each input, only the 2 best-suited experts are activated</li>
<li>The other experts are skipped (saving computation)</li>
<li>The gating network learns which experts are best for each input</li>
</ul>
<p>Think of it like consulting specialists:</p>
<ul>
<li>You don't need to see all 4 specialists for every case</li>
<li>The triage system picks the 2 most relevant ones</li>
<li>You get expert opinions while saving time</li>
</ul>
<p>TopK = 1: Fastest, each input goes to only one expert
TopK = 2: Good balance (recommended default)
TopK = 4+: More experts per input, higher quality but slower</p>
<p>The value must be at least 1 and at most equal to NumExperts.</p>

</div>




  <a id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_UseLoadBalancing_" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.UseLoadBalancing*"></a>

  <h3 id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_UseLoadBalancing" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.UseLoadBalancing">
  UseLoadBalancing
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/MixtureOfExpertsOptions.cs/#L227"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets whether to enable auxiliary load balancing loss.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public bool UseLoadBalancing { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True to enable load balancing, defaulting to true.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_UseLoadBalancing_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
When enabled, the model adds an auxiliary loss term that encourages balanced utilization of all
experts. Without load balancing, the model may learn to use only a subset of experts, wasting
capacity. The load balancing loss measures the deviation from uniform expert usage and penalizes
imbalanced routing decisions. This is crucial for effective MoE training, especially with larger
numbers of experts. The strength of this loss is controlled by LoadBalancingWeight.
</p>
<p><b>For Beginners:</b> This prevents some experts from being ignored during training.
<p>The default value of true means load balancing is enabled:</p>
<ul>
<li>Without this, the model might only use 1-2 experts and ignore the rest</li>
<li>Load balancing encourages all experts to be utilized</li>
<li>Think of it like ensuring all team members contribute, not just a few favorites</li>
</ul>
<p>Why this matters:</p>
<ul>
<li>You're paying the cost (memory, parameters) for all experts</li>
<li>If only some are used, you're wasting resources</li>
<li>Balanced usage leads to better model capacity and performance</li>
</ul>
<p>When to disable (UseLoadBalancing = false):</p>
<ul>
<li>Only for experimentation or debugging</li>
<li>Generally, you should keep this enabled</li>
</ul>
<p>Recommended: Keep the default value of true for nearly all applications.</p>

</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_Validate_" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.Validate*"></a>

  <h3 id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_Validate" data-uid="AiDotNet.Models.Options.MixtureOfExpertsOptions`1.Validate">
  Validate()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/MixtureOfExpertsOptions.cs/#L317"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Validates that all option values are within acceptable ranges.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void Validate()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_Models_Options_MixtureOfExpertsOptions_1_Validate_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method checks all configuration parameters to ensure they meet the requirements for a valid
MoE model. It verifies dimensional constraints, expert counts, routing parameters, and other settings.
Calling this method before model construction helps catch configuration errors early.
</p>
<p><b>For Beginners:</b> This method checks that all your settings make sense together.
<p>It validates things like:</p>
<ul>
<li>You have at least 1 expert</li>
<li>TopK isn't larger than the number of experts</li>
<li>Dimensions are positive numbers</li>
<li>Load balancing weight is non-negative</li>
</ul>
<p>This catches mistakes before they cause problems during training.
You don't need to call this manually - it's called automatically when creating the model.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentoutofrangeexception">ArgumentOutOfRangeException</a></dt>
    <dd><p>Thrown when any option value is invalid.</p>
</dd>
  </dl>




</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/MixtureOfExpertsOptions.cs/#L35" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
