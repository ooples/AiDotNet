<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class TransformerArchitecture&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class TransformerArchitecture&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Defines the architecture configuration for a Transformer neural network.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_NeuralNetworks_TransformerArchitecture_1.md&amp;value=---%0Auid%3A%20AiDotNet.NeuralNetworks.TransformerArchitecture%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1">



  <h1 id="AiDotNet_NeuralNetworks_TransformerArchitecture_1" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1" class="text-break">
Class TransformerArchitecture&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/TransformerArchitecture.cs/#L31"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.NeuralNetworks.html">NeuralNetworks</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Defines the architecture configuration for a Transformer neural network.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class TransformerArchitecture&lt;T&gt; : NeuralNetworkArchitecture&lt;T&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The data type used for calculations (typically float or double).</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html">NeuralNetworkArchitecture</a>&lt;T&gt;</div>
      <div><span class="xref">TransformerArchitecture&lt;T&gt;</span></div>
    </dd>
  </dl>



  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_Layers">NeuralNetworkArchitecture&lt;T&gt;.Layers</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_InputType">NeuralNetworkArchitecture&lt;T&gt;.InputType</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_InputSize">NeuralNetworkArchitecture&lt;T&gt;.InputSize</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_OutputSize">NeuralNetworkArchitecture&lt;T&gt;.OutputSize</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_InputHeight">NeuralNetworkArchitecture&lt;T&gt;.InputHeight</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_InputWidth">NeuralNetworkArchitecture&lt;T&gt;.InputWidth</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_InputDepth">NeuralNetworkArchitecture&lt;T&gt;.InputDepth</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_ImageEmbeddingDim">NeuralNetworkArchitecture&lt;T&gt;.ImageEmbeddingDim</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_TextEmbeddingDim">NeuralNetworkArchitecture&lt;T&gt;.TextEmbeddingDim</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_TaskType">NeuralNetworkArchitecture&lt;T&gt;.TaskType</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_Complexity">NeuralNetworkArchitecture&lt;T&gt;.Complexity</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_UseAutodiff">NeuralNetworkArchitecture&lt;T&gt;.UseAutodiff</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_InputDimension">NeuralNetworkArchitecture&lt;T&gt;.InputDimension</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_CalculatedInputSize">NeuralNetworkArchitecture&lt;T&gt;.CalculatedInputSize</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_ShouldReturnFullSequence">NeuralNetworkArchitecture&lt;T&gt;.ShouldReturnFullSequence</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_IsInitialized">NeuralNetworkArchitecture&lt;T&gt;.IsInitialized</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_GetHiddenLayerSizes">NeuralNetworkArchitecture&lt;T&gt;.GetHiddenLayerSizes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_GetInputShape">NeuralNetworkArchitecture&lt;T&gt;.GetInputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_GetOutputShape">NeuralNetworkArchitecture&lt;T&gt;.GetOutputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_CalculateOutputSize">NeuralNetworkArchitecture&lt;T&gt;.CalculateOutputSize()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_GetLayerSizes">NeuralNetworkArchitecture&lt;T&gt;.GetLayerSizes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.NeuralNetworkArchitecture-1.html#AiDotNet_NeuralNetworks_NeuralNetworkArchitecture_1_InitializeFromCachedData">NeuralNetworkArchitecture&lt;T&gt;.InitializeFromCachedData()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
The TransformerArchitecture class encapsulates all the hyperparameters and configuration options
needed to define a Transformer neural network. It includes settings for the encoder and decoder stacks,
attention mechanisms, model dimensions, and other key aspects that determine the network's structure
and behavior.
</p>
<p>
Transformers are particularly effective for sequence-based tasks like natural language processing,
translation, text summarization, and other tasks that benefit from understanding the relationships
between elements in a sequence.
</p>
<p><b>For Beginners:</b> Think of this class as a blueprint for building a Transformer.
<p>Just like building a house requires decisions about how many rooms, how big each room should be,
and what materials to use, building a Transformer requires decisions about:</p>
<ul>
<li>How many layers of processing to include</li>
<li>How much information to process at once</li>
<li>How to connect different parts of the network</li>
</ul>
<p>This class stores all those decisions in one place, making it easier to create Transformer
networks with different capabilities for different tasks.</p>

</div>


  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_NeuralNetworks_TransformerArchitecture_1__ctor_" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.#ctor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_TransformerArchitecture_1__ctor_AiDotNet_Enums_InputType_AiDotNet_Enums_NeuralNetworkTaskType_System_Int32_System_Int32_System_Int32_System_Int32_System_Int32_AiDotNet_Enums_NetworkComplexity_System_Int32_System_Int32_System_Double_System_Int32_System_Int32_System_Boolean_System_Double_System_Collections_Generic_List_AiDotNet_Interfaces_ILayer__0___" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.#ctor(AiDotNet.Enums.InputType,AiDotNet.Enums.NeuralNetworkTaskType,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,AiDotNet.Enums.NetworkComplexity,System.Int32,System.Int32,System.Double,System.Int32,System.Int32,System.Boolean,System.Double,System.Collections.Generic.List{AiDotNet.Interfaces.ILayer{`0}})">
  TransformerArchitecture(InputType, NeuralNetworkTaskType, int, int, int, int, int, NetworkComplexity, int, int, double, int, int, bool, double, List&lt;ILayer&lt;T&gt;&gt;?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/TransformerArchitecture.cs/#L308"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the <a class="xref" href="AiDotNet.NeuralNetworks.TransformerArchitecture-1.html">TransformerArchitecture&lt;T&gt;</a> class with the specified parameters.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public TransformerArchitecture(InputType inputType, NeuralNetworkTaskType taskType, int numEncoderLayers, int numDecoderLayers, int numHeads, int modelDimension, int feedForwardDimension, NetworkComplexity complexity = NetworkComplexity.Medium, int inputSize = 0, int outputSize = 0, double dropoutRate = 0.1, int maxSequenceLength = 512, int vocabularySize = 0, bool usePositionalEncoding = true, double temperature = 1, List&lt;ILayer&lt;T&gt;&gt;? layers = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputType</code> <a class="xref" href="AiDotNet.Enums.InputType.html">InputType</a></dt>
    <dd><p>The type of input the network will process (e.g., text, image).</p>
</dd>
    <dt><code>taskType</code> <a class="xref" href="AiDotNet.Enums.NeuralNetworkTaskType.html">NeuralNetworkTaskType</a></dt>
    <dd><p>The type of task the network will perform (e.g., classification, generation).</p>
</dd>
    <dt><code>numEncoderLayers</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of encoder layers in the Transformer.</p>
</dd>
    <dt><code>numDecoderLayers</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of decoder layers in the Transformer.</p>
</dd>
    <dt><code>numHeads</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of attention heads in each multi-head attention layer.</p>
</dd>
    <dt><code>modelDimension</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The dimension of the model's internal representations.</p>
</dd>
    <dt><code>feedForwardDimension</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The dimension of the feed-forward networks within the Transformer layers.</p>
</dd>
    <dt><code>complexity</code> <a class="xref" href="AiDotNet.Enums.NetworkComplexity.html">NetworkComplexity</a></dt>
    <dd><p>The overall complexity level of the network. Defaults to Medium.</p>
</dd>
    <dt><code>inputSize</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The size of the input for simple vector inputs. Defaults to 0.</p>
</dd>
    <dt><code>outputSize</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The size of the output of the network. Defaults to 0.</p>
</dd>
    <dt><code>dropoutRate</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The dropout rate used for regularization. Defaults to 0.1.</p>
</dd>
    <dt><code>maxSequenceLength</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The maximum length of input sequences. Defaults to 512.</p>
</dd>
    <dt><code>vocabularySize</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The size of the vocabulary for text-based tasks. Defaults to 0.</p>
</dd>
    <dt><code>usePositionalEncoding</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Whether to use positional encoding. Defaults to true.</p>
</dd>
    <dt><code>temperature</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The temperature parameter for text generation. Defaults to 1.0.</p>
</dd>
    <dt><code>layers</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.list-1">List</a>&lt;<a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;&gt;</dt>
    <dd><p>Optional custom layers for the network. Defaults to null.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_TransformerArchitecture_1__ctor_AiDotNet_Enums_InputType_AiDotNet_Enums_NeuralNetworkTaskType_System_Int32_System_Int32_System_Int32_System_Int32_System_Int32_AiDotNet_Enums_NetworkComplexity_System_Int32_System_Int32_System_Double_System_Int32_System_Int32_System_Boolean_System_Double_System_Collections_Generic_List_AiDotNet_Interfaces_ILayer__0____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This constructor initializes a new TransformerArchitecture with the specified parameters, which will
define the structure and behavior of a Transformer neural network. It passes the basic network
parameters to the base NeuralNetworkArchitecture class and initializes the Transformer-specific
parameters.
</p>
<p><b>For Beginners:</b> This constructor is where you set all the options for your Transformer.
<p>When creating a new Transformer architecture, you need to decide:</p>
<ul>
<li>What kind of input it will process (text, images, etc.)</li>
<li>What task it will perform (translation, classification, etc.)</li>
<li>How big and powerful the model should be</li>
<li>How it will handle and process sequences</li>
</ul>
<p>Many parameters have default values that work well for common cases, so you only need to specify
the ones that are important for your specific task.</p>
<p>Think of it like configuring a new computer - you specify the components and settings
that matter for what you'll be using it for.</p>

</div>




  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_DropoutRate_" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.DropoutRate*"></a>

  <h3 id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_DropoutRate" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.DropoutRate">
  DropoutRate
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/TransformerArchitecture.cs/#L167"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the dropout rate used for regularization in the Transformer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double DropoutRate { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_DropoutRate_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Dropout is a regularization technique that helps prevent overfitting by randomly "dropping out"
(setting to zero) a portion of the neurons during training. The dropout rate specifies the
probability of each neuron being dropped.
</p>
<p><b>For Beginners:</b> Dropout rate is like training with random challenges to improve resilience.
<p>Think of dropout as training a team where:</p>
<ul>
<li>During practice, random team members sit out temporarily</li>
<li>This forces the remaining members to adapt and work without relying too much on specific teammates</li>
<li>When the full team plays together later, they perform better and more robustly</li>
</ul>
<p>A typical dropout rate is around 0.1 (10%), meaning each neuron has a 10% chance of being temporarily
disabled during training. This helps prevent the model from becoming too dependent on specific
neurons, making it more robust.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_FeedForwardDimension_" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.FeedForwardDimension*"></a>

  <h3 id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_FeedForwardDimension" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.FeedForwardDimension">
  FeedForwardDimension
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/TransformerArchitecture.cs/#L144"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the dimension of the feed-forward networks within the Transformer layers.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int FeedForwardDimension { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_FeedForwardDimension_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Each Transformer layer contains a feed-forward network that processes the output of the
attention mechanism. The feed-forward dimension determines the intermediate size of this
network, which affects its capacity to transform and process the attended information.
</p>
<p><b>For Beginners:</b> Feed-forward dimension is like the processing power in each layer.
<p>The feed-forward networks:</p>
<ul>
<li>Process the information after the attention mechanism has focused on relevant parts</li>
<li>Transform the data to extract useful patterns and relationships</li>
<li>Usually have a larger dimension than the model dimension to allow for more processing capacity</li>
</ul>
<p>A larger feed-forward dimension generally allows the model to learn more complex transformations,
but requires more computation. It's common for this value to be 4 times the model dimension.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_MaxSequenceLength_" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.MaxSequenceLength*"></a>

  <h3 id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_MaxSequenceLength" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.MaxSequenceLength">
  MaxSequenceLength
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/TransformerArchitecture.cs/#L191"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the maximum length of input sequences that the Transformer can process.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int MaxSequenceLength { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_MaxSequenceLength_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This parameter limits the length of input sequences that the model can handle. It affects
the memory requirements and computational cost of the model, as longer sequences require
more resources to process. It also determines the maximum range of dependencies that the
model can capture.
</p>
<p><b>For Beginners:</b> Maximum sequence length is like the longest text the model can read at once.
<p>This setting:</p>
<ul>
<li>Limits how long your input can be (like number of words in a sentence)</li>
<li>Affects how much memory the model needs</li>
<li>Determines how far apart relationships can be captured</li>
</ul>
<p>For example, a max sequence length of 512 means the model can process texts up to 512 tokens long
(roughly 384-512 words in English). Longer texts would need to be broken into smaller chunks.
Common values range from 512 to 2048, with larger models supporting longer sequences.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_ModelDimension_" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.ModelDimension*"></a>

  <h3 id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_ModelDimension" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.ModelDimension">
  ModelDimension
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/TransformerArchitecture.cs/#L122"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the dimension of the model's internal representations.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int ModelDimension { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_ModelDimension_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The model dimension determines the size of the vectors used to represent each element in the
input and output sequences. It affects the model's capacity to store information and its
ability to capture complex patterns in the data.
</p>
<p><b>For Beginners:</b> Model dimension is like the size of the "memory" for each word or element.
<p>A larger model dimension means:</p>
<ul>
<li>Each word or element carries more information</li>
<li>The model can represent more subtle meanings and relationships</li>
<li>The network becomes more powerful but requires more memory and computation</li>
</ul>
<p>For example, a model dimension of 512 means each word is represented by 512 numbers,
which can capture various aspects of its meaning, grammatical role, and relationships
with other words.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_NumDecoderLayers_" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.NumDecoderLayers*"></a>

  <h3 id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_NumDecoderLayers" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.NumDecoderLayers">
  NumDecoderLayers
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/TransformerArchitecture.cs/#L76"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the number of decoder layers in the Transformer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int NumDecoderLayers { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_NumDecoderLayers_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Decoder layers are used to generate output sequences based on both the encoded input and
the previously generated elements of the output. Each decoder layer typically includes
both self-attention and cross-attention mechanisms followed by a feed-forward network.
</p>
<p><b>For Beginners:</b> Decoder layers are like writing stations that create your output data.
<p>Decoder layers:</p>
<ul>
<li>Generate responses or translations one element at a time</li>
<li>Look at both what they've already generated and the original input</li>
<li>Help ensure the output is coherent and relevant to the input</li>
</ul>
<p>For example, in a translation task, decoder layers would generate the translated text
word by word, making sure each new word fits with both the original text and the
translation so far.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_NumEncoderLayers_" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.NumEncoderLayers*"></a>

  <h3 id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_NumEncoderLayers" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.NumEncoderLayers">
  NumEncoderLayers
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/TransformerArchitecture.cs/#L53"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the number of encoder layers in the Transformer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int NumEncoderLayers { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_NumEncoderLayers_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Encoder layers process the input sequence and create representations that capture the meaning
and context of each element in the sequence. Each encoder layer typically consists of a
self-attention mechanism followed by a feed-forward network.
</p>
<p><b>For Beginners:</b> Encoder layers are like processing stations that understand your input data.
<p>More encoder layers mean:</p>
<ul>
<li>The network can understand more complex patterns</li>
<li>It can capture deeper relationships between words or elements</li>
<li>The model becomes more powerful but also more computationally expensive</li>
</ul>
<p>For example, with text processing, more encoder layers help the model better understand
the subtle meanings and connections between words in a sentence.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_NumHeads_" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.NumHeads*"></a>

  <h3 id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_NumHeads" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.NumHeads">
  NumHeads
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/TransformerArchitecture.cs/#L99"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the number of attention heads in each multi-head attention layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int NumHeads { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_NumHeads_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Attention heads allow the model to focus on different aspects of the input simultaneously.
Each head can learn to attend to different types of relationships or patterns in the data.
Having multiple heads improves the model's ability to capture diverse aspects of the input.
</p>
<p><b>For Beginners:</b> Attention heads are like different perspectives on the same information.
<p>Think of attention heads as different people reading the same text:</p>
<ul>
<li>One person might focus on the main characters</li>
<li>Another might focus on the setting or time period</li>
<li>A third might focus on the emotional tone</li>
</ul>
<p>By combining these different perspectives, the model gets a more complete understanding.
More heads generally means the model can capture more nuanced relationships,
but also requires more computation.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_Temperature_" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.Temperature*"></a>

  <h3 id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_Temperature" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.Temperature">
  Temperature
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/TransformerArchitecture.cs/#L261"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the temperature parameter used for controlling randomness in text generation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double Temperature { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_Temperature_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Temperature is a parameter that controls the randomness of text generation in models like
Transformers. A higher temperature increases randomness and creativity, while a lower
temperature makes the model more deterministic and focused on the most likely outputs.
</p>
<p><b>For Beginners:</b> Temperature is like a creativity dial for text generation.
<p>Think of temperature as controlling how &quot;creative&quot; or &quot;predictable&quot; the model's outputs are:</p>
<ul>
<li>Low temperature (e.g., 0.3): More focused, predictable responses</li>
<li>Medium temperature (e.g., 1.0): Balanced between predictability and creativity</li>
<li>High temperature (e.g., 1.5): More diverse, surprising, and creative outputs</li>
</ul>
<p>For example, when generating story ideas:</p>
<ul>
<li>Low temperature might give conventional plots</li>
<li>High temperature might give unusual or unexpected storylines</li>
</ul>
<p>This parameter is only relevant for text generation tasks, not for classification or other tasks.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_UsePositionalEncoding_" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.UsePositionalEncoding*"></a>

  <h3 id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_UsePositionalEncoding" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.UsePositionalEncoding">
  UsePositionalEncoding
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/TransformerArchitecture.cs/#L236"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets a value indicating whether positional encoding is used in the Transformer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public bool UsePositionalEncoding { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_UsePositionalEncoding_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Transformers don't inherently capture the order of elements in a sequence, as they process all
elements in parallel. Positional encoding adds information about the position of each element
to its representation, allowing the model to understand the sequence order.
</p>
<p><b>For Beginners:</b> Positional encoding is like adding page numbers to a book.
<p>Without positional encoding:</p>
<ul>
<li>The model would see all words at once, but wouldn't know their order</li>
<li>&quot;The dog chased the cat&quot; and &quot;The cat chased the dog&quot; would look the same</li>
</ul>
<p>Positional encoding adds location information to each word, so the model knows which word
comes first, second, and so on. This is usually set to true, as order is critical for
understanding most sequences.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_VocabularySize_" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.VocabularySize*"></a>

  <h3 id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_VocabularySize" data-uid="AiDotNet.NeuralNetworks.TransformerArchitecture`1.VocabularySize">
  VocabularySize
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/TransformerArchitecture.cs/#L214"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the size of the vocabulary for text-based tasks.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int VocabularySize { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_TransformerArchitecture_1_VocabularySize_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
For natural language processing tasks, this parameter determines the number of unique tokens
(typically words or subwords) that the model can recognize and generate. A larger vocabulary
allows for more precise representation of language but increases the model size.
</p>
<p><b>For Beginners:</b> Vocabulary size is like the dictionary the model uses.
<p>The vocabulary size:</p>
<ul>
<li>Defines how many different words or word pieces the model knows</li>
<li>Affects the model's ability to understand rare or specialized terms</li>
<li>Impacts the memory requirements of the model</li>
</ul>
<p>For example, a vocabulary size of 30,000 means the model can recognize and use 30,000 different
words or subword units. Larger vocabularies help with specialized terminology but make the model
larger. Common sizes range from 10,000 to 50,000 for general language models.</p>

</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/TransformerArchitecture.cs/#L31" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
