<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class PiSSAAdapter&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class PiSSAAdapter&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Principal Singular Values and Singular Vectors Adaptation (PiSSA) adapter for parameter-efficient fine-tuning.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_LoRA_Adapters_PiSSAAdapter_1.md&amp;value=---%0Auid%3A%20AiDotNet.LoRA.Adapters.PiSSAAdapter%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1">



  <h1 id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1" class="text-break">
Class PiSSAAdapter&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/PiSSAAdapter.cs/#L66"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.LoRA.html">LoRA</a>.<a class="xref" href="AiDotNet.LoRA.Adapters.html">Adapters</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Principal Singular Values and Singular Vectors Adaptation (PiSSA) adapter for parameter-efficient fine-tuning.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class PiSSAAdapter&lt;T&gt; : LoRAAdapterBase&lt;T&gt;, IDisposable, ILoRAAdapter&lt;T&gt;, ILayer&lt;T&gt;, IJitCompilable&lt;T&gt;, IDiagnosticsProvider, IWeightLoadable&lt;T&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for calculations, typically float or double.</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html">LayerBase</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html">LoRAAdapterBase</a>&lt;T&gt;</div>
      <div><span class="xref">PiSSAAdapter&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.idisposable">IDisposable</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.ILoRAAdapter-1.html">ILoRAAdapter</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IJitCompilable-1.html">IJitCompilable</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IDiagnosticsProvider.html">IDiagnosticsProvider</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.IWeightLoadable-1.html">IWeightLoadable</a>&lt;T&gt;</div>
    </dd>
  </dl>


  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1__baseLayer">LoRAAdapterBase&lt;T&gt;._baseLayer</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1__loraLayer">LoRAAdapterBase&lt;T&gt;._loraLayer</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1__freezeBaseLayer">LoRAAdapterBase&lt;T&gt;._freezeBaseLayer</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_BaseLayer">LoRAAdapterBase&lt;T&gt;.BaseLayer</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_LoRALayer">LoRAAdapterBase&lt;T&gt;.LoRALayer</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_IsBaseLayerFrozen">LoRAAdapterBase&lt;T&gt;.IsBaseLayerFrozen</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Rank">LoRAAdapterBase&lt;T&gt;.Rank</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Alpha">LoRAAdapterBase&lt;T&gt;.Alpha</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_ParameterCount">LoRAAdapterBase&lt;T&gt;.ParameterCount</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_SupportsTraining">LoRAAdapterBase&lt;T&gt;.SupportsTraining</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_CreateLoRALayer_System_Int32_System_Double_">LoRAAdapterBase&lt;T&gt;.CreateLoRALayer(int, double)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_UpdateParameters__0_">LoRAAdapterBase&lt;T&gt;.UpdateParameters(T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_GetParameters">LoRAAdapterBase&lt;T&gt;.GetParameters()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_SetParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LoRAAdapterBase&lt;T&gt;.SetParameters(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_CreateMergedLayerWithClone_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LoRAAdapterBase&lt;T&gt;.CreateMergedLayerWithClone(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_MergeToDenseOrFullyConnected">LoRAAdapterBase&lt;T&gt;.MergeToDenseOrFullyConnected()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_UpdateParametersFromLayers">LoRAAdapterBase&lt;T&gt;.UpdateParametersFromLayers()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_ResetState">LoRAAdapterBase&lt;T&gt;.ResetState()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_SupportsJitCompilation">LoRAAdapterBase&lt;T&gt;.SupportsJitCompilation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html#AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0___">LoRAAdapterBase&lt;T&gt;.ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Engine">LayerBase&lt;T&gt;.Engine</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ScalarActivation">LayerBase&lt;T&gt;.ScalarActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_VectorActivation">LayerBase&lt;T&gt;.VectorActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UsingVectorActivation">LayerBase&lt;T&gt;.UsingVectorActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_NumOps">LayerBase&lt;T&gt;.NumOps</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Random">LayerBase&lt;T&gt;.Random</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Parameters">LayerBase&lt;T&gt;.Parameters</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ParameterGradients">LayerBase&lt;T&gt;.ParameterGradients</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShape">LayerBase&lt;T&gt;.InputShape</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShapes">LayerBase&lt;T&gt;.InputShapes</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateInputShape_System_Int32___">LayerBase&lt;T&gt;.UpdateInputShape(int[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_OutputShape">LayerBase&lt;T&gt;.OutputShape</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsTrainingMode">LayerBase&lt;T&gt;.IsTrainingMode</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationStrategy">LayerBase&lt;T&gt;.InitializationStrategy</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsInitialized">LayerBase&lt;T&gt;.IsInitialized</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationLock">LayerBase&lt;T&gt;.InitializationLock</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_EnsureInitialized">LayerBase&lt;T&gt;.EnsureInitialized()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UseAutodiff">LayerBase&lt;T&gt;.UseAutodiff</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetTrainingMode_System_Boolean_">LayerBase&lt;T&gt;.SetTrainingMode(bool)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterGradients">LayerBase&lt;T&gt;.GetParameterGradients()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ClearGradients">LayerBase&lt;T&gt;.ClearGradients()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShape">LayerBase&lt;T&gt;.GetInputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShapes">LayerBase&lt;T&gt;.GetInputShapes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetOutputShape">LayerBase&lt;T&gt;.GetOutputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetWeights">LayerBase&lt;T&gt;.GetWeights()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetBiases">LayerBase&lt;T&gt;.GetBiases()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_MapActivationToFused">LayerBase&lt;T&gt;.MapActivationToFused()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuExecution">LayerBase&lt;T&gt;.SupportsGpuExecution</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuTraining">LayerBase&lt;T&gt;.SupportsGpuTraining</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanExecuteOnGpu">LayerBase&lt;T&gt;.CanExecuteOnGpu</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanTrainOnGpu">LayerBase&lt;T&gt;.CanTrainOnGpu</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ForwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0____">LayerBase&lt;T&gt;.ForwardGpu(params IGpuTensor&lt;T&gt;[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_BackwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0__">LayerBase&lt;T&gt;.BackwardGpu(IGpuTensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParametersGpu_AiDotNet_Interfaces_IGpuOptimizerConfig_">LayerBase&lt;T&gt;.UpdateParametersGpu(IGpuOptimizerConfig)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UploadWeightsToGpu">LayerBase&lt;T&gt;.UploadWeightsToGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_DownloadWeightsFromGpu">LayerBase&lt;T&gt;.DownloadWeightsFromGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ZeroGradientsGpu">LayerBase&lt;T&gt;.ZeroGradientsGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetActivationTypes">LayerBase&lt;T&gt;.GetActivationTypes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0____">LayerBase&lt;T&gt;.Forward(params Tensor&lt;T&gt;[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ApplyActivation(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ApplyActivation(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ActivateTensor(IActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IVectorActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ActivateTensor(IVectorActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateInputShape_System_Int32_System_Int32_System_Int32_">LayerBase&lt;T&gt;.CalculateInputShape(int, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateOutputShape_System_Int32_System_Int32_System_Int32_">LayerBase&lt;T&gt;.CalculateOutputShape(int, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Clone">LayerBase&lt;T&gt;.Clone()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_DerivativeTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.DerivativeTensor(IActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative__0__0_">LayerBase&lt;T&gt;.ApplyActivationDerivative(T, T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ApplyActivationDerivative(Tensor&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ComputeActivationJacobian_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ComputeActivationJacobian(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Vector__0__AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ApplyActivationDerivative(Vector&lt;T&gt;, Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.UpdateParameters(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Serialize_System_IO_BinaryWriter_">LayerBase&lt;T&gt;.Serialize(BinaryWriter)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Deserialize_System_IO_BinaryReader_">LayerBase&lt;T&gt;.Deserialize(BinaryReader)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetDiagnostics">LayerBase&lt;T&gt;.GetDiagnostics()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationToGraph_AiDotNet_Autodiff_ComputationNode__0__">LayerBase&lt;T&gt;.ApplyActivationToGraph(ComputationNode&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanActivationBeJitted">LayerBase&lt;T&gt;.CanActivationBeJitted()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_RegisterTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_Engines_PersistentTensorRole_">LayerBase&lt;T&gt;.RegisterTrainableParameter(Tensor&lt;T&gt;, PersistentTensorRole)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InvalidateTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.InvalidateTrainableParameter(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_HasGpuActivation">LayerBase&lt;T&gt;.HasGpuActivation()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationForwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">LayerBase&lt;T&gt;.ApplyActivationForwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationBackwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">LayerBase&lt;T&gt;.ApplyActivationBackwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetFusedActivationType">LayerBase&lt;T&gt;.GetFusedActivationType()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivation_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_">LayerBase&lt;T&gt;.ApplyGpuActivation(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int, FusedActivationType)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivationBackward_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_System_Single_">LayerBase&lt;T&gt;.ApplyGpuActivationBackward(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int, FusedActivationType, float)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose">LayerBase&lt;T&gt;.Dispose()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose_System_Boolean_">LayerBase&lt;T&gt;.Dispose(bool)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_WeightParameterName">LayerBase&lt;T&gt;.WeightParameterName</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_BiasParameterName">LayerBase&lt;T&gt;.BiasParameterName</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetWeights_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetWeights(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetBiases_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetBiases(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterNames">LayerBase&lt;T&gt;.GetParameterNames()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_TryGetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___">LayerBase&lt;T&gt;.TryGetParameter(string, out Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetParameter(string, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterShape_System_String_">LayerBase&lt;T&gt;.GetParameterShape(string)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_NamedParameterCount">LayerBase&lt;T&gt;.NamedParameterCount</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ValidateWeights_System_Collections_Generic_IEnumerable_System_String__System_Func_System_String_System_String__">LayerBase&lt;T&gt;.ValidateWeights(IEnumerable&lt;string&gt;, Func&lt;string, string&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_LoadWeights_System_Collections_Generic_Dictionary_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___System_Func_System_String_System_String__System_Boolean_">LayerBase&lt;T&gt;.LoadWeights(Dictionary&lt;string, Tensor&lt;T&gt;&gt;, Func&lt;string, string&gt;, bool)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
PiSSA (NeurIPS 2024 Spotlight) improves upon standard LoRA by initializing adapter matrices with
principal components from Singular Value Decomposition (SVD) of pretrained weights, rather than
random initialization. This results in more effective use of the rank budget and faster convergence.
</p>
<p><b>Key Differences from Standard LoRA:</b>
- Standard LoRA: A initialized randomly, B initialized to zero
- PiSSA: A and B initialized from top-r singular vectors of pretrained weights
- Standard LoRA: All weights trainable
- PiSSA: Residual weights frozen, only top-r components trainable
</p>
<p><b>How PiSSA Works:</b>
1. Perform SVD on pretrained weights: W = U Σ V^T
2. Initialize adapter matrices from top-r components:
   - A = V_r (top-r right singular vectors, dimensions: inputSize × rank)
   - B = Σ_r * U_r^T (top-r left singular vectors scaled by singular values, dimensions: rank × outputSize)
3. Freeze residual matrix: W_residual = W - (A*B)^T
4. During training: output = W_residual * input + LoRA(input)
5. Only B and A are updated; W_residual stays frozen
</p>
<p><b>Performance Benefits:</b>
PiSSA achieves superior performance compared to standard LoRA:
- GSM8K benchmark: 72.86% (PiSSA) vs 67.7% (LoRA)
- Better initialization captures important pretrained knowledge
- More effective gradient updates from the start
- Faster convergence with fewer training steps
</p>
<p><b>For Beginners:</b> Think of PiSSA as "smart LoRA initialization".
<p>Standard LoRA starts from random:</p>
<ul>
<li>Random A matrix (like throwing darts blindfolded)</li>
<li>Zero B matrix (starts with no effect)</li>
<li>Learns everything from scratch</li>
</ul>
<p>PiSSA starts from the most important parts of pretrained weights:</p>
<ul>
<li>A and B capture the top-r &quot;principal directions&quot; of the pretrained model</li>
<li>Starts closer to the optimal solution</li>
<li>Like starting a puzzle with the border pieces already connected</li>
</ul>
<p>Example: If you have a pretrained language model with a 4096x4096 weight matrix,
PiSSA with rank=8 will:</p>
<ol>
<li>Find the top 8 most important patterns in those weights via SVD</li>
<li>Put those patterns into A and B (making them trainable)</li>
<li>Freeze the remaining &quot;less important&quot; patterns</li>
<li>Train only the top 8 patterns to adapt to your task</li>
</ol>
<p>This is much more efficient than starting from random and achieves better results!</p>

<p><b>References:</b>
- Paper: "PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models"
- Venue: NeurIPS 2024 (Spotlight)
- Key Insight: SVD-based initialization &gt; random initialization for low-rank adaptation
</p>
</div>


  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1__ctor_" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.#ctor*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1__ctor_AiDotNet_Interfaces_ILayer__0__System_Int32_System_Double_System_Boolean_" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.#ctor(AiDotNet.Interfaces.ILayer{`0},System.Int32,System.Double,System.Boolean)">
  PiSSAAdapter(ILayer&lt;T&gt;, int, double, bool)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/PiSSAAdapter.cs/#L148"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new PiSSA adapter wrapping an existing layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public PiSSAAdapter(ILayer&lt;T&gt; baseLayer, int rank, double alpha = -1, bool freezeBaseLayer = true)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>baseLayer</code> <a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</dt>
    <dd><p>The layer to adapt with PiSSA.</p>
</dd>
    <dt><code>rank</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The rank of the low-rank decomposition.</p>
</dd>
    <dt><code>alpha</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The LoRA scaling factor (defaults to rank if negative).</p>
</dd>
    <dt><code>freezeBaseLayer</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Whether to freeze the base layer's parameters during training.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1__ctor_AiDotNet_Interfaces_ILayer__0__System_Int32_System_Double_System_Boolean__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This constructor creates a PiSSA adapter. After construction, you should call
InitializeFromSVD to properly initialize the adapter matrices from pretrained weights.
Without SVD initialization, the adapter behaves like standard LoRA (not recommended).
</p>
<p><b>For Beginners:</b> This creates a PiSSA adapter for any layer type.
<p>Parameters:</p>
<ul>
<li>baseLayer: The layer you want to adapt (Dense, Convolutional, etc.)</li>
<li>rank: How many principal components to use (typically 4-32)</li>
<li>alpha: Scaling factor for the adaptation strength</li>
<li>freezeBaseLayer: Usually true to freeze original weights</li>
</ul>
<p>Important: After creating the adapter, call InitializeFromSVD with the pretrained
weights to get PiSSA's performance benefits. Otherwise, it's just regular LoRA.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></dt>
    <dd><p>Thrown when baseLayer is null.</p>
</dd>
  </dl>



  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_InitializedFromSVD_" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.InitializedFromSVD*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_InitializedFromSVD" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.InitializedFromSVD">
  InitializedFromSVD
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/PiSSAAdapter.cs/#L120"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this adapter was initialized from SVD.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public bool InitializedFromSVD { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_InitializedFromSVD_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>Returns true if InitializeFromSVD was called successfully, false otherwise.</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_ResidualWeights_" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.ResidualWeights*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_ResidualWeights" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.ResidualWeights">
  ResidualWeights
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/PiSSAAdapter.cs/#L112"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the frozen residual weights matrix.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public Matrix&lt;T&gt;? ResidualWeights { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Matrix-1.html">Matrix</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_ResidualWeights_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This matrix is computed during SVD initialization and remains frozen during training.
Returns null if SVD initialization was not performed.</p>
</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_Backward_" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.Backward*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.Backward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Backward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/PiSSAAdapter.cs/#L435"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the backward pass, updating only the trainable adapter matrices (B and A).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; Backward(Tensor&lt;T&gt; outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>outputGradient</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Gradient flowing back from the next layer.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Gradient to pass to the previous layer.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The backward pass propagates gradients through both the frozen residual path and the
trainable LoRA path. However, only the LoRA parameters (A and B) are updated;
the residual weights remain frozen.
</p>
<p><b>For Beginners:</b> This is where learning happens in PiSSA.
<p>During backpropagation:</p>
<ul>
<li>Gradients flow through both the residual path and the LoRA path</li>
<li>But only the LoRA matrices (A and B) get updated</li>
<li>The residual weights stay frozen (no learning)</li>
</ul>
<p>This is the key to PiSSA's efficiency:</p>
<ul>
<li>We only train the top-r most important components</li>
<li>The rest of the weights stay fixed from pretraining</li>
<li>Fewer parameters to update = faster training and less overfitting</li>
</ul>

</div>




  <a id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_Forward_" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.Forward*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.Forward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Forward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/PiSSAAdapter.cs/#L360"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the forward pass using residual weights plus trainable PiSSA adaptation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; Forward(Tensor&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Input tensor.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Output tensor computed as: residual_output + lora_output.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
If initialized from SVD, the forward pass computes:
output = W_residual * input + LoRA(input)
<p>If not initialized from SVD (falls back to standard LoRA):
output = base_layer(input) + LoRA(input)</p>

<p><b>For Beginners:</b> This runs input through the adapter.
<p>With proper PiSSA initialization:</p>
<ul>
<li>First applies frozen residual weights (the &quot;less important&quot; parts)</li>
<li>Then adds the trainable adaptation (the &quot;important&quot; parts from A and B)</li>
<li>Result combines both for the final output</li>
</ul>
<p>Without SVD initialization (not recommended):</p>
<ul>
<li>Falls back to standard LoRA behavior</li>
<li>Uses base layer output + LoRA correction</li>
</ul>

</div>




  <a id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_InitializeFromSVD_" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.InitializeFromSVD*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_InitializeFromSVD_AiDotNet_Interfaces_ILayer__0__AiDotNet_Tensors_LinearAlgebra_Matrix__0__System_Int32_System_Double_System_Boolean_AiDotNet_Enums_AlgorithmTypes_SvdAlgorithmType_" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.InitializeFromSVD(AiDotNet.Interfaces.ILayer{`0},AiDotNet.Tensors.LinearAlgebra.Matrix{`0},System.Int32,System.Double,System.Boolean,AiDotNet.Enums.AlgorithmTypes.SvdAlgorithmType)">
  InitializeFromSVD(ILayer&lt;T&gt;, Matrix&lt;T&gt;, int, double, bool, SvdAlgorithmType)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/PiSSAAdapter.cs/#L322"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Creates a PiSSA adapter initialized from SVD of pretrained weights.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static PiSSAAdapter&lt;T&gt; InitializeFromSVD(ILayer&lt;T&gt; baseLayer, Matrix&lt;T&gt; pretrainedWeights, int rank, double alpha = -1, bool freezeBaseLayer = true, SvdAlgorithmType svdAlgorithm = SvdAlgorithmType.GolubReinsch)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>baseLayer</code> <a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</dt>
    <dd><p>The layer to adapt with PiSSA.</p>
</dd>
    <dt><code>pretrainedWeights</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Matrix-1.html">Matrix</a>&lt;T&gt;</dt>
    <dd><p>The pretrained weight matrix to decompose.</p>
</dd>
    <dt><code>rank</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The rank of the low-rank decomposition.</p>
</dd>
    <dt><code>alpha</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The LoRA scaling factor (defaults to rank if negative).</p>
</dd>
    <dt><code>freezeBaseLayer</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Whether to freeze the base layer's parameters during training.</p>
</dd>
    <dt><code>svdAlgorithm</code> <a class="xref" href="AiDotNet.Enums.AlgorithmTypes.SvdAlgorithmType.html">SvdAlgorithmType</a></dt>
    <dd><p>The SVD algorithm to use (default: GolubReinsch).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.LoRA.Adapters.PiSSAAdapter-1.html">PiSSAAdapter</a>&lt;T&gt;</dt>
    <dd><p>A PiSSA adapter initialized from SVD.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_InitializeFromSVD_AiDotNet_Interfaces_ILayer__0__AiDotNet_Tensors_LinearAlgebra_Matrix__0__System_Int32_System_Double_System_Boolean_AiDotNet_Enums_AlgorithmTypes_SvdAlgorithmType__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This static factory method creates and fully initializes a PiSSA adapter in one step.
It combines construction and SVD initialization for convenience.
</p>
<p><b>For Beginners:</b> This is the recommended way to create a PiSSA adapter.
<p>Instead of:</p>
<ol>
<li>Create adapter</li>
<li>Call InitializeFromSVD</li>
</ol>
<p>You can just:</p>
<ol>
<li>Call this method with pretrained weights</li>
</ol>
<p>Example:
var adapter = PiSSAAdapter.InitializeFromSVD(myLayer, pretrainedWeights, rank: 8);
// Ready to train!</p>

</div>




  <a id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_InitializeFromSVD_" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.InitializeFromSVD*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_InitializeFromSVD_AiDotNet_Tensors_LinearAlgebra_Matrix__0__AiDotNet_Enums_AlgorithmTypes_SvdAlgorithmType_" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.InitializeFromSVD(AiDotNet.Tensors.LinearAlgebra.Matrix{`0},AiDotNet.Enums.AlgorithmTypes.SvdAlgorithmType)">
  InitializeFromSVD(Matrix&lt;T&gt;, SvdAlgorithmType)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/PiSSAAdapter.cs/#L188"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes the adapter matrices from SVD of pretrained weights.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void InitializeFromSVD(Matrix&lt;T&gt; pretrainedWeights, SvdAlgorithmType svdAlgorithm = SvdAlgorithmType.GolubReinsch)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>pretrainedWeights</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Matrix-1.html">Matrix</a>&lt;T&gt;</dt>
    <dd><p>The pretrained weight matrix to decompose.</p>
</dd>
    <dt><code>svdAlgorithm</code> <a class="xref" href="AiDotNet.Enums.AlgorithmTypes.SvdAlgorithmType.html">SvdAlgorithmType</a></dt>
    <dd><p>The SVD algorithm to use (default: GolubReinsch).</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_InitializeFromSVD_AiDotNet_Tensors_LinearAlgebra_Matrix__0__AiDotNet_Enums_AlgorithmTypes_SvdAlgorithmType__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs the core PiSSA initialization:
1. Computes SVD: W = U Σ V^T
2. Extracts top-r components: U_r, Σ_r, V_r
3. Initializes A = V_r^T (right singular vectors)
4. Initializes B = U_r Σ_r (left singular vectors scaled by singular values)
5. Computes residual: W_residual = W - B*A
</p>
<p><b>For Beginners:</b> This is where the magic happens!
<p>The method:</p>
<ol>
<li>Takes your pretrained weights (like from a large language model)</li>
<li>Finds the most important patterns using SVD (mathematical technique)</li>
<li>Puts those patterns into the adapter matrices A and B</li>
<li>Saves the &quot;leftover&quot; patterns as frozen residual weights</li>
</ol>
<p>Think of it like:</p>
<ul>
<li>Original weights = complete painting</li>
<li>SVD = identifying the main strokes vs. minor details</li>
<li>A and B = the main strokes (what we'll adjust)</li>
<li>Residual = the minor details (kept frozen)</li>
</ul>
<p>This initialization is what makes PiSSA better than LoRA - it starts from
a smart place instead of random values.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></dt>
    <dd><p>Thrown when pretrainedWeights is null.</p>
</dd>
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a></dt>
    <dd><p>Thrown when weight matrix dimensions don't match layer dimensions.</p>
</dd>
  </dl>



  <a id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_MergeToOriginalLayer_" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.MergeToOriginalLayer*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_MergeToOriginalLayer" data-uid="AiDotNet.LoRA.Adapters.PiSSAAdapter`1.MergeToOriginalLayer">
  MergeToOriginalLayer()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/PiSSAAdapter.cs/#L510"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Merges the PiSSA adaptation into the original layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override ILayer&lt;T&gt; MergeToOriginalLayer()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</dt>
    <dd><p>A new layer with PiSSA weights merged back into a single weight matrix.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_LoRA_Adapters_PiSSAAdapter_1_MergeToOriginalLayer_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method reconstructs the full weight matrix by combining:
W_merged = W_residual + (A * B)^T
<p>This allows you to deploy the adapted model without the PiSSA overhead.</p>

<p><b>For Beginners:</b> This "bakes in" the PiSSA adaptation.
<p>After training:</p>
<ul>
<li>You have: frozen residual weights + trained A and B matrices</li>
<li>Merging combines them: residual + A*B = final weights</li>
<li>Result: a single regular layer with all improvements included</li>
</ul>
<p>Benefits:</p>
<ul>
<li>Faster inference (no need to compute residual + LoRA separately)</li>
<li>Simpler deployment (just one layer)</li>
<li>Compatible with systems that don't support LoRA/PiSSA</li>
</ul>
<p>Example:
var mergedLayer = adapter.MergeToOriginalLayer();
// Now you have a standard layer with PiSSA improvements built in!</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown when the adapter was not initialized from SVD.</p>
</dd>
  </dl>




</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/PiSSAAdapter.cs/#L66" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
