<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Interface IGradientComputable&lt;T, TInput, TOutput&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Interface IGradientComputable&lt;T, TInput, TOutput&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Base interface for models that can compute gradients explicitly without updating parameters.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_Interfaces_IGradientComputable_3.md&amp;value=---%0Auid%3A%20AiDotNet.Interfaces.IGradientComputable%603%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.Interfaces.IGradientComputable`3">



  <h1 id="AiDotNet_Interfaces_IGradientComputable_3" data-uid="AiDotNet.Interfaces.IGradientComputable`3" class="text-break">
Interface IGradientComputable&lt;T, TInput, TOutput&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/IGradientComputable.cs/#L41"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.Interfaces.html">Interfaces</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Base interface for models that can compute gradients explicitly without updating parameters.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public interface IGradientComputable&lt;T, TInput, TOutput&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric data type (e.g., float, double).</p>
</dd>
    <dt><code>TInput</code></dt>
    <dd><p>The input data type.</p>
</dd>
    <dt><code>TOutput</code></dt>
    <dd><p>The output data type.</p>
</dd>
  </dl>








  <h2 id="AiDotNet_Interfaces_IGradientComputable_3_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
This interface enables models to compute gradients without immediately applying parameter updates.
This is essential for:
- <b>Distributed Training</b>: Compute local gradients, synchronize across workers, then apply averaged gradients
- <b>Meta-Learning</b>: Compute gradients on query sets after adaptation (see <a class="xref" href="AiDotNet.Interfaces.ISecondOrderGradientComputable-3.html">ISecondOrderGradientComputable&lt;T, TInput, TOutput&gt;</a>)
- <b>Custom Optimization</b>: Manually control when and how to apply gradients
- <b>Gradient Analysis</b>: Inspect gradient values for debugging or monitoring
</p>
<p><b>For Beginners:</b>
Regular training computes gradients and immediately updates the model in one step.
This interface separates those two operations:
<ol>
<li><a class="xref" href="AiDotNet.Interfaces.IGradientComputable-3.html#AiDotNet_Interfaces_IGradientComputable_3_ComputeGradients__1__2_AiDotNet_Interfaces_ILossFunction__0__">ComputeGradients(TInput, TOutput, ILossFunction&lt;T&gt;?)</a> - Calculate which direction improves the model (WITHOUT changing it)</li>
<li><a class="xref" href="AiDotNet.Interfaces.IGradientComputable-3.html#AiDotNet_Interfaces_IGradientComputable_3_ApplyGradients_AiDotNet_Tensors_LinearAlgebra_Vector__0___0_">ApplyGradients(Vector&lt;T&gt;, T)</a> - Actually update the model using those directions</li>
</ol>
<p>This separation is crucial when you need to process gradients before applying them,
such as averaging gradients across multiple GPUs in distributed training.</p>

<p><b>Distributed Training Use Case:</b>
In Data Parallel training (DDP), each GPU:
1. Computes gradients on its local data batch
2. Communicates gradients with other GPUs to compute the average
3. Applies the averaged gradients to update parameters
<p>Without this interface, step 2 would be impossible because gradients would already
be applied in step 1.</p>

</div>


  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_Interfaces_IGradientComputable_3_ApplyGradients_" data-uid="AiDotNet.Interfaces.IGradientComputable`3.ApplyGradients*"></a>

  <h3 id="AiDotNet_Interfaces_IGradientComputable_3_ApplyGradients_AiDotNet_Tensors_LinearAlgebra_Vector__0___0_" data-uid="AiDotNet.Interfaces.IGradientComputable`3.ApplyGradients(AiDotNet.Tensors.LinearAlgebra.Vector{`0},`0)">
  ApplyGradients(Vector&lt;T&gt;, T)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/IGradientComputable.cs/#L95"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies pre-computed gradients to update the model parameters.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">void ApplyGradients(Vector&lt;T&gt; gradients, T learningRate)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>gradients</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The gradient vector to apply.</p>
</dd>
    <dt><code>learningRate</code> <span class="xref">T</span></dt>
    <dd><p>The learning rate for the update.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_Interfaces_IGradientComputable_3_ApplyGradients_AiDotNet_Tensors_LinearAlgebra_Vector__0___0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Updates parameters using: θ = θ - learningRate * gradients
</p>
<p><b>For Beginners:</b>
After computing gradients (seeing which direction to move),
this method actually moves the model in that direction.
The learning rate controls how big of a step to take.
</p>
<p><b>Distributed Training:</b>
In DDP/ZeRO-2, this applies the synchronized (averaged) gradients after
communication across workers. Each worker applies the same averaged gradients
to keep parameters consistent.
</p>
</div>




  <a id="AiDotNet_Interfaces_IGradientComputable_3_ComputeGradients_" data-uid="AiDotNet.Interfaces.IGradientComputable`3.ComputeGradients*"></a>

  <h3 id="AiDotNet_Interfaces_IGradientComputable_3_ComputeGradients__1__2_AiDotNet_Interfaces_ILossFunction__0__" data-uid="AiDotNet.Interfaces.IGradientComputable`3.ComputeGradients(`1,`2,AiDotNet.Interfaces.ILossFunction{`0})">
  ComputeGradients(TInput, TOutput, ILossFunction&lt;T&gt;?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/IGradientComputable.cs/#L73"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes gradients of the loss function with respect to model parameters for the given data,
WITHOUT updating the model parameters.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Vector&lt;T&gt; ComputeGradients(TInput input, TOutput target, ILossFunction&lt;T&gt;? lossFunction = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <span class="xref">TInput</span></dt>
    <dd><p>The input data.</p>
</dd>
    <dt><code>target</code> <span class="xref">TOutput</span></dt>
    <dd><p>The target/expected output.</p>
</dd>
    <dt><code>lossFunction</code> <a class="xref" href="AiDotNet.Interfaces.ILossFunction-1.html">ILossFunction</a>&lt;T&gt;</dt>
    <dd><p>The loss function to use for gradient computation. If null, uses the model's default loss function.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>A vector containing gradients with respect to all model parameters.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Interfaces_IGradientComputable_3_ComputeGradients__1__2_AiDotNet_Interfaces_ILossFunction__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs a forward pass, computes the loss, and back-propagates to compute gradients,
but does NOT update the model's parameters. The parameters remain unchanged after this call.
</p>
<p><b>Distributed Training:</b>
In DDP/ZeRO-2, each worker calls this to compute local gradients on its data batch.
These gradients are then synchronized (averaged) across workers before applying updates.
This ensures all workers compute the same parameter updates despite having different data.
</p>
<p><b>For Meta-Learning:</b>
After adapting a model on a support set, you can use this method to compute gradients
on the query set. These gradients become the meta-gradients for updating the meta-parameters.
</p>
<p><b>For Beginners:</b>
Think of this as "dry run" training:
- The model sees what direction it should move (the gradients)
- But it doesn't actually move (parameters stay the same)
- You get to decide what to do with this information (average with others, inspect, modify, etc.)
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>If lossFunction is null and the model has no default loss function.</p>
</dd>
  </dl>




</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/IGradientComputable.cs/#L41" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
