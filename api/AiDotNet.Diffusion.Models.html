<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Namespace AiDotNet.Diffusion.Models | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Namespace AiDotNet.Diffusion.Models | AiDotNet Documentation ">
      
      
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.Diffusion.Models">

  <h1 id="AiDotNet_Diffusion_Models" data-uid="AiDotNet.Diffusion.Models" class="text-break">Namespace AiDotNet.Diffusion.Models</h1>
  <div class="markdown level0 summary"></div>
  <div class="markdown level0 conceptual"></div>
  <div class="markdown level0 remarks"></div>

    <h3 id="classes">
Classes
</h3>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.AnimateDiffModel-1.html">AnimateDiffModel&lt;T&gt;</a></dt>
      <dd><p>AnimateDiff model for text-to-video and image-to-video generation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.AudioLDM2Model-1.html">AudioLDM2Model&lt;T&gt;</a></dt>
      <dd><p>AudioLDM 2 - Enhanced Audio Latent Diffusion Model with dual text encoders.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.AudioLDMModel-1.html">AudioLDMModel&lt;T&gt;</a></dt>
      <dd><p>Audio Latent Diffusion Model (AudioLDM) for text-to-audio generation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.CameraEmbedding-1.html">CameraEmbedding&lt;T&gt;</a></dt>
      <dd><p>Camera position embedding for view conditioning.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.CameraPose.html">CameraPose</a></dt>
      <dd><p>Camera pose for rendering.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.CameraPoseEncoder-1.html">CameraPoseEncoder&lt;T&gt;</a></dt>
      <dd><p>Encodes camera pose (polar, azimuth, radius) into embeddings.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.ConsistencyModel-1.html">ConsistencyModel&lt;T&gt;</a></dt>
      <dd><p>Consistency Model for single-step or few-step image generation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.ControlNetEncoder-1.html">ControlNetEncoder&lt;T&gt;</a></dt>
      <dd><p>ControlNet encoder that processes control signals.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.ControlNetModel-1.html">ControlNetModel&lt;T&gt;</a></dt>
      <dd><p>ControlNet model for adding spatial conditioning to diffusion models.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.DallE3Model-1.html">DallE3Model&lt;T&gt;</a></dt>
      <dd><p>DALL-E 3 style text-to-image generation model with advanced prompt understanding
and high-fidelity image generation capabilities.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.DiffWaveModel-1.html">DiffWaveModel&lt;T&gt;</a></dt>
      <dd><p>DiffWave model for high-quality audio waveform synthesis using diffusion.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.DiffWaveNetwork-1.html">DiffWaveNetwork&lt;T&gt;</a></dt>
      <dd><p>DiffWave neural network with dilated convolutions.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.DiffWaveResidualBlock-1.html">DiffWaveResidualBlock&lt;T&gt;</a></dt>
      <dd><p>Residual block for DiffWave with dilated convolution.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.DreamFusionConfig.html">DreamFusionConfig</a></dt>
      <dd><p>Configuration for DreamFusion model.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.DreamFusionModel-1.html">DreamFusionModel&lt;T&gt;</a></dt>
      <dd><p>DreamFusion model for text-to-3D generation via Score Distillation Sampling (SDS).
Uses a 2D diffusion prior to optimize a 3D neural radiance field representation.
Based on &quot;DreamFusion: Text-to-3D using 2D Diffusion&quot; (Poole et al., 2022).</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.DreamMesh-1.html">DreamMesh&lt;T&gt;</a></dt>
      <dd><p>Simple mesh representation for DreamFusion.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.IPAdapterModel-1.html">IPAdapterModel&lt;T&gt;</a></dt>
      <dd><p>IP-Adapter model for image-based prompt conditioning in diffusion models.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.ImageEncoder-1.html">ImageEncoder&lt;T&gt;</a></dt>
      <dd><p>Image encoder for extracting features from reference images.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.ImageProjector-1.html">ImageProjector&lt;T&gt;</a></dt>
      <dd><p>Projects image features to text embedding space.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.MVDreamConfig.html">MVDreamConfig</a></dt>
      <dd><p>Configuration for MVDream model.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.MVDreamModel-1.html">MVDreamModel&lt;T&gt;</a></dt>
      <dd><p>MVDream - Multi-View Diffusion Model for 3D-consistent image generation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.MelodyEncoder-1.html">MelodyEncoder&lt;T&gt;</a></dt>
      <dd><p>Melody encoder for extracting melodic features from audio.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.MotionModuleConfig.html">MotionModuleConfig</a></dt>
      <dd><p>Configuration for AnimateDiff motion modules.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.MultiViewAttention-1.html">MultiViewAttention&lt;T&gt;</a></dt>
      <dd><p>Multi-view attention module for cross-view consistency.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.MultiViewUNet-1.html">MultiViewUNet&lt;T&gt;</a></dt>
      <dd><p>Multi-view aware U-Net for MVDream.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.MusicGenModel-1.html">MusicGenModel&lt;T&gt;</a></dt>
      <dd><p>MusicGen - Diffusion-based music generation model with advanced musical controls.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.NeRFNetwork-1.html">NeRFNetwork&lt;T&gt;</a></dt>
      <dd><p>Neural Radiance Field network for 3D representation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.NeRFResult-1.html">NeRFResult&lt;T&gt;</a></dt>
      <dd><p>Result from DreamFusion generation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.PixArtModel-1.html">PixArtModel&lt;T&gt;</a></dt>
      <dd><p>PixArt-α model for efficient high-quality text-to-image generation using DiT architecture.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.PixArtOptions-1.html">PixArtOptions&lt;T&gt;</a></dt>
      <dd><p>Options for PixArt-α model configuration.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.PointEModel-1.html">PointEModel&lt;T&gt;</a></dt>
      <dd><p>Point-E model for text-to-3D point cloud generation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.PointEModel-1.PointCounts.html">PointEModel&lt;T&gt;.PointCounts</a></dt>
      <dd><p>Standard Point-E point counts.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.RhythmEncoder-1.html">RhythmEncoder&lt;T&gt;</a></dt>
      <dd><p>Rhythm encoder for extracting beat/rhythm features from audio.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.RiffusionModel-1.html">RiffusionModel&lt;T&gt;</a></dt>
      <dd><p>Riffusion model for music generation via spectrogram diffusion.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.SDXLModel-1.html">SDXLModel&lt;T&gt;</a></dt>
      <dd><p>Stable Diffusion XL (SDXL) model for high-resolution image generation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.SDXLRefiner-1.html">SDXLRefiner&lt;T&gt;</a></dt>
      <dd><p>SDXL Refiner model for enhancing generated images.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.ShapEModel-1.html">ShapEModel&lt;T&gt;</a></dt>
      <dd><p>Shap-E model for text-to-3D and image-to-3D generation with implicit neural representations.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.SpectrogramConfig.html">SpectrogramConfig</a></dt>
      <dd><p>Configuration for spectrogram generation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.StableVideoDiffusion-1.html">StableVideoDiffusion&lt;T&gt;</a></dt>
      <dd><p>Stable Video Diffusion (SVD) model for image-to-video generation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.VideoCrafterModel-1.html">VideoCrafterModel&lt;T&gt;</a></dt>
      <dd><p>VideoCrafter model for high-quality text-to-video and image-to-video generation.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.Zero123Model-1.html">Zero123Model&lt;T&gt;</a></dt>
      <dd><p>Zero-1-to-3 model for novel view synthesis from a single image.</p>
</dd>
    </dl>
    <h3 id="structs">
Structs
</h3>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.DreamVector3-1.html">DreamVector3&lt;T&gt;</a></dt>
      <dd><p>3D vector type for DreamFusion.</p>
</dd>
    </dl>
    <h3 id="enums">
Enums
</h3>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.AudioLDM2Variant.html">AudioLDM2Variant</a></dt>
      <dd><p>AudioLDM 2 model variant.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.ControlType.html">ControlType</a></dt>
      <dd><p>Types of control signals supported by ControlNet.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.Diffusion.Models.MusicGenSize.html">MusicGenSize</a></dt>
      <dd><p>MusicGen model size variants.</p>
</dd>
    </dl>


</article>

        <div class="contribution d-print-none">
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
