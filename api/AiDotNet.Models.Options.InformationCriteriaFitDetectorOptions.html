<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class InformationCriteriaFitDetectorOptions | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class InformationCriteriaFitDetectorOptions | AiDotNet Documentation ">
      
      <meta name="description" content="Configuration options for the Information Criteria Fit Detector, which uses statistical information criteria like AIC and BIC to evaluate model quality and complexity trade-offs.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions.md&amp;value=---%0Auid%3A%20AiDotNet.Models.Options.InformationCriteriaFitDetectorOptions%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.Models.Options.InformationCriteriaFitDetectorOptions">



  <h1 id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions" data-uid="AiDotNet.Models.Options.InformationCriteriaFitDetectorOptions" class="text-break">
Class InformationCriteriaFitDetectorOptions  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/InformationCriteriaFitDetectorOptions.cs/#L29"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.Models.html">Models</a>.<a class="xref" href="AiDotNet.Models.Options.html">Options</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Configuration options for the Information Criteria Fit Detector, which uses statistical information
criteria like AIC and BIC to evaluate model quality and complexity trade-offs.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class InformationCriteriaFitDetectorOptions</code></pre>
  </div>




  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><span class="xref">InformationCriteriaFitDetectorOptions</span></div>
    </dd>
  </dl>



  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
Information criteria are statistical measures that balance model fit against complexity to help select
the most appropriate model. The two most common criteria are AIC (Akaike Information Criterion) and
BIC (Bayesian Information Criterion), which penalize models based on the number of parameters they use.
This helps prevent overfitting by favoring simpler models unless more complex ones provide significantly
better fit.
</p>
<p><b>For Beginners:</b> This detector helps you choose the best model by balancing two competing
goals: how well the model fits your data and how simple the model is.
<p>Think of it like shopping for a car. You want good performance (model fit), but you also care about
fuel efficiency (model simplicity). Information criteria like AIC and BIC give you a single score that
considers both aspects, helping you make better decisions.</p>
<p>Why is this important? Because a very complex model might fit your training data perfectly but perform
poorly on new data (like a gas-guzzling sports car that's impractical for daily use). On the other hand,
a model that's too simple might miss important patterns (like an underpowered car that can't handle hills).</p>
<p>The Information Criteria Fit Detector uses these scores to help you find the &quot;sweet spot&quot; - a model that's
just complex enough to capture the important patterns in your data, but no more complex than necessary.</p>
</div>


  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_AicThreshold_" data-uid="AiDotNet.Models.Options.InformationCriteriaFitDetectorOptions.AicThreshold*"></a>

  <h3 id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_AicThreshold" data-uid="AiDotNet.Models.Options.InformationCriteriaFitDetectorOptions.AicThreshold">
  AicThreshold
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/InformationCriteriaFitDetectorOptions.cs/#L59"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the threshold for significant differences in AIC (Akaike Information Criterion) values
when comparing models.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double AicThreshold { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The AIC threshold, defaulting to 2.0.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_AicThreshold_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This threshold determines when the difference between AIC values of two models is considered significant.
If the difference in AIC exceeds this threshold, the model with the lower AIC is considered substantially
better. The AIC balances model fit against complexity with a relatively lighter penalty for complexity
compared to BIC.
</p>
<p><b>For Beginners:</b> AIC (Akaike Information Criterion) is a score that helps compare different
models - lower scores are better. This threshold setting determines how much better one model's AIC
score needs to be before we consider it meaningfully superior to another model.
<p>With the default value of 2.0, if Model A has an AIC that's at least 2.0 points lower than Model B,
we would consider Model A to be significantly better than Model B. If the difference is smaller,
we might consider the models roughly equivalent.</p>
<p>AIC tends to be more lenient toward complex models than BIC, making it useful when you have a lot of
data and want to capture subtle patterns. It's like a judge who's a bit more forgiving about fuel
efficiency as long as the car performs well.</p>
<p>The value of 2.0 comes from statistical theory - differences of about 2 or more suggest &quot;substantial&quot;
evidence favoring the model with the lower AIC. You might adjust this threshold based on how
conservative you want to be in model selection.</p>
</div>




  <a id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_BicThreshold_" data-uid="AiDotNet.Models.Options.InformationCriteriaFitDetectorOptions.BicThreshold*"></a>

  <h3 id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_BicThreshold" data-uid="AiDotNet.Models.Options.InformationCriteriaFitDetectorOptions.BicThreshold">
  BicThreshold
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/InformationCriteriaFitDetectorOptions.cs/#L90"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the threshold for significant differences in BIC (Bayesian Information Criterion) values
when comparing models.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double BicThreshold { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The BIC threshold, defaulting to 2.0.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_BicThreshold_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This threshold determines when the difference between BIC values of two models is considered significant.
If the difference in BIC exceeds this threshold, the model with the lower BIC is considered substantially
better. The BIC balances model fit against complexity with a stronger penalty for complexity compared to AIC,
especially as sample size increases.
</p>
<p><b>For Beginners:</b> BIC (Bayesian Information Criterion) is another score for comparing models,
similar to AIC but with a stronger preference for simpler models. Like AIC, lower scores are better.
This threshold setting determines how much better one model's BIC score needs to be before we consider
it meaningfully superior to another model.
<p>With the default value of 2.0, if Model A has a BIC that's at least 2.0 points lower than Model B,
we would consider Model A to be significantly better than Model B. If the difference is smaller,
we might consider the models roughly equivalent.</p>
<p>BIC is more strict about model complexity than AIC, especially when you have a lot of data. It's like
a judge who really values fuel efficiency and will only accept gas-guzzling sports cars if they offer
dramatically better performance.</p>
<p>BIC is often preferred when you want to avoid overfitting and are willing to potentially miss some
subtle patterns in exchange for a more robust, generalizable model. The threshold of 2.0 is based on
statistical theory about what constitutes &quot;substantial&quot; evidence favoring one model over another.</p>
</div>




  <a id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_HighVarianceThreshold_" data-uid="AiDotNet.Models.Options.InformationCriteriaFitDetectorOptions.HighVarianceThreshold*"></a>

  <h3 id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_HighVarianceThreshold" data-uid="AiDotNet.Models.Options.InformationCriteriaFitDetectorOptions.HighVarianceThreshold">
  HighVarianceThreshold
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/InformationCriteriaFitDetectorOptions.cs/#L178"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the threshold for detecting high variance based on the relative difference between
information criteria across different data samples.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double HighVarianceThreshold { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The high variance threshold, defaulting to 0.2 (20%).</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_HighVarianceThreshold_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This threshold determines when a model is considered to have high variance based on how much its
information criteria scores vary across different data samples. If the relative standard deviation
of the information criteria exceeds this threshold when evaluated on different subsets of the data,
the model likely has high variance and may be sensitive to the specific data used for training.
</p>
<p><b>For Beginners:</b> This setting helps identify when your model's quality is too inconsistent
across different subsets of your data. With the default value of 0.2, if your model's information
criteria scores vary by more than 20% when evaluated on different random samples of your data, it's
flagged as having high variance.
<p>For example, if you calculate AIC scores for your model using 5 different random samples of your data
and get values that vary widely (like 120, 90, 150, 105, 135), the relative standard deviation might
exceed 20%, indicating high variance. This suggests your model's performance depends too much on which
specific data points it sees.</p>
<p>Think of it like a car that performs great on dry roads but terribly in rain - it's inconsistent and
not reliable across different conditions. High variance often indicates that your model is too complex
for the amount of data you have, or that there's too much noise in your data.</p>
<p>When high variance is detected, you might want to:</p>
<ul>
<li>Simplify your model</li>
<li>Gather more training data</li>
<li>Use regularization techniques</li>
<li>Apply ensemble methods to stabilize predictions</li>
</ul>
</div>




  <a id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_OverfitThreshold_" data-uid="AiDotNet.Models.Options.InformationCriteriaFitDetectorOptions.OverfitThreshold*"></a>

  <h3 id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_OverfitThreshold" data-uid="AiDotNet.Models.Options.InformationCriteriaFitDetectorOptions.OverfitThreshold">
  OverfitThreshold
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/InformationCriteriaFitDetectorOptions.cs/#L118"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the threshold for detecting overfitting based on the relative difference between
information criteria of nested models.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double OverfitThreshold { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The overfit threshold, defaulting to 0.1 (10%).</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_OverfitThreshold_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This threshold determines when a more complex model is considered to be overfitting compared to a simpler
nested model. If the relative improvement in fit (adjusted for the information criterion penalty) is less
than this threshold when moving to a more complex model, the more complex model is likely overfitting.
</p>
<p><b>For Beginners:</b> This setting helps identify when adding complexity to your model isn't
providing enough benefit to justify the added complexity. With the default value of 0.1, if adding
more features or parameters to your model improves the fit by less than 10% (after accounting for
the complexity penalty in the information criteria), the more complex model is flagged as potentially
overfitting.
<p>For example, if you have a simple model with 3 features and a more complex model with 10 features,
but the complex model only improves the adjusted fit by 8%, it would be flagged as overfitting. This
suggests that the additional 7 features aren't providing enough value to justify their inclusion.</p>
<p>Think of it like upgrading to a more expensive car that only drives slightly better - probably not
worth the extra cost. When overfitting is detected, you're usually better off sticking with the
simpler model, which is likely to perform better on new data even if it's slightly less accurate
on the training data.</p>
</div>




  <a id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_UnderfitThreshold_" data-uid="AiDotNet.Models.Options.InformationCriteriaFitDetectorOptions.UnderfitThreshold*"></a>

  <h3 id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_UnderfitThreshold" data-uid="AiDotNet.Models.Options.InformationCriteriaFitDetectorOptions.UnderfitThreshold">
  UnderfitThreshold
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/InformationCriteriaFitDetectorOptions.cs/#L144"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the threshold for detecting underfitting based on the relative difference between
information criteria of nested models.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double UnderfitThreshold { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The underfit threshold, defaulting to 0.1 (10%).</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_InformationCriteriaFitDetectorOptions_UnderfitThreshold_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This threshold determines when a simpler model is considered to be underfitting compared to a more complex
nested model. If the relative improvement in fit (adjusted for the information criterion penalty) exceeds
this threshold when moving to a more complex model, the simpler model is likely underfitting.
</p>
<p><b>For Beginners:</b> This setting helps identify when your model is too simple and would benefit
significantly from added complexity. With the default value of 0.1, if adding more features or parameters
to your model improves the fit by more than 10% (after accounting for the complexity penalty in the
information criteria), the simpler model is flagged as potentially underfitting.
<p>For example, if you have a simple model with 3 features and a more complex model with 5 features,
and the complex model improves the adjusted fit by 15%, the simpler model would be flagged as underfitting.
This suggests that the additional 2 features are capturing important patterns that the simpler model misses.</p>
<p>Think of it like upgrading from a basic car to a mid-range model that drives significantly better -
the upgrade is probably worth the extra cost. When underfitting is detected, you're usually better off
using the more complex model, as the simpler one is missing important patterns in the data.</p>
</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/InformationCriteriaFitDetectorOptions.cs/#L29" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
