<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Enum MetaLearningAlgorithmType | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Enum MetaLearningAlgorithmType | AiDotNet Documentation ">
      
      <meta name="description" content="Specifies the type of meta-learning algorithm used for few-shot learning and quick adaptation.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_MetaLearning_MetaLearningAlgorithmType.md&amp;value=---%0Auid%3A%20AiDotNet.MetaLearning.MetaLearningAlgorithmType%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.MetaLearning.MetaLearningAlgorithmType">




  <h1 id="AiDotNet_MetaLearning_MetaLearningAlgorithmType" data-uid="AiDotNet.MetaLearning.MetaLearningAlgorithmType" class="text-break">
Enum MetaLearningAlgorithmType  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/MetaLearning/MetaLearningAlgorithmType.cs/#L22"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.MetaLearning.html">MetaLearning</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Specifies the type of meta-learning algorithm used for few-shot learning and quick adaptation.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public enum MetaLearningAlgorithmType</code></pre>
  </div>









  <h2 id="fields">Fields
</h2>
  <dl class="parameters">
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_ANIL"><code>ANIL = 13</code></dt>
  <dd><p>Almost No Inner Loop (Raghu et al., 2020).
A simplified version of MAML that only adapts the final classification layer.</p>
<p>
<b>Key Idea:</b> The feature extractor is frozen during inner-loop adaptation;
only the classifier head is updated. Much faster than full MAML.
</p>
<p>
<b>Use When:</b> You want faster adaptation with comparable performance to MAML.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_BOIL"><code>BOIL = 16</code></dt>
  <dd><p>Body Only Inner Loop (Oh et al., 2021).
Opposite of ANIL - only adapts the feature extractor, keeping the head frozen.</p>
<p>
<b>Key Idea:</b> The classifier head is frozen; only the feature extractor (body)
is adapted during the inner loop. Provides different inductive biases than ANIL.
</p>
<p>
<b>Use When:</b> You believe task-specific features are more important than
task-specific classifiers.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_CNAP"><code>CNAP = 4</code></dt>
  <dd><p>Conditional Neural Adaptive Processes (Requeima et al., 2019).
Combines neural processes with task-specific adaptation using FiLM layers.</p>
<p>
<b>Key Idea:</b> Generate task-specific parameters by conditioning on the support set,
enabling fast adaptation without gradient-based fine-tuning at test time.
</p>
<p>
<b>Use When:</b> You need fast inference-time adaptation without gradient computation.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_GNNMeta"><code>GNNMeta = 7</code></dt>
  <dd><p>Graph Neural Network for Meta-Learning.
Uses graph neural networks to model relationships between examples in few-shot learning.</p>
<p>
<b>Key Idea:</b> Treat the support and query examples as nodes in a graph and use
message passing to propagate information for classification.
</p>
<p>
<b>Use When:</b> You want to explicitly model relationships between all examples
in a task.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_LEO"><code>LEO = 14</code></dt>
  <dd><p>Latent Embedding Optimization (Rusu et al., 2019).
Performs optimization in a low-dimensional latent space for faster adaptation.</p>
<p>
<b>Key Idea:</b> Learn a low-dimensional latent space for model parameters.
Adaptation happens in this latent space, then maps back to full parameters.
</p>
<p>
<b>Use When:</b> You need to adapt very large models quickly with limited data.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_MAML"><code>MAML = 0</code></dt>
  <dd><p>Model-Agnostic Meta-Learning (Finn et al., 2017).
The foundational gradient-based meta-learning algorithm that learns an initialization
that can be quickly fine-tuned to new tasks with a few gradient steps.</p>
<p>
<b>Key Idea:</b> Find initial parameters that are sensitive to task-specific changes,
so that small gradient updates produce large improvements in task performance.
</p>
<p>
<b>Use When:</b> You need a general-purpose meta-learning approach that works across
different domains (classification, regression, reinforcement learning).
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_MANN"><code>MANN = 9</code></dt>
  <dd><p>Memory-Augmented Neural Network (Santoro et al., 2016).
Uses external memory for one-shot learning without explicit training phases.</p>
<p>
<b>Key Idea:</b> Store examples in external memory and learn to retrieve similar
examples for classification. No explicit support/query split at inference.
</p>
<p>
<b>Use When:</b> You need online learning capabilities where examples arrive sequentially.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_MatchingNetworks"><code>MatchingNetworks = 10</code></dt>
  <dd><p>Matching Networks for One Shot Learning (Vinyals et al., 2016).
Uses attention over support examples for one-shot classification.</p>
<p>
<b>Key Idea:</b> Embed examples in a shared space and classify by computing
attention-weighted similarity to support examples.
</p>
<p>
<b>Use When:</b> You need simple, non-parametric few-shot classification with
attention mechanisms.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_MetaOptNet"><code>MetaOptNet = 15</code></dt>
  <dd><p>Meta-learning with differentiable convex optimization (Lee et al., 2019).
Uses a differentiable SVM or ridge regression for the final classification.</p>
<p>
<b>Key Idea:</b> Replace the inner-loop gradient descent with a closed-form
convex optimization (like ridge regression or SVM) that is differentiable.
</p>
<p>
<b>Use When:</b> You want theoretically grounded, stable optimization in the inner loop.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_MetaSGD"><code>MetaSGD = 2</code></dt>
  <dd><p>Meta-SGD with per-parameter learning rates (Li et al., 2017).
Extends MAML by learning not just the initialization but also per-parameter learning rates.</p>
<p>
<b>Key Idea:</b> Different parameters may need different learning rates for optimal
adaptation. Meta-SGD learns these rates as part of the meta-learning process.
</p>
<p>
<b>Use When:</b> You suspect that uniform learning rates are suboptimal for your
model architecture.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_NTM"><code>NTM = 8</code></dt>
  <dd><p>Neural Turing Machine for meta-learning.
Uses external memory with read/write heads for meta-learning.</p>
<p>
<b>Key Idea:</b> Use a differentiable external memory to store and retrieve
task-relevant information across examples.
</p>
<p>
<b>Use When:</b> Tasks require storing and retrieving specific examples or patterns.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_ProtoNets"><code>ProtoNets = 11</code></dt>
  <dd><p>Prototypical Networks (Snell et al., 2017).
Learns a metric space where classification is performed by computing distances to class prototypes.</p>
<p>
<b>Key Idea:</b> Represent each class by the mean (prototype) of its support examples
in embedding space. Classify by nearest prototype.
</p>
<p>
<b>Use When:</b> You want simple, effective metric-based few-shot learning with
strong baselines.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_RelationNetwork"><code>RelationNetwork = 12</code></dt>
  <dd><p>Relation Network for few-shot learning (Sung et al., 2018).
Learns to compare query and support examples through a learned relation module.</p>
<p>
<b>Key Idea:</b> Instead of using a fixed distance metric, learn a neural network
that computes relation scores between example pairs.
</p>
<p>
<b>Use When:</b> You want to learn complex, non-linear similarity functions.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_Reptile"><code>Reptile = 1</code></dt>
  <dd><p>Reptile meta-learning algorithm (Nichol et al., 2018).
A simpler alternative to MAML that avoids computing second-order derivatives.</p>
<p>
<b>Key Idea:</b> Repeatedly sample a task, train on it, and move the initialization
towards the trained weights. Simpler gradient computation than MAML.
</p>
<p>
<b>Use When:</b> You want MAML-like performance with lower computational cost and
simpler implementation.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_SEAL"><code>SEAL = 5</code></dt>
  <dd><p>Self-Explanatory Attention Learning.
Combines attention mechanisms with meta-learning for interpretable few-shot learning.</p>
<p>
<b>Key Idea:</b> Use attention to focus on relevant features and provide
explanations for predictions in few-shot scenarios.
</p>
<p>
<b>Use When:</b> You need interpretable meta-learning with attention-based explanations.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_TADAM"><code>TADAM = 6</code></dt>
  <dd><p>Task-Dependent Adaptive Metric (Oreshkin et al., 2018).
Combines metric-based learning with task-dependent feature scaling.</p>
<p>
<b>Key Idea:</b> Learn to adapt the metric space based on the task at hand,
combining prototypical networks with task-conditional scaling.
</p>
<p>
<b>Use When:</b> You want metric-based learning with task-specific adaptation.
</p>
</dd>
  
    <dt id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_iMAML"><code>iMAML = 3</code></dt>
  <dd><p>Implicit MAML with implicit gradients (Rajeswaran et al., 2019).
Uses implicit differentiation to compute meta-gradients more efficiently.</p>
<p>
<b>Key Idea:</b> Instead of differentiating through the optimization path, use
the implicit function theorem to compute gradients. Enables more inner-loop steps.
</p>
<p>
<b>Use When:</b> You need many inner-loop adaptation steps and MAML's memory
requirements become prohibitive.
</p>
</dd>
  
  </dl>


  <h2 id="AiDotNet_MetaLearning_MetaLearningAlgorithmType_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
<b>For Beginners:</b> Meta-learning algorithms are designed to "learn how to learn."
Instead of learning a single task, they learn to quickly adapt to new tasks with minimal data.
This enum lists all supported meta-learning algorithms in the framework.
</p>
<p>
<b>Algorithm Categories:</b>
<ul><li><b>Optimization-based:</b> MAML, Reptile, Meta-SGD, iMAML, ANIL, BOIL, LEO</li><li><b>Metric-based:</b> ProtoNets, MatchingNetworks, RelationNetwork, TADAM</li><li><b>Memory-based:</b> MANN, NTM</li><li><b>Hybrid/Advanced:</b> CNAP, SEAL, GNNMeta, MetaOptNet</li></ul>

</div>

</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/MetaLearning/MetaLearningAlgorithmType.cs/#L22" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
