<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class LayerBase&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class LayerBase&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Represents the base class for all neural network layers, providing common functionality and interfaces.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_NeuralNetworks_Layers_LayerBase_1.md&amp;value=---%0Auid%3A%20AiDotNet.NeuralNetworks.Layers.LayerBase%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1">



  <h1 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1" class="text-break">
Class LayerBase&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L34"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.NeuralNetworks.html">NeuralNetworks</a>.<a class="xref" href="AiDotNet.NeuralNetworks.Layers.html">Layers</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Represents the base class for all neural network layers, providing common functionality and interfaces.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public abstract class LayerBase&lt;T&gt; : ILayer&lt;T&gt;, IJitCompilable&lt;T&gt;, IDiagnosticsProvider, IWeightLoadable&lt;T&gt;, IDisposable</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for calculations, typically float or double.</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><span class="xref">LayerBase&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IJitCompilable-1.html">IJitCompilable</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IDiagnosticsProvider.html">IDiagnosticsProvider</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.IWeightLoadable-1.html">IWeightLoadable</a>&lt;T&gt;</div>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.idisposable">IDisposable</a></div>
    </dd>
  </dl>

  <dl class="typelist derived">
    <dt>Derived</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.Diffusion.Attention.DiffusionAttention-1.html">DiffusionAttention&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.Diffusion.Attention.DiffusionCrossAttention-1.html">DiffusionCrossAttention&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.Diffusion.VAE.DownBlock-1.html">DownBlock&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.Diffusion.VAE.UpBlock-1.html">UpBlock&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.Diffusion.VAE.VAEDecoder-1.html">VAEDecoder&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.Diffusion.VAE.VAEEncoder-1.html">VAEEncoder&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.Diffusion.VAE.VAEResBlock-1.html">VAEResBlock&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.LoRAAdapterBase-1.html">LoRAAdapterBase&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.LoRALayer-1.html">LoRALayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Attention.FlashAttentionLayer-1.html">FlashAttentionLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.ActivationLayer-1.html">ActivationLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.AdaptiveAveragePoolingLayer-1.html">AdaptiveAveragePoolingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.AddLayer-1.html">AddLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.AnomalyDetectorLayer-1.html">AnomalyDetectorLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.AttentionLayer-1.html">AttentionLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.AveragePoolingLayer-1.html">AveragePoolingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.BasicBlock-1.html">BasicBlock&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer-1.html">BatchNormalizationLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.BidirectionalLayer-1.html">BidirectionalLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.BottleneckBlock-1.html">BottleneckBlock&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.CapsuleLayer-1.html">CapsuleLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.ConcatenateLayer-1.html">ConcatenateLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.ConditionalRandomFieldLayer-1.html">ConditionalRandomFieldLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.ContinuumMemorySystemLayer-1.html">ContinuumMemorySystemLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.Conv3DLayer-1.html">Conv3DLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.ConvLSTMLayer-1.html">ConvLSTMLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.ConvolutionalLayer-1.html">ConvolutionalLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.CroppingLayer-1.html">CroppingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.CrossAttentionLayer-1.html">CrossAttentionLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.DecoderLayer-1.html">DecoderLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.DeconvolutionalLayer-1.html">DeconvolutionalLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.DeformableConvolutionalLayer-1.html">DeformableConvolutionalLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.DenseBlock-1.html">DenseBlock&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.DenseLayer-1.html">DenseLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.DepthwiseSeparableConvolutionalLayer-1.html">DepthwiseSeparableConvolutionalLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.DiffusionConvLayer-1.html">DiffusionConvLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.DigitCapsuleLayer-1.html">DigitCapsuleLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.DilatedConvolutionalLayer-1.html">DilatedConvolutionalLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.DirectionalGraphLayer-1.html">DirectionalGraphLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.DropoutLayer-1.html">DropoutLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.EdgeConditionalConvolutionalLayer-1.html">EdgeConditionalConvolutionalLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.EmbeddingLayer-1.html">EmbeddingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.ExpertLayer-1.html">ExpertLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.FeedForwardLayer-1.html">FeedForwardLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.FlattenLayer-1.html">FlattenLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.FullyConnectedLayer-1.html">FullyConnectedLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.GRULayer-1.html">GRULayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.GatedLinearUnitLayer-1.html">GatedLinearUnitLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.GaussianNoiseLayer-1.html">GaussianNoiseLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.GlobalPoolingLayer-1.html">GlobalPoolingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.GraphAttentionLayer-1.html">GraphAttentionLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.GraphConvolutionalLayer-1.html">GraphConvolutionalLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.GraphIsomorphismLayer-1.html">GraphIsomorphismLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.GraphSAGELayer-1.html">GraphSAGELayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.GraphTransformerLayer-1.html">GraphTransformerLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.GroupNormalizationLayer-1.html">GroupNormalizationLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.HeterogeneousGraphLayer-1.html">HeterogeneousGraphLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.HighwayLayer-1.html">HighwayLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.HyperbolicLinearLayer-1.html">HyperbolicLinearLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.InputLayer-1.html">InputLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.InstanceNormalizationLayer-1.html">InstanceNormalizationLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.InvertedResidualBlock-1.html">InvertedResidualBlock&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.LSTMLayer-1.html">LSTMLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.LambdaLayer-1.html">LambdaLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerNormalizationLayer-1.html">LayerNormalizationLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.LocallyConnectedLayer-1.html">LocallyConnectedLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.LogVarianceLayer-1.html">LogVarianceLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.MaskingLayer-1.html">MaskingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.MaxPool3DLayer-1.html">MaxPool3DLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.MaxPoolingLayer-1.html">MaxPoolingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.MeanLayer-1.html">MeanLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.MeasurementLayer-1.html">MeasurementLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.MemoryReadLayer-1.html">MemoryReadLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.MemoryWriteLayer-1.html">MemoryWriteLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.MeshEdgeConvLayer-1.html">MeshEdgeConvLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.MeshPoolLayer-1.html">MeshPoolLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.MessagePassingLayer-1.html">MessagePassingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.MixtureOfExpertsLayer-1.html">MixtureOfExpertsLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.MultiHeadAttentionLayer-1.html">MultiHeadAttentionLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.MultiplyLayer-1.html">MultiplyLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.OctonionLinearLayer-1.html">OctonionLinearLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.PaddingLayer-1.html">PaddingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.PatchEmbeddingLayer-1.html">PatchEmbeddingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.PixelShuffleLayer-1.html">PixelShuffleLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.PoolingLayer-1.html">PoolingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.PositionalEncodingLayer-1.html">PositionalEncodingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.PrimaryCapsuleLayer-1.html">PrimaryCapsuleLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.PrincipalNeighbourhoodAggregationLayer-1.html">PrincipalNeighbourhoodAggregationLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.QuantumLayer-1.html">QuantumLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.RBFLayer-1.html">RBFLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.RBMLayer-1.html">RBMLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.RRDBLayer-1.html">RRDBLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.RRDBNetGenerator-1.html">RRDBNetGenerator&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.ReadoutLayer-1.html">ReadoutLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.ReconstructionLayer-1.html">ReconstructionLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.RecurrentLayer-1.html">RecurrentLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.RepParameterizationLayer-1.html">RepParameterizationLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.ReservoirLayer-1.html">ReservoirLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.ReshapeLayer-1.html">ReshapeLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.ResidualDenseBlock-1.html">ResidualDenseBlock&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.ResidualLayer-1.html">ResidualLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SelfAttentionLayer-1.html">SelfAttentionLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SeparableConvolutionalLayer-1.html">SeparableConvolutionalLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SequenceLastLayer-1.html">SequenceLastLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SparseLinearLayer-1.html">SparseLinearLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SpatialPoolerLayer-1.html">SpatialPoolerLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SpatialTransformerLayer-1.html">SpatialTransformerLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SpectralNormalizationLayer-1.html">SpectralNormalizationLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SpikingLayer-1.html">SpikingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SpiralConvLayer-1.html">SpiralConvLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SplitLayer-1.html">SplitLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SpyNetLayer-1.html">SpyNetLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SqueezeAndExcitationLayer-1.html">SqueezeAndExcitationLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SubpixelConvolutionalLayer-1.html">SubpixelConvolutionalLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SwinPatchEmbeddingLayer-1.html">SwinPatchEmbeddingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SwinPatchMergingLayer-1.html">SwinPatchMergingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SwinTransformerBlockLayer-1.html">SwinTransformerBlockLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.SynapticPlasticityLayer-1.html">SynapticPlasticityLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.TemporalMemoryLayer-1.html">TemporalMemoryLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.TimeDistributedLayer-1.html">TimeDistributedLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.TimeEmbeddingLayer-1.html">TimeEmbeddingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.TransformerDecoderLayer-1.html">TransformerDecoderLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.TransformerEncoderLayer-1.html">TransformerEncoderLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.TransitionLayer-1.html">TransitionLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.UNetDiscriminator-1.html">UNetDiscriminator&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.Upsample3DLayer-1.html">Upsample3DLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.UpsamplingLayer-1.html">UpsamplingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.PhysicsInformed.NeuralOperators.FourierLayer-1.html">FourierLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.PointCloud.Layers.MaxPoolingLayer-1.html">MaxPoolingLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.PointCloud.Layers.PointConvolutionLayer-1.html">PointConvolutionLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.PointCloud.Layers.TNetLayer-1.html">TNetLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.UncertaintyQuantification.Layers.BayesianDenseLayer-1.html">BayesianDenseLayer&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.UncertaintyQuantification.Layers.MCDropoutLayer-1.html">MCDropoutLayer&lt;T&gt;</a></div>
    </dd>
  </dl>

  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
LayerBase is an abstract class that serves as the foundation for all neural network layers. It defines 
the common structure and functionality that all layers must implement, such as forward and backward 
propagation, parameter management, and activation functions. This class handles the core mechanics 
of layers in a neural network, allowing derived classes to focus on their specific implementations.
</p>
<p><b>For Beginners:</b> This is the blueprint that all neural network layers follow.
<p>Think of LayerBase as the common foundation that all layers are built upon:</p>
<ul>
<li>It defines what every layer must be able to do (process data forward and backward)</li>
<li>It provides shared tools that all layers can use (like activation functions)</li>
<li>It manages the shapes of data flowing in and out of layers</li>
<li>It handles saving and loading layer parameters</li>
</ul>
<p>All specific layer types (like convolutional, dense, etc.) inherit from this class,
which ensures they all work together consistently in a neural network.</p>

</div>


  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.#ctor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_System_Int32___System_Int32___" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.#ctor(System.Int32[],System.Int32[])">
  LayerBase(int[], int[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L441"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html">LayerBase&lt;T&gt;</a> class with the specified input and output shapes.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected LayerBase(int[] inputShape, int[] outputShape)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The shape of the input tensor.</p>
</dd>
    <dt><code>outputShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The shape of the output tensor.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_System_Int32___System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This constructor creates a new Layer with the specified input and output shapes. It initializes
an empty parameter vector and sets up the single input shape.
</p>
<p><b>For Beginners:</b> This creates a new layer with the specified data shapes.
<p>When creating a layer, you need to define:</p>
<ul>
<li>The shape of data coming in (inputShape)</li>
<li>The shape of data going out (outputShape)</li>
</ul>
<p>This helps the layer organize its operations and connect properly with other layers.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.#ctor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_System_Int32___System_Int32___AiDotNet_Interfaces_IActivationFunction__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.#ctor(System.Int32[],System.Int32[],AiDotNet.Interfaces.IActivationFunction{`0})">
  LayerBase(int[], int[], IActivationFunction&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L469"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html">LayerBase&lt;T&gt;</a> class with the specified shapes and element-wise activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected LayerBase(int[] inputShape, int[] outputShape, IActivationFunction&lt;T&gt; scalarActivation)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The shape of the input tensor.</p>
</dd>
    <dt><code>outputShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The shape of the output tensor.</p>
</dd>
    <dt><code>scalarActivation</code> <a class="xref" href="AiDotNet.Interfaces.IActivationFunction-1.html">IActivationFunction</a>&lt;T&gt;</dt>
    <dd><p>The element-wise activation function to apply.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_System_Int32___System_Int32___AiDotNet_Interfaces_IActivationFunction__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This constructor creates a new Layer with the specified input and output shapes and element-wise activation function.
</p>
<p><b>For Beginners:</b> This creates a new layer with a standard activation function.
<p>In addition to the shapes, this also sets up:</p>
<ul>
<li>A scalar activation function that processes each value independently</li>
<li>The foundation for a layer that transforms data in a specific way</li>
</ul>
<p>For example, you might create a layer with a ReLU activation function,
which turns all negative values to zero while keeping positive values.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.#ctor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_System_Int32___System_Int32___AiDotNet_Interfaces_IVectorActivationFunction__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.#ctor(System.Int32[],System.Int32[],AiDotNet.Interfaces.IVectorActivationFunction{`0})">
  LayerBase(int[], int[], IVectorActivationFunction&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L497"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html">LayerBase&lt;T&gt;</a> class with the specified shapes and vector activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected LayerBase(int[] inputShape, int[] outputShape, IVectorActivationFunction&lt;T&gt; vectorActivation)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The shape of the input tensor.</p>
</dd>
    <dt><code>outputShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The shape of the output tensor.</p>
</dd>
    <dt><code>vectorActivation</code> <a class="xref" href="AiDotNet.Interfaces.IVectorActivationFunction-1.html">IVectorActivationFunction</a>&lt;T&gt;</dt>
    <dd><p>The vector activation function to apply.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_System_Int32___System_Int32___AiDotNet_Interfaces_IVectorActivationFunction__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This constructor creates a new Layer with the specified input and output shapes and vector activation function.
Vector activation functions operate on entire vectors rather than individual elements.
</p>
<p><b>For Beginners:</b> This creates a new layer with an advanced vector-based activation.
<p>This constructor:</p>
<ul>
<li>Sets up the layer's input and output shapes</li>
<li>Configures a vector activation that processes groups of values together</li>
<li>Marks the layer as using vector activation</li>
</ul>
<p>Vector activations like Softmax are important for specific tasks like
classification, where outputs need to be interpreted as probabilities.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.#ctor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_System_Int32_____System_Int32___" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.#ctor(System.Int32[][],System.Int32[])">
  LayerBase(int[][], int[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L525"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html">LayerBase&lt;T&gt;</a> class with multiple input shapes and a specified output shape.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected LayerBase(int[][] inputShapes, int[] outputShape)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputShapes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[][]</dt>
    <dd><p>The shapes of the input tensors.</p>
</dd>
    <dt><code>outputShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The shape of the output tensor.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_System_Int32_____System_Int32____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This constructor creates a new Layer that accepts multiple inputs with different shapes. This is
useful for layers that combine multiple inputs, such as concatenation or addition layers.
</p>
<p><b>For Beginners:</b> This creates a layer that can handle multiple input sources.
<p>When creating a layer that combines different data sources:</p>
<ul>
<li>You need to specify the shape of each input source</li>
<li>The layer needs to know how to handle multiple inputs</li>
<li>The output shape defines what comes out after combining them</li>
</ul>
<p>For example, a layer that combines features from images and text would
need to know the shape of both the image and text data.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.#ctor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_System_Int32_____System_Int32___AiDotNet_Interfaces_IActivationFunction__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.#ctor(System.Int32[][],System.Int32[],AiDotNet.Interfaces.IActivationFunction{`0})">
  LayerBase(int[][], int[], IActivationFunction&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L554"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html">LayerBase&lt;T&gt;</a> class with multiple input shapes, a specified output shape, and an element-wise activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected LayerBase(int[][] inputShapes, int[] outputShape, IActivationFunction&lt;T&gt; scalarActivation)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputShapes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[][]</dt>
    <dd><p>The shapes of the input tensors.</p>
</dd>
    <dt><code>outputShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The shape of the output tensor.</p>
</dd>
    <dt><code>scalarActivation</code> <a class="xref" href="AiDotNet.Interfaces.IActivationFunction-1.html">IActivationFunction</a>&lt;T&gt;</dt>
    <dd><p>The element-wise activation function to apply.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_System_Int32_____System_Int32___AiDotNet_Interfaces_IActivationFunction__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This constructor creates a new Layer that accepts multiple inputs with different shapes and applies
an element-wise activation function to the output.
</p>
<p><b>For Beginners:</b> This creates a layer that handles multiple inputs and applies a standard activation.
<p>This constructor:</p>
<ul>
<li>Sets up the layer to accept multiple input sources</li>
<li>Defines the shape of the combined output</li>
<li>Adds a scalar activation function that processes each output value independently</li>
</ul>
<p>This is useful for creating complex networks that merge data from different sources.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.#ctor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_System_Int32_____System_Int32___AiDotNet_Interfaces_IVectorActivationFunction__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.#ctor(System.Int32[][],System.Int32[],AiDotNet.Interfaces.IVectorActivationFunction{`0})">
  LayerBase(int[][], int[], IVectorActivationFunction&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L582"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html">LayerBase&lt;T&gt;</a> class with multiple input shapes, a specified output shape, and a vector activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected LayerBase(int[][] inputShapes, int[] outputShape, IVectorActivationFunction&lt;T&gt; vectorActivation)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputShapes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[][]</dt>
    <dd><p>The shapes of the input tensors.</p>
</dd>
    <dt><code>outputShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The shape of the output tensor.</p>
</dd>
    <dt><code>vectorActivation</code> <a class="xref" href="AiDotNet.Interfaces.IVectorActivationFunction-1.html">IVectorActivationFunction</a>&lt;T&gt;</dt>
    <dd><p>The vector activation function to apply.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1__ctor_System_Int32_____System_Int32___AiDotNet_Interfaces_IVectorActivationFunction__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This constructor creates a new Layer that accepts multiple inputs with different shapes and applies
a vector activation function to the output.
</p>
<p><b>For Beginners:</b> This creates a layer that handles multiple inputs and applies a vector-based activation.
<p>This constructor:</p>
<ul>
<li>Sets up the layer to accept multiple input sources</li>
<li>Defines the shape of the combined output</li>
<li>Adds a vector activation function that processes groups of output values together</li>
<li>Marks the layer as using vector activation</li>
</ul>
<p>This combines the flexibility of multiple inputs with the power of vector activations.</p>

</div>




  <h2 class="section" id="fields">Fields
</h2>



  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_BiasParameterName" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.BiasParameterName">
  BiasParameterName
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2652"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Standard parameter name for bias tensors.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected const string BiasParameterName = &quot;bias&quot;</code></pre>
  </div>




  <h4 class="section">Field Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd></dd>
  </dl>










  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationLock" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.InitializationLock">
  InitializationLock
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L339"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Object used for thread-safe lazy initialization.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected readonly object InitializationLock</code></pre>
  </div>




  <h4 class="section">Field Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></dt>
    <dd></dd>
  </dl>










  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsTrainingMode" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.IsTrainingMode">
  IsTrainingMode
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L279"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets a value indicating whether the layer is in training mode.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected bool IsTrainingMode</code></pre>
  </div>




  <h4 class="section">Field Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>





  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsTrainingMode_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This flag indicates whether the layer is currently in training mode or inference (evaluation) mode.
Some layers behave differently during training versus inference, such as Dropout or BatchNormalization.
</p>
<p><b>For Beginners:</b> This tells the layer whether it's currently training or being used for predictions.
<p>This mode flag:</p>
<ul>
<li>Affects how certain layers behave</li>
<li>Can turn on/off special training features</li>
<li>Helps the network switch between learning and using what it learned</li>
</ul>
<p>For example, dropout layers randomly turn off neurons during training to improve
generalization, but during inference they don't drop anything.</p>

</div>





  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ParameterGradients" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ParameterGradients">
  ParameterGradients
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L184"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>The gradients of the trainable parameters.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected Vector&lt;T&gt;? ParameterGradients</code></pre>
  </div>




  <h4 class="section">Field Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>





  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ParameterGradients_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This vector contains the gradients of all trainable parameters for the layer. These gradients
indicate how each parameter should be adjusted during training to reduce the error.
</p>
<p><b>For Beginners:</b> These values show how to adjust the parameters during training.
<p>Parameter gradients:</p>
<ul>
<li>Tell the network which direction to change each parameter</li>
<li>Show how sensitive the error is to each parameter</li>
<li>Guide the learning process</li>
</ul>
<p>A larger gradient means a parameter has more influence on the error and
needs a bigger adjustment during training.</p>

</div>





  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Parameters" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Parameters">
  Parameters
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L163"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>The trainable parameters of this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected Vector&lt;T&gt; Parameters</code></pre>
  </div>




  <h4 class="section">Field Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>





  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Parameters_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This vector contains all trainable parameters for the layer, such as weights and biases.
The specific interpretation of these parameters depends on the layer type.
</p>
<p><b>For Beginners:</b> These are the values that the layer learns during training.
<p>Parameters include:</p>
<ul>
<li>Weights that determine how important each input is</li>
<li>Biases that provide a baseline or starting point</li>
<li>Other learnable values specific to certain layer types</li>
</ul>
<p>During training, these values are adjusted to make the network's predictions better.</p>

</div>





  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_WeightParameterName" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.WeightParameterName">
  WeightParameterName
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2647"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Standard parameter name for weight tensors.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected const string WeightParameterName = &quot;weight&quot;</code></pre>
  </div>




  <h4 class="section">Field Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd></dd>
  </dl>









  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanExecuteOnGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.CanExecuteOnGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanExecuteOnGpu" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.CanExecuteOnGpu">
  CanExecuteOnGpu
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L990"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this layer can execute its forward pass on GPU.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual bool CanExecuteOnGpu { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanExecuteOnGpu_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Returns true when both the layer supports GPU execution AND a GPU engine is currently active.
Use this to check at runtime whether GPU forward pass is available.
</p>
<p><b>For Beginners:</b> Check this before calling ForwardGpu.
It combines "does the layer have GPU code?" with "is the GPU engine active?"
</p>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanTrainOnGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.CanTrainOnGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanTrainOnGpu" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.CanTrainOnGpu">
  CanTrainOnGpu
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1003"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this layer can execute GPU training (forward, backward, parameter update).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual bool CanTrainOnGpu { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanTrainOnGpu_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Returns true when both the layer supports GPU training AND a GPU engine is currently active.
</p>
<p><b>For Beginners:</b> Check this before attempting GPU-resident training.
If false, training will fall back to CPU operations.
</p>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Engine_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Engine*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Engine" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Engine">
  Engine
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L39"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the global execution engine for vector operations.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected IEngine Engine { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.Engines.IEngine.html">IEngine</a></dt>
    <dd></dd>
  </dl>








  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationStrategy_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.InitializationStrategy*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationStrategy" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.InitializationStrategy">
  InitializationStrategy
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L313"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the initialization strategy for this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public IInitializationStrategy&lt;T&gt;? InitializationStrategy { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Initialization.IInitializationStrategy-1.html">IInitializationStrategy</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationStrategy_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The initialization strategy controls when and how the layer's weights are allocated
and initialized. Lazy initialization defers weight allocation until the first forward
pass, which significantly speeds up network construction.
</p>
<p><b>For Beginners:</b> This controls when the layer sets up its internal weights.
<p>Lazy initialization:</p>
<ul>
<li>Defers weight allocation until the layer is actually used</li>
<li>Makes network construction much faster</li>
<li>Useful for tests and when comparing network architectures</li>
</ul>
<p>Eager initialization:</p>
<ul>
<li>Allocates weights immediately at construction time</li>
<li>Traditional behavior, weights are ready immediately</li>
</ul>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShape_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.InputShape*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShape" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.InputShape">
  InputShape
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L205"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the input shape for this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected int[] InputShape { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShape_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property contains the shape of the input tensor that the layer expects. For example,
a 2D convolutional layer might expect an input shape of [batchSize, channels, height, width].
</p>
<p><b>For Beginners:</b> This defines the shape of data this layer expects to receive.
<p>The input shape:</p>
<ul>
<li>Tells the layer how many dimensions the input data has</li>
<li>Specifies the size of each dimension</li>
<li>Helps the layer organize its operations properly</li>
</ul>
<p>For example, if processing images that are 28x28 pixels with 1 color channel,
the input shape might be [1, 28, 28] (channels, height, width).</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShapes_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.InputShapes*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShapes" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.InputShapes">
  InputShapes
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L226"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the input shapes for this layer, supporting multiple inputs.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected int[][] InputShapes { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[][]</dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShapes_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property contains the shapes of all input tensors that the layer expects, for layers that
accept multiple inputs (such as merge layers).
</p>
<p><b>For Beginners:</b> This defines the shapes of all input sources for layers that take multiple inputs.
<p>For layers that combine multiple data sources:</p>
<ul>
<li>Each input may have a different shape</li>
<li>This array stores all those shapes</li>
<li>Helps the layer handle multiple inputs properly</li>
</ul>
<p>For example, a layer that combines features from two different sources
would need to know the shape of each source.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsInitialized_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.IsInitialized*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsInitialized" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.IsInitialized">
  IsInitialized
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L334"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets a value indicating whether this layer has been initialized.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual bool IsInitialized { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsInitialized_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
For layers with lazy initialization, this indicates whether the weights have been
allocated and initialized. For eager initialization, this is always true after construction.
</p>
<p><b>For Beginners:</b> This tells you if the layer's weights are ready to use.
<p>A value of true means:</p>
<ul>
<li>Weights have been allocated</li>
<li>The layer is ready for forward/backward passes</li>
</ul>
<p>A value of false means:</p>
<ul>
<li>Weights are not yet allocated (lazy initialization)</li>
<li>The first Forward() call will initialize them</li>
</ul>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_NamedParameterCount_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.NamedParameterCount*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_NamedParameterCount" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.NamedParameterCount">
  NamedParameterCount
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2814"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the total number of named parameters.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual int NamedParameterCount { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>








  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_NumOps_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.NumOps*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_NumOps" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.NumOps">
  NumOps
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L123"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the numeric operations provider for type T.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected INumericOperations&lt;T&gt; NumOps { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.Interfaces.INumericOperations-1.html">INumericOperations</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_NumOps_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property provides access to numeric operations (like addition, multiplication, etc.) that work
with the generic type T. This allows the layer to perform mathematical operations regardless of
whether T is float, double, or another numeric type.
</p>
<p><b>For Beginners:</b> This is a toolkit for math operations that works with different number types.
<p>It provides:</p>
<ul>
<li>Basic math operations (add, subtract, multiply, etc.)</li>
<li>Ways to convert between different number formats</li>
<li>Special math functions needed by neural networks</li>
</ul>
<p>This allows the layer to work with different types of numbers (float, double, etc.)
without needing different code for each type.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_OutputShape_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.OutputShape*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_OutputShape" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.OutputShape">
  OutputShape
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L258"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the output shape for this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected int[] OutputShape { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_OutputShape_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property contains the shape of the output tensor that the layer produces. For example,
a 2D convolutional layer with 16 filters might produce an output shape of [batchSize, 16, height, width].
</p>
<p><b>For Beginners:</b> This defines the shape of data this layer produces as output.
<p>The output shape:</p>
<ul>
<li>Tells the next layer what shape of data to expect</li>
<li>Shows how this layer transforms the data dimensions</li>
<li>Helps verify the network is structured correctly</li>
</ul>
<p>For example, if a layer reduces image size from 28x28 to 14x14 and produces 16 feature maps,
the output shape might be [16, 14, 14] (channels, height, width).</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ParameterCount_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ParameterCount*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ParameterCount" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ParameterCount">
  ParameterCount
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1847"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the total number of parameters in this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual int ParameterCount { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The total number of trainable parameters.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ParameterCount_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property returns the total number of trainable parameters in the layer. By default, it returns
the length of the Parameters vector, but derived classes can override this to calculate the number
of parameters differently.
</p>
<p><b>For Beginners:</b> This tells you how many learnable values the layer has.
<p>The parameter count:</p>
<ul>
<li>Shows how complex the layer is</li>
<li>Indicates how many values need to be learned during training</li>
<li>Can help estimate memory usage and computational requirements</li>
</ul>
<p>Layers with more parameters can potentially learn more complex patterns
but may also require more data to train effectively.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Random_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Random*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Random" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Random">
  Random
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L143"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the thread-safe random number generator.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected static Random Random { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.random">Random</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Random_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property provides access to the centralized thread-safe random number generator,
which is used for initializing weights and other parameters that require randomization.
</p>
<p><b>For Beginners:</b> This provides random numbers for initializing the layer.
<p>Random numbers are needed to:</p>
<ul>
<li>Set starting values for weights and biases</li>
<li>Add randomness to avoid symmetry problems</li>
<li>Help the network learn diverse patterns</li>
</ul>
<p>Good initialization with proper randomness is important for neural networks to learn effectively.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ScalarActivation_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ScalarActivation*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ScalarActivation" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ScalarActivation">
  ScalarActivation
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L60"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the element-wise activation function for this layer, if specified.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public IActivationFunction&lt;T&gt;? ScalarActivation { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Interfaces.IActivationFunction-1.html">IActivationFunction</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ScalarActivation_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The scalar activation function applies to individual values in the layer's output tensor.
Common activation functions include ReLU, Sigmoid, and Tanh.
</p>
<p><b>For Beginners:</b> This is the function that adds non-linearity to each value individually.
<p>Activation functions:</p>
<ul>
<li>Add non-linearity, helping the network learn complex patterns</li>
<li>Process each number one at a time</li>
<li>Transform values into more useful ranges (like 0 to 1, or -1 to 1)</li>
</ul>
<p>For example, ReLU turns all negative values to zero while keeping positive values unchanged.
Without activation functions, neural networks couldn't learn complex patterns.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuExecution_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SupportsGpuExecution*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuExecution" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SupportsGpuExecution">
  SupportsGpuExecution
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L950"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this layer has a GPU execution implementation for inference.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected virtual bool SupportsGpuExecution { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuExecution_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Override this to return true when the layer implements <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ForwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0____">ForwardGpu(params IGpuTensor&lt;T&gt;[])</a>.
The actual <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanExecuteOnGpu">CanExecuteOnGpu</a> property combines this with engine availability.
</p>
<p><b>For Beginners:</b> This flag indicates if the layer has GPU code for the forward pass.
Set this to true in derived classes that implement ForwardGpu.
</p>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuTraining_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SupportsGpuTraining*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuTraining" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SupportsGpuTraining">
  SupportsGpuTraining
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L976"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this layer has full GPU training support (forward, backward, and parameter updates).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual bool SupportsGpuTraining { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuTraining_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property indicates whether the layer can perform its entire training cycle on GPU
without downloading data to CPU. A layer has full GPU training support when:
<ul><li>ForwardGpu is implemented</li><li>BackwardGpu is implemented</li><li>UpdateParametersGpu is implemented (for layers with trainable parameters)</li><li>GPU weight/bias/gradient buffers are properly managed</li></ul>

<p><b>For Beginners:</b> This tells you if training can happen entirely on GPU.
<p>GPU-resident training is much faster because:</p>
<ul>
<li>Data stays on GPU between forward and backward passes</li>
<li>No expensive CPU-GPU transfers during each training step</li>
<li>GPU kernels handle all gradient computation</li>
</ul>
<p>Only layers that return true here can participate in fully GPU-resident training.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsJitCompilation_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SupportsJitCompilation*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsJitCompilation" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SupportsJitCompilation">
  SupportsJitCompilation
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L825"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this layer supports JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public abstract bool SupportsJitCompilation { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if the layer can be JIT compiled, false otherwise.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsJitCompilation_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property indicates whether the layer has implemented ExportComputationGraph()
and can benefit from JIT compilation. All layers MUST implement this property.
</p>
<p><b>For Beginners:</b> JIT compilation can make inference 5-10x faster by converting
the layer's operations into optimized native code.
<p>Layers should return false if they:</p>
<ul>
<li>Have not yet implemented a working ExportComputationGraph()</li>
<li>Use dynamic operations that change based on input data</li>
<li>Are too simple to benefit from JIT compilation</li>
</ul>
<p>When false, the layer will use the standard Forward() method instead.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsTraining_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SupportsTraining*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsTraining" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SupportsTraining">
  SupportsTraining
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L389"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets a value indicating whether this layer supports training.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public abstract bool SupportsTraining { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p><code>true</code> if the layer has trainable parameters and supports backpropagation; otherwise, <code>false</code>.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsTraining_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property indicates whether the layer can be trained through backpropagation.
Layers with trainable parameters such as weights and biases typically return true, while layers
that only perform fixed transformations (like pooling or activation layers) typically return false.
</p>
<p><b>For Beginners:</b> This property tells you if the layer can learn from data.
<p>A value of true means:</p>
<ul>
<li>The layer has parameters that can be adjusted during training</li>
<li>It will improve its performance as it sees more data</li>
<li>It participates in the learning process</li>
</ul>
<p>A value of false means:</p>
<ul>
<li>The layer doesn't have any adjustable parameters</li>
<li>It performs the same operation regardless of training</li>
<li>It doesn't need to learn (but may still be useful)</li>
</ul>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UseAutodiff_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.UseAutodiff*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UseAutodiff" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.UseAutodiff">
  UseAutodiff
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L420"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets a value indicating whether this layer uses automatic differentiation for backward passes.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public bool UseAutodiff { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p><code>true</code> if the layer should use autodiff; <code>false</code> if it uses manual backward implementation. Default is <code>false</code>.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UseAutodiff_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property controls whether the layer uses the automatic differentiation system (autodiff) or
manual backward pass implementations during training. Manual backward passes are typically faster
but require explicit gradient computation code. Autodiff is more flexible and can be useful for:
- Custom layer implementations where manual gradients are complex
- Research and experimentation with novel architectures
- Rapid prototyping of new layer types
</p>
<p><b>For Beginners:</b> This controls how the layer computes gradients during training.
<p>Two modes are available:</p>
<ul>
<li><b>Manual (default, false):</b> Uses hand-written, optimized gradient code. Faster but requires careful implementation.</li>
<li><b>Autodiff (true):</b> Uses automatic differentiation to compute gradients. Slower but more flexible and less error-prone.</li>
</ul>
<p>Most users should leave this as false (default) for best performance. Set to true only for:</p>
<ul>
<li>Custom layers with complex gradients</li>
<li>Experimental or research purposes</li>
<li>When you need guaranteed correct gradients for a new operation</li>
</ul>
<p><b>Note:</b> Autodiff support must be implemented by the specific layer type. Not all layers support autodiff mode yet.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UsingVectorActivation_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.UsingVectorActivation*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UsingVectorActivation" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.UsingVectorActivation">
  UsingVectorActivation
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L101"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets a value indicating whether this layer uses a vector activation function.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected bool UsingVectorActivation { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UsingVectorActivation_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property indicates whether the layer is using a vector activation function or an element-wise
activation function. It is used to determine which type of activation to apply during forward and
backward passes.
</p>
<p><b>For Beginners:</b> This tells the layer which type of activation function to use.
<p>It's like a switch that determines:</p>
<ul>
<li>Whether to process values one by one (scalar activation)</li>
<li>Or to process groups of values together (vector activation)</li>
</ul>
<p>This helps the layer know which method to use when applying activations.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_VectorActivation_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.VectorActivation*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_VectorActivation" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.VectorActivation">
  VectorActivation
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L81"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the vector activation function for this layer, if specified.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public IVectorActivationFunction&lt;T&gt;? VectorActivation { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Interfaces.IVectorActivationFunction-1.html">IVectorActivationFunction</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_VectorActivation_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The vector activation function applies to entire vectors in the layer's output tensor.
This can capture dependencies between different elements of the vectors, such as in Softmax.
</p>
<p><b>For Beginners:</b> This is a more advanced function that processes groups of values together.
<p>Vector activation functions:</p>
<ul>
<li>Process entire groups of numbers together, not just one at a time</li>
<li>Can capture relationships between different features</li>
<li>Are used for special purposes like classification (Softmax)</li>
</ul>
<p>For example, Softmax turns a vector of numbers into probabilities that sum to 1,
which is useful for classifying inputs into categories.</p>

</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ActivateTensor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ActivateTensor(AiDotNet.Interfaces.IActivationFunction{`0},AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  ActivateTensor(IActivationFunction&lt;T&gt;?, Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1430"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies a scalar activation function to each element of a tensor.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected Tensor&lt;T&gt; ActivateTensor(IActivationFunction&lt;T&gt;? activation, Tensor&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>activation</code> <a class="xref" href="AiDotNet.Interfaces.IActivationFunction-1.html">IActivationFunction</a>&lt;T&gt;</dt>
    <dd><p>The scalar activation function to apply.</p>
</dd>
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The input tensor to activate.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The activated tensor.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This helper method applies a scalar activation function to each element of a tensor. If the activation
function is null, it returns the input tensor unchanged.
</p>
<p><b>For Beginners:</b> This method applies an activation function to each value in a tensor.
<p>Activation functions:</p>
<ul>
<li>Transform values in specific ways (like sigmoid squeezes values between 0 and 1)</li>
<li>Add non-linearity, which helps neural networks learn complex patterns</li>
<li>Are applied individually to each number in the data</li>
</ul>
<p>If no activation function is provided, the values pass through unchanged.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ActivateTensor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IVectorActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ActivateTensor(AiDotNet.Interfaces.IVectorActivationFunction{`0},AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  ActivateTensor(IVectorActivationFunction&lt;T&gt;?, Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1462"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies a vector activation function to a tensor.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected Tensor&lt;T&gt; ActivateTensor(IVectorActivationFunction&lt;T&gt;? activation, Tensor&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>activation</code> <a class="xref" href="AiDotNet.Interfaces.IVectorActivationFunction-1.html">IVectorActivationFunction</a>&lt;T&gt;</dt>
    <dd><p>The vector activation function to apply.</p>
</dd>
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The input tensor to activate.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The activated tensor.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IVectorActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This helper method applies a vector activation function to a tensor. If the activation function is null,
it returns the input tensor unchanged. Vector activation functions operate on entire tensors at once,
which can be more efficient than element-wise operations.
</p>
<p><b>For Beginners:</b> This method applies an activation function to an entire tensor at once.
<p>Vector activation functions:</p>
<ul>
<li>Process entire groups of values simultaneously</li>
<li>Can be more efficient than processing one value at a time</li>
<li>Provide the same mathematical result but often faster</li>
</ul>
<p>If no activation function is provided, the values pass through unchanged.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivation*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivation(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  ApplyActivation(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1356"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the activation function to a tensor.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected Tensor&lt;T&gt; ApplyActivation(Tensor&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The input tensor to activate.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The activated tensor.</p>
</dd>
  </dl>











  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivation*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivation(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  ApplyActivation(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1392"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the activation function to a vector.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected Vector&lt;T&gt; ApplyActivation(Vector&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The input vector to activate.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The activated vector.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Vector__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method applies the layer's activation function to a vector. It uses the vector activation function
if one is specified, or applies the scalar activation function element-wise if no vector activation is available.
</p>
<p><b>For Beginners:</b> This method applies the activation function to a vector of values.
<p>This method:</p>
<ul>
<li>First checks if a vector activation function is available (processes all elements together)</li>
<li>If not, uses the scalar activation function (processes each element independently)</li>
<li>If neither is available, returns the input unchanged (identity function)</li>
</ul>
<p>This flexibility allows the layer to use the most appropriate activation method
based on what was specified during creation.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationBackwardGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivationBackwardGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationBackwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivationBackwardGpu(AiDotNet.Tensors.Engines.DirectGpu.IDirectGpuBackend,AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer,AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer,AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer,AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer,System.Int32)">
  ApplyActivationBackwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer?, IGpuBuffer?, IGpuBuffer, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2366"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the layer's activation function backward pass on GPU using the activation's own GPU method.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected bool ApplyActivationBackwardGpu(IDirectGpuBackend backend, IGpuBuffer gradOutput, IGpuBuffer? input, IGpuBuffer? output, IGpuBuffer gradInput, int size)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>backend</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IDirectGpuBackend.html">IDirectGpuBackend</a></dt>
    <dd><p>The GPU backend to use for execution.</p>
</dd>
    <dt><code>gradOutput</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer.html">IGpuBuffer</a></dt>
    <dd><p>The gradient flowing back from the next layer.</p>
</dd>
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer.html">IGpuBuffer</a></dt>
    <dd><p>The input buffer from the forward pass (needed for some activations).</p>
</dd>
    <dt><code>output</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer.html">IGpuBuffer</a></dt>
    <dd><p>The output buffer from the forward pass (needed for some activations).</p>
</dd>
    <dt><code>gradInput</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer.html">IGpuBuffer</a></dt>
    <dd><p>The buffer to store the input gradient.</p>
</dd>
    <dt><code>size</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of elements to process.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if the backward pass was applied on GPU; false if no activation or GPU not supported.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationBackwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method follows the Open/Closed Principle by delegating to the activation function's
own GPU backward implementation. Each activation function knows what it needs:
- ReLU, GELU, Swish, LeakyReLU, SiLU, Mish, etc.: Need the input from forward pass
- Sigmoid, Tanh: Need the output from forward pass
- ELU: Needs both input and output from forward pass
</p>
<p>
<b>For Beginners:</b> During training, we need to compute how the activation affects
the gradients. Each activation function handles this differently, and by delegating
to the activation's BackwardGpu method, we don't need to know the details here.
</p>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivationDerivative*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivationDerivative(AiDotNet.Tensors.LinearAlgebra.Tensor{`0},AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  ApplyActivationDerivative(Tensor&lt;T&gt;, Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1668"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the derivative of the activation function to a tensor.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected Tensor&lt;T&gt; ApplyActivationDerivative(Tensor&lt;T&gt; input, Tensor&lt;T&gt; outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The input tensor.</p>
</dd>
    <dt><code>outputGradient</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The output gradient tensor.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The input gradient tensor after applying the activation derivative.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method applies the derivative of the layer's activation function to a tensor during the
backward pass. It multiplies the derivative of the activation function at each point in the input tensor
by the corresponding output gradient.
</p>
<p><b>For Beginners:</b> This calculates how small changes in values affect the output.
<p>During backpropagation:</p>
<ul>
<li>This method handles tensors (multi-dimensional arrays of values)</li>
<li>It applies the correct derivative calculation based on the activation type</li>
<li>For vector activations, it uses the specialized derivative method</li>
<li>For scalar activations, it applies the derivative to each value independently</li>
</ul>
<p>This is a key part of the math that allows neural networks to learn through backpropagation.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a></dt>
    <dd><p>Thrown when the input and output gradient tensors have different ranks.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivationDerivative*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Vector__0__AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivationDerivative(AiDotNet.Tensors.LinearAlgebra.Vector{`0},AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  ApplyActivationDerivative(Vector&lt;T&gt;, Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1785"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the derivative of the activation function to a vector.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected Vector&lt;T&gt; ApplyActivationDerivative(Vector&lt;T&gt; input, Vector&lt;T&gt; outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The input vector.</p>
</dd>
    <dt><code>outputGradient</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The output gradient vector.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The input gradient vector after applying the activation derivative.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Vector__0__AiDotNet_Tensors_LinearAlgebra_Vector__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method applies the derivative of the activation function to a vector during the backward pass.
It computes the Jacobian matrix of the activation function and multiplies it by the output gradient.
</p>
<p><b>For Beginners:</b> This calculates how changes in a vector of values affect the output.
<p>For vector operations:</p>
<ul>
<li>This method computes the full matrix of relationships between inputs and outputs</li>
<li>It then multiplies this matrix by the incoming gradient</li>
<li>The result shows how each input value should be adjusted</li>
</ul>
<p>This is a more comprehensive approach than the element-wise method,
accounting for cases where each output depends on multiple inputs.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivationDerivative*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative__0__0_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivationDerivative(`0,`0)">
  ApplyActivationDerivative(T, T)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1631"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the derivative of the activation function to a single value.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected T ApplyActivationDerivative(T input, T outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <span class="xref">T</span></dt>
    <dd><p>The input value.</p>
</dd>
    <dt><code>outputGradient</code> <span class="xref">T</span></dt>
    <dd><p>The output gradient.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><span class="xref">T</span></dt>
    <dd><p>The input gradient after applying the activation derivative.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative__0__0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method applies the derivative of the layer's activation function to a single value during the
backward pass. It multiplies the derivative of the activation function at the input value by the
output gradient.
</p>
<p><b>For Beginners:</b> This calculates how a small change in one value affects the output.
<p>During backpropagation:</p>
<ul>
<li>We need to know how sensitive each value is to changes</li>
<li>This method calculates that sensitivity for a single value</li>
<li>It multiplies the activation derivative by the incoming gradient</li>
</ul>
<p>This helps determine how much each individual value should be adjusted during training.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationForwardGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivationForwardGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationForwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivationForwardGpu(AiDotNet.Tensors.Engines.DirectGpu.IDirectGpuBackend,AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer,AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer,System.Int32)">
  ApplyActivationForwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2331"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the layer's activation function forward pass on GPU using the activation's own GPU method.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected bool ApplyActivationForwardGpu(IDirectGpuBackend backend, IGpuBuffer input, IGpuBuffer output, int size)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>backend</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IDirectGpuBackend.html">IDirectGpuBackend</a></dt>
    <dd><p>The GPU backend to use for execution.</p>
</dd>
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer.html">IGpuBuffer</a></dt>
    <dd><p>The input GPU buffer.</p>
</dd>
    <dt><code>output</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer.html">IGpuBuffer</a></dt>
    <dd><p>The output GPU buffer.</p>
</dd>
    <dt><code>size</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of elements to process.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if the activation was applied on GPU; false if no activation or GPU not supported.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationForwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method follows the Open/Closed Principle by delegating to the activation function's
own GPU implementation rather than using a switch statement on activation types.
Each activation function knows how to apply itself on GPU.
</p>
<p>
<b>For Beginners:</b> Instead of having one giant switch statement that handles every
possible activation type, each activation function has its own ForwardGpu method.
This makes it easy to add new activation functions without modifying this code.
</p>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationToGraph_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivationToGraph*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationToGraph_AiDotNet_Autodiff_ComputationNode__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyActivationToGraph(AiDotNet.Autodiff.ComputationNode{`0})">
  ApplyActivationToGraph(ComputationNode&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2112"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the layer's configured activation function to a computation graph node.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected ComputationNode&lt;T&gt; ApplyActivationToGraph(ComputationNode&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The computation node to apply activation to.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The computation node with activation applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationToGraph_AiDotNet_Autodiff_ComputationNode__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This helper method delegates to the activation's ApplyToGraph method,
following the Open/Closed Principle. Adding new activations does not require
modifying layer code.
</p>
<p><b>For Beginners:</b> This method adds the activation function to the computation graph.
<p>Instead of the layer code checking what type of activation is configured (which would
require changing the layer every time a new activation is added), this method simply
asks the activation to add itself to the graph. This makes the code more maintainable
and extensible.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></dt>
    <dd><p>Thrown if input is null.</p>
</dd>
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.notsupportedexception">NotSupportedException</a></dt>
    <dd><p>Thrown if activation does not support JIT.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivation_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyGpuActivation*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivation_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyGpuActivation(AiDotNet.Tensors.Engines.DirectGpu.IDirectGpuBackend,AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer,AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer,System.Int32,AiDotNet.Tensors.Engines.FusedActivationType)">
  ApplyGpuActivation(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int, FusedActivationType)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2444"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the specified activation function on GPU using the direct backend operations.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected static void ApplyGpuActivation(IDirectGpuBackend backend, IGpuBuffer input, IGpuBuffer output, int size, FusedActivationType activation)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>backend</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IDirectGpuBackend.html">IDirectGpuBackend</a></dt>
    <dd><p>The GPU backend to use for activation.</p>
</dd>
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer.html">IGpuBuffer</a></dt>
    <dd><p>The input GPU buffer.</p>
</dd>
    <dt><code>output</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer.html">IGpuBuffer</a></dt>
    <dd><p>The output GPU buffer.</p>
</dd>
    <dt><code>size</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of elements to process.</p>
</dd>
    <dt><code>activation</code> <a class="xref" href="AiDotNet.Tensors.Engines.FusedActivationType.html">FusedActivationType</a></dt>
    <dd><p>The type of activation function to apply.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivation_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method is primarily used for fused kernel operations where the activation type
is specified via the <a class="xref" href="AiDotNet.Tensors.Engines.FusedActivationType.html">FusedActivationType</a> enum. It maps enum values to
the corresponding backend activation kernels.
</p>
<p>
<b>Note:</b> For new code, prefer using <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationForwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">ApplyActivationForwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int)</a> which
follows the Open/Closed Principle by delegating to each activation function's own
GPU implementation. This allows new activation functions to be added without modifying
this switch statement.
</p>
<p>
This static method only supports common activations (ReLU, Sigmoid, Tanh, GELU, LeakyReLU, Swish).
For other activations, use the OCP-compliant method instead.
</p>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivationBackward_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyGpuActivationBackward*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivationBackward_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_System_Single_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ApplyGpuActivationBackward(AiDotNet.Tensors.Engines.DirectGpu.IDirectGpuBackend,AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer,AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer,AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer,AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer,System.Int32,AiDotNet.Tensors.Engines.FusedActivationType,System.Single)">
  ApplyGpuActivationBackward(IDirectGpuBackend, IGpuBuffer, IGpuBuffer?, IGpuBuffer?, IGpuBuffer, int, FusedActivationType, float)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2503"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Applies the backward pass of the specified activation function on GPU.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected static bool ApplyGpuActivationBackward(IDirectGpuBackend backend, IGpuBuffer gradOutput, IGpuBuffer? input, IGpuBuffer? output, IGpuBuffer gradInput, int size, FusedActivationType activation, float alpha = 0.01)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>backend</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IDirectGpuBackend.html">IDirectGpuBackend</a></dt>
    <dd><p>The GPU backend to use for activation backward.</p>
</dd>
    <dt><code>gradOutput</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer.html">IGpuBuffer</a></dt>
    <dd><p>The gradient from the next layer.</p>
</dd>
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer.html">IGpuBuffer</a></dt>
    <dd><p>The input from the forward pass (needed for ReLU, LeakyReLU, GELU, Swish).</p>
</dd>
    <dt><code>output</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer.html">IGpuBuffer</a></dt>
    <dd><p>The output from the forward pass (needed for Sigmoid, Tanh).</p>
</dd>
    <dt><code>gradInput</code> <a class="xref" href="AiDotNet.Tensors.Engines.DirectGpu.IGpuBuffer.html">IGpuBuffer</a></dt>
    <dd><p>The buffer to store the input gradient.</p>
</dd>
    <dt><code>size</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of elements to process.</p>
</dd>
    <dt><code>activation</code> <a class="xref" href="AiDotNet.Tensors.Engines.FusedActivationType.html">FusedActivationType</a></dt>
    <dd><p>The type of activation function.</p>
</dd>
    <dt><code>alpha</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.single">float</a></dt>
    <dd><p>Alpha parameter for LeakyReLU (default 0.01).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if the backward was handled on GPU, false if CPU fallback is needed.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivationBackward_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_System_Single__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method is primarily used for fused kernel operations where the activation type
is specified via the <a class="xref" href="AiDotNet.Tensors.Engines.FusedActivationType.html">FusedActivationType</a> enum.
</p>
<p>
<b>Note:</b> For new code, prefer using <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationBackwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">ApplyActivationBackwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer?, IGpuBuffer?, IGpuBuffer, int)</a> which
follows the Open/Closed Principle by delegating to each activation function's own
GPU backward implementation. This allows new activation functions to be added without
modifying this switch statement.
</p>
<p>
Different activation functions require different cached values from forward pass:
<ul><li>ReLU, LeakyReLU, GELU, Swish: Need the input from forward pass</li><li>Sigmoid, Tanh: Need the output from forward pass</li></ul>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Backward_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Backward*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Backward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Backward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L934"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the backward pass of the layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public abstract Tensor&lt;T&gt; Backward(Tensor&lt;T&gt; outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>outputGradient</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The gradient of the loss with respect to the layer's output.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The gradient of the loss with respect to the layer's input.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This abstract method must be implemented by derived classes to define the backward pass of the layer.
The backward pass propagates error gradients from the output of the layer back to its input,
and calculates gradients for any trainable parameters.
</p>
<p><b>For Beginners:</b> This method is used during training to calculate how the layer's input
should change to reduce errors.
<p>During the backward pass:</p>
<ol>
<li>The layer receives information about how its output contributed to errors</li>
<li>It calculates how its parameters should change to reduce errors</li>
<li>It calculates how its input should change, which will be used by earlier layers</li>
</ol>
<p>This is the core of how neural networks learn from their mistakes during training.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_BackwardGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.BackwardGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_BackwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.BackwardGpu(AiDotNet.Tensors.Engines.Gpu.IGpuTensor{`0})">
  BackwardGpu(IGpuTensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1057"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the backward pass of the layer on GPU.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual IGpuTensor&lt;T&gt; BackwardGpu(IGpuTensor&lt;T&gt; outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>outputGradient</code> <a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;</dt>
    <dd><p>The GPU-resident gradient of the loss with respect to the layer's output.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;</dt>
    <dd><p>The GPU-resident gradient of the loss with respect to the layer's input.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_BackwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs the layer's backward computation entirely on GPU, including:
<ul><li>Computing input gradients to pass to previous layers</li><li>Computing and storing weight gradients on GPU (for layers with trainable parameters)</li><li>Computing and storing bias gradients on GPU</li></ul>

<p><b>For Beginners:</b> This is like Backward() but runs entirely on GPU.
<p>During GPU training:</p>
<ol>
<li>Output gradients come in (on GPU)</li>
<li>Input gradients are computed (stay on GPU)</li>
<li>Weight/bias gradients are computed and stored (on GPU)</li>
<li>Input gradients are returned for the previous layer</li>
</ol>
<p>All data stays on GPU - no CPU round-trips needed!</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.notsupportedexception">NotSupportedException</a></dt>
    <dd><p>Thrown when the layer does not support GPU training.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateInputShape_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.CalculateInputShape*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateInputShape_System_Int32_System_Int32_System_Int32_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.CalculateInputShape(System.Int32,System.Int32,System.Int32)">
  CalculateInputShape(int, int, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1495"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Calculates a standard input shape for 2D data with batch size of 1.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected static int[] CalculateInputShape(int inputDepth, int height, int width)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputDepth</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The depth (number of channels) of the input.</p>
</dd>
    <dt><code>height</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The height of the input.</p>
</dd>
    <dt><code>width</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The width of the input.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>An array representing the input shape [batch, depth, height, width].</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateInputShape_System_Int32_System_Int32_System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This helper method calculates a standard input shape for 2D data (like images) with a batch size of 1.
The shape follows the NCHW (batch, channels, height, width) format.
</p>
<p><b>For Beginners:</b> This method creates a standard shape for image-like data.
<p>When working with images or similar 2D data:</p>
<ul>
<li>This creates a standard shape array in the format [batch, channels, height, width]</li>
<li>The batch dimension is set to 1 (processing one item at a time)</li>
<li>The other dimensions come from the parameters</li>
</ul>
<p>For example, for a 28x28 grayscale image, you might use inputDepth=1, height=28, width=28,
resulting in a shape of [1, 1, 28, 28].</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateOutputShape_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.CalculateOutputShape*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateOutputShape_System_Int32_System_Int32_System_Int32_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.CalculateOutputShape(System.Int32,System.Int32,System.Int32)">
  CalculateOutputShape(int, int, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1523"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Calculates a standard output shape for 2D data with batch size of 1.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected static int[] CalculateOutputShape(int outputDepth, int outputHeight, int outputWidth)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>outputDepth</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The depth (number of channels) of the output.</p>
</dd>
    <dt><code>outputHeight</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The height of the output.</p>
</dd>
    <dt><code>outputWidth</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The width of the output.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>An array representing the output shape [batch, depth, height, width].</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateOutputShape_System_Int32_System_Int32_System_Int32__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This helper method calculates a standard output shape for 2D data (like images) with a batch size of 1.
The shape follows the NCHW (batch, channels, height, width) format.
</p>
<p><b>For Beginners:</b> This method creates a standard shape for image-like output data.
<p>When defining the output shape for 2D data:</p>
<ul>
<li>This creates a standard shape array in the format [batch, channels, height, width]</li>
<li>The batch dimension is set to 1 (producing one output at a time)</li>
<li>The other dimensions come from the parameters</li>
</ul>
<p>For example, if a convolutional layer produces 16 feature maps of size 14x14,
you might use outputDepth=16, outputHeight=14, outputWidth=14.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanActivationBeJitted_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.CanActivationBeJitted*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanActivationBeJitted" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.CanActivationBeJitted">
  CanActivationBeJitted()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2166"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Checks if the layer's current activation function supports JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected bool CanActivationBeJitted()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if the activation can be JIT compiled, false otherwise.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanActivationBeJitted_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method checks whether the layer's configured activation function supports
JIT compilation by querying the activation's SupportsJitCompilation property.
If no activation is configured, returns true (identity function is always JIT-compatible).
</p>
<p><b>For Beginners:</b> This method checks if the activation is ready for JIT compilation.
<p>The layer uses this to determine if it can export a computation graph for faster inference.
If the activation does not support JIT yet (because gradients are not implemented), the
layer will fall back to the standard execution path.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ClearGradients_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ClearGradients*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ClearGradients" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ClearGradients">
  ClearGradients()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L667"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Clears all parameter gradients in this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual void ClearGradients()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ClearGradients_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method sets all parameter gradients to zero. This is typically called at the beginning of
each batch during training to ensure that gradients from previous batches don't affect the current batch.
</p>
<p><b>For Beginners:</b> This method resets all adjustment values to zero to start fresh.
<p>Clearing gradients:</p>
<ul>
<li>Erases all previous adjustment information</li>
<li>Prepares the layer for a new training batch</li>
<li>Prevents old adjustments from interfering with new ones</li>
</ul>
<p>This is typically done at the start of processing each batch of training data
to ensure clean, accurate gradient calculations.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Clone_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Clone*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Clone" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Clone">
  Clone()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1551"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Creates a copy of this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual LayerBase&lt;T&gt; Clone()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html">LayerBase</a>&lt;T&gt;</dt>
    <dd><p>A new instance of the layer with the same configuration.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Clone_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method creates a shallow copy of the layer with deep copies of the input/output shapes and
activation functions. Derived classes should override this method to properly copy any additional
fields they define.
</p>
<p><b>For Beginners:</b> This method creates a duplicate of this layer.
<p>When copying a layer:</p>
<ul>
<li>Basic properties like shapes are duplicated</li>
<li>Activation functions are cloned</li>
<li>The new layer works independently from the original</li>
</ul>
<p>This is useful for:</p>
<ul>
<li>Creating similar layers with small variations</li>
<li>Implementing complex network architectures with repeated patterns</li>
<li>Saving a layer's state before making changes</li>
</ul>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ComputeActivationJacobian_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ComputeActivationJacobian*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ComputeActivationJacobian_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ComputeActivationJacobian(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  ComputeActivationJacobian(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1744"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes the Jacobian matrix of the activation function for a given input vector.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected Matrix&lt;T&gt; ComputeActivationJacobian(Vector&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The input vector.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Matrix-1.html">Matrix</a>&lt;T&gt;</dt>
    <dd><p>The Jacobian matrix of the activation function at the input.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ComputeActivationJacobian_AiDotNet_Tensors_LinearAlgebra_Vector__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method computes the Jacobian matrix of the activation function, which represents how each
output element changes with respect to each input element. For vector activation functions,
it uses the function's derivative method. For scalar activation functions, it creates a diagonal
matrix with the derivatives.
</p>
<p><b>For Beginners:</b> This calculates a matrix that shows how changes in inputs affect outputs.
<p>The Jacobian matrix:</p>
<ul>
<li>Shows how each output value depends on each input value</li>
<li>For scalar activations, it's a diagonal matrix (each output depends only on the corresponding input)</li>
<li>For vector activations, it can have off-diagonal elements (outputs depend on multiple inputs)</li>
</ul>
<p>This is an advanced concept used in certain optimization techniques and for
precise gradient calculations.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_DerivativeTensor_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.DerivativeTensor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_DerivativeTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.DerivativeTensor(AiDotNet.Interfaces.IActivationFunction{`0},AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  DerivativeTensor(IActivationFunction&lt;T&gt;?, Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1599"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Calculates the derivative of a scalar activation function for each element of a tensor.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected Tensor&lt;T&gt; DerivativeTensor(IActivationFunction&lt;T&gt;? activation, Tensor&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>activation</code> <a class="xref" href="AiDotNet.Interfaces.IActivationFunction-1.html">IActivationFunction</a>&lt;T&gt;</dt>
    <dd><p>The scalar activation function.</p>
</dd>
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The input tensor.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>A tensor containing the derivatives.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_DerivativeTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This helper method calculates the derivative of a scalar activation function for each element of a tensor.
If the activation function is null, it returns a tensor filled with ones, representing the derivative of
the identity function.
</p>
<p><b>For Beginners:</b> This method calculates how sensitive each value is to changes.
<p>The derivative:</p>
<ul>
<li>Measures how much the output changes when the input changes slightly</li>
<li>Is essential for the backpropagation algorithm during training</li>
<li>Helps determine how to adjust weights to reduce errors</li>
</ul>
<p>If no activation function is provided, it assumes the identity function (y = x),
which has a derivative of 1 everywhere.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Deserialize_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Deserialize*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Deserialize_System_IO_BinaryReader_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Deserialize(System.IO.BinaryReader)">
  Deserialize(BinaryReader)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1898"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Deserializes the layer's parameters from a binary reader.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual void Deserialize(BinaryReader reader)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>reader</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.io.binaryreader">BinaryReader</a></dt>
    <dd><p>The binary reader to read from.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Deserialize_System_IO_BinaryReader__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method reads the layer's parameters from a binary reader, which can be used to load the layer's
state from a file or other storage medium. It reads the parameter count followed by each parameter value.
</p>
<p><b>For Beginners:</b> This method loads the layer's learned values from storage.
<p>When deserializing a layer:</p>
<ul>
<li>The number of parameters is read first</li>
<li>Then each parameter value is read</li>
<li>All values are converted from doubles to the appropriate numeric type</li>
</ul>
<p>This allows you to load a previously trained layer without
having to retrain it from scratch.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Dispose*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Dispose">
  Dispose()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2582"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Releases all resources used by this layer, including any GPU resources.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void Dispose()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method releases any resources allocated by the layer, including GPU memory for
persistent tensors. All layers that allocate resources should override Dispose(bool)
to properly release them.
</p>
<p><b>For Beginners:</b> GPU memory is limited and precious.
<p>When you're done with a layer:</p>
<ul>
<li>Call Dispose() or use a 'using' statement</li>
<li>This frees up GPU memory for other operations</li>
<li>Failing to dispose can cause memory leaks</li>
</ul>
<p>Example:</p>
<pre><code class="lang-csharp">using var layer = new DenseLayer&lt;float&gt;(784, 128);
// ... use layer ...
// Automatically disposed when out of scope</code></pre>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Dispose*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose_System_Boolean_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Dispose(System.Boolean)">
  Dispose(bool)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2613"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Releases resources used by this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected virtual void Dispose(bool disposing)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>disposing</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if called from Dispose(), false if called from finalizer.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose_System_Boolean__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Override this method in derived classes to release layer-specific resources.
Always call base.Dispose(disposing) after releasing your resources.
</p>
<p><b>For Beginners:</b> When creating a custom layer with resources:
<pre><code class="lang-csharp">protected override void Dispose(bool disposing)
{
    if (disposing)
    {
        // Release your managed resources here
        _myGpuHandle?.Dispose();
        _myGpuHandle = null;
    }
    base.Dispose(disposing);
}</code></pre>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_DownloadWeightsFromGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.DownloadWeightsFromGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_DownloadWeightsFromGpu" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.DownloadWeightsFromGpu">
  DownloadWeightsFromGpu()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1136"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Downloads the layer's weights and biases from GPU memory back to CPU.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual void DownloadWeightsFromGpu()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_DownloadWeightsFromGpu_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Call this after GPU training to sync weights back to CPU for:
<ul><li>Model checkpointing / saving</li><li>CPU inference</li><li>Inspection of trained weights</li></ul>

<p><b>For Beginners:</b> This copies learned values back from GPU to CPU.
<p>During GPU training, weights are modified on GPU and the CPU copy is stale.
Call this to:</p>
<ul>
<li>Save the model to disk</li>
<li>Switch to CPU inference</li>
<li>Examine what the layer learned</li>
</ul>
<p>This is relatively expensive, so only do it when necessary (not every batch).</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_EnsureInitialized_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.EnsureInitialized*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_EnsureInitialized" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.EnsureInitialized">
  EnsureInitialized()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L358"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Ensures that the layer is initialized. Call this at the start of Forward() for lazy initialization.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected virtual void EnsureInitialized()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_EnsureInitialized_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
For layers that support lazy initialization, this method should be called at the start
of Forward() to ensure weights are allocated before use. The default implementation
does nothing (for layers without lazy initialization support).
</p>
<p><b>For Beginners:</b> This makes sure the layer is ready before processing data.
<p>For lazy initialization:</p>
<ul>
<li>First call allocates and initializes weights</li>
<li>Subsequent calls do nothing (weights already initialized)</li>
<li>Thread-safe for parallel execution</li>
</ul>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ExportComputationGraph_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ExportComputationGraph*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0___" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ExportComputationGraph(System.Collections.Generic.List{AiDotNet.Autodiff.ComputationNode{`0}})">
  ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L803"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Exports the layer's computation graph for JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public abstract ComputationNode&lt;T&gt; ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt; inputNodes)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputNodes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.list-1">List</a>&lt;<a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;&gt;</dt>
    <dd><p>List to populate with input computation nodes.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The output computation node representing the layer's operation.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method constructs a computation graph representation of the layer's forward pass
that can be JIT compiled for faster inference. All layers MUST implement this method
to support JIT compilation.
</p>
<p><b>For Beginners:</b> JIT (Just-In-Time) compilation converts the layer's operations
into optimized native code for 5-10x faster inference.
<p>To support JIT compilation, a layer must:</p>
<ol>
<li>Implement this method to export its computation graph</li>
<li>Set SupportsJitCompilation to true</li>
<li>Use ComputationNode and TensorOperations to build the graph</li>
</ol>
<p>All layers are required to implement this method, even if they set SupportsJitCompilation = false.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Forward_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Forward*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Forward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Forward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L847"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the forward pass of the layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public abstract Tensor&lt;T&gt; Forward(Tensor&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The input tensor to process.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The output tensor after processing.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This abstract method must be implemented by derived classes to define the forward pass of the layer.
The forward pass transforms the input tensor according to the layer's operation and activation function.
</p>
<p><b>For Beginners:</b> This method processes your data through the layer.
<p>The forward pass:</p>
<ul>
<li>Takes input data from the previous layer or the network input</li>
<li>Applies the layer's specific transformation (like convolution or matrix multiplication)</li>
<li>Applies any activation function</li>
<li>Passes the result to the next layer</li>
</ul>
<p>This is where the actual data processing happens during both training and prediction.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Forward_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Forward*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0____" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Forward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0}[])">
  Forward(params Tensor&lt;T&gt;[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1290"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the forward pass of the layer with multiple input tensors.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Tensor&lt;T&gt; Forward(params Tensor&lt;T&gt;[] inputs)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputs</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;[]</dt>
    <dd><p>The input tensors to process.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The output tensor after processing.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0_____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method implements a default forward pass for layers that accept multiple inputs. By default,
it concatenates the inputs along the channel dimension. Derived classes can override this method
to implement more specific behavior for multiple inputs.
</p>
<p><b>For Beginners:</b> This method handles processing multiple inputs through the layer.
<p>When a layer needs to combine multiple data sources:</p>
<ul>
<li>This method takes all the input tensors</li>
<li>By default, it combines them by stacking them along the channel dimension</li>
<li>It checks that the inputs are compatible (same shape except for channels)</li>
<li>It then passes the combined data forward</li>
</ul>
<p>For example, if combining features from two sources each with 10 channels,
this would create a tensor with 20 channels by default.</p>
<p>Specialized layers can override this to combine inputs in different ways.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a></dt>
    <dd><p>Thrown when no input tensors are provided or when input tensors have incompatible shapes.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ForwardGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ForwardGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ForwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0____" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ForwardGpu(AiDotNet.Tensors.Engines.Gpu.IGpuTensor{`0}[])">
  ForwardGpu(params IGpuTensor&lt;T&gt;[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1025"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the forward pass of the layer on GPU.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual IGpuTensor&lt;T&gt; ForwardGpu(params IGpuTensor&lt;T&gt;[] inputs)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputs</code> <a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;[]</dt>
    <dd><p>The GPU-resident input tensor(s).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;</dt>
    <dd><p>The GPU-resident output tensor.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ForwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0_____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs the layer's forward computation entirely on GPU. The input and output
tensors remain in GPU memory, avoiding expensive CPU-GPU transfers.
</p>
<p><b>For Beginners:</b> This is like Forward() but runs on the graphics card.
<p>The key difference:</p>
<ul>
<li>Forward() uses CPU tensors that may be copied to/from GPU</li>
<li>ForwardGpu() keeps everything on GPU the whole time</li>
</ul>
<p>Override this in derived classes that support GPU acceleration.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.notsupportedexception">NotSupportedException</a></dt>
    <dd><p>Thrown when the layer does not support GPU execution.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetActivationTypes_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetActivationTypes*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetActivationTypes" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetActivationTypes">
  GetActivationTypes()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1210"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the types of activation functions used by this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual IEnumerable&lt;ActivationFunction&gt; GetActivationTypes()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ienumerable-1">IEnumerable</a>&lt;<a class="xref" href="AiDotNet.Enums.ActivationFunction.html">ActivationFunction</a>&gt;</dt>
    <dd><p>An enumerable of activation function types.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetActivationTypes_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method returns the types of activation functions used by this layer. This is useful for
serialization and debugging purposes.
</p>
<p><b>For Beginners:</b> This method tells you what kinds of activation functions the layer uses.
<p>This information:</p>
<ul>
<li>Helps identify what non-linearities are applied in the layer</li>
<li>Is useful for saving/loading models</li>
<li>Helps with debugging and visualization</li>
</ul>
<p>The information is returned as standardized activation types (like ReLU, Sigmoid, etc.)
rather than the actual function objects.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetBiases_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetBiases*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetBiases" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetBiases">
  GetBiases()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L779"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the bias tensor for layers that have trainable biases.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Tensor&lt;T&gt;? GetBiases()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The bias tensor, or null if the layer has no biases.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetBiases_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method provides access to the layer's bias tensor for layers that use biases
during computation. Layers without biases return null.
</p>
<p><b>For Beginners:</b> Biases are learnable offsets added to the layer's output.
<p>Think of biases as a starting point:</p>
<ul>
<li>Without bias: output = weights  input</li>
<li>With bias: output = weights  input + bias</li>
</ul>
<p>Biases help the network learn more flexible patterns by shifting the activation function.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetDiagnostics_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetDiagnostics*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetDiagnostics" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetDiagnostics">
  GetDiagnostics()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2063"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets diagnostic information about this layer's state and behavior.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Dictionary&lt;string, string&gt; GetDiagnostics()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.dictionary-2">Dictionary</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>, <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>A dictionary containing diagnostic metrics for this layer. Base implementation provides
common metrics like layer type, input/output shapes, and parameter count. Derived classes
can override this method to add layer-specific diagnostics.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetDiagnostics_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The base implementation provides the following diagnostics:
<ul><li><code>layer.type</code>: The concrete type name of the layer</li><li><code>layer.input_shape</code>: The shape of input tensors</li><li><code>layer.output_shape</code>: The shape of output tensors</li><li><code>layer.parameter_count</code>: The total number of trainable parameters</li><li><code>layer.supports_training</code>: Whether the layer has trainable parameters</li><li><code>layer.activation</code>: The activation function type, if any</li></ul>

<p><b>For Beginners:</b> This method returns a report card with useful information about the layer.
<p>The diagnostics help you understand:</p>
<ul>
<li>What type of layer this is (Dense, Convolutional, etc.)</li>
<li>What size of data it expects (input shape)</li>
<li>What size of data it produces (output shape)</li>
<li>How many parameters it's learning</li>
<li>What activation function it uses</li>
</ul>
<p>Derived classes (specific layer types) can add more detailed information:</p>
<ul>
<li>Attention layers might report attention weights statistics</li>
<li>Batch normalization layers might report running mean/variance</li>
<li>Dropout layers might report dropout rate</li>
</ul>
<p>Example usage:</p>
<pre><code class="lang-csharp">var diagnostics = layer.GetDiagnostics();
foreach (var (key, value) in diagnostics)
{
    Console.WriteLine($"{key}: {value}");
}</code></pre>

<p>
<b>Override Guidelines:</b>
When overriding in derived classes:
<ol><li>Call base.GetDiagnostics() first to get common metrics</li><li>Add your layer-specific diagnostics to the returned dictionary</li><li>Use consistent key naming (e.g., "activation.mean", "gradient.norm")</li><li>Provide human-readable string values</li><li>Keep computations lightweight to avoid impacting performance</li></ol>
<p>Example override:</p>
<pre><code class="lang-csharp">public override Dictionary&lt;string, string&gt; GetDiagnostics()
{
    var diagnostics = base.GetDiagnostics();

    if (_lastActivations != null)
    {
        diagnostics["activation.mean"] = ComputeMean(_lastActivations).ToString();
        diagnostics["activation.std"] = ComputeStd(_lastActivations).ToString();
    }

    return diagnostics;
}</code></pre>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetFusedActivationType_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetFusedActivationType*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetFusedActivationType" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetFusedActivationType">
  GetFusedActivationType()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2404"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the fused activation type for IEngine fused operations.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected FusedActivationType GetFusedActivationType()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.Engines.FusedActivationType.html">FusedActivationType</a></dt>
    <dd><p>The FusedActivationType enum value for the current activation function.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetFusedActivationType_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method maps the layer's activation function to a FusedActivationType enum value,
allowing IEngine to use optimized fused GPU kernels (e.g., GEMM+Bias+ReLU in one kernel).
</p>
<p><b>For Beginners:</b> GPU operations are faster when combined.
Instead of doing MatMul, then adding bias, then applying ReLU as separate steps,
fused operations do all three in one GPU kernel - this is 20-50% faster.
This method tells the GPU which activation to fuse with other operations.
</p>
<p><b>Supported Activations:</b></p>
<ul><li>ReLU  FusedActivationType.ReLU</li><li>Sigmoid  FusedActivationType.Sigmoid</li><li>Tanh  FusedActivationType.Tanh</li><li>GELU  FusedActivationType.GELU</li><li>LeakyReLU  FusedActivationType.LeakyReLU</li><li>Swish/SiLU  FusedActivationType.Swish</li><li>Other/None  FusedActivationType.None (activation applied separately)</li></ul>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShape_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetInputShape*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShape" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetInputShape">
  GetInputShape()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L694"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the input shape for this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual int[] GetInputShape()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The input shape as an array of integers.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShape_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method returns the input shape of the layer. If the layer has multiple input shapes,
it returns the first one.
</p>
<p><b>For Beginners:</b> This method tells you what shape of data the layer expects.
<p>The input shape:</p>
<ul>
<li>Shows the dimensions of data this layer processes</li>
<li>Is needed to connect this layer with previous layers</li>
<li>Helps verify the network structure is correct</li>
</ul>
<p>For layers with multiple inputs, this returns just the first input shape.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShapes_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetInputShapes*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShapes" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetInputShapes">
  GetInputShapes()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L715"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets all input shapes for this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual int[][] GetInputShapes()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[][]</dt>
    <dd><p>An array of input shapes.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShapes_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method returns all input shapes of the layer. This is particularly useful for layers that
accept multiple inputs with different shapes.
</p>
<p><b>For Beginners:</b> This method tells you the shapes of all data sources this layer can accept.
<p>For layers that combine multiple inputs:</p>
<ul>
<li>This returns all the input shapes in an array</li>
<li>Each shape defines the dimensions of one input source</li>
<li>Helpful for understanding complex network connections</li>
</ul>
<p>This is most useful for layers like concatenation or merge layers.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetOutputShape_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetOutputShape*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetOutputShape" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetOutputShape">
  GetOutputShape()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L737"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the output shape for this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int[] GetOutputShape()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The output shape as an array of integers.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetOutputShape_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method returns the output shape of the layer, which defines the dimensions of the tensor
that will be produced when data flows through this layer.
</p>
<p><b>For Beginners:</b> This method tells you what shape of data the layer produces.
<p>The output shape:</p>
<ul>
<li>Shows the dimensions of data after this layer processes it</li>
<li>Is needed to connect this layer with the next layer</li>
<li>Helps verify that data flows correctly through the network</li>
</ul>
<p>For example, a convolutional layer might change the number of channels in the data,
which would be reflected in the output shape.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterGradients_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetParameterGradients*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterGradients" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetParameterGradients">
  GetParameterGradients()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L638"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the gradients of all trainable parameters in this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Vector&lt;T&gt; GetParameterGradients()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>A vector containing the gradients of all trainable parameters.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterGradients_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method returns the gradients of all trainable parameters in the layer. If the gradients
haven't been calculated yet, it initializes a new vector of the appropriate size.
</p>
<p><b>For Beginners:</b> This method provides the current adjustment values for all parameters.
<p>The parameter gradients:</p>
<ul>
<li>Show how each parameter should be adjusted during training</li>
<li>Are calculated during the backward pass</li>
<li>Guide the optimization process</li>
</ul>
<p>These gradients are usually passed to an optimizer like SGD or Adam,
which uses them to update the parameters in a way that reduces errors.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterNames_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetParameterNames*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterNames" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetParameterNames">
  GetParameterNames()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2700"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets all parameter names in this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual IEnumerable&lt;string&gt; GetParameterNames()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ienumerable-1">IEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>A collection of parameter names (&quot;weight&quot;, &quot;bias&quot;, or both depending on layer type).</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterNames_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The default implementation returns "weight" and/or "bias" based on whether
GetWeights() and GetBiases() return non-null values.
</p>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterShape_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetParameterShape*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterShape_System_String_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetParameterShape(System.String)">
  GetParameterShape(string)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2794"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the expected shape for a parameter.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual int[]? GetParameterShape(string name)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>name</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The parameter name (&quot;weight&quot; or &quot;bias&quot;).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd><p>The expected shape, or null if the parameter doesn't exist.</p>
</dd>
  </dl>











  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameters_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetParameters*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameters" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetParameters">
  GetParameters()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1931"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets all trainable parameters of the layer as a single vector.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public abstract Vector&lt;T&gt; GetParameters()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>A vector containing all trainable parameters.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameters_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This abstract method must be implemented by derived classes to provide access to all trainable
parameters of the layer as a single vector. This is useful for optimization algorithms that operate
on all parameters at once, or for saving and loading model weights.
</p>
<p><b>For Beginners:</b> This method collects all the learnable values from the layer.
<p>The parameters:</p>
<ul>
<li>Are the numbers that the neural network learns during training</li>
<li>Include weights, biases, and other learnable values</li>
<li>Are combined into a single long list (vector)</li>
</ul>
<p>This is useful for:</p>
<ul>
<li>Saving the model to disk</li>
<li>Loading parameters from a previously trained model</li>
<li>Advanced optimization techniques that need access to all parameters</li>
</ul>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetWeights_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetWeights*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetWeights" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.GetWeights">
  GetWeights()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L759"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the weight matrix for layers that have trainable weights.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Tensor&lt;T&gt;? GetWeights()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The weight matrix, or null if the layer has no weights.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetWeights_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method provides access to the layer's weight matrix for layers that use weights
during computation. Layers without weights (like pooling or activation layers) return null.
</p>
<p><b>For Beginners:</b> Weights are the learnable parameters that define how a layer transforms data.
<p>For example:</p>
<ul>
<li>Dense layers use a weight matrix to transform inputs</li>
<li>Convolutional layers use filters (which are weights) to detect patterns</li>
<li>Pooling layers have no weights, so they return null</li>
</ul>
<p>This method lets you inspect or modify the weights after training.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_HasGpuActivation_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.HasGpuActivation*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_HasGpuActivation" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.HasGpuActivation">
  HasGpuActivation()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2306"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Checks if the layer's scalar activation function supports GPU training.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected bool HasGpuActivation()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if the activation function has GPU kernels; false otherwise.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_HasGpuActivation_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
<b>For Beginners:</b> Not all activation functions have GPU implementations yet.
This method checks whether the layer's activation can run entirely on the GPU.
If false, the layer must fall back to CPU computation for the activation.
</p>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_InvalidateTrainableParameter_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.InvalidateTrainableParameter*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_InvalidateTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.InvalidateTrainableParameter(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  InvalidateTrainableParameter(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2285"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Notifies the engine that a registered persistent tensor's data has changed.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected void InvalidateTrainableParameter(Tensor&lt;T&gt; tensor)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>tensor</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The tensor whose data has been modified.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_InvalidateTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Call this method after modifying a registered tensor's data (e.g., during parameter updates).
The engine will re-upload the data to GPU on the next operation that uses the tensor.
</p>
<p><b>For Beginners:</b> When you change the values in a registered tensor (like updating
weights during training), you need to tell the GPU that the copy it has is outdated.
This method does that - it tells the GPU "hey, this data changed, please get a fresh copy."
</p>
<p><b>Usage Pattern:</b></p>
<p>
Call after UpdateParameters modifies weights:
<pre><code class="lang-csharp">public override void UpdateParameters(T learningRate)
{
    // Update weights using gradients
    _weights = _weights.Subtract(_weightGradients.Multiply(learningRate));
<pre><code>// Notify engine that GPU copy is stale
InvalidateTrainableParameter(_weights);
</code></pre>
<p>}</p></code></pre>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_LoadWeights_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.LoadWeights*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_LoadWeights_System_Collections_Generic_Dictionary_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___System_Func_System_String_System_String__System_Boolean_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.LoadWeights(System.Collections.Generic.Dictionary{System.String,AiDotNet.Tensors.LinearAlgebra.Tensor{`0}},System.Func{System.String,System.String},System.Boolean)">
  LoadWeights(Dictionary&lt;string, Tensor&lt;T&gt;&gt;, Func&lt;string, string?&gt;?, bool)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2878"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Loads weights from a dictionary of tensors using optional name mapping.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual WeightLoadResult LoadWeights(Dictionary&lt;string, Tensor&lt;T&gt;&gt; weights, Func&lt;string, string?&gt;? mapping = null, bool strict = false)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>weights</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.dictionary-2">Dictionary</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>, <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;&gt;</dt>
    <dd><p>Dictionary of weight name to tensor.</p>
</dd>
    <dt><code>mapping</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.func-2">Func</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>, <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>Optional function to map source names to target names.</p>
</dd>
    <dt><code>strict</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>If true, fails when any mapped weight fails to load.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Interfaces.WeightLoadResult.html">WeightLoadResult</a></dt>
    <dd><p>Load result with statistics.</p>
</dd>
  </dl>











  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_MapActivationToFused_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.MapActivationToFused*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_MapActivationToFused" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.MapActivationToFused">
  MapActivationToFused()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L868"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Maps the layer's activation function to a <a class="xref" href="AiDotNet.Tensors.Engines.FusedActivationType.html">FusedActivationType</a> for GPU-fused operations.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected FusedActivationType MapActivationToFused()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.Engines.FusedActivationType.html">FusedActivationType</a></dt>
    <dd><p>The corresponding <a class="xref" href="AiDotNet.Tensors.Engines.FusedActivationType.html">FusedActivationType</a> for the layer's activation function,
or <a class="xref" href="AiDotNet.Tensors.Engines.FusedActivationType.html#AiDotNet_Tensors_Engines_FusedActivationType_None">None</a> if no activation is configured or the activation
type is not supported for GPU fusion.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_MapActivationToFused_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method is used by GPU-optimized layers to determine which fused activation kernel to use.
Fused operations combine matrix multiplication, bias addition, and activation into a single
GPU kernel, reducing memory bandwidth and improving performance.
</p>
<p><b>For Beginners:</b> When running on a GPU, combining multiple operations (like
matrix multiply and activation) into one step is faster than doing them separately.
This method tells the GPU which activation function to include in the combined operation.
</p>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_RegisterTrainableParameter_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.RegisterTrainableParameter*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_RegisterTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_Engines_PersistentTensorRole_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.RegisterTrainableParameter(AiDotNet.Tensors.LinearAlgebra.Tensor{`0},AiDotNet.Tensors.Engines.PersistentTensorRole)">
  RegisterTrainableParameter(Tensor&lt;T&gt;, PersistentTensorRole)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2248"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Registers a trainable parameter tensor with the engine for GPU memory optimization.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected void RegisterTrainableParameter(Tensor&lt;T&gt; tensor, PersistentTensorRole role)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>tensor</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The tensor to register (typically weights or biases).</p>
</dd>
    <dt><code>role</code> <a class="xref" href="AiDotNet.Tensors.Engines.PersistentTensorRole.html">PersistentTensorRole</a></dt>
    <dd><p>The role of the tensor for optimization hints.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_RegisterTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_Engines_PersistentTensorRole__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method hints to the engine that the tensor will be reused across many operations
and should be kept resident in GPU memory when a GPU engine is active. This avoids
expensive CPU-GPU data transfers on every forward pass.
</p>
<p><b>Performance Impact:</b></p>
<p>
Without registration: Layer weights (e.g., 285MB for a large Dense layer) are
transferred to GPU on every forward pass.
</p>
<p>
With registration: Weights are transferred once and cached on GPU. Only activations
(much smaller) are transferred per pass. Expected speedup: 100-1000x for large layers.
</p>
<p><b>For Beginners:</b> This method tells the GPU to keep certain data (like learned weights)
in its fast memory instead of copying it back and forth every time. Think of it like keeping
frequently used books on your desk instead of walking to the library each time.
</p>
<p><b>Usage Pattern:</b></p>
<p>
Call this method in the layer's constructor after initializing weight tensors:
<pre><code class="lang-csharp">public DenseLayer(int inputSize, int outputSize)
{
    _weights = new Tensor&lt;T&gt;(outputSize, inputSize);
    _biases = new Tensor&lt;T&gt;(outputSize);
    InitializeWeights();
<pre><code>// Register for GPU persistence
RegisterTrainableParameter(_weights, PersistentTensorRole.Weights);
RegisterTrainableParameter(_biases, PersistentTensorRole.Biases);
</code></pre>
<p>}</p></code></pre>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ResetState_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ResetState*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ResetState" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ResetState">
  ResetState()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1990"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Resets the internal state of the layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public abstract void ResetState()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ResetState_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This abstract method must be implemented by derived classes to reset any internal state the layer
maintains between forward and backward passes. This is useful when starting to process a new sequence
or when implementing stateful recurrent networks.
</p>
<p><b>For Beginners:</b> This method clears the layer's memory to start fresh.
<p>When resetting the state:</p>
<ul>
<li>Cached inputs and outputs are cleared</li>
<li>Any temporary calculations are discarded</li>
<li>The layer is ready to process new data without being influenced by previous data</li>
</ul>
<p>This is important for:</p>
<ul>
<li>Processing a new, unrelated sequence</li>
<li>Preventing information from one sequence affecting another</li>
<li>Starting a new training episode</li>
</ul>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Serialize_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Serialize*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Serialize_System_IO_BinaryWriter_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.Serialize(System.IO.BinaryWriter)">
  Serialize(BinaryWriter)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1869"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Serializes the layer's parameters to a binary writer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual void Serialize(BinaryWriter writer)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>writer</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.io.binarywriter">BinaryWriter</a></dt>
    <dd><p>The binary writer to write to.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_Serialize_System_IO_BinaryWriter__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method writes the layer's parameters to a binary writer, which can be used to save the layer's
state to a file or other storage medium. It writes the parameter count followed by each parameter value.
</p>
<p><b>For Beginners:</b> This method saves the layer's learned values to storage.
<p>When serializing a layer:</p>
<ul>
<li>The number of parameters is written first</li>
<li>Then each parameter value is written</li>
<li>All values are converted to doubles for consistent storage</li>
</ul>
<p>This allows you to save a trained layer and reload it later without
having to retrain it from scratch.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetBiases_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SetBiases*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetBiases_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SetBiases(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  SetBiases(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2683"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sets the bias tensor for this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected virtual void SetBiases(Tensor&lt;T&gt; biases)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>biases</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The bias tensor to set.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetBiases_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Derived classes with trainable biases should override this method to update their internal bias storage.
The default implementation throws an exception since LayerBase doesn't know the layer's bias structure.
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown if the layer does not support biases.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetParameter_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SetParameter*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SetParameter(System.String,AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  SetParameter(string, Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2748"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sets a parameter tensor by name.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual bool SetParameter(string name, Tensor&lt;T&gt; value)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>name</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The parameter name (&quot;weight&quot; or &quot;bias&quot;).</p>
</dd>
    <dt><code>value</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The tensor value to set.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if the parameter was set successfully, false if the name was not found.</p>
</dd>
  </dl>








  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a></dt>
    <dd><p>Thrown when the tensor shape doesn't match expected shape.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetParameters_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SetParameters*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SetParameters(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  SetParameters(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1958"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sets the trainable parameters of the layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual void SetParameters(Vector&lt;T&gt; parameters)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>parameters</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>A vector containing all parameters to set.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method sets all the trainable parameters of the layer from a single vector of parameters.
The parameters vector must have the correct length to match the total number of parameters in the layer.
By default, it simply assigns the parameters vector to the Parameters field, but derived classes
may override this to handle the parameters differently.
</p>
<p><b>For Beginners:</b> This method updates all the learnable values in the layer.
<p>When setting parameters:</p>
<ul>
<li>The input must be a vector with the correct length</li>
<li>The layer parses this vector to set all its internal parameters</li>
<li>Throws an error if the input doesn't match the expected number of parameters</li>
</ul>
<p>This is useful for:</p>
<ul>
<li>Loading a previously saved model</li>
<li>Transferring parameters from another model</li>
<li>Setting specific parameter values for testing</li>
</ul>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a></dt>
    <dd><p>Thrown when the parameters vector has incorrect length.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetTrainingMode_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SetTrainingMode*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetTrainingMode_System_Boolean_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SetTrainingMode(System.Boolean)">
  SetTrainingMode(bool)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L610"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sets whether the layer is in training mode or inference mode.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual void SetTrainingMode(bool isTraining)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>isTraining</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p><code>true</code> to set the layer to training mode; <code>false</code> to set it to inference mode.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetTrainingMode_System_Boolean__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method sets the layer's mode to either training or inference (evaluation). Some layers behave
differently during training versus inference, such as Dropout or BatchNormalization. This method
only has an effect if the layer supports training.
</p>
<p><b>For Beginners:</b> This method switches the layer between learning mode and prediction mode.
<p>Setting this mode:</p>
<ul>
<li>Tells the layer whether to optimize for learning or for making predictions</li>
<li>Changes behavior in layers like Dropout (which randomly ignores neurons during training)</li>
<li>Has no effect in layers that don't support training</li>
</ul>
<p>It's important to set this correctly before using a network - training mode for learning,
inference mode for making predictions.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetWeights_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SetWeights*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetWeights_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.SetWeights(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  SetWeights(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2665"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sets the weight tensor for this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected virtual void SetWeights(Tensor&lt;T&gt; weights)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>weights</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The weight tensor to set.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetWeights_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Derived classes with trainable weights should override this method to update their internal weight storage.
The default implementation throws an exception since LayerBase doesn't know the layer's weight structure.
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown if the layer does not support weights.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_TryGetParameter_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.TryGetParameter*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_TryGetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.TryGetParameter(System.String,AiDotNet.Tensors.LinearAlgebra.Tensor{`0}@)">
  TryGetParameter(string, out Tensor&lt;T&gt;?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2723"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Tries to get a parameter tensor by name.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual bool TryGetParameter(string name, out Tensor&lt;T&gt;? tensor)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>name</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The parameter name (&quot;weight&quot; or &quot;bias&quot;).</p>
</dd>
    <dt><code>tensor</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The parameter tensor if found.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if the parameter was found, false otherwise.</p>
</dd>
  </dl>











  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateInputShape_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.UpdateInputShape*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateInputShape_System_Int32___" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.UpdateInputShape(System.Int32[])">
  UpdateInputShape(int[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L228"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"></div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected void UpdateInputShape(int[] inputShape)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd></dd>
  </dl>












  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParameters_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.UpdateParameters*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.UpdateParameters(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  UpdateParameters(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1814"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Updates the parameters of the layer with the given vector of parameter values.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual void UpdateParameters(Vector&lt;T&gt; parameters)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>parameters</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>A vector containing all parameters to set.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method sets all the parameters of the layer from a single vector of parameters.
The parameters vector must have the correct length to match the total number of parameters in the layer.
</p>
<p><b>For Beginners:</b> This method updates all the learnable values in the layer at once.
<p>When updating parameters:</p>
<ul>
<li>The input must be a vector with the correct length</li>
<li>This replaces all the current parameters with the new ones</li>
<li>Throws an error if the input doesn't match the expected number of parameters</li>
</ul>
<p>This is useful for:</p>
<ul>
<li>Optimizers that work with all parameters at once</li>
<li>Applying parameters from another source</li>
<li>Setting parameters to specific values for testing</li>
</ul>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a></dt>
    <dd><p>Thrown when the parameters vector has incorrect length.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParameters_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.UpdateParameters*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParameters__0_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.UpdateParameters(`0)">
  UpdateParameters(T)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1188"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Updates the parameters of the layer using the calculated gradients.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public abstract void UpdateParameters(T learningRate)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>learningRate</code> <span class="xref">T</span></dt>
    <dd><p>The learning rate to use for the parameter updates.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParameters__0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This abstract method must be implemented by derived classes to define how the layer's parameters
are updated during training. The learning rate controls the size of the parameter updates.
</p>
<p><b>For Beginners:</b> This method updates the layer's internal values during training.
<p>When updating parameters:</p>
<ul>
<li>The weights, biases, or other parameters are adjusted to reduce prediction errors</li>
<li>The learning rate controls how big each update step is</li>
<li>Smaller learning rates mean slower but more stable learning</li>
<li>Larger learning rates mean faster but potentially unstable learning</li>
</ul>
<p>This is how the layer &quot;learns&quot; from data over time, gradually improving
its ability to extract useful patterns from inputs.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParametersGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.UpdateParametersGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParametersGpu_AiDotNet_Interfaces_IGpuOptimizerConfig_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.UpdateParametersGpu(AiDotNet.Interfaces.IGpuOptimizerConfig)">
  UpdateParametersGpu(IGpuOptimizerConfig)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1083"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Updates the layer's parameters on GPU using the specified optimizer configuration.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual void UpdateParametersGpu(IGpuOptimizerConfig config)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>config</code> <a class="xref" href="AiDotNet.Interfaces.IGpuOptimizerConfig.html">IGpuOptimizerConfig</a></dt>
    <dd><p>The GPU optimizer configuration specifying the update algorithm and hyperparameters.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParametersGpu_AiDotNet_Interfaces_IGpuOptimizerConfig__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method updates weights and biases directly on GPU using the optimizer specified in the config.
Supported optimizers include SGD, Adam, AdamW, RMSprop, Adagrad, NAG, LARS, and LAMB.
</p>
<p><b>For Beginners:</b> This updates the layer's learned values entirely on GPU.
<p>The config determines which optimizer algorithm to use:</p>
<ul>
<li>SGD: Simple gradient descent with optional momentum</li>
<li>Adam: Adaptive learning rates with moment estimates (most popular)</li>
<li>AdamW: Adam with proper weight decay (recommended for transformers)</li>
</ul>
<p>Using this method keeps all training computation on the GPU for maximum speed.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.notsupportedexception">NotSupportedException</a></dt>
    <dd><p>Thrown when the layer does not support GPU training.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UploadWeightsToGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.UploadWeightsToGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UploadWeightsToGpu" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.UploadWeightsToGpu">
  UploadWeightsToGpu()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1107"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Uploads the layer's weights and biases to GPU memory for GPU-resident training.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual void UploadWeightsToGpu()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_UploadWeightsToGpu_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Call this before starting GPU training to initialize GPU weight buffers.
The CPU weights are copied to GPU and remain there until DownloadWeightsFromGpu is called.
</p>
<p><b>For Beginners:</b> This copies the layer's learned values to the GPU.
<p>Call this once at the start of training to:</p>
<ul>
<li>Create GPU buffers for weights and biases</li>
<li>Copy current values from CPU to GPU</li>
<li>Create GPU buffers for gradients and optimizer states (momentum, etc.)</li>
</ul>
<p>After this, all training can happen on GPU without CPU involvement.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ValidateWeights_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ValidateWeights*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ValidateWeights_System_Collections_Generic_IEnumerable_System_String__System_Func_System_String_System_String__" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ValidateWeights(System.Collections.Generic.IEnumerable{System.String},System.Func{System.String,System.String})">
  ValidateWeights(IEnumerable&lt;string&gt;, Func&lt;string, string?&gt;?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L2831"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Validates that a set of weight names can be loaded into this layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual WeightLoadValidation ValidateWeights(IEnumerable&lt;string&gt; weightNames, Func&lt;string, string?&gt;? mapping = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>weightNames</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ienumerable-1">IEnumerable</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>Names of weights to validate.</p>
</dd>
    <dt><code>mapping</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.func-2">Func</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>, <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</dt>
    <dd><p>Optional weight name mapping function.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Interfaces.WeightLoadValidation.html">WeightLoadValidation</a></dt>
    <dd><p>Validation result with matched and unmatched names.</p>
</dd>
  </dl>











  <a id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ZeroGradientsGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ZeroGradientsGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ZeroGradientsGpu" data-uid="AiDotNet.NeuralNetworks.Layers.LayerBase`1.ZeroGradientsGpu">
  ZeroGradientsGpu()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L1159"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Resets the GPU gradient accumulators to zero.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual void ZeroGradientsGpu()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_LayerBase_1_ZeroGradientsGpu_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Call this at the start of each training batch to clear accumulated gradients from the previous batch.
</p>
<p><b>For Beginners:</b> This clears the "how to improve" information from the last batch.
<p>Each batch computes new gradients. Before processing a new batch, you need to:</p>
<ul>
<li>Clear the old gradients</li>
<li>Compute fresh gradients for the current batch</li>
<li>Update weights based on the new gradients</li>
</ul>
<p>If you forget to zero gradients, they accumulate and training goes wrong!</p>

</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/LayerBase.cs/#L34" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
