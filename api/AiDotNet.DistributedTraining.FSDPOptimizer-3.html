<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class FSDPOptimizer&lt;T, TInput, TOutput&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class FSDPOptimizer&lt;T, TInput, TOutput&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Implements FSDP (Fully Sharded Data Parallel) optimizer wrapper that coordinates optimization across multiple processes.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_DistributedTraining_FSDPOptimizer_3.md&amp;value=---%0Auid%3A%20AiDotNet.DistributedTraining.FSDPOptimizer%603%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3">



  <h1 id="AiDotNet_DistributedTraining_FSDPOptimizer_3" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3" class="text-break">
Class FSDPOptimizer&lt;T, TInput, TOutput&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/DistributedTraining/FSDPOptimizer.cs/#L61"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.DistributedTraining.html">DistributedTraining</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Implements FSDP (Fully Sharded Data Parallel) optimizer wrapper that coordinates optimization across multiple processes.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class FSDPOptimizer&lt;T, TInput, TOutput&gt; : ShardedOptimizerBase&lt;T, TInput, TOutput&gt;, IShardedOptimizer&lt;T, TInput, TOutput&gt;, IOptimizer&lt;T, TInput, TOutput&gt;, IModelSerializer</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type</p>
</dd>
    <dt><code>TInput</code></dt>
    <dd><p>The input type for the model</p>
</dd>
    <dt><code>TOutput</code></dt>
    <dd><p>The output type for the model</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html">ShardedOptimizerBase</a>&lt;T, TInput, TOutput&gt;</div>
      <div><span class="xref">FSDPOptimizer&lt;T, TInput, TOutput&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.DistributedTraining.IShardedOptimizer-3.html">IShardedOptimizer</a>&lt;T, TInput, TOutput&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IOptimizer-3.html">IOptimizer</a>&lt;T, TInput, TOutput&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IModelSerializer.html">IModelSerializer</a></div>
    </dd>
  </dl>

  <dl class="typelist derived">
    <dt>Derived</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.DistributedTraining.ZeRO3Optimizer-3.html">ZeRO3Optimizer&lt;T, TInput, TOutput&gt;</a></div>
    </dd>
  </dl>

  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_NumOps">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.NumOps</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_Config">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.Config</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_WrappedOptimizer">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.WrappedOptimizer</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_WrappedOptimizerInternal">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.WrappedOptimizerInternal</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_Rank">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.Rank</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_WorldSize">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.WorldSize</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_ShardingConfiguration">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.ShardingConfiguration</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_Optimize_AiDotNet_Models_Inputs_OptimizationInputData__0__1__2__">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.Optimize(OptimizationInputData&lt;T, TInput, TOutput&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_SynchronizeOptimizerState">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.SynchronizeOptimizerState()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_SynchronizeParameters_AiDotNet_Interfaces_IFullModel__0__1__2__">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.SynchronizeParameters(IFullModel&lt;T, TInput, TOutput&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_ShouldEarlyStop">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.ShouldEarlyStop()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_GetOptions">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.GetOptions()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_LastComputedGradients">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.LastComputedGradients</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_ApplyGradients_AiDotNet_Tensors_LinearAlgebra_Vector__0__AiDotNet_Interfaces_IFullModel__0__1__2__">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.ApplyGradients(Vector&lt;T&gt;, IFullModel&lt;T, TInput, TOutput&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_Reset">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.Reset()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_Serialize">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.Serialize()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_Deserialize_System_Byte___">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.Deserialize(byte[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_SaveModel_System_String_">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.SaveModel(string)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.DistributedTraining.ShardedOptimizerBase-3.html#AiDotNet_DistributedTraining_ShardedOptimizerBase_3_LoadModel_System_String_">ShardedOptimizerBase&lt;T, TInput, TOutput&gt;.LoadModel(string)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>

  <dl class="typelist extensionMethods">
    <dt>Extension Methods</dt>
    <dd>
  <div>
      <a class="xref" href="AiDotNet.DistributedTraining.DistributedExtensions.html#AiDotNet_DistributedTraining_DistributedExtensions_AsDistributed__3_AiDotNet_Interfaces_IOptimizer___0___1___2__AiDotNet_DistributedTraining_ICommunicationBackend___0__">DistributedExtensions.AsDistributed&lt;T, TInput, TOutput&gt;(IOptimizer&lt;T, TInput, TOutput&gt;, ICommunicationBackend&lt;T&gt;)</a>
  </div>
  <div>
      <a class="xref" href="AiDotNet.DistributedTraining.DistributedExtensions.html#AiDotNet_DistributedTraining_DistributedExtensions_AsDistributed__3_AiDotNet_Interfaces_IOptimizer___0___1___2__AiDotNet_DistributedTraining_IShardingConfiguration___0__">DistributedExtensions.AsDistributed&lt;T, TInput, TOutput&gt;(IOptimizer&lt;T, TInput, TOutput&gt;, IShardingConfiguration&lt;T&gt;)</a>
  </div>
  </dd></dl>



  <h2 id="AiDotNet_DistributedTraining_FSDPOptimizer_3_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p><b>Strategy Overview:</b>
FSDP optimizer works in conjunction with FSDPModel to provide full sharding of optimizer states.
This means momentum buffers, variance estimates, and all other optimizer-specific state are sharded
across processes, minimizing memory usage while maintaining training effectiveness.
</p>
<p><b>For Beginners:</b>
This class wraps any existing optimizer (like Adam, SGD, etc.) and makes it work with FSDP strategy
across multiple GPUs or machines. It automatically handles:
- Synchronizing gradients across all processes
- Sharding optimizer states (momentum, variance) to save memory
- Coordinating parameter updates
- Ensuring all processes stay in sync
</p>
<p>
Think of it like a team of coaches working together - each coach has their own expertise
(the wrapped optimizer), but they share only the essential information and keep their detailed
notes (optimizer states) private to save space.
</p>
<p><b>Use Cases:</b>
- Training very large models with optimizers that have significant state (Adam, RMSprop)
- Maximizing memory efficiency when using stateful optimizers
- Scaling to hundreds or thousands of GPUs
</p>
<p><b>Trade-offs:</b>
- Memory: Excellent - shards optimizer states across processes
- Communication: Moderate - syncs gradients and occasional state synchronization
- Complexity: Moderate - automatic state sharding
- Best for: Large models with stateful optimizers (Adam, RMSprop, etc.)
</p>
<p>
Example:
<pre><code class="lang-csharp">// Original optimizer
var optimizer = new AdamOptimizer&lt;double, Tensor&lt;double&gt;, Tensor&lt;double&gt;&gt;(model, options);
<p>// Wrap it for FSDP distributed training
var backend = new InMemoryCommunicationBackend&lt;double&gt;(rank: 0, worldSize: 4);
var config = new ShardingConfiguration&lt;double&gt;(backend);
var fsdpOptimizer = new FSDPOptimizer&lt;double, Tensor&lt;double&gt;, Tensor&lt;double&gt;&gt;(
optimizer, config);</p>
<p>// Now optimize as usual - FSDP magic happens automatically!
var result = fsdpOptimizer.Optimize(inputData);</p></code></pre>

</div>


  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_DistributedTraining_FSDPOptimizer_3__ctor_" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.#ctor*"></a>

  <h3 id="AiDotNet_DistributedTraining_FSDPOptimizer_3__ctor_AiDotNet_Interfaces_IOptimizer__0__1__2__AiDotNet_DistributedTraining_IShardingConfiguration__0__" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.#ctor(AiDotNet.Interfaces.IOptimizer{`0,`1,`2},AiDotNet.DistributedTraining.IShardingConfiguration{`0})">
  FSDPOptimizer(IOptimizer&lt;T, TInput, TOutput&gt;, IShardingConfiguration&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/DistributedTraining/FSDPOptimizer.cs/#L81"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Creates a new FSDP optimizer wrapping an existing optimizer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public FSDPOptimizer(IOptimizer&lt;T, TInput, TOutput&gt; wrappedOptimizer, IShardingConfiguration&lt;T&gt; config)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>wrappedOptimizer</code> <a class="xref" href="AiDotNet.Interfaces.IOptimizer-3.html">IOptimizer</a>&lt;T, TInput, TOutput&gt;</dt>
    <dd><p>The optimizer to wrap with FSDP capabilities</p>
</dd>
    <dt><code>config</code> <a class="xref" href="AiDotNet.DistributedTraining.IShardingConfiguration-1.html">IShardingConfiguration</a>&lt;T&gt;</dt>
    <dd><p>Configuration for sharding and communication</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_DistributedTraining_FSDPOptimizer_3__ctor_AiDotNet_Interfaces_IOptimizer__0__1__2__AiDotNet_DistributedTraining_IShardingConfiguration__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Beginners:</b>
This constructor takes your existing optimizer and makes it distributed using FSDP strategy.
You provide:
1. The optimizer you want to make distributed
2. A configuration that tells us how to do the distribution
</p>
<p>
The optimizer will automatically synchronize across all processes during optimization
and shard optimizer states to minimize memory usage.
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></dt>
    <dd><p>Thrown if optimizer or config is null</p>
</dd>
  </dl>



  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_DistributedTraining_FSDPOptimizer_3_Deserialize_" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.Deserialize*"></a>

  <h3 id="AiDotNet_DistributedTraining_FSDPOptimizer_3_Deserialize_System_Byte___" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.Deserialize(System.Byte[])">
  Deserialize(byte[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/DistributedTraining/FSDPOptimizer.cs/#L187"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Loads a previously serialized model from binary data.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void Deserialize(byte[] data)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>data</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.byte">byte</a>[]</dt>
    <dd><p>The byte array containing the serialized model data.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_DistributedTraining_FSDPOptimizer_3_Deserialize_System_Byte____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This method takes binary data created by the Serialize method and uses it to
restore a model to its previous state.</p>
<p><b>For Beginners:</b> This is like opening a saved file to continue your work.</p>
<p>When you call this method:</p>
<ul>
<li>You provide the binary data (bytes) that was previously created by Serialize</li>
<li>The model rebuilds itself using this data</li>
<li>After deserializing, the model is exactly as it was when serialized</li>
<li>It's ready to make predictions without needing to be trained again</li>
</ul>
<p>For example:</p>
<ul>
<li>You download a pre-trained model file for detecting spam emails</li>
<li>You deserialize this file into your application</li>
<li>Immediately, your application can detect spam without any training</li>
<li>The model has all the knowledge that was built into it by its original creator</li>
</ul>
<p>This is particularly useful when:</p>
<ul>
<li>You want to use a model that took days to train</li>
<li>You need to deploy the same model across multiple devices</li>
<li>You're creating an application that non-technical users will use</li>
</ul>
<p>Think of it like installing the brain of a trained expert directly into your application.</p>
</div>




  <a id="AiDotNet_DistributedTraining_FSDPOptimizer_3_GetOptions_" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.GetOptions*"></a>

  <h3 id="AiDotNet_DistributedTraining_FSDPOptimizer_3_GetOptions" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.GetOptions">
  GetOptions()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/DistributedTraining/FSDPOptimizer.cs/#L160"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the configuration options for the optimization algorithm.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override OptimizationAlgorithmOptions&lt;T, TInput, TOutput&gt; GetOptions()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Models.Options.OptimizationAlgorithmOptions-3.html">OptimizationAlgorithmOptions</a>&lt;T, TInput, TOutput&gt;</dt>
    <dd><p>The configuration options for the optimization algorithm.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_DistributedTraining_FSDPOptimizer_3_GetOptions_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>These options control how the optimization algorithm behaves, including
parameters like learning rate, maximum iterations, and convergence criteria.</p>
<p><b>For Beginners:</b> This provides the &quot;settings&quot; or &quot;rules&quot; that the optimizer follows.
Just like a recipe has instructions (bake at 350Â°F for 30 minutes), an optimizer
has settings (learn at rate 0.01, stop after 1000 tries).</p>
<p>Common optimization options include:</p>
<ul>
<li>Learning rate: How big of adjustments to make (step size)</li>
<li>Maximum iterations: How many attempts to make before giving up</li>
<li>Tolerance: How small an improvement is considered &quot;good enough&quot; to stop</li>
<li>Regularization: Settings that prevent the model from becoming too complex</li>
</ul>
</div>




  <a id="AiDotNet_DistributedTraining_FSDPOptimizer_3_LoadModel_" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.LoadModel*"></a>

  <h3 id="AiDotNet_DistributedTraining_FSDPOptimizer_3_LoadModel_System_String_" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.LoadModel(System.String)">
  LoadModel(string)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/DistributedTraining/FSDPOptimizer.cs/#L243"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Loads the model from a file.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void LoadModel(string filePath)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>filePath</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The path to the file containing the saved model.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_DistributedTraining_FSDPOptimizer_3_LoadModel_System_String__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This method provides a convenient way to load a model directly from disk.
It combines file I/O operations with deserialization.</p>
<p><b>For Beginners:</b> This is like clicking &quot;Open&quot; in a document editor.
Instead of manually reading from a file and then calling Deserialize(), this method does both steps for you.</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.io.filenotfoundexception">FileNotFoundException</a></dt>
    <dd><p>Thrown when the specified file does not exist.</p>
</dd>
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.io.ioexception">IOException</a></dt>
    <dd><p>Thrown when an I/O error occurs while reading from the file or when the file contains corrupted or invalid model data.</p>
</dd>
  </dl>



  <a id="AiDotNet_DistributedTraining_FSDPOptimizer_3_Optimize_" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.Optimize*"></a>

  <h3 id="AiDotNet_DistributedTraining_FSDPOptimizer_3_Optimize_AiDotNet_Models_Inputs_OptimizationInputData__0__1__2__" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.Optimize(AiDotNet.Models.Inputs.OptimizationInputData{`0,`1,`2})">
  Optimize(OptimizationInputData&lt;T, TInput, TOutput&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/DistributedTraining/FSDPOptimizer.cs/#L89"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the optimization process to find the best parameters for a model.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override OptimizationResult&lt;T, TInput, TOutput&gt; Optimize(OptimizationInputData&lt;T, TInput, TOutput&gt; inputData)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputData</code> <a class="xref" href="AiDotNet.Models.Inputs.OptimizationInputData-3.html">OptimizationInputData</a>&lt;T, TInput, TOutput&gt;</dt>
    <dd><p>The data needed for optimization, including the objective function,
initial parameters, and any constraints.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Models.Results.OptimizationResult-3.html">OptimizationResult</a>&lt;T, TInput, TOutput&gt;</dt>
    <dd><p>The result of the optimization process, including the optimized parameters
and performance metrics.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_DistributedTraining_FSDPOptimizer_3_Optimize_AiDotNet_Models_Inputs_OptimizationInputData__0__1__2___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This method takes input data and attempts to find the optimal parameters
that minimize or maximize the objective function.</p>
<p><b>For Beginners:</b> This is where the actual &quot;learning&quot; happens. The optimizer looks at your data
and tries different parameter values to find the ones that make your model perform best.</p>
<p>The process typically involves:</p>
<ol>
<li>Evaluating how well the current parameters perform</li>
<li>Calculating how to change the parameters to improve performance</li>
<li>Updating the parameters</li>
<li>Repeating until the model performs well enough or reaches a maximum number of attempts</li>
</ol>
</div>




  <a id="AiDotNet_DistributedTraining_FSDPOptimizer_3_SaveModel_" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.SaveModel*"></a>

  <h3 id="AiDotNet_DistributedTraining_FSDPOptimizer_3_SaveModel_System_String_" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.SaveModel(System.String)">
  SaveModel(string)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/DistributedTraining/FSDPOptimizer.cs/#L221"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Saves the model to a file.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void SaveModel(string filePath)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>filePath</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The path where the model should be saved.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_DistributedTraining_FSDPOptimizer_3_SaveModel_System_String__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This method provides a convenient way to save the model directly to disk.
It combines serialization with file I/O operations.</p>
<p><b>For Beginners:</b> This is like clicking &quot;Save As&quot; in a document editor.
Instead of manually calling Serialize() and then writing to a file, this method does both steps for you.</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.io.ioexception">IOException</a></dt>
    <dd><p>Thrown when an I/O error occurs while writing to the file.</p>
</dd>
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.unauthorizedaccessexception">UnauthorizedAccessException</a></dt>
    <dd><p>Thrown when the caller does not have the required permission to write to the specified file path.</p>
</dd>
  </dl>



  <a id="AiDotNet_DistributedTraining_FSDPOptimizer_3_Serialize_" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.Serialize*"></a>

  <h3 id="AiDotNet_DistributedTraining_FSDPOptimizer_3_Serialize" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.Serialize">
  Serialize()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/DistributedTraining/FSDPOptimizer.cs/#L166"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Converts the current state of a machine learning model into a binary format.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override byte[] Serialize()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.byte">byte</a>[]</dt>
    <dd><p>A byte array containing the serialized model data.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_DistributedTraining_FSDPOptimizer_3_Serialize_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This method captures all the essential information about a trained model and converts it
into a sequence of bytes that can be stored or transmitted.</p>
<p><b>For Beginners:</b> This is like exporting your work to a file.</p>
<p>When you call this method:</p>
<ul>
<li>The model's current state (all its learned patterns and parameters) is captured</li>
<li>This information is converted into a compact binary format (bytes)</li>
<li>You can then save these bytes to a file, database, or send them over a network</li>
</ul>
<p>For example:</p>
<ul>
<li>After training a model to recognize cats vs. dogs in images</li>
<li>You can serialize the model to save all its learned knowledge</li>
<li>Later, you can use this saved data to recreate the model exactly as it was</li>
<li>The recreated model will make the same predictions as the original</li>
</ul>
<p>Think of it like taking a snapshot of your model's brain at a specific moment in time.</p>
</div>




  <a id="AiDotNet_DistributedTraining_FSDPOptimizer_3_ShouldEarlyStop_" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.ShouldEarlyStop*"></a>

  <h3 id="AiDotNet_DistributedTraining_FSDPOptimizer_3_ShouldEarlyStop" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.ShouldEarlyStop">
  ShouldEarlyStop()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/DistributedTraining/FSDPOptimizer.cs/#L138"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Determines whether the optimization process should stop early.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool ShouldEarlyStop()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if the optimization process should stop early; otherwise, false.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_DistributedTraining_FSDPOptimizer_3_ShouldEarlyStop_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>Early stopping is a technique to prevent overfitting by stopping the optimization
process before it completes all iterations if certain conditions are met.</p>
<p><b>For Beginners:</b> This is like knowing when to stop cooking - if the model is &quot;done&quot;
(trained well enough), this method says &quot;stop now&quot; instead of continuing unnecessarily.</p>
<p>Common reasons for early stopping include:</p>
<ul>
<li>The model's performance isn't improving anymore</li>
<li>The model's performance on validation data is getting worse (overfitting)</li>
<li>The changes in parameters are becoming very small (convergence)</li>
</ul>
<p>Early stopping helps:</p>
<ul>
<li>Save computation time</li>
<li>Prevent the model from becoming too specialized to the training data</li>
<li>Produce models that generalize better to new data</li>
</ul>
</div>




  <a id="AiDotNet_DistributedTraining_FSDPOptimizer_3_SynchronizeOptimizerState_" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.SynchronizeOptimizerState*"></a>

  <h3 id="AiDotNet_DistributedTraining_FSDPOptimizer_3_SynchronizeOptimizerState" data-uid="AiDotNet.DistributedTraining.FSDPOptimizer`3.SynchronizeOptimizerState">
  SynchronizeOptimizerState()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/DistributedTraining/FSDPOptimizer.cs/#L118"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Synchronizes optimizer state (like momentum buffers) across all processes.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void SynchronizeOptimizerState()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_DistributedTraining_FSDPOptimizer_3_SynchronizeOptimizerState_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Beginners:</b>
Some optimizers (like Adam) keep track of past gradients to make smarter updates.
This method makes sure all processes have the same optimizer state, so they stay
coordinated. It's like making sure all team members are reading from the same playbook.
</p>
</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/DistributedTraining/FSDPOptimizer.cs/#L61" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
