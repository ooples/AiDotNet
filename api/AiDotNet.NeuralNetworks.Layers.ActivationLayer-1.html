<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class ActivationLayer&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class ActivationLayer&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="A layer that applies an activation function to transform the input data.  Activation functions introduce non-linearity to neural networks. Non-linearity means the output isn&#39;t  simply proportional to the input (like y = 2x). Instead, it can follow curves or more complex patterns. severely limiting what it can learn.   Common activation functions include: - ReLU: Returns 0 for negative inputs, or the input value for positive inputs - Sigmoid: Squashes values between 0 and 1, useful for probabilities - Tanh: Similar to sigmoid but outputs values between -1 and 1">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_NeuralNetworks_Layers_ActivationLayer_1.md&amp;value=---%0Auid%3A%20AiDotNet.NeuralNetworks.Layers.ActivationLayer%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1">



  <h1 id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1" class="text-break">
Class ActivationLayer&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L22"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.NeuralNetworks.html">NeuralNetworks</a>.<a class="xref" href="AiDotNet.NeuralNetworks.Layers.html">Layers</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>A layer that applies an activation function to transform the input data.</p>
<p>
Activation functions introduce non-linearity to neural networks. Non-linearity means the output isn't 
simply proportional to the input (like y = 2x). Instead, it can follow curves or more complex patterns.
severely limiting what it can learn.
</p>
<p>
Common activation functions include:
- ReLU: Returns 0 for negative inputs, or the input value for positive inputs
- Sigmoid: Squashes values between 0 and 1, useful for probabilities
- Tanh: Similar to sigmoid but outputs values between -1 and 1
</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class ActivationLayer&lt;T&gt; : LayerBase&lt;T&gt;, ILayer&lt;T&gt;, IJitCompilable&lt;T&gt;, IDiagnosticsProvider, IWeightLoadable&lt;T&gt;, IDisposable</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for calculations (like float, double, etc.)</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html">LayerBase</a>&lt;T&gt;</div>
      <div><span class="xref">ActivationLayer&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IJitCompilable-1.html">IJitCompilable</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IDiagnosticsProvider.html">IDiagnosticsProvider</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.IWeightLoadable-1.html">IWeightLoadable</a>&lt;T&gt;</div>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.idisposable">IDisposable</a></div>
    </dd>
  </dl>


  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Engine">LayerBase&lt;T&gt;.Engine</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ScalarActivation">LayerBase&lt;T&gt;.ScalarActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_VectorActivation">LayerBase&lt;T&gt;.VectorActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UsingVectorActivation">LayerBase&lt;T&gt;.UsingVectorActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_NumOps">LayerBase&lt;T&gt;.NumOps</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Random">LayerBase&lt;T&gt;.Random</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Parameters">LayerBase&lt;T&gt;.Parameters</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ParameterGradients">LayerBase&lt;T&gt;.ParameterGradients</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShape">LayerBase&lt;T&gt;.InputShape</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShapes">LayerBase&lt;T&gt;.InputShapes</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateInputShape_System_Int32___">LayerBase&lt;T&gt;.UpdateInputShape(int[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_OutputShape">LayerBase&lt;T&gt;.OutputShape</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsTrainingMode">LayerBase&lt;T&gt;.IsTrainingMode</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationStrategy">LayerBase&lt;T&gt;.InitializationStrategy</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsInitialized">LayerBase&lt;T&gt;.IsInitialized</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationLock">LayerBase&lt;T&gt;.InitializationLock</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_EnsureInitialized">LayerBase&lt;T&gt;.EnsureInitialized()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UseAutodiff">LayerBase&lt;T&gt;.UseAutodiff</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetTrainingMode_System_Boolean_">LayerBase&lt;T&gt;.SetTrainingMode(bool)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterGradients">LayerBase&lt;T&gt;.GetParameterGradients()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ClearGradients">LayerBase&lt;T&gt;.ClearGradients()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShape">LayerBase&lt;T&gt;.GetInputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShapes">LayerBase&lt;T&gt;.GetInputShapes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetOutputShape">LayerBase&lt;T&gt;.GetOutputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetWeights">LayerBase&lt;T&gt;.GetWeights()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetBiases">LayerBase&lt;T&gt;.GetBiases()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_MapActivationToFused">LayerBase&lt;T&gt;.MapActivationToFused()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuTraining">LayerBase&lt;T&gt;.SupportsGpuTraining</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanExecuteOnGpu">LayerBase&lt;T&gt;.CanExecuteOnGpu</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanTrainOnGpu">LayerBase&lt;T&gt;.CanTrainOnGpu</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParametersGpu_AiDotNet_Interfaces_IGpuOptimizerConfig_">LayerBase&lt;T&gt;.UpdateParametersGpu(IGpuOptimizerConfig)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UploadWeightsToGpu">LayerBase&lt;T&gt;.UploadWeightsToGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_DownloadWeightsFromGpu">LayerBase&lt;T&gt;.DownloadWeightsFromGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ZeroGradientsGpu">LayerBase&lt;T&gt;.ZeroGradientsGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetActivationTypes">LayerBase&lt;T&gt;.GetActivationTypes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0____">LayerBase&lt;T&gt;.Forward(params Tensor&lt;T&gt;[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ApplyActivation(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ApplyActivation(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ActivateTensor(IActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IVectorActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ActivateTensor(IVectorActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateInputShape_System_Int32_System_Int32_System_Int32_">LayerBase&lt;T&gt;.CalculateInputShape(int, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateOutputShape_System_Int32_System_Int32_System_Int32_">LayerBase&lt;T&gt;.CalculateOutputShape(int, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Clone">LayerBase&lt;T&gt;.Clone()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_DerivativeTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.DerivativeTensor(IActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative__0__0_">LayerBase&lt;T&gt;.ApplyActivationDerivative(T, T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ApplyActivationDerivative(Tensor&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ComputeActivationJacobian_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ComputeActivationJacobian(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Vector__0__AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ApplyActivationDerivative(Vector&lt;T&gt;, Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.UpdateParameters(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ParameterCount">LayerBase&lt;T&gt;.ParameterCount</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Serialize_System_IO_BinaryWriter_">LayerBase&lt;T&gt;.Serialize(BinaryWriter)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Deserialize_System_IO_BinaryReader_">LayerBase&lt;T&gt;.Deserialize(BinaryReader)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.SetParameters(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetDiagnostics">LayerBase&lt;T&gt;.GetDiagnostics()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationToGraph_AiDotNet_Autodiff_ComputationNode__0__">LayerBase&lt;T&gt;.ApplyActivationToGraph(ComputationNode&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanActivationBeJitted">LayerBase&lt;T&gt;.CanActivationBeJitted()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_RegisterTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_Engines_PersistentTensorRole_">LayerBase&lt;T&gt;.RegisterTrainableParameter(Tensor&lt;T&gt;, PersistentTensorRole)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InvalidateTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.InvalidateTrainableParameter(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_HasGpuActivation">LayerBase&lt;T&gt;.HasGpuActivation()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationForwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">LayerBase&lt;T&gt;.ApplyActivationForwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationBackwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">LayerBase&lt;T&gt;.ApplyActivationBackwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetFusedActivationType">LayerBase&lt;T&gt;.GetFusedActivationType()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivation_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_">LayerBase&lt;T&gt;.ApplyGpuActivation(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int, FusedActivationType)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivationBackward_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_System_Single_">LayerBase&lt;T&gt;.ApplyGpuActivationBackward(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int, FusedActivationType, float)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose">LayerBase&lt;T&gt;.Dispose()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose_System_Boolean_">LayerBase&lt;T&gt;.Dispose(bool)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_WeightParameterName">LayerBase&lt;T&gt;.WeightParameterName</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_BiasParameterName">LayerBase&lt;T&gt;.BiasParameterName</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetWeights_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetWeights(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetBiases_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetBiases(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterNames">LayerBase&lt;T&gt;.GetParameterNames()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_TryGetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___">LayerBase&lt;T&gt;.TryGetParameter(string, out Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetParameter(string, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterShape_System_String_">LayerBase&lt;T&gt;.GetParameterShape(string)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_NamedParameterCount">LayerBase&lt;T&gt;.NamedParameterCount</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ValidateWeights_System_Collections_Generic_IEnumerable_System_String__System_Func_System_String_System_String__">LayerBase&lt;T&gt;.ValidateWeights(IEnumerable&lt;string&gt;, Func&lt;string, string&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_LoadWeights_System_Collections_Generic_Dictionary_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___System_Func_System_String_System_String__System_Boolean_">LayerBase&lt;T&gt;.LoadWeights(Dictionary&lt;string, Tensor&lt;T&gt;&gt;, Func&lt;string, string&gt;, bool)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>






  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1__ctor_" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.#ctor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1__ctor_System_Int32___AiDotNet_Interfaces_IActivationFunction__0__" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.#ctor(System.Int32[],AiDotNet.Interfaces.IActivationFunction{`0})">
  ActivationLayer(int[], IActivationFunction&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L117"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"></div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public ActivationLayer(int[] inputShape, IActivationFunction&lt;T&gt; activationFunction)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd></dd>
    <dt><code>activationFunction</code> <a class="xref" href="AiDotNet.Interfaces.IActivationFunction-1.html">IActivationFunction</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>












  <a id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1__ctor_" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.#ctor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1__ctor_System_Int32___AiDotNet_Interfaces_IVectorActivationFunction__0__" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.#ctor(System.Int32[],AiDotNet.Interfaces.IVectorActivationFunction{`0})">
  ActivationLayer(int[], IVectorActivationFunction&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L165"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"></div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public ActivationLayer(int[] inputShape, IVectorActivationFunction&lt;T&gt; vectorActivationFunction)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputShape</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>[]</dt>
    <dd></dd>
    <dt><code>vectorActivationFunction</code> <a class="xref" href="AiDotNet.Interfaces.IVectorActivationFunction-1.html">IVectorActivationFunction</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>












  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_SupportsGpuExecution_" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.SupportsGpuExecution*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_SupportsGpuExecution" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.SupportsGpuExecution">
  SupportsGpuExecution
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L665"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this layer's activation function supports GPU execution.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected override bool SupportsGpuExecution { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_SupportsGpuExecution_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
GPU execution is supported for common scalar activation functions that have
dedicated GPU kernels: ReLU, LeakyReLU, Sigmoid, Tanh, GELU, and Swish.
</p>
<p><b>For Beginners:</b> This tells you if the activation function can run on GPU.
Most common activations like ReLU and Sigmoid have GPU support.
Exotic or vector activations (like Softmax) may not support GPU execution yet.
</p>
</div>




  <a id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_SupportsJitCompilation_" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.SupportsJitCompilation*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_SupportsJitCompilation" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.SupportsJitCompilation">
  SupportsJitCompilation
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L641"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this activation layer supports JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsJitCompilation { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if the activation function supports JIT compilation, false otherwise.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_SupportsJitCompilation_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property checks whether the configured activation function supports JIT compilation.
Returns false if no activation is configured or if the activation doesn't support JIT.
</p>
<p><b>For Beginners:</b> This tells you if this layer can use JIT compilation for faster inference.
<p>The layer can be JIT compiled if:</p>
<ul>
<li>The activation function (ReLU, Sigmoid, etc.) has JIT support implemented</li>
<li>The activation's gradient computation is available</li>
</ul>
<p>Common activations like ReLU, Sigmoid, and Tanh typically support JIT.
Custom or exotic activations may not support it yet.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_SupportsTraining_" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.SupportsTraining*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_SupportsTraining" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.SupportsTraining">
  SupportsTraining
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L77"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Indicates whether this layer has trainable parameters.</p>
<p>
Always returns false because activation layers don't have parameters to train.
Unlike layers such as Dense/Convolutional layers which have weights and biases
that need updating during training, activation layers simply apply a fixed
mathematical function to their inputs.
</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsTraining { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_SupportsTraining_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property overrides the base class property to specify that activation layers do not have trainable parameters.
Trainable parameters are values within a layer that are adjusted during the training process to minimize the loss
function. Since activation layers simply apply a fixed mathematical function to their inputs without any adjustable
parameters, this property always returns false.
</p>
<p><b>For Beginners:</b> This tells you that activation layers don't learn or change during training.
<p>While layers like Dense layers have weights that get updated during training,
activation layers just apply a fixed mathematical formula that never changes.</p>
<p>Think of it like this:</p>
<ul>
<li>Dense layers are like adjustable knobs that the network learns to tune</li>
<li>Activation layers are like fixed functions (like f(x) = max(0, x) for ReLU)</li>
</ul>
<p>This property helps the training system know that it doesn't need to
update anything in this layer during the training process.</p>

</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_Backward_" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.Backward*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.Backward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Backward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L261"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Calculates how changes in the output affect the input during training.</p>
<p>
This is called during the backward pass (backpropagation) when training the neural network.
Backpropagation is the algorithm that determines how much each neuron contributed to the error
in the network's prediction, allowing the network to adjust its parameters to reduce future errors.
</p>
<p>
For activation layers, the backward pass calculates how the gradient (rate of change) of the error
with respect to the layer's output should be modified to get the gradient with respect to the layer's input.
This involves applying the derivative of the activation function.
</p>
<p>
For example, with ReLU activation, the derivative is 1 for inputs that were positive, and 0 for inputs
that were negative or zero. This means the gradient flows unchanged through positive activations
but gets blocked (multiplied by zero) for negative activations.
</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; Backward(Tensor&lt;T&gt; outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>outputGradient</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>How much the network's error changes with respect to this layer's output</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>How much the network's error changes with respect to this layer's input</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method implements the backward pass for the activation layer. It checks that a forward pass has been performed
and that the output gradient has the same shape as the input. Then it applies either the scalar or vector activation
derivative based on the layer's configuration. For scalar activation, the derivative is applied element-wise and
multiplied by the output gradient. For vector activation, the derivative tensor is multiplied by the output gradient.
</p>
<p><b>For Beginners:</b> This method calculates how the error gradient flows backward through this layer.
<p>During backpropagation, the network calculates how each part contributed to the error.
This method:</p>
<ol>
<li>Checks that Forward() was called first (we need the saved input)</li>
<li>Verifies the gradient has the correct shape</li>
<li>Calculates how the gradient changes as it passes through this layer</li>
<li>Returns the modified gradient</li>
</ol>
<p>For example, with ReLU activation:</p>
<ul>
<li>If the input was positive, the gradient passes through unchanged</li>
<li>If the input was negative, the gradient is blocked (becomes 0)</li>
</ul>
<p>This is because ReLU's derivative is 1 for positive inputs and 0 for negative inputs.</p>
<p>This process helps the network understand which neurons to adjust during training.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Exceptions.ForwardPassRequiredException.html">ForwardPassRequiredException</a></dt>
    <dd><p>Thrown if called before Forward method</p>
</dd>
    <dt><a class="xref" href="AiDotNet.Exceptions.TensorShapeMismatchException.html">TensorShapeMismatchException</a></dt>
    <dd><p>Thrown if the gradient shape doesn't match the input shape</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_BackwardGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.BackwardGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_BackwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.BackwardGpu(AiDotNet.Tensors.Engines.Gpu.IGpuTensor{`0})">
  BackwardGpu(IGpuTensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L717"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs GPU-resident backward pass for the activation layer.
Computes gradient with respect to input entirely on GPU - no CPU roundtrip.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override IGpuTensor&lt;T&gt; BackwardGpu(IGpuTensor&lt;T&gt; outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>outputGradient</code> <a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;</dt>
    <dd><p>GPU-resident gradient from the next layer.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;</dt>
    <dd><p>GPU-resident gradient to pass to the previous layer.</p>
</dd>
  </dl>








  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown if ForwardGpu was not called first.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_ExportComputationGraph_" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.ExportComputationGraph*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0___" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.ExportComputationGraph(System.Collections.Generic.List{AiDotNet.Autodiff.ComputationNode{`0}})">
  ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L592"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Exports the activation layer's computation graph for JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override ComputationNode&lt;T&gt; ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt; inputNodes)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputNodes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.list-1">List</a>&lt;<a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;&gt;</dt>
    <dd><p>List to populate with input computation nodes.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The output computation node representing the activation function applied to the input.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method constructs a computation graph representation of the activation layer by:
1. Validating input parameters and layer configuration
2. Creating a symbolic input node with proper batch dimension
3. Applying the activation function to the symbolic input
</p>
<p><b>For Beginners:</b> This method converts the activation layer into a computation graph for JIT compilation.
<p>The computation graph describes:</p>
<ul>
<li>Input: A symbolic tensor with batch size = 1 plus the layer's input shape</li>
<li>Operation: Apply the activation function (ReLU, Sigmoid, etc.)</li>
<li>Output: The activated tensor</li>
</ul>
<p>JIT compilation can make inference 5-10x faster by optimizing this graph into native code.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_Forward_" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.Forward*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.Forward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Forward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L208"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Processes the input data by applying the activation function.</p>
<p>
This is called during the forward pass of the neural network, which is when
data flows from the input layer through all hidden layers to the output layer.
The forward pass is used both during training and when making predictions with a trained model.
</p>
<p>
For example, if using ReLU activation, this method would replace all negative values in the input
with zeros while keeping positive values unchanged.
</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; Forward(Tensor&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The input data to process</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The transformed data after applying the activation function</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method implements the forward pass for the activation layer. It stores the input tensor for later use in the
backward pass, then applies either a scalar or vector activation function based on the layer's configuration.
For scalar activation, the function is applied to each element independently. For vector activation, the function
is applied to the entire tensor at once.
</p>
<p><b>For Beginners:</b> This method applies the activation function to transform the input data.
<p>During the forward pass, data flows through the network from input to output.
This method:</p>
<ol>
<li>Saves the input for later use in backpropagation</li>
<li>Applies the activation function to transform the data</li>
<li>Returns the transformed data</li>
</ol>
<p>For example, with ReLU activation:</p>
<ul>
<li>Input: [-2, 0, 3, -1, 5]</li>
<li>Output: [0, 0, 3, 0, 5] (negative values become 0)</li>
</ul>
<p>This transformation adds non-linearity to the network, which is essential
for learning complex patterns in the data.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_ForwardGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.ForwardGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_ForwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0____" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.ForwardGpu(AiDotNet.Tensors.Engines.Gpu.IGpuTensor{`0}[])">
  ForwardGpu(params IGpuTensor&lt;T&gt;[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L684"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the forward pass on GPU using GPU-accelerated activation kernels.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override IGpuTensor&lt;T&gt; ForwardGpu(params IGpuTensor&lt;T&gt;[] inputs)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputs</code> <a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;[]</dt>
    <dd></dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;</dt>
    <dd><p>A GPU tensor with the activation function applied.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_ForwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0_____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method applies the activation function entirely on the GPU using optimized kernels.
Supported activations: ReLU, LeakyReLU, Sigmoid, Tanh, GELU, Swish.
</p>
<p><b>For Beginners:</b> The GPU version of activation is much faster for large tensors
because GPUs can process thousands of values in parallel.
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown when GPU execution is not supported for this activation type.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_GetParameters_" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.GetParameters*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_GetParameters" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.GetParameters">
  GetParameters()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L515"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets all trainable parameters of this layer as a flat vector.</p>
<p>
This method is useful for operations that need to work with all parameters at once,
such as certain optimization algorithms, regularization techniques, or when saving a model.
</p>
<p>
Returns an empty vector since activation layers have no trainable parameters.
Other layer types like Dense layers would return their weights and biases.
</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Vector&lt;T&gt; GetParameters()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>An empty vector representing the layer's parameters</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_GetParameters_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method returns all trainable parameters of the layer as a flat vector. For layers with trainable
parameters, this would involve reshaping multi-dimensional parameters (like weight matrices) into a
one-dimensional vector. However, since activation layers have no trainable parameters, this method
returns an empty vector.
</p>
<p><b>For Beginners:</b> This method returns all the layer's trainable values as a single list, but activation layers have none.
<p>Some operations in neural networks need to work with all parameters at once:</p>
<ul>
<li>Saving and loading models</li>
<li>Applying regularization (techniques to prevent overfitting)</li>
<li>Using advanced optimization algorithms</li>
</ul>
<p>This method provides those parameters as a single vector, but since
activation layers don't have any trainable parameters, it returns an empty vector.</p>
<p>For comparison:</p>
<ul>
<li>A Dense layer with 100 inputs and 10 outputs would return a vector with 1,010 values
(1,000 weights + 10 biases)</li>
<li>This ActivationLayer returns an empty vector with 0 values</li>
</ul>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_ResetState_" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.ResetState*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_ResetState" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.ResetState">
  ResetState()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L561"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Clears the layer's memory of previous inputs.</p>
<p>
Neural networks maintain state between operations, especially during training.
This method resets that state, which is useful in several scenarios:
- When starting to process a new batch of data
- Between training epochs
- When switching from training to evaluation mode
- When you want to ensure the layer behaves deterministically
</p>
<p>
For activation layers, this means forgetting the last input that was processed,
which was stored to help with the backward pass calculations.
</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void ResetState()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_ResetState_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method resets the internal state of the layer by clearing the cached input tensor. The activation
layer stores the input from the most recent forward pass to use during the backward pass for calculating
gradients. Resetting this state is useful when starting to process new data or when you want to ensure
the layer behaves deterministically.
</p>
<p><b>For Beginners:</b> This method clears the layer's memory of previous calculations.
<p>During training, the layer remembers the last input it processed to help with
backpropagation calculations. This method makes the layer &quot;forget&quot; that input.</p>
<p>You might need to reset state:</p>
<ul>
<li>When starting a new batch of training data</li>
<li>Between training epochs</li>
<li>When switching from training to testing</li>
<li>When you want to ensure consistent behavior</li>
</ul>
<p>For activation layers, this is simple - it just clears the saved input tensor.
Other layer types might have more complex state to reset.</p>
<p>This helps ensure that processing one batch doesn't accidentally affect
the processing of the next batch.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_UpdateParameters_" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.UpdateParameters*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_UpdateParameters__0_" data-uid="AiDotNet.NeuralNetworks.Layers.ActivationLayer`1.UpdateParameters(`0)">
  UpdateParameters(T)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L475"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Updates the layer's internal parameters during training.</p>
<p>
This method is part of the training process where layers adjust their parameters
(weights and biases) based on the gradients calculated during backpropagation.
</p>
<p>
For activation layers, this method does nothing because they have no trainable parameters.
Unlike layers such as Dense layers which need to update their weights and biases,
activation layers simply apply a fixed mathematical function.
</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void UpdateParameters(T learningRate)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>learningRate</code> <span class="xref">T</span></dt>
    <dd><p>How quickly the network should learn from new data. Higher values mean bigger parameter updates.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_ActivationLayer_1_UpdateParameters__0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method is called during the training process after the forward and backward passes have been completed.
For layers with trainable parameters, this method would update those parameters based on the gradients
calculated during backpropagation and the provided learning rate. However, since activation layers have
no trainable parameters, this method does nothing.
</p>
<p><b>For Beginners:</b> This method would update the layer's internal values during training, but activation layers have nothing to update.
<p>In neural networks, training involves adjusting parameters to reduce errors.
This method is where those adjustments happen, but activation layers don't have
any adjustable parameters, so this method is empty.</p>
<p>For comparison:</p>
<ul>
<li>In a Dense layer, this would update weights and biases</li>
<li>In a BatchNorm layer, this would update scale and shift parameters</li>
<li>In this ActivationLayer, there's nothing to update</li>
</ul>
<p>The learning rate parameter controls how big the updates would be if there
were any parameters to update - higher values mean bigger changes.</p>

</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/ActivationLayer.cs/#L22" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
