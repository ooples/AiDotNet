<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class ProductQuantizationCompression&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class ProductQuantizationCompression&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Implements Product Quantization (PQ) compression for model weights.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_ModelCompression_ProductQuantizationCompression_1.md&amp;value=---%0Auid%3A%20AiDotNet.ModelCompression.ProductQuantizationCompression%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.ModelCompression.ProductQuantizationCompression`1">



  <h1 id="AiDotNet_ModelCompression_ProductQuantizationCompression_1" data-uid="AiDotNet.ModelCompression.ProductQuantizationCompression`1" class="text-break">
Class ProductQuantizationCompression&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ModelCompression/ProductQuantizationCompression.cs/#L60"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.ModelCompression.html">ModelCompression</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Implements Product Quantization (PQ) compression for model weights.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class ProductQuantizationCompression&lt;T&gt; : ModelCompressionBase&lt;T&gt;, IModelCompressionStrategy&lt;T&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for calculations (e.g., float, double).</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.ModelCompression.ModelCompressionBase-1.html">ModelCompressionBase</a>&lt;T&gt;</div>
      <div><span class="xref">ProductQuantizationCompression&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.Interfaces.IModelCompressionStrategy-1.html">IModelCompressionStrategy</a>&lt;T&gt;</div>
    </dd>
  </dl>


  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.ModelCompression.ModelCompressionBase-1.html#AiDotNet_ModelCompression_ModelCompressionBase_1_NumOps">ModelCompressionBase&lt;T&gt;.NumOps</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ModelCompression.ModelCompressionBase-1.html#AiDotNet_ModelCompression_ModelCompressionBase_1_CalculateCompressionRatio_System_Int64_System_Int64_">ModelCompressionBase&lt;T&gt;.CalculateCompressionRatio(long, long)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ModelCompression.ModelCompressionBase-1.html#AiDotNet_ModelCompression_ModelCompressionBase_1_CompressMatrix_AiDotNet_Tensors_LinearAlgebra_Matrix__0__">ModelCompressionBase&lt;T&gt;.CompressMatrix(Matrix&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ModelCompression.ModelCompressionBase-1.html#AiDotNet_ModelCompression_ModelCompressionBase_1_DecompressMatrix_AiDotNet_Tensors_LinearAlgebra_Matrix__0__AiDotNet_Interfaces_ICompressionMetadata__0__">ModelCompressionBase&lt;T&gt;.DecompressMatrix(Matrix&lt;T&gt;, ICompressionMetadata&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ModelCompression.ModelCompressionBase-1.html#AiDotNet_ModelCompression_ModelCompressionBase_1_GetCompressedSize_AiDotNet_Tensors_LinearAlgebra_Matrix__0__AiDotNet_Interfaces_ICompressionMetadata__0__">ModelCompressionBase&lt;T&gt;.GetCompressedSize(Matrix&lt;T&gt;, ICompressionMetadata&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ModelCompression.ModelCompressionBase-1.html#AiDotNet_ModelCompression_ModelCompressionBase_1_CompressTensor_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">ModelCompressionBase&lt;T&gt;.CompressTensor(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ModelCompression.ModelCompressionBase-1.html#AiDotNet_ModelCompression_ModelCompressionBase_1_DecompressTensor_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Interfaces_ICompressionMetadata__0__">ModelCompressionBase&lt;T&gt;.DecompressTensor(Tensor&lt;T&gt;, ICompressionMetadata&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ModelCompression.ModelCompressionBase-1.html#AiDotNet_ModelCompression_ModelCompressionBase_1_GetCompressedSize_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Interfaces_ICompressionMetadata__0__">ModelCompressionBase&lt;T&gt;.GetCompressedSize(Tensor&lt;T&gt;, ICompressionMetadata&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ModelCompression.ModelCompressionBase-1.html#AiDotNet_ModelCompression_ModelCompressionBase_1_GetElementSize">ModelCompressionBase&lt;T&gt;.GetElementSize()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ModelCompression.ModelCompressionBase-1.html#AiDotNet_ModelCompression_ModelCompressionBase_1_MatrixToVector_AiDotNet_Tensors_LinearAlgebra_Matrix__0__">ModelCompressionBase&lt;T&gt;.MatrixToVector(Matrix&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ModelCompression.ModelCompressionBase-1.html#AiDotNet_ModelCompression_ModelCompressionBase_1_VectorToMatrix_AiDotNet_Tensors_LinearAlgebra_Vector__0__System_Int32_System_Int32_">ModelCompressionBase&lt;T&gt;.VectorToMatrix(Vector&lt;T&gt;, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ModelCompression.ModelCompressionBase-1.html#AiDotNet_ModelCompression_ModelCompressionBase_1_TensorToVector_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">ModelCompressionBase&lt;T&gt;.TensorToVector(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.ModelCompression.ModelCompressionBase-1.html#AiDotNet_ModelCompression_ModelCompressionBase_1_VectorToTensor_AiDotNet_Tensors_LinearAlgebra_Vector__0__System_Int32___">ModelCompressionBase&lt;T&gt;.VectorToTensor(Vector&lt;T&gt;, int[])</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_ModelCompression_ProductQuantizationCompression_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
Product Quantization is a powerful compression technique that divides weight vectors into subvectors
and quantizes each subvector separately using its own codebook. This provides a good balance between
compression ratio and reconstruction accuracy.
</p>
<p><b>For Beginners:</b> Product Quantization is like organizing a closet using multiple small bins.
<p>Instead of trying to compress all your clothes in one big box:</p>
<ol>
<li>Divide clothes into categories (shirts, pants, socks)</li>
<li>For each category, pick a few representative items</li>
<li>Store only which representative each item is most similar to</li>
</ol>
<p>For neural network weights:</p>
<ul>
<li>Divide each weight vector into M smaller pieces (subvectors)</li>
<li>For each piece, find K cluster centers (codebook)</li>
<li>Replace each subvector with its nearest codebook entry</li>
</ul>
<p>Benefits:</p>
<ul>
<li>Better accuracy than global clustering for the same compression ratio</li>
<li>Very efficient for high-dimensional weight vectors</li>
<li>Commonly used in production systems (e.g., FAISS library)</li>
</ul>
<p>Example:</p>
<ul>
<li>1024-dimensional weight vector divided into 8 subvectors of 128 dimensions each</li>
<li>Each subvector has 256 possible codes (8-bit quantization)</li>
<li>Original: 1024 × 32 bits = 32,768 bits</li>
<li>Compressed: 8 × 8 bits + codebook = ~64 bits + codebook</li>
<li>Massive compression with minimal accuracy loss!</li>
</ul>

<p><b>Important Limitation:</b> This implementation is designed for compressing a single weight vector.
Traditional PQ achieves compression by training codebooks on multiple vectors and amortizing codebook storage.
For single-vector compression, the codebook overhead may exceed the original data size.
<p><b>When to use this compressor:</b></p>
<ul>
<li>When you have very high-dimensional weight vectors (thousands of dimensions)</li>
<li>When reconstruction quality is more important than compression ratio</li>
<li>When you plan to extend to batch compression of multiple similar vectors</li>
</ul>
<p><b>For better single-vector compression:</b></p>
<ul>
<li>Consider <a class="xref" href="AiDotNet.ModelCompression.WeightClusteringCompression-1.html">WeightClusteringCompression&lt;T&gt;</a> for simpler k-means clustering</li>
<li>Consider <a class="xref" href="AiDotNet.ModelCompression.HuffmanEncodingCompression-1.html">HuffmanEncodingCompression&lt;T&gt;</a> for lossless entropy coding</li>
<li>Consider <a class="xref" href="AiDotNet.ModelCompression.DeepCompression-1.html">DeepCompression&lt;T&gt;</a> for a multi-stage pipeline</li>
</ul>

</div>


  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_ModelCompression_ProductQuantizationCompression_1__ctor_" data-uid="AiDotNet.ModelCompression.ProductQuantizationCompression`1.#ctor*"></a>

  <h3 id="AiDotNet_ModelCompression_ProductQuantizationCompression_1__ctor_System_Int32_System_Int32_System_Int32_System_Double_System_Nullable_System_Int32__" data-uid="AiDotNet.ModelCompression.ProductQuantizationCompression`1.#ctor(System.Int32,System.Int32,System.Int32,System.Double,System.Nullable{System.Int32})">
  ProductQuantizationCompression(int, int, int, double, int?)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ModelCompression/ProductQuantizationCompression.cs/#L93"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of the ProductQuantizationCompression class.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public ProductQuantizationCompression(int numSubvectors = 8, int numCentroids = 256, int maxIterations = 100, double tolerance = 1E-06, int? randomSeed = null)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>numSubvectors</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Number of subvectors to divide each weight vector into (default: 8).</p>
</dd>
    <dt><code>numCentroids</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Number of centroids per subvector codebook (default: 256 for 8-bit).</p>
</dd>
    <dt><code>maxIterations</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Maximum K-means iterations per codebook (default: 100).</p>
</dd>
    <dt><code>tolerance</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Convergence tolerance for K-means (default: 1e-6).</p>
</dd>
    <dt><code>randomSeed</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a>?</dt>
    <dd><p>Random seed for reproducibility.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_ModelCompression_ProductQuantizationCompression_1__ctor_System_Int32_System_Int32_System_Int32_System_Double_System_Nullable_System_Int32___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Beginners:</b> These parameters control the compression behavior:
<ul>
<li><p>numSubvectors: How many pieces to split each weight vector into</p>
<ul>
<li>More subvectors = more compression but potentially lower accuracy</li>
<li>Fewer subvectors = less compression but higher accuracy</li>
<li>Must divide evenly into your weight vector length</li>
</ul>
</li>
<li><p>numCentroids: How many representative values per subvector</p>
<ul>
<li>256 centroids = 8-bit codes (very common)</li>
<li>16 centroids = 4-bit codes (more aggressive)</li>
<li>65536 centroids = 16-bit codes (higher quality)</li>
</ul>
</li>
<li><p>maxIterations/tolerance: Control the K-means clustering quality</p>
<ul>
<li>Defaults work well for most cases</li>
</ul>
</li>
</ul>

</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_ModelCompression_ProductQuantizationCompression_1_Compress_" data-uid="AiDotNet.ModelCompression.ProductQuantizationCompression`1.Compress*"></a>

  <h3 id="AiDotNet_ModelCompression_ProductQuantizationCompression_1_Compress_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.ModelCompression.ProductQuantizationCompression`1.Compress(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  Compress(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ModelCompression/ProductQuantizationCompression.cs/#L129"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Compresses weights using Product Quantization.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override (Vector&lt;T&gt; compressedWeights, ICompressionMetadata&lt;T&gt; metadata) Compress(Vector&lt;T&gt; weights)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>weights</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The original model weights.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt>(<a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt; <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.valuetuple-aidotnet.tensors.linearalgebra.vector--0-,aidotnet.interfaces.icompressionmetadata--0--.compressedweights">compressedWeights</a>, <a class="xref" href="AiDotNet.Interfaces.ICompressionMetadata-1.html">ICompressionMetadata</a>&lt;T&gt; <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.valuetuple-aidotnet.tensors.linearalgebra.vector--0-,aidotnet.interfaces.icompressionmetadata--0--.metadata">metadata</a>)</dt>
    <dd><p>Compressed weights and metadata containing codebooks and codes.</p>
</dd>
  </dl>











  <a id="AiDotNet_ModelCompression_ProductQuantizationCompression_1_Decompress_" data-uid="AiDotNet.ModelCompression.ProductQuantizationCompression`1.Decompress*"></a>

  <h3 id="AiDotNet_ModelCompression_ProductQuantizationCompression_1_Decompress_AiDotNet_Tensors_LinearAlgebra_Vector__0__AiDotNet_Interfaces_ICompressionMetadata__0__" data-uid="AiDotNet.ModelCompression.ProductQuantizationCompression`1.Decompress(AiDotNet.Tensors.LinearAlgebra.Vector{`0},AiDotNet.Interfaces.ICompressionMetadata{`0})">
  Decompress(Vector&lt;T&gt;, ICompressionMetadata&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ModelCompression/ProductQuantizationCompression.cs/#L202"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Decompresses weights by reconstructing from codebooks and codes.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Vector&lt;T&gt; Decompress(Vector&lt;T&gt; compressedWeights, ICompressionMetadata&lt;T&gt; metadata)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>compressedWeights</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The compressed weights (codebook indices).</p>
</dd>
    <dt><code>metadata</code> <a class="xref" href="AiDotNet.Interfaces.ICompressionMetadata-1.html">ICompressionMetadata</a>&lt;T&gt;</dt>
    <dd><p>The metadata containing codebooks.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The decompressed weights.</p>
</dd>
  </dl>











  <a id="AiDotNet_ModelCompression_ProductQuantizationCompression_1_GetCompressedSize_" data-uid="AiDotNet.ModelCompression.ProductQuantizationCompression`1.GetCompressedSize*"></a>

  <h3 id="AiDotNet_ModelCompression_ProductQuantizationCompression_1_GetCompressedSize_AiDotNet_Tensors_LinearAlgebra_Vector__0__AiDotNet_Interfaces_ICompressionMetadata__0__" data-uid="AiDotNet.ModelCompression.ProductQuantizationCompression`1.GetCompressedSize(AiDotNet.Tensors.LinearAlgebra.Vector{`0},AiDotNet.Interfaces.ICompressionMetadata{`0})">
  GetCompressedSize(Vector&lt;T&gt;, ICompressionMetadata&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/ModelCompression/ProductQuantizationCompression.cs/#L240"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the compressed size including codebooks and codes.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override long GetCompressedSize(Vector&lt;T&gt; compressedWeights, ICompressionMetadata&lt;T&gt; metadata)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>compressedWeights</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd></dd>
    <dt><code>metadata</code> <a class="xref" href="AiDotNet.Interfaces.ICompressionMetadata-1.html">ICompressionMetadata</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int64">long</a></dt>
    <dd></dd>
  </dl>












</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/ModelCompression/ProductQuantizationCompression.cs/#L60" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
