<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class BatchNormalizationLayer&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class BatchNormalizationLayer&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Implements batch normalization for neural networks, which normalizes the inputs across a mini-batch.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1.md&amp;value=---%0Auid%3A%20AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1">



  <h1 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1" class="text-break">
Class BatchNormalizationLayer&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L39"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.NeuralNetworks.html">NeuralNetworks</a>.<a class="xref" href="AiDotNet.NeuralNetworks.Layers.html">Layers</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Implements batch normalization for neural networks, which normalizes the inputs across a mini-batch.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class BatchNormalizationLayer&lt;T&gt; : LayerBase&lt;T&gt;, ILayer&lt;T&gt;, IJitCompilable&lt;T&gt;, IDiagnosticsProvider, IWeightLoadable&lt;T&gt;, IDisposable</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for computations (e.g., float, double).</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html">LayerBase</a>&lt;T&gt;</div>
      <div><span class="xref">BatchNormalizationLayer&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IJitCompilable-1.html">IJitCompilable</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IDiagnosticsProvider.html">IDiagnosticsProvider</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.IWeightLoadable-1.html">IWeightLoadable</a>&lt;T&gt;</div>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.idisposable">IDisposable</a></div>
    </dd>
  </dl>


  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Engine">LayerBase&lt;T&gt;.Engine</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ScalarActivation">LayerBase&lt;T&gt;.ScalarActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_VectorActivation">LayerBase&lt;T&gt;.VectorActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UsingVectorActivation">LayerBase&lt;T&gt;.UsingVectorActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_NumOps">LayerBase&lt;T&gt;.NumOps</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Random">LayerBase&lt;T&gt;.Random</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Parameters">LayerBase&lt;T&gt;.Parameters</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ParameterGradients">LayerBase&lt;T&gt;.ParameterGradients</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShape">LayerBase&lt;T&gt;.InputShape</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShapes">LayerBase&lt;T&gt;.InputShapes</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateInputShape_System_Int32___">LayerBase&lt;T&gt;.UpdateInputShape(int[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_OutputShape">LayerBase&lt;T&gt;.OutputShape</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsTrainingMode">LayerBase&lt;T&gt;.IsTrainingMode</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationStrategy">LayerBase&lt;T&gt;.InitializationStrategy</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsInitialized">LayerBase&lt;T&gt;.IsInitialized</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationLock">LayerBase&lt;T&gt;.InitializationLock</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_EnsureInitialized">LayerBase&lt;T&gt;.EnsureInitialized()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UseAutodiff">LayerBase&lt;T&gt;.UseAutodiff</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetTrainingMode_System_Boolean_">LayerBase&lt;T&gt;.SetTrainingMode(bool)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterGradients">LayerBase&lt;T&gt;.GetParameterGradients()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ClearGradients">LayerBase&lt;T&gt;.ClearGradients()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShape">LayerBase&lt;T&gt;.GetInputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShapes">LayerBase&lt;T&gt;.GetInputShapes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetOutputShape">LayerBase&lt;T&gt;.GetOutputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetWeights">LayerBase&lt;T&gt;.GetWeights()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetBiases">LayerBase&lt;T&gt;.GetBiases()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_MapActivationToFused">LayerBase&lt;T&gt;.MapActivationToFused()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuTraining">LayerBase&lt;T&gt;.SupportsGpuTraining</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanExecuteOnGpu">LayerBase&lt;T&gt;.CanExecuteOnGpu</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanTrainOnGpu">LayerBase&lt;T&gt;.CanTrainOnGpu</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParametersGpu_AiDotNet_Interfaces_IGpuOptimizerConfig_">LayerBase&lt;T&gt;.UpdateParametersGpu(IGpuOptimizerConfig)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UploadWeightsToGpu">LayerBase&lt;T&gt;.UploadWeightsToGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_DownloadWeightsFromGpu">LayerBase&lt;T&gt;.DownloadWeightsFromGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ZeroGradientsGpu">LayerBase&lt;T&gt;.ZeroGradientsGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetActivationTypes">LayerBase&lt;T&gt;.GetActivationTypes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0____">LayerBase&lt;T&gt;.Forward(params Tensor&lt;T&gt;[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ApplyActivation(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ApplyActivation(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ActivateTensor(IActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IVectorActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ActivateTensor(IVectorActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateInputShape_System_Int32_System_Int32_System_Int32_">LayerBase&lt;T&gt;.CalculateInputShape(int, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateOutputShape_System_Int32_System_Int32_System_Int32_">LayerBase&lt;T&gt;.CalculateOutputShape(int, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Clone">LayerBase&lt;T&gt;.Clone()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_DerivativeTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.DerivativeTensor(IActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative__0__0_">LayerBase&lt;T&gt;.ApplyActivationDerivative(T, T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ApplyActivationDerivative(Tensor&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ComputeActivationJacobian_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ComputeActivationJacobian(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Vector__0__AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ApplyActivationDerivative(Vector&lt;T&gt;, Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.UpdateParameters(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Serialize_System_IO_BinaryWriter_">LayerBase&lt;T&gt;.Serialize(BinaryWriter)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Deserialize_System_IO_BinaryReader_">LayerBase&lt;T&gt;.Deserialize(BinaryReader)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetDiagnostics">LayerBase&lt;T&gt;.GetDiagnostics()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationToGraph_AiDotNet_Autodiff_ComputationNode__0__">LayerBase&lt;T&gt;.ApplyActivationToGraph(ComputationNode&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanActivationBeJitted">LayerBase&lt;T&gt;.CanActivationBeJitted()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_RegisterTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_Engines_PersistentTensorRole_">LayerBase&lt;T&gt;.RegisterTrainableParameter(Tensor&lt;T&gt;, PersistentTensorRole)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InvalidateTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.InvalidateTrainableParameter(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_HasGpuActivation">LayerBase&lt;T&gt;.HasGpuActivation()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationForwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">LayerBase&lt;T&gt;.ApplyActivationForwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationBackwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">LayerBase&lt;T&gt;.ApplyActivationBackwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetFusedActivationType">LayerBase&lt;T&gt;.GetFusedActivationType()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivation_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_">LayerBase&lt;T&gt;.ApplyGpuActivation(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int, FusedActivationType)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivationBackward_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_System_Single_">LayerBase&lt;T&gt;.ApplyGpuActivationBackward(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int, FusedActivationType, float)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose">LayerBase&lt;T&gt;.Dispose()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose_System_Boolean_">LayerBase&lt;T&gt;.Dispose(bool)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_WeightParameterName">LayerBase&lt;T&gt;.WeightParameterName</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_BiasParameterName">LayerBase&lt;T&gt;.BiasParameterName</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetWeights_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetWeights(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetBiases_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetBiases(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterNames">LayerBase&lt;T&gt;.GetParameterNames()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_TryGetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___">LayerBase&lt;T&gt;.TryGetParameter(string, out Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetParameter(string, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterShape_System_String_">LayerBase&lt;T&gt;.GetParameterShape(string)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_NamedParameterCount">LayerBase&lt;T&gt;.NamedParameterCount</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ValidateWeights_System_Collections_Generic_IEnumerable_System_String__System_Func_System_String_System_String__">LayerBase&lt;T&gt;.ValidateWeights(IEnumerable&lt;string&gt;, Func&lt;string, string&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_LoadWeights_System_Collections_Generic_Dictionary_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___System_Func_System_String_System_String__System_Boolean_">LayerBase&lt;T&gt;.LoadWeights(Dictionary&lt;string, Tensor&lt;T&gt;&gt;, Func&lt;string, string&gt;, bool)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
Batch normalization helps stabilize and accelerate training by normalizing layer inputs.
It works by normalizing each feature to have zero mean and unit variance across the batch,
then applying learnable scale (gamma) and shift (beta) parameters.
</p>
<p>
Benefits include:
- Faster training convergence
- Reduced sensitivity to weight initialization
- Ability to use higher learning rates
- Acts as a form of regularization
</p>
<p><b>For Beginners:</b> Batch normalization is like standardizing test scores in a classroom.
<p>Imagine a class where each student (input) has a raw test score. Batch normalization:</p>
<ol>
<li>Calculates the average score and how spread out the scores are</li>
<li>Converts each score to show how many standard deviations it is from the average</li>
<li>Applies adjustable scaling and shifting to the standardized scores</li>
</ol>
<p>This helps neural networks learn more efficiently by:</p>
<ul>
<li>Keeping input values in a consistent range</li>
<li>Reducing the &quot;internal covariate shift&quot; problem</li>
<li>Making the network less sensitive to poor weight initialization</li>
<li>Allowing higher learning rates without divergence</li>
</ul>
<p>In practice, this means your network will typically train faster and perform better.</p>

</div>


  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1__ctor_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.#ctor*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1__ctor_System_Int32_System_Double_System_Double_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.#ctor(System.Int32,System.Double,System.Double)">
  BatchNormalizationLayer(int, double, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L281"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"></div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public BatchNormalizationLayer(int numFeatures, double epsilon = 1E-05, double momentum = 0.9)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>numFeatures</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
    <dt><code>epsilon</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd></dd>
    <dt><code>momentum</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd></dd>
  </dl>












  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ParameterCount_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.ParameterCount*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ParameterCount" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.ParameterCount">
  ParameterCount
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L723"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets all trainable parameters of the batch normalization layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override int ParameterCount { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>A vector containing all trainable parameters (gamma and beta) concatenated together.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ParameterCount_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method returns a single vector containing all trainable parameters of the layer:
- First half: gamma (scale) parameters
- Second half: beta (shift) parameters
</p>
<p>
This is useful for optimization algorithms that need access to all parameters at once,
or for saving/loading model weights.
</p>
<p><b>For Beginners:</b> This method returns all the learnable parameters as a single vector.
<p>Batch normalization has two sets of learnable parameters:</p>
<ul>
<li>Gamma (scale): Controls how much to stretch or compress the normalized data</li>
<li>Beta (shift): Controls how much to move the normalized data up or down</li>
</ul>
<p>This method combines both sets into a single vector, with gamma values first,
followed by beta values. For example, with 3 features:</p>
<p>[gamma1, gamma2, gamma3, beta1, beta2, beta3]</p>
<p>This format is useful for:</p>
<ul>
<li>Saving and loading models</li>
<li>Advanced optimization algorithms that work with all parameters at once</li>
<li>Regularization techniques that need to access all parameters</li>
</ul>
<p>The total length of the returned vector is twice the number of features,
since there's one gamma and one beta parameter per feature.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_SupportsGpuExecution_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.SupportsGpuExecution*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_SupportsGpuExecution" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.SupportsGpuExecution">
  SupportsGpuExecution
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L428"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this layer has a GPU implementation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected override bool SupportsGpuExecution { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>








  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_SupportsJitCompilation_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.SupportsJitCompilation*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_SupportsJitCompilation" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.SupportsJitCompilation">
  SupportsJitCompilation
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L1012"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this batch normalization layer supports JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsJitCompilation { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if the layer parameters and running statistics are initialized.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_SupportsJitCompilation_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property indicates whether the layer can be JIT compiled. The layer supports JIT if:
- Gamma (scale) and beta (shift) parameters are initialized
- Running mean and variance statistics are initialized (from training)
</p>
<p><b>For Beginners:</b> This tells you if this layer can use JIT compilation for faster inference.
<p>The layer can be JIT compiled if:</p>
<ul>
<li>The layer has been initialized with learnable parameters (gamma and beta)</li>
<li>The model has been trained, so running statistics are available</li>
</ul>
<p>Batch normalization during inference requires running statistics collected during training,
so JIT compilation is only supported after the model has been trained at least once.</p>
<p>Once these conditions are met, JIT compilation can provide significant speedup (5-10x)
by optimizing the normalization, scaling, and shifting operations.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_SupportsTraining_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.SupportsTraining*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_SupportsTraining" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.SupportsTraining">
  SupportsTraining
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L242"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets a value indicating whether this layer supports training.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsTraining { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p><code>true</code> if the layer has trainable parameters and supports backpropagation; otherwise, <code>false</code>.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_SupportsTraining_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This property indicates whether the layer can be trained through backpropagation.
Layers with trainable parameters such as weights and biases typically return true, while layers
that only perform fixed transformations (like pooling or activation layers) typically return false.
</p>
<p><b>For Beginners:</b> This property tells you if the layer can learn from data.
<p>A value of true means:</p>
<ul>
<li>The layer has parameters that can be adjusted during training</li>
<li>It will improve its performance as it sees more data</li>
<li>It participates in the learning process</li>
</ul>
<p>A value of false means:</p>
<ul>
<li>The layer doesn't have any adjustable parameters</li>
<li>It performs the same operation regardless of training</li>
<li>It doesn't need to learn (but may still be useful)</li>
</ul>

</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_Backward_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.Backward*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.Backward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Backward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L571"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the backward pass of batch normalization.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; Backward(Tensor&lt;T&gt; outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>outputGradient</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The gradient of the loss with respect to the layer's output.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The gradient of the loss with respect to the layer's input.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The backward pass computes three types of gradients:
1. Gradients for the input (to pass to previous layers)
2. Gradients for gamma (scale parameter)
3. Gradients for beta (shift parameter)
</p>
<p>
This is a complex calculation that accounts for how each input affects:
- The normalized value directly
- The batch mean
- The batch variance
</p>
<p>
The implementation follows the chain rule of calculus to properly backpropagate
through all operations in the forward pass.
</p>
<p><b>For Beginners:</b> This method calculates how the error gradients flow backward through this layer.
<p>During backpropagation, this method:</p>
<ol>
<li>Checks that Forward() was called first</li>
<li>Creates tensors to hold the gradients for inputs and parameters</li>
<li>Calculates the inverse standard deviation (1/sqrt(variance + epsilon))</li>
<li>For each feature:
<ul>
<li>Sums the output gradients across the batch</li>
<li>Sums the product of output gradients and normalized values</li>
<li>Calculates gradients for gamma and beta parameters</li>
<li>Calculates gradients for each input value</li>
</ul>
</li>
</ol>
<p>The calculation is complex because in batch normalization, each input affects:</p>
<ul>
<li>Its own normalized value directly</li>
<li>The mean of the batch (which affects all normalized values)</li>
<li>The variance of the batch (which affects all normalized values)</li>
</ul>
<p>The formula accounts for all these dependencies using the chain rule of calculus.</p>
<p>This method stores the gradients for gamma and beta to use during parameter updates,
and returns the gradient for the input to pass to previous layers.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown when backward is called before forward.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_BackwardGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.BackwardGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_BackwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.BackwardGpu(AiDotNet.Tensors.Engines.Gpu.IGpuTensor{`0})">
  BackwardGpu(IGpuTensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L494"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs GPU-resident backward pass for the batch normalization layer.
Computes gradients for input, gamma, and beta entirely on GPU.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override IGpuTensor&lt;T&gt; BackwardGpu(IGpuTensor&lt;T&gt; outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>outputGradient</code> <a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;</dt>
    <dd><p>GPU-resident gradient from the next layer.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;</dt>
    <dd><p>GPU-resident gradient to pass to the previous layer.</p>
</dd>
  </dl>








  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown if ForwardGpu was not called first.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ExportComputationGraph_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.ExportComputationGraph*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0___" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.ExportComputationGraph(System.Collections.Generic.List{AiDotNet.Autodiff.ComputationNode{`0}})">
  ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L946"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Exports the batch normalization layer as a computation graph for JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override ComputationNode&lt;T&gt; ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt; inputNodes)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputNodes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.list-1">List</a>&lt;<a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;&gt;</dt>
    <dd><p>List to which the input node will be added.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The output computation node representing the batch normalization operation.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method creates a symbolic computation graph for JIT compilation:
1. Creates a symbolic input node with shape [batch=1, features]
2. Creates constant nodes for gamma (scale) and beta (shift) parameters
3. Uses running statistics (mean and variance) for inference mode
4. Applies the batch normalization operation: gamma * ((x - mean) / sqrt(variance + epsilon)) + beta
</p>
<p><b>For Beginners:</b> This method builds a symbolic representation of batch normalization for JIT.
<p>JIT compilation converts the batch normalization operation into optimized native code.
During inference (prediction), batch normalization uses:</p>
<ul>
<li>Running mean and variance collected during training (not batch statistics)</li>
<li>Learned scale (gamma) and shift (beta) parameters</li>
</ul>
<p>The symbolic graph allows the JIT compiler to:</p>
<ul>
<li>Optimize the normalization formula: (x - mean) / sqrt(variance + epsilon)</li>
<li>Fuse the scale and shift operations: result * gamma + beta</li>
<li>Generate SIMD-optimized code for better performance</li>
</ul>
<p>This typically provides 5-10x speedup compared to interpreted execution.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></dt>
    <dd><p>Thrown when inputNodes is null.</p>
</dd>
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown when layer shape or parameters are not initialized.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_Forward_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.Forward*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.Forward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Forward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L333"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the forward pass of batch normalization.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; Forward(Tensor&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The input tensor with shape [batchSize, featureSize].</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The normalized, scaled, and shifted output tensor.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The forward pass performs these steps:
1. If in training mode:
   - Compute mean and variance of the current batch
   - Update running statistics for inference
   - Normalize using batch statistics
2. If in inference mode:
   - Normalize using running statistics collected during training
3. Apply scale (gamma) and shift (beta) parameters
</p>
<p>
The normalization formula is: y = gamma * ((x - mean) / sqrt(variance + epsilon)) + beta
</p>
<p><b>For Beginners:</b> This method normalizes the input data and applies learned scaling and shifting.
<p>During the forward pass, this method:</p>
<ol>
<li>Saves the input for later use in backpropagation</li>
<li>If in training mode:
<ul>
<li>Calculates the mean and variance of each feature across the batch</li>
<li>Updates the running statistics for use during inference</li>
<li>Normalizes the data using the batch statistics</li>
</ul>
</li>
<li>If in inference/testing mode:
<ul>
<li>Uses the running statistics collected during training</li>
</ul>
</li>
<li>Applies the learned scale (gamma) and shift (beta) parameters</li>
</ol>
<p>The normalization makes each feature have approximately zero mean and unit variance,
while the scale and shift parameters allow the network to learn the optimal
distribution for each feature.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ForwardGpu_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.ForwardGpu*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ForwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0____" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.ForwardGpu(AiDotNet.Tensors.Engines.Gpu.IGpuTensor{`0}[])">
  ForwardGpu(params IGpuTensor&lt;T&gt;[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L446"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs GPU-resident batch normalization forward pass.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override IGpuTensor&lt;T&gt; ForwardGpu(params IGpuTensor&lt;T&gt;[] inputs)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputs</code> <a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;[]</dt>
    <dd></dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.Engines.Gpu.IGpuTensor-1.html">IGpuTensor</a>&lt;T&gt;</dt>
    <dd><p>GPU-resident output tensor with same shape as input.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ForwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0_____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method performs batch normalization entirely on GPU, avoiding CPU round-trips.
The input and output tensors remain GPU-resident for chained GPU operations.
</p>
<p>
During training mode, running statistics (mean and variance) are updated on GPU
and then downloaded back to CPU for persistence.
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown when GPU engine is not available.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetBeta_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.GetBeta*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetBeta" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.GetBeta">
  GetBeta()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L179"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the beta (shift) parameters of the batch normalization layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public Tensor&lt;T&gt; GetBeta()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The beta tensor used for shifting scaled values.</p>
</dd>
  </dl>











  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetEpsilon_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.GetEpsilon*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetEpsilon" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.GetEpsilon">
  GetEpsilon()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L219"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the epsilon value used for numerical stability.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public T GetEpsilon()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><span class="xref">T</span></dt>
    <dd><p>The epsilon value.</p>
</dd>
  </dl>











  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetGamma_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.GetGamma*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetGamma" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.GetGamma">
  GetGamma()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L170"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets a value indicating whether this layer supports training mode.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public Tensor&lt;T&gt; GetGamma()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The gamma tensor used for scaling normalized values.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetGamma_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Batch normalization behaves differently during training versus inference:
- During training: Uses statistics from the current batch
- During inference: Uses running statistics collected during training
</p>
<p>
This property always returns true because the layer needs to track its training state.
</p>
<p><b>For Beginners:</b> This tells the network that this layer behaves differently during training versus testing.
<p>During training, batch normalization uses statistics (mean and variance) calculated from
the current batch of data. During testing or inference, it uses the average statistics
collected during training.</p>
<p>This property being true means:</p>
<ul>
<li>The layer needs to know whether it's in training or inference mode</li>
<li>The layer has parameters that can be updated during training</li>
<li>The layer's behavior will change depending on the mode</li>
</ul>
<p>This is important because it affects how the network processes data and how
the layer's internal statistics are updated.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetMomentum_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.GetMomentum*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetMomentum" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.GetMomentum">
  GetMomentum()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L228"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the momentum value for running statistics.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public T GetMomentum()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><span class="xref">T</span></dt>
    <dd><p>The momentum value.</p>
</dd>
  </dl>











  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetParameters_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.GetParameters*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetParameters" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.GetParameters">
  GetParameters()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L726"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets all trainable parameters of the layer as a single vector.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Vector&lt;T&gt; GetParameters()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>A vector containing all trainable parameters.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetParameters_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This abstract method must be implemented by derived classes to provide access to all trainable
parameters of the layer as a single vector. This is useful for optimization algorithms that operate
on all parameters at once, or for saving and loading model weights.
</p>
<p><b>For Beginners:</b> This method collects all the learnable values from the layer.
<p>The parameters:</p>
<ul>
<li>Are the numbers that the neural network learns during training</li>
<li>Include weights, biases, and other learnable values</li>
<li>Are combined into a single long list (vector)</li>
</ul>
<p>This is useful for:</p>
<ul>
<li>Saving the model to disk</li>
<li>Loading parameters from a previously trained model</li>
<li>Advanced optimization techniques that need access to all parameters</li>
</ul>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetRunningMean_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.GetRunningMean*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetRunningMean" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.GetRunningMean">
  GetRunningMean()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L202"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the running mean of the batch normalization layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public Tensor&lt;T&gt; GetRunningMean()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The running mean tensor used during inference.</p>
</dd>
  </dl>











  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetRunningVariance_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.GetRunningVariance*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_GetRunningVariance" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.GetRunningVariance">
  GetRunningVariance()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L211"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the running variance of the batch normalization layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public Tensor&lt;T&gt; GetRunningVariance()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>The running variance tensor used during inference.</p>
</dd>
  </dl>











  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ResetState_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.ResetState*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ResetState" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.ResetState">
  ResetState()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L903"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Resets the internal state of the batch normalization layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void ResetState()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ResetState_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method clears all cached values from the forward and backward passes,
including:
- Last input tensor
- Last normalized values
- Last batch mean and variance
- Gradients for gamma and beta parameters
</p>
<p>
It does NOT reset the learned parameters (gamma and beta) or the running statistics
(running mean and variance) used for inference.
</p>
<p>
This is typically called when starting a new training epoch or when switching
between training and inference modes.
</p>
<p><b>For Beginners:</b> This method clears the layer's memory of previous calculations.
<p>During training, the batch normalization layer keeps track of:</p>
<ul>
<li>The last input it processed</li>
<li>The normalized values it calculated</li>
<li>The mean and variance of the last batch</li>
<li>The gradients for its parameters</li>
</ul>
<p>This method clears all of these temporary values, which is useful when:</p>
<ul>
<li>Starting a new training epoch</li>
<li>Switching between training and testing modes</li>
<li>Ensuring the layer behaves deterministically</li>
</ul>
<p>Important: This does NOT reset the learned parameters (gamma and beta) or
the running statistics (running mean and variance) that are used during inference.
It only clears temporary calculation values.</p>
<p>Think of it as clearing the layer's short-term memory while preserving its
long-term learning.</p>

</div>




  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_SetParameters_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.SetParameters*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_SetParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.SetParameters(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  SetParameters(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L767"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sets all trainable parameters of the batch normalization layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void SetParameters(Vector&lt;T&gt; parameters)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>parameters</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>A vector containing all parameters (gamma and beta) concatenated together.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_SetParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method expects a single vector containing all trainable parameters:
- First half: gamma (scale) parameters
- Second half: beta (shift) parameters
</p>
<p>
The length of the parameters vector must be exactly twice the feature size.
This method is useful for loading pre-trained weights or setting parameters
after optimization.
</p>
<p><b>For Beginners:</b> This method loads parameters into the layer from a single vector.
<p>This is the counterpart to GetParameters() - it takes a vector containing
all parameters and sets them in the layer. The vector must have the format:</p>
<p>[gamma1, gamma2, ..., gammaN, beta1, beta2, ..., betaN]</p>
<p>Where N is the number of features. The total length must be exactly 2*N.</p>
<p>This method is commonly used for:</p>
<ul>
<li>Loading pre-trained models</li>
<li>Setting parameters after external optimization</li>
<li>Implementing transfer learning</li>
<li>Testing different parameter configurations</li>
</ul>
<p>If the vector doesn't have the expected length, the method will throw an
exception to prevent incorrect parameter assignments.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentexception">ArgumentException</a></dt>
    <dd><p>Thrown when the parameters vector has incorrect length.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_UpdateParameters_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.UpdateParameters*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_UpdateParameters__0_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.UpdateParameters(`0)">
  UpdateParameters(T)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L825"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Updates the layer's parameters using the computed gradients.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void UpdateParameters(T learningRate)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>learningRate</code> <span class="xref">T</span></dt>
    <dd><p>The learning rate for parameter updates.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_UpdateParameters__0__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method updates the gamma (scale) and beta (shift) parameters using gradient descent:
- gamma = gamma - learningRate * gammaGradient
- beta = beta - learningRate * betaGradient
</p>
<p>
The gradients are computed during the backward pass and represent how much
each parameter should change to reduce the loss function.
</p>
<p><b>For Beginners:</b> This method updates the layer's learnable parameters during training.
<p>After the backward pass calculates how each parameter affects the error,
this method adjusts those parameters to reduce the error:</p>
<ol>
<li>It checks that the backward pass has been called first</li>
<li>It updates the gamma (scale) parameters:
gamma = gamma - learningRate * gammaGradient</li>
<li>It updates the beta (shift) parameters:
beta = beta - learningRate * betaGradient</li>
</ol>
<p>The learning rate controls how big the updates are:</p>
<ul>
<li>A larger learning rate means bigger changes (faster learning but potentially unstable)</li>
<li>A smaller learning rate means smaller changes (slower but more stable learning)</li>
</ul>
<p>For example, if a particular gamma value is causing high error, its gradient
will be large, and this method will adjust that parameter more significantly
to reduce the error in the next forward pass.</p>
<p>This is the step where actual &quot;learning&quot; happens in the neural network.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown when update is called before backward.</p>
</dd>
  </dl>



  <a id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ZeroInitGamma_" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.ZeroInitGamma*"></a>

  <h3 id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ZeroInitGamma" data-uid="AiDotNet.NeuralNetworks.Layers.BatchNormalizationLayer`1.ZeroInitGamma">
  ZeroInitGamma()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L192"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes gamma (scale) parameters to zero.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void ZeroInitGamma()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_NeuralNetworks_Layers_BatchNormalizationLayer_1_ZeroInitGamma_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This is used for zero-init residual in ResNet, where the last BatchNorm in each
residual block has gamma initialized to zero. This makes the residual blocks
start as identity mappings, which can improve training.</p>
</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/NeuralNetworks/Layers/BatchNormalizationLayer.cs/#L39" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
