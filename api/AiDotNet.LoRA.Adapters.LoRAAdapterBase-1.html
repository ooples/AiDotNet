<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class LoRAAdapterBase&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class LoRAAdapterBase&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Abstract base class for LoRA (Low-Rank Adaptation) adapters that wrap existing layers.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_LoRA_Adapters_LoRAAdapterBase_1.md&amp;value=---%0Auid%3A%20AiDotNet.LoRA.Adapters.LoRAAdapterBase%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1">



  <h1 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1" class="text-break">
Class LoRAAdapterBase&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L35"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.LoRA.html">LoRA</a>.<a class="xref" href="AiDotNet.LoRA.Adapters.html">Adapters</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Abstract base class for LoRA (Low-Rank Adaptation) adapters that wrap existing layers.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public abstract class LoRAAdapterBase&lt;T&gt; : LayerBase&lt;T&gt;, IDisposable, ILoRAAdapter&lt;T&gt;, ILayer&lt;T&gt;, IJitCompilable&lt;T&gt;, IDiagnosticsProvider, IWeightLoadable&lt;T&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for calculations, typically float or double.</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html">LayerBase</a>&lt;T&gt;</div>
      <div><span class="xref">LoRAAdapterBase&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.idisposable">IDisposable</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.ILoRAAdapter-1.html">ILoRAAdapter</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IJitCompilable-1.html">IJitCompilable</a>&lt;T&gt;</div>
      <div><a class="xref" href="AiDotNet.Interfaces.IDiagnosticsProvider.html">IDiagnosticsProvider</a></div>
      <div><a class="xref" href="AiDotNet.Interfaces.IWeightLoadable-1.html">IWeightLoadable</a>&lt;T&gt;</div>
    </dd>
  </dl>

  <dl class="typelist derived">
    <dt>Derived</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.AdaLoRAAdapter-1.html">AdaLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.ChainLoRAAdapter-1.html">ChainLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.DVoRAAdapter-1.html">DVoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.DeltaLoRAAdapter-1.html">DeltaLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.DenseLoRAAdapter-1.html">DenseLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.DoRAAdapter-1.html">DoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.DyLoRAAdapter-1.html">DyLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.FloraAdapter-1.html">FloraAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.GLoRAAdapter-1.html">GLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.GraphConvolutionalLoRAAdapter-1.html">GraphConvolutionalLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.HRAAdapter-1.html">HRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.LoHaAdapter-1.html">LoHaAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.LoKrAdapter-1.html">LoKrAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.LoRADropAdapter-1.html">LoRADropAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.LoRAFAAdapter-1.html">LoRAFAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.LoRAPlusAdapter-1.html">LoRAPlusAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.LoRAXSAdapter-1.html">LoRAXSAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.LoRETTAAdapter-1.html">LoRETTAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.LoftQAdapter-1.html">LoftQAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.LongLoRAAdapter-1.html">LongLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.MoRAAdapter-1.html">MoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.MultiLoRAAdapter-1.html">MultiLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.NOLAAdapter-1.html">NOLAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.PiSSAAdapter-1.html">PiSSAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.QALoRAAdapter-1.html">QALoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.QLoRAAdapter-1.html">QLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.ReLoRAAdapter-1.html">ReLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.RoSAAdapter-1.html">RoSAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.SLoRAAdapter-1.html">SLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.StandardLoRAAdapter-1.html">StandardLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.TiedLoRAAdapter-1.html">TiedLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.VBLoRAAdapter-1.html">VBLoRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.VeRAAdapter-1.html">VeRAAdapter&lt;T&gt;</a></div>
      <div><a class="xref" href="AiDotNet.LoRA.Adapters.XLoRAAdapter-1.html">XLoRAAdapter&lt;T&gt;</a></div>
    </dd>
  </dl>

  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Engine">LayerBase&lt;T&gt;.Engine</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ScalarActivation">LayerBase&lt;T&gt;.ScalarActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_VectorActivation">LayerBase&lt;T&gt;.VectorActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UsingVectorActivation">LayerBase&lt;T&gt;.UsingVectorActivation</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_NumOps">LayerBase&lt;T&gt;.NumOps</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Random">LayerBase&lt;T&gt;.Random</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Parameters">LayerBase&lt;T&gt;.Parameters</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ParameterGradients">LayerBase&lt;T&gt;.ParameterGradients</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShape">LayerBase&lt;T&gt;.InputShape</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InputShapes">LayerBase&lt;T&gt;.InputShapes</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateInputShape_System_Int32___">LayerBase&lt;T&gt;.UpdateInputShape(int[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_OutputShape">LayerBase&lt;T&gt;.OutputShape</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsTrainingMode">LayerBase&lt;T&gt;.IsTrainingMode</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationStrategy">LayerBase&lt;T&gt;.InitializationStrategy</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_IsInitialized">LayerBase&lt;T&gt;.IsInitialized</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InitializationLock">LayerBase&lt;T&gt;.InitializationLock</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_EnsureInitialized">LayerBase&lt;T&gt;.EnsureInitialized()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UseAutodiff">LayerBase&lt;T&gt;.UseAutodiff</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetTrainingMode_System_Boolean_">LayerBase&lt;T&gt;.SetTrainingMode(bool)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterGradients">LayerBase&lt;T&gt;.GetParameterGradients()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ClearGradients">LayerBase&lt;T&gt;.ClearGradients()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShape">LayerBase&lt;T&gt;.GetInputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetInputShapes">LayerBase&lt;T&gt;.GetInputShapes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetOutputShape">LayerBase&lt;T&gt;.GetOutputShape()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetWeights">LayerBase&lt;T&gt;.GetWeights()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetBiases">LayerBase&lt;T&gt;.GetBiases()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_MapActivationToFused">LayerBase&lt;T&gt;.MapActivationToFused()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuExecution">LayerBase&lt;T&gt;.SupportsGpuExecution</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SupportsGpuTraining">LayerBase&lt;T&gt;.SupportsGpuTraining</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanExecuteOnGpu">LayerBase&lt;T&gt;.CanExecuteOnGpu</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanTrainOnGpu">LayerBase&lt;T&gt;.CanTrainOnGpu</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ForwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0____">LayerBase&lt;T&gt;.ForwardGpu(params IGpuTensor&lt;T&gt;[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_BackwardGpu_AiDotNet_Tensors_Engines_Gpu_IGpuTensor__0__">LayerBase&lt;T&gt;.BackwardGpu(IGpuTensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParametersGpu_AiDotNet_Interfaces_IGpuOptimizerConfig_">LayerBase&lt;T&gt;.UpdateParametersGpu(IGpuOptimizerConfig)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UploadWeightsToGpu">LayerBase&lt;T&gt;.UploadWeightsToGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_DownloadWeightsFromGpu">LayerBase&lt;T&gt;.DownloadWeightsFromGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ZeroGradientsGpu">LayerBase&lt;T&gt;.ZeroGradientsGpu()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetActivationTypes">LayerBase&lt;T&gt;.GetActivationTypes()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0____">LayerBase&lt;T&gt;.Forward(params Tensor&lt;T&gt;[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ApplyActivation(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivation_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ApplyActivation(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ActivateTensor(IActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ActivateTensor_AiDotNet_Interfaces_IVectorActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ActivateTensor(IVectorActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateInputShape_System_Int32_System_Int32_System_Int32_">LayerBase&lt;T&gt;.CalculateInputShape(int, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CalculateOutputShape_System_Int32_System_Int32_System_Int32_">LayerBase&lt;T&gt;.CalculateOutputShape(int, int, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Clone">LayerBase&lt;T&gt;.Clone()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_DerivativeTensor_AiDotNet_Interfaces_IActivationFunction__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.DerivativeTensor(IActivationFunction&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative__0__0_">LayerBase&lt;T&gt;.ApplyActivationDerivative(T, T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.ApplyActivationDerivative(Tensor&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ComputeActivationJacobian_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ComputeActivationJacobian(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationDerivative_AiDotNet_Tensors_LinearAlgebra_Vector__0__AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.ApplyActivationDerivative(Vector&lt;T&gt;, Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_UpdateParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__">LayerBase&lt;T&gt;.UpdateParameters(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Serialize_System_IO_BinaryWriter_">LayerBase&lt;T&gt;.Serialize(BinaryWriter)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Deserialize_System_IO_BinaryReader_">LayerBase&lt;T&gt;.Deserialize(BinaryReader)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetDiagnostics">LayerBase&lt;T&gt;.GetDiagnostics()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationToGraph_AiDotNet_Autodiff_ComputationNode__0__">LayerBase&lt;T&gt;.ApplyActivationToGraph(ComputationNode&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_CanActivationBeJitted">LayerBase&lt;T&gt;.CanActivationBeJitted()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_RegisterTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__AiDotNet_Tensors_Engines_PersistentTensorRole_">LayerBase&lt;T&gt;.RegisterTrainableParameter(Tensor&lt;T&gt;, PersistentTensorRole)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_InvalidateTrainableParameter_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.InvalidateTrainableParameter(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_HasGpuActivation">LayerBase&lt;T&gt;.HasGpuActivation()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationForwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">LayerBase&lt;T&gt;.ApplyActivationForwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyActivationBackwardGpu_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_">LayerBase&lt;T&gt;.ApplyActivationBackwardGpu(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetFusedActivationType">LayerBase&lt;T&gt;.GetFusedActivationType()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivation_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_">LayerBase&lt;T&gt;.ApplyGpuActivation(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, int, FusedActivationType)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ApplyGpuActivationBackward_AiDotNet_Tensors_Engines_DirectGpu_IDirectGpuBackend_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_AiDotNet_Tensors_Engines_DirectGpu_IGpuBuffer_System_Int32_AiDotNet_Tensors_Engines_FusedActivationType_System_Single_">LayerBase&lt;T&gt;.ApplyGpuActivationBackward(IDirectGpuBackend, IGpuBuffer, IGpuBuffer, IGpuBuffer, IGpuBuffer, int, FusedActivationType, float)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose">LayerBase&lt;T&gt;.Dispose()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_Dispose_System_Boolean_">LayerBase&lt;T&gt;.Dispose(bool)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_WeightParameterName">LayerBase&lt;T&gt;.WeightParameterName</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_BiasParameterName">LayerBase&lt;T&gt;.BiasParameterName</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetWeights_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetWeights(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetBiases_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetBiases(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterNames">LayerBase&lt;T&gt;.GetParameterNames()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_TryGetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___">LayerBase&lt;T&gt;.TryGetParameter(string, out Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_SetParameter_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0__">LayerBase&lt;T&gt;.SetParameter(string, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_GetParameterShape_System_String_">LayerBase&lt;T&gt;.GetParameterShape(string)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_NamedParameterCount">LayerBase&lt;T&gt;.NamedParameterCount</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_ValidateWeights_System_Collections_Generic_IEnumerable_System_String__System_Func_System_String_System_String__">LayerBase&lt;T&gt;.ValidateWeights(IEnumerable&lt;string&gt;, Func&lt;string, string&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.NeuralNetworks.Layers.LayerBase-1.html#AiDotNet_NeuralNetworks_Layers_LayerBase_1_LoadWeights_System_Collections_Generic_Dictionary_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0___System_Func_System_String_System_String__System_Boolean_">LayerBase&lt;T&gt;.LoadWeights(Dictionary&lt;string, Tensor&lt;T&gt;&gt;, Func&lt;string, string&gt;, bool)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
This base class provides common functionality for all LoRA adapter implementations.
It manages the base layer, LoRA layer, and parameter synchronization, while allowing
derived classes to implement layer-type-specific logic such as merging and validation.
</p>
<p><b>For Beginners:</b> This is the foundation for all LoRA adapters in the library.
<p>A LoRA adapter wraps an existing layer (like a dense or convolutional layer) and adds
a small &quot;correction layer&quot; that learns what adjustments are needed. This base class:</p>
<ul>
<li>Manages both the original layer and the LoRA correction layer</li>
<li>Handles parameter synchronization between them</li>
<li>Provides common forward/backward pass logic (original + correction)</li>
<li>Lets specialized adapters handle layer-specific details</li>
</ul>
<p>This design allows you to create LoRA adapters for any layer type by:</p>
<ol>
<li>Inheriting from this base class</li>
<li>Implementing layer-specific validation</li>
<li>Implementing how to merge the LoRA weights back into the original layer</li>
</ol>
<p>The result is parameter-efficient fine-tuning that works across different layer architectures!</p>

</div>


  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1__ctor_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.#ctor*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1__ctor_AiDotNet_Interfaces_ILayer__0__System_Int32_System_Double_System_Boolean_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.#ctor(AiDotNet.Interfaces.ILayer{`0},System.Int32,System.Double,System.Boolean)">
  LoRAAdapterBase(ILayer&lt;T&gt;, int, double, bool)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L166"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new LoRA adapter base with the specified parameters.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected LoRAAdapterBase(ILayer&lt;T&gt; baseLayer, int rank, double alpha = -1, bool freezeBaseLayer = true)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>baseLayer</code> <a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</dt>
    <dd><p>The layer to adapt with LoRA.</p>
</dd>
    <dt><code>rank</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The rank of the LoRA decomposition.</p>
</dd>
    <dt><code>alpha</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The LoRA scaling factor (defaults to rank if negative).</p>
</dd>
    <dt><code>freezeBaseLayer</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>Whether to freeze the base layer's parameters during training.</p>
</dd>
  </dl>








  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1__ctor_AiDotNet_Interfaces_ILayer__0__System_Int32_System_Double_System_Boolean__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Beginners:</b> This creates the foundation for a LoRA adapter.
<p>Parameters:</p>
<ul>
<li>baseLayer: The layer you want to make more efficient to fine-tune</li>
<li>rank: How much compression (lower = fewer parameters, less flexibility)</li>
<li>alpha: How strong the LoRA adaptation is</li>
<li>freezeBaseLayer: Whether to lock the original layer's weights (usually true for efficiency)</li>
</ul>
<p>Derived classes will call this constructor and then add their own layer-specific logic.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></dt>
    <dd><p>Thrown when baseLayer is null.</p>
</dd>
  </dl>



  <h2 class="section" id="fields">Fields
</h2>



  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1__baseLayer" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1._baseLayer">
  _baseLayer
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L40"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>The base layer being adapted.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected readonly ILayer&lt;T&gt; _baseLayer</code></pre>
  </div>




  <h4 class="section">Field Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>










  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1__freezeBaseLayer" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1._freezeBaseLayer">
  _freezeBaseLayer
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L50"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Whether the base layer's parameters are frozen (not trainable).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected readonly bool _freezeBaseLayer</code></pre>
  </div>




  <h4 class="section">Field Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>










  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1__loraLayer" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1._loraLayer">
  _loraLayer
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L45"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>The LoRA layer that provides the adaptation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected readonly LoRALayer&lt;T&gt; _loraLayer</code></pre>
  </div>




  <h4 class="section">Field Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.LoRA.LoRALayer-1.html">LoRALayer</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>









  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Alpha_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.Alpha*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Alpha" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.Alpha">
  Alpha
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L105"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the scaling factor (alpha) for the LoRA adaptation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double Alpha { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Alpha_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>Alpha controls how strongly the LoRA adaptation affects the output.
The actual LoRA contribution is scaled by alpha/rank.
Common practice: alpha = rank (scaling factor of 1.0)</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_BaseLayer_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.BaseLayer*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_BaseLayer" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.BaseLayer">
  BaseLayer
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L59"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the base layer being adapted with LoRA.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public ILayer&lt;T&gt; BaseLayer { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_BaseLayer_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This is the original layer that's being enhanced with LoRA adaptations.
It may be frozen (non-trainable) during fine-tuning for maximum efficiency.</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_IsBaseLayerFrozen_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.IsBaseLayerFrozen*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_IsBaseLayerFrozen" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.IsBaseLayerFrozen">
  IsBaseLayerFrozen
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L77"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether the base layer's parameters are frozen during training.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public bool IsBaseLayerFrozen { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_IsBaseLayerFrozen_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>When true, only the LoRA parameters are trained, dramatically reducing
memory requirements and training time. This is the typical use case for LoRA.</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_LoRALayer_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.LoRALayer*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_LoRALayer" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.LoRALayer">
  LoRALayer
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L68"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the LoRA layer providing the low-rank adaptation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public LoRALayer&lt;T&gt; LoRALayer { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.LoRA.LoRALayer-1.html">LoRALayer</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_LoRALayer_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This layer implements the low-rank decomposition (A and B matrices)
that provides the adaptation to the base layer's behavior.</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_ParameterCount_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.ParameterCount*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_ParameterCount" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.ParameterCount">
  ParameterCount
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L114"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the total number of trainable parameters.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override int ParameterCount { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_ParameterCount_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>If the base layer is frozen, this returns only the LoRA parameter count.
Otherwise, it returns the sum of base and LoRA parameters.</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Rank_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.Rank*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Rank" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.Rank">
  Rank
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L95"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the rank of the low-rank decomposition.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int Rank { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Rank_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The rank determines how many parameters the LoRA adaptation uses.
Lower rank = fewer parameters = more efficient but less flexible.
</p>
<p>
Typical values:
- rank=1-4: Very efficient, minimal parameters
- rank=8: Good balance (default for many applications)
- rank=16-32: More flexibility, more parameters
- rank=64+: Diminishing returns, approaching full fine-tuning
</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_SupportsJitCompilation_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.SupportsJitCompilation*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_SupportsJitCompilation" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.SupportsJitCompilation">
  SupportsJitCompilation
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L589"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this LoRA adapter supports JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsJitCompilation { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if both the base layer and LoRA layer support JIT compilation.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_SupportsJitCompilation_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
LoRA adapters support JIT compilation when both their component layers (the base layer
and the LoRA layer) support JIT compilation. The computation graph combines both layers:
output = base_layer(input) + lora_layer(input)
</p>
<p><b>For Beginners:</b> JIT compilation makes layers run faster by converting
their math operations into optimized native code.
<p>A LoRA adapter can be JIT compiled when:</p>
<ul>
<li>The base layer supports JIT compilation (has its weights initialized)</li>
<li>The LoRA layer supports JIT compilation (has its A and B matrices initialized)</li>
</ul>
<p>The JIT-compiled version computes both the base layer's output and the LoRA adaptation
in parallel, then adds them together. This can provide significant speedup (5-10x).</p>
<p>Alternatively, you can merge the LoRA weights into the base layer using MergeToOriginalLayer()
for an even simpler and potentially faster deployment.</p>

</div>




  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_SupportsTraining_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.SupportsTraining*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_SupportsTraining" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.SupportsTraining">
  SupportsTraining
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L121"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this adapter supports training.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override bool SupportsTraining { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>








  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Backward_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.Backward*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.Backward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Backward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L258"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the backward pass through both layers.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; Backward(Tensor&lt;T&gt; outputGradient)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>outputGradient</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Gradient flowing back from the next layer.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Gradient to pass to the previous layer.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Backward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The backward pass propagates gradients through both the LoRA layer and (if not frozen)
the base layer. The input gradients from both paths are summed.
</p>
<p><b>For Beginners:</b> During learning, this figures out how to improve both layers:
- Always updates the LoRA layer (that's what we're training)
- Only updates the base layer if it's not frozen
- Combines the gradients from both paths to tell earlier layers how to improve
</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_CreateLoRALayer_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.CreateLoRALayer*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_CreateLoRALayer_System_Int32_System_Double_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.CreateLoRALayer(System.Int32,System.Double)">
  CreateLoRALayer(int, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L203"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Creates the LoRA layer for this adapter.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected virtual LoRALayer&lt;T&gt; CreateLoRALayer(int rank, double alpha)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>rank</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The rank of the LoRA decomposition.</p>
</dd>
    <dt><code>alpha</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The LoRA scaling factor.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.LoRA.LoRALayer-1.html">LoRALayer</a>&lt;T&gt;</dt>
    <dd><p>A LoRA layer configured for this adapter.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_CreateLoRALayer_System_Int32_System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method can be overridden by derived classes to customize LoRA layer creation.
By default, it creates a standard LoRA layer with the adapter's input and output dimensions.
</p>
<p><b>For Beginners:</b> This creates the "correction layer" that learns adaptations.
<p>Different adapter types might need different LoRA layer configurations:</p>
<ul>
<li>Dense layers: Standard 1D LoRA</li>
<li>Convolutional layers: LoRA with spatial dimensions</li>
<li>Attention layers: LoRA for query/key/value projections</li>
</ul>
<p>This method lets each adapter type create the right kind of LoRA layer.</p>

</div>




  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_CreateMergedLayerWithClone_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.CreateMergedLayerWithClone*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_CreateMergedLayerWithClone_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.CreateMergedLayerWithClone(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  CreateMergedLayerWithClone(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L433"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Helper method to create a merged layer by cloning the base layer and updating its parameters.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected ILayer&lt;T&gt; CreateMergedLayerWithClone(Vector&lt;T&gt; mergedParams)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>mergedParams</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>The merged parameters to set on the cloned layer.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</dt>
    <dd><p>A cloned layer with merged parameters and preserved activation function.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_CreateMergedLayerWithClone_AiDotNet_Tensors_LinearAlgebra_Vector__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This helper method preserves the activation function and other settings from the base layer
by using Clone() instead of creating a new layer. This ensures the merged layer behaves
identically to the original adapted layer.
</p>
<p><b>For Beginners:</b> This is a utility method that derived classes can use to create
a properly merged layer without duplicating the Clone() pattern everywhere.
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown when base layer is not DenseLayer or FullyConnectedLayer.</p>
</dd>
  </dl>



  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_ExportComputationGraph_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.ExportComputationGraph*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0___" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.ExportComputationGraph(System.Collections.Generic.List{AiDotNet.Autodiff.ComputationNode{`0}})">
  ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L620"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Exports the computation graph for JIT compilation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override ComputationNode&lt;T&gt; ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt; inputNodes)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputNodes</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.list-1">List</a>&lt;<a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;&gt;</dt>
    <dd><p>List to which input nodes will be added.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Autodiff.ComputationNode-1.html">ComputationNode</a>&lt;T&gt;</dt>
    <dd><p>The output computation node representing the combined base + LoRA transformation.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0____remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The computation graph implements: output = base_layer(input) + lora_layer(input)
<p>This mirrors the Forward() method logic where:</p>
<ol>
<li>The input is passed through the base layer</li>
<li>The same input is passed through the LoRA layer</li>
<li>The two outputs are added element-wise</li>
</ol>

<p><b>For Beginners:</b> This exports the LoRA adapter's computation as a graph of operations
that can be optimized and compiled to fast native code.
<p>The graph represents:</p>
<ol>
<li>Input  base layer computation  base output</li>
<li>Input  LoRA layer computation  LoRA output</li>
<li>base output + LoRA output  final output</li>
</ol>
<p>The JIT compiler can then fuse operations, apply SIMD vectorization, and perform
other optimizations to make inference faster.</p>

</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></dt>
    <dd><p>Thrown when inputNodes is null.</p>
</dd>
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown when component layers are not initialized.</p>
</dd>
  </dl>



  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Forward_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.Forward*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.Forward(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  Forward(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L224"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Performs the forward pass through both base and LoRA layers.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Tensor&lt;T&gt; Forward(Tensor&lt;T&gt; input)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Input tensor.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Sum of base layer output and LoRA output.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_Forward_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
The forward pass computes: output = base_layer(input) + lora_layer(input)
</p>
<p><b>For Beginners:</b> This runs the input through both the original layer and the
LoRA correction layer, then adds their outputs together. The result is the original
behavior plus the learned adaptation.
</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_GetParameters_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.GetParameters*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_GetParameters" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.GetParameters">
  GetParameters()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L303"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the current parameters as a vector.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override Vector&lt;T&gt; GetParameters()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>Vector containing parameters (LoRA only if base is frozen, otherwise both).</p>
</dd>
  </dl>











  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_MergeToDenseOrFullyConnected_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.MergeToDenseOrFullyConnected*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_MergeToDenseOrFullyConnected" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.MergeToDenseOrFullyConnected">
  MergeToDenseOrFullyConnected()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L475"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Merges LoRA weights into the base layer for DenseLayer or FullyConnectedLayer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected ILayer&lt;T&gt; MergeToDenseOrFullyConnected()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</dt>
    <dd><p>A new layer with merged weights.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_MergeToDenseOrFullyConnected_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This helper method implements the standard LoRA merge logic for Dense and FullyConnected layers:
1. Get LoRA weight contribution from low-rank matrices
2. Add to base layer weights element-wise
3. Preserve biases unchanged
4. Create new layer with merged parameters
</p>
<p><b>For Beginners:</b> This combines the base weights with the LoRA adaptation,
creating a single layer that doesn't need the adapter anymore. Useful for deployment!
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></dt>
    <dd><p>Thrown when base layer is not DenseLayer or FullyConnectedLayer.</p>
</dd>
  </dl>



  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_MergeToOriginalLayer_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.MergeToOriginalLayer*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_MergeToOriginalLayer" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.MergeToOriginalLayer">
  MergeToOriginalLayer()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L415"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Merges the LoRA adaptation into the base layer and returns the merged layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public abstract ILayer&lt;T&gt; MergeToOriginalLayer()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Interfaces.ILayer-1.html">ILayer</a>&lt;T&gt;</dt>
    <dd><p>A new layer with LoRA weights merged into the base layer's weights.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_MergeToOriginalLayer_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This method must be implemented by derived classes to handle layer-type-specific
merging logic. Each type of adapter (Dense, Convolutional, etc.) needs to know
how to combine its LoRA weights with the base layer's weights.
</p>
<p><b>For Beginners:</b> This "bakes in" your LoRA adaptation to create a regular layer.
After training with LoRA, you can merge the adaptation into the original weights for:
- Faster inference (no need to compute LoRA separately)
- Simpler deployment (single layer instead of two)
- Compatibility with systems that don't support LoRA
<p>Each layer type implements this differently because they have different internal structures.</p>

</div>




  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_ResetState_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.ResetState*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_ResetState" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.ResetState">
  ResetState()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L559"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Resets the internal state of both the base layer and LoRA layer.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void ResetState()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_ResetState_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Beginners:</b> This clears the memory of both the base layer and the LoRA layer.
It's useful when starting to process a completely new, unrelated batch of data.
</p>
</div>




  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_SetParameters_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.SetParameters*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_SetParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.SetParameters(AiDotNet.Tensors.LinearAlgebra.Vector{`0})">
  SetParameters(Vector&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L312"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Sets the layer parameters from a vector.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void SetParameters(Vector&lt;T&gt; parameters)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>parameters</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Vector-1.html">Vector</a>&lt;T&gt;</dt>
    <dd><p>Vector containing parameters.</p>
</dd>
  </dl>












  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_UpdateParameters_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.UpdateParameters*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_UpdateParameters__0_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.UpdateParameters(`0)">
  UpdateParameters(T)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L284"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Updates parameters using the specified learning rate.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public override void UpdateParameters(T learningRate)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>learningRate</code> <span class="xref">T</span></dt>
    <dd><p>The learning rate for parameter updates.</p>
</dd>
  </dl>












  <a id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_UpdateParametersFromLayers_" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.UpdateParametersFromLayers*"></a>

  <h3 id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_UpdateParametersFromLayers" data-uid="AiDotNet.LoRA.Adapters.LoRAAdapterBase`1.UpdateParametersFromLayers">
  UpdateParametersFromLayers()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L531"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Updates the parameter vector from the current base and LoRA layer states.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected virtual void UpdateParametersFromLayers()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_LoRA_Adapters_LoRAAdapterBase_1_UpdateParametersFromLayers_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This helper method synchronizes the adapter's parameter vector with the current state
of the base and LoRA layers after updates. It packs parameters in the standard order:
base layer parameters (if not frozen) followed by LoRA parameters.
</p>
<p><b>For Beginners:</b> This ensures the adapter's parameter vector stays in sync
with its component layers. Called after parameter updates.
</p>
</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/LoRA/Adapters/LoRAAdapterBase.cs/#L35" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
