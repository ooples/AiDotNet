<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class VoiceActivityDetectorBase&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class VoiceActivityDetectorBase&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Base class for algorithmic voice activity detection implementations (non-neural network).">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1.md&amp;value=---%0Auid%3A%20AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1">



  <h1 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1" class="text-break">
Class VoiceActivityDetectorBase&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L31"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.Audio.html">Audio</a>.<a class="xref" href="AiDotNet.Audio.VoiceActivity.html">VoiceActivity</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Base class for algorithmic voice activity detection implementations (non-neural network).</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public abstract class VoiceActivityDetectorBase&lt;T&gt; : IVoiceActivityDetector&lt;T&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for calculations.</p>
</dd>
  </dl>

  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><span class="xref">VoiceActivityDetectorBase&lt;T&gt;</span></div>
    </dd>
  </dl>

  <dl class="typelist implements">
    <dt>Implements</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.Interfaces.IVoiceActivityDetector-1.html">IVoiceActivityDetector</a>&lt;T&gt;</div>
    </dd>
  </dl>

  <dl class="typelist derived">
    <dt>Derived</dt>
    <dd>
      <div><a class="xref" href="AiDotNet.Audio.VoiceActivity.EnergyBasedVad-1.html">EnergyBasedVad&lt;T&gt;</a></div>
    </dd>
  </dl>

  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
Voice Activity Detection (VAD) determines whether audio contains speech or silence.
This is fundamental to many audio applications including speech recognition,
communication systems, and noise reduction.
</p>
<p><b>For Beginners:</b> VAD answers a simple question: "Is someone speaking right now?"
<p>Common uses:</p>
<ul>
<li>Skip silence during transcription</li>
<li>Reduce transmission bandwidth in VoIP</li>
<li>Trigger recording only when speech is detected</li>
<li>Segment audio into speaker turns</li>
</ul>
<p>This base class provides:</p>
<ul>
<li>Frame-based processing with hangover logic</li>
<li>Streaming mode with state management</li>
<li>Segment detection across entire audio files</li>
</ul>
<p>For neural network-based VAD (like Silero), see classes that extend AudioNeuralNetworkBase.</p>

</div>


  <h2 class="section" id="constructors">Constructors
</h2>


  <a id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1__ctor_" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.#ctor*"></a>

  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1__ctor_System_Int32_System_Int32_System_Double_System_Int32_System_Int32_" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.#ctor(System.Int32,System.Int32,System.Double,System.Int32,System.Int32)">
  VoiceActivityDetectorBase(int, int, double, int, int)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L88"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Initializes a new instance of VoiceActivityDetectorBase.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected VoiceActivityDetectorBase(int sampleRate = 16000, int frameSize = 480, double threshold = 0.5, int minSpeechDurationMs = 250, int minSilenceDurationMs = 300)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>sampleRate</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Audio sample rate.</p>
</dd>
    <dt><code>frameSize</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Frame size in samples.</p>
</dd>
    <dt><code>threshold</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Detection threshold (0-1).</p>
</dd>
    <dt><code>minSpeechDurationMs</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Minimum speech duration in ms.</p>
</dd>
    <dt><code>minSilenceDurationMs</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>Minimum silence duration in ms.</p>
</dd>
  </dl>












  <h2 class="section" id="fields">Fields
</h2>



  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_NumOps" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.NumOps">
  NumOps
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L38"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Numeric operations for type T.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected readonly INumericOperations&lt;T&gt; NumOps</code></pre>
  </div>




  <h4 class="section">Field Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.Interfaces.INumericOperations-1.html">INumericOperations</a>&lt;T&gt;</dt>
    <dd></dd>
  </dl>










  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1__inSpeech" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1._inSpeech">
  _inSpeech
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L76"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Current speech state.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected bool _inSpeech</code></pre>
  </div>




  <h4 class="section">Field Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>










  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1__silenceFrameCount" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1._silenceFrameCount">
  _silenceFrameCount
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L71"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Number of consecutive silence frames.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected int _silenceFrameCount</code></pre>
  </div>




  <h4 class="section">Field Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>










  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1__speechFrameCount" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1._speechFrameCount">
  _speechFrameCount
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L66"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Number of consecutive speech frames.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected int _speechFrameCount</code></pre>
  </div>




  <h4 class="section">Field Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>









  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_FrameSize_" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.FrameSize*"></a>

  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_FrameSize" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.FrameSize">
  FrameSize
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L48"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the frame size in samples used for detection.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int FrameSize { get; protected set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>








  <a id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_MinSilenceDurationMs_" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.MinSilenceDurationMs*"></a>

  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_MinSilenceDurationMs" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.MinSilenceDurationMs">
  MinSilenceDurationMs
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L57"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the minimum silence duration in milliseconds.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int MinSilenceDurationMs { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_MinSilenceDurationMs_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>Silence gaps shorter than this don't split speech segments.</p>
</div>




  <a id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_MinSpeechDurationMs_" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.MinSpeechDurationMs*"></a>

  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_MinSpeechDurationMs" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.MinSpeechDurationMs">
  MinSpeechDurationMs
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L54"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the minimum speech duration in milliseconds.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int MinSpeechDurationMs { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_MinSpeechDurationMs_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>Speech segments shorter than this are ignored (reduces false triggers).</p>
</div>




  <a id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_SampleRate_" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.SampleRate*"></a>

  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_SampleRate" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.SampleRate">
  SampleRate
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L45"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the sample rate this VAD operates at.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int SampleRate { get; protected set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>








  <a id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_Threshold_" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.Threshold*"></a>

  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_Threshold" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.Threshold">
  Threshold
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L51"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the detection threshold (0.0 to 1.0).</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double Threshold { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_Threshold_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>Higher threshold = fewer false positives but may miss quiet speech.
Lower threshold = catches more speech but may trigger on noise.
Default is typically 0.5.</p>
</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_ComputeFrameProbability_" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.ComputeFrameProbability*"></a>

  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_ComputeFrameProbability__0___" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.ComputeFrameProbability(`0[])">
  ComputeFrameProbability(T[])
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L112"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Computes speech probability for a single frame.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected abstract T ComputeFrameProbability(T[] frame)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>frame</code> T[]</dt>
    <dd><p>Audio frame data.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><span class="xref">T</span></dt>
    <dd><p>Speech probability (0-1).</p>
</dd>
  </dl>











  <a id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_DetectSpeech_" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.DetectSpeech*"></a>

  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_DetectSpeech_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.DetectSpeech(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  DetectSpeech(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L119"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Detects whether speech is present in an audio frame.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual bool DetectSpeech(Tensor&lt;T&gt; audioFrame)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>audioFrame</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Audio frame with shape [samples] or [channels, samples].</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd><p>True if speech is detected, false otherwise.</p>
</dd>
  </dl>











  <a id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_DetectSpeechSegments_" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.DetectSpeechSegments*"></a>

  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_DetectSpeechSegments_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.DetectSpeechSegments(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  DetectSpeechSegments(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L133"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Detects speech segments in a longer audio recording.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual IReadOnlyList&lt;(int StartSample, int EndSample)&gt; DetectSpeechSegments(Tensor&lt;T&gt; audio)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>audio</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Full audio recording.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ireadonlylist-1">IReadOnlyList</a>&lt;(<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.valuetuple-system.int32,system.int32-.startsample">StartSample</a>, <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.valuetuple-system.int32,system.int32-.endsample">EndSample</a>)&gt;</dt>
    <dd><p>List of (startSample, endSample) tuples for each speech segment.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_DetectSpeechSegments_AiDotNet_Tensors_LinearAlgebra_Tensor__0___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Beginners:</b> This finds all the parts where someone is talking.
<p>Example result for a 10-second recording:
[(0.5s, 2.3s), (4.1s, 6.8s), (8.0s, 9.5s)]
Meaning: Speech from 0.5-2.3s, silence, speech from 4.1-6.8s, etc.</p>

</div>




  <a id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_GetFrameProbabilities_" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.GetFrameProbabilities*"></a>

  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_GetFrameProbabilities_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.GetFrameProbabilities(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  GetFrameProbabilities(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L194"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets frame-by-frame speech probabilities for the entire audio.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual T[] GetFrameProbabilities(Tensor&lt;T&gt; audio)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>audio</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Full audio recording.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt>T[]</dt>
    <dd><p>Array of speech probabilities, one per frame.</p>
</dd>
  </dl>











  <a id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_GetSpeechProbability_" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.GetSpeechProbability*"></a>

  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_GetSpeechProbability_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.GetSpeechProbability(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  GetSpeechProbability(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L126"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the speech probability for an audio frame.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual T GetSpeechProbability(Tensor&lt;T&gt; audioFrame)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>audioFrame</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Audio frame to analyze.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><span class="xref">T</span></dt>
    <dd><p>Probability of speech (0.0 = definitely not speech, 1.0 = definitely speech).</p>
</dd>
  </dl>











  <a id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_ProcessChunk_" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.ProcessChunk*"></a>

  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_ProcessChunk_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.ProcessChunk(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  ProcessChunk(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L211"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Processes audio in streaming mode, maintaining state between calls.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual (bool IsSpeech, T Probability) ProcessChunk(Tensor&lt;T&gt; audioChunk)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>audioChunk</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>A chunk of audio for real-time processing.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt>(<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.valuetuple-system.boolean,-0-.samelanguage">SameLanguage</a>, T <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.valuetuple-system.boolean,-0-.confidence">Confidence</a>)</dt>
    <dd><p>Speech detection result with probability.</p>
</dd>
  </dl>











  <a id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_ResetState_" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.ResetState*"></a>

  <h3 id="AiDotNet_Audio_VoiceActivity_VoiceActivityDetectorBase_1_ResetState" data-uid="AiDotNet.Audio.VoiceActivity.VoiceActivityDetectorBase`1.ResetState">
  ResetState()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L244"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Resets internal state for streaming mode.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual void ResetState()</code></pre>
  </div>














</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/Audio/VoiceActivity/VoiceActivityDetectorBase.cs/#L31" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
