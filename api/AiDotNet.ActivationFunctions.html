<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Namespace AiDotNet.ActivationFunctions | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Namespace AiDotNet.ActivationFunctions | AiDotNet Documentation ">
      
      
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.ActivationFunctions">

  <h1 id="AiDotNet_ActivationFunctions" data-uid="AiDotNet.ActivationFunctions" class="text-break">Namespace AiDotNet.ActivationFunctions</h1>
  <div class="markdown level0 summary"></div>
  <div class="markdown level0 conceptual"></div>
  <div class="markdown level0 remarks"></div>

    <h3 id="classes">
Classes
</h3>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.ActivationFunctionBase-1.html">ActivationFunctionBase&lt;T&gt;</a></dt>
      <dd><p>Base class for all activation functions used in neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.BentIdentityActivation-1.html">BentIdentityActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Bent Identity activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.BinarySpikingActivation-1.html">BinarySpikingActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Binary Spiking activation function for neural networks, particularly for spiking neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.CELUActivation-1.html">CELUActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Continuously Differentiable Exponential Linear Unit (CELU) activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.ELUActivation-1.html">ELUActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Exponential Linear Unit (ELU) activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.GELUActivation-1.html">GELUActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Gaussian Error Linear Unit (GELU) activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.GaussianActivation-1.html">GaussianActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Gaussian activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.GumbelSoftmaxActivation-1.html">GumbelSoftmaxActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Gumbel-Softmax activation function for neural networks, which enables
differentiable sampling from discrete distributions.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.HardSigmoidActivation-1.html">HardSigmoidActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Hard Sigmoid activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.HardSwishActivation-1.html">HardSwishActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Hard Swish activation function used in MobileNetV3.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.HardTanhActivation-1.html">HardTanhActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Hard Tanh activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.HierarchicalSoftmaxActivation-1.html">HierarchicalSoftmaxActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Hierarchical Softmax activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.ISRUActivation-1.html">ISRUActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Inverse Square Root Unit (ISRU) activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.IdentityActivation-1.html">IdentityActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Identity activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.LeakyReLUActivation-1.html">LeakyReLUActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Leaky Rectified Linear Unit (Leaky ReLU) activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.LiSHTActivation-1.html">LiSHTActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Linearly Scaled Hyperbolic Tangent (LiSHT) activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.LogSoftmaxActivation-1.html">LogSoftmaxActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the LogSoftmax activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.LogSoftminActivation-1.html">LogSoftminActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the LogSoftmin activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.MaxoutActivation-1.html">MaxoutActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Maxout activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.MishActivation-1.html">MishActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Mish activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.PReLUActivation-1.html">PReLUActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Parametric Rectified Linear Unit (PReLU) activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.RReLUActivation-1.html">RReLUActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Randomized Rectified Linear Unit (RReLU) activation function.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.ReLU6Activation-1.html">ReLU6Activation&lt;T&gt;</a></dt>
      <dd><p>Implements the ReLU6 (Rectified Linear Unit capped at 6) activation function.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.ReLUActivation-1.html">ReLUActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Rectified Linear Unit (ReLU) activation function.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.SELUActivation-1.html">SELUActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Scaled Exponential Linear Unit (SELU) activation function.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.SQRBFActivation-1.html">SQRBFActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Squared Radial Basis Function (SQRBF) activation function.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.ScaledTanhActivation-1.html">ScaledTanhActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Scaled Hyperbolic Tangent (tanh) activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.SiLUActivation-1.html">SiLUActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the SiLU (Sigmoid Linear Unit) activation function, also known as Swish.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.SigmoidActivation-1.html">SigmoidActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Sigmoid activation function, one of the most common activation functions in neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.SignActivation-1.html">SignActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Sign activation function, which returns -1 for negative inputs, 1 for positive inputs, and 0 for zero.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.SoftPlusActivation-1.html">SoftPlusActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the SoftPlus activation function, which is a smooth approximation of the ReLU function.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.SoftSignActivation-1.html">SoftSignActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the SoftSign activation function, which is a smooth alternative to the tanh function.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.SoftmaxActivation-1.html">SoftmaxActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Softmax activation function, which converts a vector of real numbers into a probability distribution.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.SoftminActivation-1.html">SoftminActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Softmin activation function, which is the opposite of Softmax and highlights the smallest values in a vector.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.SparsemaxActivation-1.html">SparsemaxActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Sparsemax activation function, which is an alternative to Softmax that can produce sparse probability distributions.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.SphericalSoftmaxActivation-1.html">SphericalSoftmaxActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Spherical Softmax activation function, which normalizes inputs to the unit sphere before applying softmax.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.SquashActivation-1.html">SquashActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Squash activation function, which normalizes vectors to have a magnitude between 0 and 1.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.SwishActivation-1.html">SwishActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Swish activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.TanhActivation-1.html">TanhActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Hyperbolic Tangent (tanh) activation function for neural networks.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.TaylorSoftmaxActivation-1.html">TaylorSoftmaxActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Taylor Softmax activation function, which is a computationally efficient approximation of the standard Softmax function.</p>
</dd>
    </dl>
    <dl class="jumplist">
      <dt><a class="xref" href="AiDotNet.ActivationFunctions.ThresholdedReLUActivation-1.html">ThresholdedReLUActivation&lt;T&gt;</a></dt>
      <dd><p>Implements the Thresholded ReLU activation function, a variant of the standard ReLU function with an adjustable threshold.</p>
</dd>
    </dl>


</article>

        <div class="contribution d-print-none">
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
