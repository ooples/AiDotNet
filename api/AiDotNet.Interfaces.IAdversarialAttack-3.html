<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Interface IAdversarialAttack&lt;T, TInput, TOutput&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Interface IAdversarialAttack&lt;T, TInput, TOutput&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Defines the contract for adversarial attack algorithms that generate adversarial examples.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_Interfaces_IAdversarialAttack_3.md&amp;value=---%0Auid%3A%20AiDotNet.Interfaces.IAdversarialAttack%603%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.Interfaces.IAdversarialAttack`3">



  <h1 id="AiDotNet_Interfaces_IAdversarialAttack_3" data-uid="AiDotNet.Interfaces.IAdversarialAttack`3" class="text-break">
Interface IAdversarialAttack&lt;T, TInput, TOutput&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/IAdversarialAttack.cs/#L31"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.Interfaces.html">Interfaces</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Defines the contract for adversarial attack algorithms that generate adversarial examples.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public interface IAdversarialAttack&lt;T, TInput, TOutput&gt; : IModelSerializer</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric data type used for calculations (e.g., float, double).</p>
</dd>
    <dt><code>TInput</code></dt>
    <dd><p>The input data type for the model (e.g., Vector&lt;T&gt;, string).</p>
</dd>
    <dt><code>TOutput</code></dt>
    <dd><p>The output data type for the model (e.g., Vector&lt;T&gt;, int).</p>
</dd>
  </dl>




  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IModelSerializer.html#AiDotNet_Interfaces_IModelSerializer_Serialize">IModelSerializer.Serialize()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IModelSerializer.html#AiDotNet_Interfaces_IModelSerializer_Deserialize_System_Byte___">IModelSerializer.Deserialize(byte[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IModelSerializer.html#AiDotNet_Interfaces_IModelSerializer_SaveModel_System_String_">IModelSerializer.SaveModel(string)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IModelSerializer.html#AiDotNet_Interfaces_IModelSerializer_LoadModel_System_String_">IModelSerializer.LoadModel(string)</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_Interfaces_IAdversarialAttack_3_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>An adversarial attack crafts inputs that cause machine learning models to make mistakes,
used for robustness testing and improving model security.</p>
<p><b>For Beginners:</b> Think of an adversarial attack as a &quot;stress test&quot; for your AI model.
Just like testing if a building can withstand an earthquake, these attacks test if your model
can handle tricky inputs that are designed to fool it.</p>
<p>Common examples of adversarial attacks include:</p>
<ul>
<li>FGSM (Fast Gradient Sign Method): Quick attacks using gradient information</li>
<li>PGD (Projected Gradient Descent): More powerful iterative attacks</li>
<li>C&amp;W (Carlini &amp; Wagner): Sophisticated optimization-based attacks</li>
</ul>
<p>Why adversarial attacks matter:</p>
<ul>
<li>They reveal vulnerabilities in models before deployment</li>
<li>They help create more robust models through adversarial training</li>
<li>They're essential for safety-critical applications (self-driving cars, medical diagnosis)</li>
<li>They demonstrate potential security risks</li>
</ul>
</div>


  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_Interfaces_IAdversarialAttack_3_CalculatePerturbation_" data-uid="AiDotNet.Interfaces.IAdversarialAttack`3.CalculatePerturbation*"></a>

  <h3 id="AiDotNet_Interfaces_IAdversarialAttack_3_CalculatePerturbation__1__1_" data-uid="AiDotNet.Interfaces.IAdversarialAttack`3.CalculatePerturbation(`1,`1)">
  CalculatePerturbation(TInput, TInput)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/IAdversarialAttack.cs/#L84"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Calculates the perturbation added to create an adversarial example.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">TInput CalculatePerturbation(TInput original, TInput adversarial)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>original</code> <span class="xref">TInput</span></dt>
    <dd><p>The original clean input.</p>
</dd>
    <dt><code>adversarial</code> <span class="xref">TInput</span></dt>
    <dd><p>The generated adversarial example.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><span class="xref">TInput</span></dt>
    <dd><p>The perturbation representation (difference between adversarial and original).</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Interfaces_IAdversarialAttack_3_CalculatePerturbation__1__1__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Beginners:</b> This shows you what changes were made to fool the model.
By comparing the original input with the adversarial example, you can see exactly
what the attack changed. This helps understand how the attack works.</p>
<p>Note: For non-vector inputs (e.g., strings), this returns a representation of the difference
that is appropriate for the input type.</p>
</div>




  <a id="AiDotNet_Interfaces_IAdversarialAttack_3_GenerateAdversarialBatch_" data-uid="AiDotNet.Interfaces.IAdversarialAttack`3.GenerateAdversarialBatch*"></a>

  <h3 id="AiDotNet_Interfaces_IAdversarialAttack_3_GenerateAdversarialBatch__1____2___AiDotNet_Interfaces_IFullModel__0__1__2__" data-uid="AiDotNet.Interfaces.IAdversarialAttack`3.GenerateAdversarialBatch(`1[],`2[],AiDotNet.Interfaces.IFullModel{`0,`1,`2})">
  GenerateAdversarialBatch(TInput[], TOutput[], IFullModel&lt;T, TInput, TOutput&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/IAdversarialAttack.cs/#L68"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Generates a batch of adversarial examples from multiple clean inputs.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">TInput[] GenerateAdversarialBatch(TInput[] inputs, TOutput[] trueLabels, IFullModel&lt;T, TInput, TOutput&gt; targetModel)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>inputs</code> TInput[]</dt>
    <dd><p>The batch of clean input data.</p>
</dd>
    <dt><code>trueLabels</code> TOutput[]</dt>
    <dd><p>The correct labels for each input.</p>
</dd>
    <dt><code>targetModel</code> <a class="xref" href="AiDotNet.Interfaces.IFullModel-3.html">IFullModel</a>&lt;T, TInput, TOutput&gt;</dt>
    <dd><p>The model to attack.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt>TInput[]</dt>
    <dd><p>The batch of generated adversarial examples.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Interfaces_IAdversarialAttack_3_GenerateAdversarialBatch__1____2___AiDotNet_Interfaces_IFullModel__0__1__2___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Beginners:</b> This is the same as GenerateAdversarialExample, but it processes
multiple inputs at once for efficiency. It's like batch processing - instead of attacking
one image at a time, you attack many images together.</p>
</div>




  <a id="AiDotNet_Interfaces_IAdversarialAttack_3_GenerateAdversarialExample_" data-uid="AiDotNet.Interfaces.IAdversarialAttack`3.GenerateAdversarialExample*"></a>

  <h3 id="AiDotNet_Interfaces_IAdversarialAttack_3_GenerateAdversarialExample__1__2_AiDotNet_Interfaces_IFullModel__0__1__2__" data-uid="AiDotNet.Interfaces.IAdversarialAttack`3.GenerateAdversarialExample(`1,`2,AiDotNet.Interfaces.IFullModel{`0,`1,`2})">
  GenerateAdversarialExample(TInput, TOutput, IFullModel&lt;T, TInput, TOutput&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/IAdversarialAttack.cs/#L54"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Generates adversarial examples from clean input data.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">TInput GenerateAdversarialExample(TInput input, TOutput trueLabel, IFullModel&lt;T, TInput, TOutput&gt; targetModel)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>input</code> <span class="xref">TInput</span></dt>
    <dd><p>The clean input data to be perturbed.</p>
</dd>
    <dt><code>trueLabel</code> <span class="xref">TOutput</span></dt>
    <dd><p>The correct label for the input.</p>
</dd>
    <dt><code>targetModel</code> <a class="xref" href="AiDotNet.Interfaces.IFullModel-3.html">IFullModel</a>&lt;T, TInput, TOutput&gt;</dt>
    <dd><p>The model to attack.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><span class="xref">TInput</span></dt>
    <dd><p>The generated adversarial example.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Interfaces_IAdversarialAttack_3_GenerateAdversarialExample__1__2_AiDotNet_Interfaces_IFullModel__0__1__2___remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>This method takes normal inputs and perturbs them slightly to create adversarial examples
that fool the target model while appearing similar to the original inputs.</p>
<p><b>For Beginners:</b> This is like creating optical illusions for AI. You make tiny changes
to an image or input that a human wouldn't notice, but these changes trick the AI into
making wrong predictions.</p>
<p>The process typically involves:</p>
<ol>
<li>Taking a clean input (e.g., an image of a cat)</li>
<li>Calculating how to modify it to fool the model</li>
<li>Creating a modified version (adversarial example)</li>
<li>The model might now think the cat is a dog, even though it looks the same to humans</li>
</ol>
</div>




  <a id="AiDotNet_Interfaces_IAdversarialAttack_3_GetOptions_" data-uid="AiDotNet.Interfaces.IAdversarialAttack`3.GetOptions*"></a>

  <h3 id="AiDotNet_Interfaces_IAdversarialAttack_3_GetOptions" data-uid="AiDotNet.Interfaces.IAdversarialAttack`3.GetOptions">
  GetOptions()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/IAdversarialAttack.cs/#L96"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the configuration options for the adversarial attack.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">AdversarialAttackOptions&lt;T&gt; GetOptions()</code></pre>
  </div>


  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Models.Options.AdversarialAttackOptions-1.html">AdversarialAttackOptions</a>&lt;T&gt;</dt>
    <dd><p>The configuration options for the attack.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Interfaces_IAdversarialAttack_3_GetOptions_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Beginners:</b> These are the &quot;settings&quot; for the attack, like:</p>
<ul>
<li>How strong the attack should be (perturbation budget)</li>
<li>How many steps to take when crafting the adversarial example</li>
<li>What type of perturbation to use (L2, L-infinity, etc.)</li>
</ul>
</div>




  <a id="AiDotNet_Interfaces_IAdversarialAttack_3_Reset_" data-uid="AiDotNet.Interfaces.IAdversarialAttack`3.Reset*"></a>

  <h3 id="AiDotNet_Interfaces_IAdversarialAttack_3_Reset" data-uid="AiDotNet.Interfaces.IAdversarialAttack`3.Reset">
  Reset()
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/IAdversarialAttack.cs/#L105"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Resets the attack state to prepare for a fresh attack run.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">void Reset()</code></pre>
  </div>









  <h4 class="section" id="AiDotNet_Interfaces_IAdversarialAttack_3_Reset_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p><b>For Beginners:</b> This clears any saved state from previous attacks,
ensuring each new attack starts fresh without being influenced by previous runs.</p>
</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/IAdversarialAttack.cs/#L31" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
