<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Enum NormalizationMethod | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Enum NormalizationMethod | AiDotNet Documentation ">
      
      <meta name="description" content="Defines different methods for normalizing data before processing in machine learning algorithms.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_Enums_NormalizationMethod.md&amp;value=---%0Auid%3A%20AiDotNet.Enums.NormalizationMethod%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.Enums.NormalizationMethod">




  <h1 id="AiDotNet_Enums_NormalizationMethod" data-uid="AiDotNet.Enums.NormalizationMethod" class="text-break">
Enum NormalizationMethod  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Enums/NormalizationMethod.cs/#L15"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.Enums.html">Enums</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Defines different methods for normalizing data before processing in machine learning algorithms.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public enum NormalizationMethod</code></pre>
  </div>









  <h2 id="fields">Fields
</h2>
  <dl class="parameters">
    <dt id="AiDotNet_Enums_NormalizationMethod_Binning"><code>Binning = 5</code></dt>
  <dd><p>Groups continuous data into discrete bins or categories.</p>
<p>
<b>For Beginners:</b> Binning is like grouping people by age ranges (0-10, 11-20, 21-30, etc.) instead of 
using their exact ages. It converts continuous numbers into categorical groups. This can help reduce 
noise in the data and reveal patterns that might be hidden when looking at exact values.
</p>
</dd>
  
    <dt id="AiDotNet_Enums_NormalizationMethod_Decimal"><code>Decimal = 3</code></dt>
  <dd><p>Scales values by dividing by powers of 10 to bring all values between 0 and 1.</p>
<p>
<b>For Beginners:</b> Decimal scaling moves the decimal point in your numbers until all values are between 
-1 and 1. For example, if your largest number is 1,000, you'd divide everything by 1,000, so that 
number becomes 1.0. This is useful when your data has different numbers of digits but is otherwise similar.
Formula: x / 10^j where j is the smallest integer such that max(|x|) &lt; 1
</p>
</dd>
  
    <dt id="AiDotNet_Enums_NormalizationMethod_GlobalContrast"><code>GlobalContrast = 6</code></dt>
  <dd><p>Normalizes data by adjusting contrast across the entire dataset.</p>
<p>
<b>For Beginners:</b> Global Contrast Normalization is like adjusting the contrast on a photo to make 
features more visible. It's especially useful for image data, where it helps highlight important 
patterns while reducing the impact of variations in lighting or brightness.
</p>
</dd>
  
    <dt id="AiDotNet_Enums_NormalizationMethod_Log"><code>Log = 4</code></dt>
  <dd><p>Applies a logarithmic transformation to compress the range of values.</p>
<p>
<b>For Beginners:</b> Log transformation is useful when your data has a few very large values that would 
otherwise dominate. It compresses high values while spreading out smaller values. For example, the 
difference between 1 and 10 becomes the same as the difference between 10 and 100. This is often 
used for data that grows exponentially, like population counts or prices.
Formula: log(x) (Note: typically requires handling zero or negative values specially)
</p>
</dd>
  
    <dt id="AiDotNet_Enums_NormalizationMethod_LogMeanVariance"><code>LogMeanVariance = 7</code></dt>
  <dd><p>Applies logarithmic transformation followed by mean-variance normalization.</p>
<p>
<b>For Beginners:</b> This is a two-step process: first, a log transformation compresses very large values 
(like turning 1,000,000 into 6), then the result is standardized around a mean of 0. This is useful 
for data with both exponential growth patterns and the need for standardization, such as financial 
or scientific measurements that vary by orders of magnitude.
</p>
</dd>
  
    <dt id="AiDotNet_Enums_NormalizationMethod_LpNorm"><code>LpNorm = 8</code></dt>
  <dd><p>Normalizes data using the Lp norm (typically L1 or L2 norm).</p>
<p>
<b>For Beginners:</b> Lp Norm scaling is like making sure the total "energy" of your data equals 1. 
The most common version (L2 norm) is similar to making sure the length of a vector equals 1. 
This is useful in text analysis and when working with high-dimensional data, as it helps compare 
documents or data points of different lengths fairly.
Formula for L2 norm: x / sqrt(sum(x^2))
</p>
</dd>
  
    <dt id="AiDotNet_Enums_NormalizationMethod_MaxAbsScaler"><code>MaxAbsScaler = 11</code></dt>
  <dd><p>Scales features to the range [-1, 1] by dividing by the maximum absolute value.</p>
<p>
<b>For Beginners:</b> MaxAbsScaler is like MinMax scaling, but instead of using both the minimum and
maximum values, it only uses the maximum absolute value (the largest value ignoring signs). This
method preserves zeros and the sign of values, which is important for sparse data where many values
are zero. For example, if your largest value is 100 and smallest is -50, everything gets divided by 100,
so results fall between -1 and 1.
Formula: x / max(|x|)
</p>
</dd>
  
    <dt id="AiDotNet_Enums_NormalizationMethod_MeanVariance"><code>MeanVariance = 9</code></dt>
  <dd><p>Standardizes data to have a specified mean and variance (typically mean=0, variance=1).</p>
<p>
<b>For Beginners:</b> Mean-Variance normalization is similar to Z-Score but gives you more control. 
It adjusts your data to have a specific average (usually 0) and spread (usually 1). This makes 
different features comparable and helps many machine learning algorithms perform better.
Formula: (x - mean) / standard_deviation
</p>
</dd>
  
    <dt id="AiDotNet_Enums_NormalizationMethod_MinMax"><code>MinMax = 1</code></dt>
  <dd><p>Scales all values to a range between 0 and 1.</p>
<p>
<b>For Beginners:</b> MinMax scaling takes your data and squeezes it to fit between 0 and 1. 
The smallest value becomes 0, the largest becomes 1, and everything else falls in between. 
It's like converting heights of people in a classroom to percentages of the tallest person.
Formula: (x - min) / (max - min)
</p>
</dd>
  
    <dt id="AiDotNet_Enums_NormalizationMethod_None"><code>None = 0</code></dt>
  <dd><p>No normalization is applied to the data.</p>
<p>
<b>For Beginners:</b> This option means "don't change my data at all." Use this when your data 
is already on a similar scale or when you specifically want to preserve the original values.
</p>
</dd>
  
    <dt id="AiDotNet_Enums_NormalizationMethod_QuantileTransformer"><code>QuantileTransformer = 12</code></dt>
  <dd><p>Transforms features to follow a uniform or normal distribution using quantiles.</p>
<p>
<b>For Beginners:</b> QuantileTransformer is a powerful technique that changes your data's distribution
to be either uniform (flat, where all ranges have equal numbers of values) or normal (bell-shaped).
It works by ranking values and mapping them to a target distribution. This is extremely effective at
handling outliers because it spreads them out across the distribution. Think of it as redistributing
your data so that it matches a desired pattern, regardless of the original distribution.
</p>
</dd>
  
    <dt id="AiDotNet_Enums_NormalizationMethod_RobustScaling"><code>RobustScaling = 10</code></dt>
  <dd><p>Scales features using statistics that are robust to outliers.</p>
<p>
<b>For Beginners:</b> Robust Scaling is designed to handle data with outliers (extreme values that don't
follow the pattern). Instead of using the minimum and maximum values (which can be skewed by outliers),
it uses the median and quartiles. It's like saying "ignore the extremely tall and short people when
standardizing heights." This is useful when your data contains unusual values that shouldn't influence
the overall scaling.
Formula: (x - median) / (Q3 - Q1) where Q1 is the 25th percentile and Q3 is the 75th percentile
</p>
</dd>
  
    <dt id="AiDotNet_Enums_NormalizationMethod_ZScore"><code>ZScore = 2</code></dt>
  <dd><p>Standardizes values to have a mean of 0 and a standard deviation of 1.</p>
<p>
<b>For Beginners:</b> Z-Score (also called standardization) centers your data around 0, with most values 
falling between -3 and +3. It tells you how many "standard deviations" away from average each value is. 
For example, a Z-Score of 2 means "this value is 2 standard deviations above average." This method 
works well when your data follows a bell curve pattern.
Formula: (x - mean) / standard_deviation
</p>
</dd>
  
  </dl>


  <h2 id="AiDotNet_Enums_NormalizationMethod_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
<b>For Beginners:</b> Normalization is like converting different measurements to a common scale. 
Imagine you have data about people's heights (in feet) and weights (in pounds) - these numbers 
are on very different scales. Normalization transforms all your data to similar ranges (like 0-1) 
so that one feature doesn't overwhelm others just because it uses bigger numbers. This helps 
machine learning algorithms work better and faster.
</p>
</div>

</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/Enums/NormalizationMethod.cs/#L15" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
