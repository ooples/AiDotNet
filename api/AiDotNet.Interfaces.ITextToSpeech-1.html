<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Interface ITextToSpeech&lt;T&gt; | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Interface ITextToSpeech&lt;T&gt; | AiDotNet Documentation ">
      
      <meta name="description" content="Interface for text-to-speech (TTS) models that synthesize spoken audio from text.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_Interfaces_ITextToSpeech_1.md&amp;value=---%0Auid%3A%20AiDotNet.Interfaces.ITextToSpeech%601%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.Interfaces.ITextToSpeech`1">



  <h1 id="AiDotNet_Interfaces_ITextToSpeech_1" data-uid="AiDotNet.Interfaces.ITextToSpeech`1" class="text-break">
Interface ITextToSpeech&lt;T&gt;  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/ITextToSpeech.cs/#L36"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.Interfaces.html">Interfaces</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Interface for text-to-speech (TTS) models that synthesize spoken audio from text.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public interface ITextToSpeech&lt;T&gt; : IFullModel&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;, IModel&lt;Tensor&lt;T&gt;, Tensor&lt;T&gt;, ModelMetadata&lt;T&gt;&gt;, IModelSerializer, ICheckpointableModel, IParameterizable&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;, IFeatureAware, IFeatureImportance&lt;T&gt;, ICloneable&lt;IFullModel&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;&gt;, IGradientComputable&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;, IJitCompilable&lt;T&gt;</code></pre>
  </div>



  <h4 class="section">Type Parameters</h4>
  <dl class="parameters">
    <dt><code>T</code></dt>
    <dd><p>The numeric type used for calculations.</p>
</dd>
  </dl>




  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IFullModel-3.html#AiDotNet_Interfaces_IFullModel_3_DefaultLossFunction">IFullModel&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;.DefaultLossFunction</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IModel-3.html#AiDotNet_Interfaces_IModel_3_Train__0__1_">IModel&lt;Tensor&lt;T&gt;, Tensor&lt;T&gt;, ModelMetadata&lt;T&gt;&gt;.Train(Tensor&lt;T&gt;, Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IModel-3.html#AiDotNet_Interfaces_IModel_3_Predict__0_">IModel&lt;Tensor&lt;T&gt;, Tensor&lt;T&gt;, ModelMetadata&lt;T&gt;&gt;.Predict(Tensor&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IModel-3.html#AiDotNet_Interfaces_IModel_3_GetModelMetadata">IModel&lt;Tensor&lt;T&gt;, Tensor&lt;T&gt;, ModelMetadata&lt;T&gt;&gt;.GetModelMetadata()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IModelSerializer.html#AiDotNet_Interfaces_IModelSerializer_Serialize">IModelSerializer.Serialize()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IModelSerializer.html#AiDotNet_Interfaces_IModelSerializer_Deserialize_System_Byte___">IModelSerializer.Deserialize(byte[])</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IModelSerializer.html#AiDotNet_Interfaces_IModelSerializer_SaveModel_System_String_">IModelSerializer.SaveModel(string)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IModelSerializer.html#AiDotNet_Interfaces_IModelSerializer_LoadModel_System_String_">IModelSerializer.LoadModel(string)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.ICheckpointableModel.html#AiDotNet_Interfaces_ICheckpointableModel_SaveState_System_IO_Stream_">ICheckpointableModel.SaveState(Stream)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.ICheckpointableModel.html#AiDotNet_Interfaces_ICheckpointableModel_LoadState_System_IO_Stream_">ICheckpointableModel.LoadState(Stream)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IParameterizable-3.html#AiDotNet_Interfaces_IParameterizable_3_GetParameters">IParameterizable&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;.GetParameters()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IParameterizable-3.html#AiDotNet_Interfaces_IParameterizable_3_SetParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__">IParameterizable&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;.SetParameters(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IParameterizable-3.html#AiDotNet_Interfaces_IParameterizable_3_ParameterCount">IParameterizable&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;.ParameterCount</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IParameterizable-3.html#AiDotNet_Interfaces_IParameterizable_3_WithParameters_AiDotNet_Tensors_LinearAlgebra_Vector__0__">IParameterizable&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;.WithParameters(Vector&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IFeatureAware.html#AiDotNet_Interfaces_IFeatureAware_GetActiveFeatureIndices">IFeatureAware.GetActiveFeatureIndices()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IFeatureAware.html#AiDotNet_Interfaces_IFeatureAware_SetActiveFeatureIndices_System_Collections_Generic_IEnumerable_System_Int32__">IFeatureAware.SetActiveFeatureIndices(IEnumerable&lt;int&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IFeatureAware.html#AiDotNet_Interfaces_IFeatureAware_IsFeatureUsed_System_Int32_">IFeatureAware.IsFeatureUsed(int)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IFeatureImportance-1.html#AiDotNet_Interfaces_IFeatureImportance_1_GetFeatureImportance">IFeatureImportance&lt;T&gt;.GetFeatureImportance()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.ICloneable-1.html#AiDotNet_Interfaces_ICloneable_1_DeepCopy">ICloneable&lt;IFullModel&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;&gt;.DeepCopy()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.ICloneable-1.html#AiDotNet_Interfaces_ICloneable_1_Clone">ICloneable&lt;IFullModel&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;&gt;.Clone()</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IGradientComputable-3.html#AiDotNet_Interfaces_IGradientComputable_3_ComputeGradients__1__2_AiDotNet_Interfaces_ILossFunction__0__">IGradientComputable&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;.ComputeGradients(Tensor&lt;T&gt;, Tensor&lt;T&gt;, ILossFunction&lt;T&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IGradientComputable-3.html#AiDotNet_Interfaces_IGradientComputable_3_ApplyGradients_AiDotNet_Tensors_LinearAlgebra_Vector__0___0_">IGradientComputable&lt;T, Tensor&lt;T&gt;, Tensor&lt;T&gt;&gt;.ApplyGradients(Vector&lt;T&gt;, T)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IJitCompilable-1.html#AiDotNet_Interfaces_IJitCompilable_1_ExportComputationGraph_System_Collections_Generic_List_AiDotNet_Autodiff_ComputationNode__0___">IJitCompilable&lt;T&gt;.ExportComputationGraph(List&lt;ComputationNode&lt;T&gt;&gt;)</a>
    </div>
    <div>
      <a class="xref" href="AiDotNet.Interfaces.IJitCompilable-1.html#AiDotNet_Interfaces_IJitCompilable_1_SupportsJitCompilation">IJitCompilable&lt;T&gt;.SupportsJitCompilation</a>
    </div>
  </dd></dl>

  <dl class="typelist extensionMethods">
    <dt>Extension Methods</dt>
    <dd>
  <div>
      <a class="xref" href="AiDotNet.DistributedTraining.DistributedExtensions.html#AiDotNet_DistributedTraining_DistributedExtensions_AsDistributedForHighBandwidth__3_AiDotNet_Interfaces_IFullModel___0___1___2__AiDotNet_DistributedTraining_ICommunicationBackend___0__">DistributedExtensions.AsDistributedForHighBandwidth&lt;T, TInput, TOutput&gt;(IFullModel&lt;T, TInput, TOutput&gt;, ICommunicationBackend&lt;T&gt;)</a>
  </div>
  <div>
      <a class="xref" href="AiDotNet.DistributedTraining.DistributedExtensions.html#AiDotNet_DistributedTraining_DistributedExtensions_AsDistributedForLowBandwidth__3_AiDotNet_Interfaces_IFullModel___0___1___2__AiDotNet_DistributedTraining_ICommunicationBackend___0__">DistributedExtensions.AsDistributedForLowBandwidth&lt;T, TInput, TOutput&gt;(IFullModel&lt;T, TInput, TOutput&gt;, ICommunicationBackend&lt;T&gt;)</a>
  </div>
  <div>
      <a class="xref" href="AiDotNet.DistributedTraining.DistributedExtensions.html#AiDotNet_DistributedTraining_DistributedExtensions_AsDistributed__3_AiDotNet_Interfaces_IFullModel___0___1___2__AiDotNet_DistributedTraining_ICommunicationBackend___0__">DistributedExtensions.AsDistributed&lt;T, TInput, TOutput&gt;(IFullModel&lt;T, TInput, TOutput&gt;, ICommunicationBackend&lt;T&gt;)</a>
  </div>
  <div>
      <a class="xref" href="AiDotNet.DistributedTraining.DistributedExtensions.html#AiDotNet_DistributedTraining_DistributedExtensions_AsDistributed__3_AiDotNet_Interfaces_IFullModel___0___1___2__AiDotNet_DistributedTraining_IShardingConfiguration___0__">DistributedExtensions.AsDistributed&lt;T, TInput, TOutput&gt;(IFullModel&lt;T, TInput, TOutput&gt;, IShardingConfiguration&lt;T&gt;)</a>
  </div>
  </dd></dl>



  <h2 id="AiDotNet_Interfaces_ITextToSpeech_1_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
Text-to-speech models convert written text into natural-sounding spoken audio.
Modern TTS systems use neural networks to produce high-quality, expressive speech
that can sound nearly indistinguishable from human speakers.
</p>
<p>
<b>For Beginners:</b> TTS is like having a computer read text out loud to you.
<p>How TTS works:</p>
<ol>
<li>Text is analyzed for pronunciation, emphasis, and pacing</li>
<li>The model generates audio features (mel-spectrograms)</li>
<li>A vocoder converts features to waveform audio</li>
</ol>
<p>Common use cases:</p>
<ul>
<li>Accessibility (screen readers for visually impaired)</li>
<li>Voice assistants and chatbots</li>
<li>Audiobook and podcast generation</li>
<li>Language learning applications</li>
</ul>
<p>Key features:</p>
<ul>
<li>Voice cloning: Make it sound like a specific person</li>
<li>Emotion control: Express happiness, sadness, excitement</li>
<li>Speed control: Speak faster or slower</li>
</ul>

<p>
This interface extends <a class="xref" href="AiDotNet.Interfaces.IFullModel-3.html">IFullModel&lt;T, TInput, TOutput&gt;</a> for Tensor-based audio processing.
</p>
</div>


  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_Interfaces_ITextToSpeech_1_AvailableVoices_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.AvailableVoices*"></a>

  <h3 id="AiDotNet_Interfaces_ITextToSpeech_1_AvailableVoices" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.AvailableVoices">
  AvailableVoices
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/ITextToSpeech.cs/#L56"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the list of available built-in voices.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">IReadOnlyList&lt;VoiceInfo&lt;T&gt;&gt; AvailableVoices { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.ireadonlylist-1">IReadOnlyList</a>&lt;<a class="xref" href="AiDotNet.Interfaces.VoiceInfo-1.html">VoiceInfo</a>&lt;T&gt;&gt;</dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Interfaces_ITextToSpeech_1_AvailableVoices_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Each voice has unique characteristics (gender, age, accent, style).
</p>
</div>




  <a id="AiDotNet_Interfaces_ITextToSpeech_1_IsOnnxMode_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.IsOnnxMode*"></a>

  <h3 id="AiDotNet_Interfaces_ITextToSpeech_1_IsOnnxMode" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.IsOnnxMode">
  IsOnnxMode
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/ITextToSpeech.cs/#L88"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this model is running in ONNX inference mode.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">bool IsOnnxMode { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Interfaces_ITextToSpeech_1_IsOnnxMode_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
When true, the model uses pre-trained ONNX weights for inference.
When false, the model can be trained from scratch using the neural network infrastructure.
</p>
</div>




  <a id="AiDotNet_Interfaces_ITextToSpeech_1_SampleRate_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.SampleRate*"></a>

  <h3 id="AiDotNet_Interfaces_ITextToSpeech_1_SampleRate" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.SampleRate">
  SampleRate
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/ITextToSpeech.cs/#L46"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets the sample rate of generated audio.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">int SampleRate { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Interfaces_ITextToSpeech_1_SampleRate_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Common values: 22050 Hz (standard), 44100 Hz (high quality), 16000 Hz (telephony).
</p>
</div>




  <a id="AiDotNet_Interfaces_ITextToSpeech_1_SupportsEmotionControl_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.SupportsEmotionControl*"></a>

  <h3 id="AiDotNet_Interfaces_ITextToSpeech_1_SupportsEmotionControl" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.SupportsEmotionControl">
  SupportsEmotionControl
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/ITextToSpeech.cs/#L72"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this model supports emotional expression control.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">bool SupportsEmotionControl { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>








  <a id="AiDotNet_Interfaces_ITextToSpeech_1_SupportsStreaming_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.SupportsStreaming*"></a>

  <h3 id="AiDotNet_Interfaces_ITextToSpeech_1_SupportsStreaming" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.SupportsStreaming">
  SupportsStreaming
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/ITextToSpeech.cs/#L77"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this model supports streaming audio generation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">bool SupportsStreaming { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>








  <a id="AiDotNet_Interfaces_ITextToSpeech_1_SupportsVoiceCloning_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.SupportsVoiceCloning*"></a>

  <h3 id="AiDotNet_Interfaces_ITextToSpeech_1_SupportsVoiceCloning" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.SupportsVoiceCloning">
  SupportsVoiceCloning
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/ITextToSpeech.cs/#L67"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets whether this model supports voice cloning from reference audio.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">bool SupportsVoiceCloning { get; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></dt>
    <dd></dd>
  </dl>




  <h4 class="section" id="AiDotNet_Interfaces_ITextToSpeech_1_SupportsVoiceCloning_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
<b>For Beginners:</b> Voice cloning lets you make the TTS sound like
a specific person by providing a sample of their voice.
</p>
</div>




  <h2 class="section" id="methods">Methods
</h2>


  <a id="AiDotNet_Interfaces_ITextToSpeech_1_ExtractSpeakerEmbedding_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.ExtractSpeakerEmbedding*"></a>

  <h3 id="AiDotNet_Interfaces_ITextToSpeech_1_ExtractSpeakerEmbedding_AiDotNet_Tensors_LinearAlgebra_Tensor__0__" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.ExtractSpeakerEmbedding(AiDotNet.Tensors.LinearAlgebra.Tensor{`0})">
  ExtractSpeakerEmbedding(Tensor&lt;T&gt;)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/ITextToSpeech.cs/#L171"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Extracts speaker embedding from reference audio for voice cloning.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Tensor&lt;T&gt; ExtractSpeakerEmbedding(Tensor&lt;T&gt; referenceAudio)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>referenceAudio</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Reference audio sample.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Speaker embedding tensor that captures voice characteristics.</p>
</dd>
  </dl>











  <a id="AiDotNet_Interfaces_ITextToSpeech_1_StartStreamingSession_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.StartStreamingSession*"></a>

  <h3 id="AiDotNet_Interfaces_ITextToSpeech_1_StartStreamingSession_System_String_System_Double_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.StartStreamingSession(System.String,System.Double)">
  StartStreamingSession(string?, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/ITextToSpeech.cs/#L180"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Starts a streaming synthesis session for incremental audio generation.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">IStreamingSynthesisSession&lt;T&gt; StartStreamingSession(string? voiceId = null, double speakingRate = 1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>voiceId</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>Optional voice identifier.</p>
</dd>
    <dt><code>speakingRate</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Speed multiplier.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Interfaces.IStreamingSynthesisSession-1.html">IStreamingSynthesisSession</a>&lt;T&gt;</dt>
    <dd><p>A streaming session that can receive text incrementally.</p>
</dd>
  </dl>








  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.notsupportedexception">NotSupportedException</a></dt>
    <dd><p>Thrown if streaming is not supported.</p>
</dd>
  </dl>



  <a id="AiDotNet_Interfaces_ITextToSpeech_1_Synthesize_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.Synthesize*"></a>

  <h3 id="AiDotNet_Interfaces_ITextToSpeech_1_Synthesize_System_String_System_String_System_Double_System_Double_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.Synthesize(System.String,System.String,System.Double,System.Double)">
  Synthesize(string, string?, double, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/ITextToSpeech.cs/#L105"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Synthesizes speech from text.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Tensor&lt;T&gt; Synthesize(string text, string? voiceId = null, double speakingRate = 1, double pitch = 0)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>text</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The text to speak.</p>
</dd>
    <dt><code>voiceId</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>Optional voice identifier. Uses default if null.</p>
</dd>
    <dt><code>speakingRate</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Speed multiplier (0.5 = half speed, 2.0 = double speed).</p>
</dd>
    <dt><code>pitch</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Pitch adjustment in semitones (-12 to +12).</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Audio waveform tensor [samples] or [channels, samples].</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Interfaces_ITextToSpeech_1_Synthesize_System_String_System_String_System_Double_System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
<b>For Beginners:</b> This is the main method for converting text to speech.
- Pass in text like "Hello, how are you?"
- Get back audio you can play through speakers
</p>
</div>




  <a id="AiDotNet_Interfaces_ITextToSpeech_1_SynthesizeAsync_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.SynthesizeAsync*"></a>

  <h3 id="AiDotNet_Interfaces_ITextToSpeech_1_SynthesizeAsync_System_String_System_String_System_Double_System_Double_System_Threading_CancellationToken_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.SynthesizeAsync(System.String,System.String,System.Double,System.Double,System.Threading.CancellationToken)">
  SynthesizeAsync(string, string?, double, double, CancellationToken)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/ITextToSpeech.cs/#L120"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Synthesizes speech from text asynchronously.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Task&lt;Tensor&lt;T&gt;&gt; SynthesizeAsync(string text, string? voiceId = null, double speakingRate = 1, double pitch = 0, CancellationToken cancellationToken = default)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>text</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The text to speak.</p>
</dd>
    <dt><code>voiceId</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>Optional voice identifier. Uses default if null.</p>
</dd>
    <dt><code>speakingRate</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Speed multiplier (0.5 = half speed, 2.0 = double speed).</p>
</dd>
    <dt><code>pitch</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Pitch adjustment in semitones (-12 to +12).</p>
</dd>
    <dt><code>cancellationToken</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.threading.cancellationtoken">CancellationToken</a></dt>
    <dd><p>Cancellation token for async operation.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.threading.tasks.task-1">Task</a>&lt;<a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;&gt;</dt>
    <dd><p>Audio waveform tensor [samples] or [channels, samples].</p>
</dd>
  </dl>











  <a id="AiDotNet_Interfaces_ITextToSpeech_1_SynthesizeWithEmotion_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.SynthesizeWithEmotion*"></a>

  <h3 id="AiDotNet_Interfaces_ITextToSpeech_1_SynthesizeWithEmotion_System_String_System_String_System_Double_System_String_System_Double_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.SynthesizeWithEmotion(System.String,System.String,System.Double,System.String,System.Double)">
  SynthesizeWithEmotion(string, string, double, string?, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/ITextToSpeech.cs/#L159"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Synthesizes speech with emotional expression.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Tensor&lt;T&gt; SynthesizeWithEmotion(string text, string emotion, double emotionIntensity = 0.5, string? voiceId = null, double speakingRate = 1)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>text</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The text to speak.</p>
</dd>
    <dt><code>emotion</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The emotion to express (e.g., &quot;happy&quot;, &quot;sad&quot;, &quot;angry&quot;).</p>
</dd>
    <dt><code>emotionIntensity</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Intensity of the emotion (0.0 to 1.0).</p>
</dd>
    <dt><code>voiceId</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>Optional voice identifier.</p>
</dd>
    <dt><code>speakingRate</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Speed multiplier.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Audio waveform tensor with emotional expression.</p>
</dd>
  </dl>








  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.notsupportedexception">NotSupportedException</a></dt>
    <dd><p>Thrown if emotion control is not supported.</p>
</dd>
  </dl>



  <a id="AiDotNet_Interfaces_ITextToSpeech_1_SynthesizeWithVoiceCloning_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.SynthesizeWithVoiceCloning*"></a>

  <h3 id="AiDotNet_Interfaces_ITextToSpeech_1_SynthesizeWithVoiceCloning_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0__System_Double_System_Double_" data-uid="AiDotNet.Interfaces.ITextToSpeech`1.SynthesizeWithVoiceCloning(System.String,AiDotNet.Tensors.LinearAlgebra.Tensor{`0},System.Double,System.Double)">
  SynthesizeWithVoiceCloning(string, Tensor&lt;T&gt;, double, double)
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/ITextToSpeech.cs/#L143"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Synthesizes speech using a cloned voice from reference audio.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">Tensor&lt;T&gt; SynthesizeWithVoiceCloning(string text, Tensor&lt;T&gt; referenceAudio, double speakingRate = 1, double pitch = 0)</code></pre>
  </div>

  <h4 class="section">Parameters</h4>
  <dl class="parameters">
    <dt><code>text</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></dt>
    <dd><p>The text to speak.</p>
</dd>
    <dt><code>referenceAudio</code> <a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Reference audio sample of the voice to clone.</p>
</dd>
    <dt><code>speakingRate</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Speed multiplier.</p>
</dd>
    <dt><code>pitch</code> <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>Pitch adjustment in semitones.</p>
</dd>
  </dl>

  <h4 class="section">Returns</h4>
  <dl class="parameters">
    <dt><a class="xref" href="AiDotNet.Tensors.LinearAlgebra.Tensor-1.html">Tensor</a>&lt;T&gt;</dt>
    <dd><p>Audio waveform tensor matching the reference voice.</p>
</dd>
  </dl>







  <h4 class="section" id="AiDotNet_Interfaces_ITextToSpeech_1_SynthesizeWithVoiceCloning_System_String_AiDotNet_Tensors_LinearAlgebra_Tensor__0__System_Double_System_Double__remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
<b>For Beginners:</b> This creates speech that sounds like the person
in the reference audio. The model learns the voice characteristics
from the sample and applies them to new text.
</p>
</div>

  <h4 class="section">Exceptions</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.notsupportedexception">NotSupportedException</a></dt>
    <dd><p>Thrown if voice cloning is not supported.</p>
</dd>
  </dl>




</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/Interfaces/ITextToSpeech.cs/#L36" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
