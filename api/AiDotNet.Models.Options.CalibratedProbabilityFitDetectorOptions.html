<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Class CalibratedProbabilityFitDetectorOptions | AiDotNet Documentation </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Class CalibratedProbabilityFitDetectorOptions | AiDotNet Documentation ">
      
      <meta name="description" content="Configuration options for the Calibrated Probability Fit Detector, which evaluates how well a model&#39;s predicted probabilities match actual outcomes.">
      <link rel="icon" href="../favicon.ico">
      <link rel="stylesheet" href="../public/docfx.min.css">
      <link rel="stylesheet" href="../public/main.css">
      <meta name="docfx:navrel" content="../toc.html">
      <meta name="docfx:tocrel" content="toc.html">
      
      <meta name="docfx:rel" content="../">
      
      
      <meta name="docfx:docurl" content="https://github.com/ooples/AiDotNet/new/master/apiSpec/new?filename=AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions.md&amp;value=---%0Auid%3A%20AiDotNet.Models.Options.CalibratedProbabilityFitDetectorOptions%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="ManagedReference">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../index.html">
            <img id="logo" class="svg" src="../logo.svg" alt="AiDotNet">
            AiDotNet
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="AiDotNet.Models.Options.CalibratedProbabilityFitDetectorOptions">



  <h1 id="AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions" data-uid="AiDotNet.Models.Options.CalibratedProbabilityFitDetectorOptions" class="text-break">
Class CalibratedProbabilityFitDetectorOptions  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/CalibratedProbabilityFitDetectorOptions.cs/#L19"><i class="bi bi-code-slash"></i></a>
  </h1>

  <div class="facts text-secondary">
    <dl><dt>Namespace</dt><dd><a class="xref" href="AiDotNet.html">AiDotNet</a>.<a class="xref" href="AiDotNet.Models.html">Models</a>.<a class="xref" href="AiDotNet.Models.Options.html">Options</a></dd></dl>
  <dl><dt>Assembly</dt><dd>AiDotNet.dll</dd></dl>
  </div>

  <div class="markdown summary"><p>Configuration options for the Calibrated Probability Fit Detector, which evaluates how well a model's
predicted probabilities match actual outcomes.</p>
</div>
  <div class="markdown conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class CalibratedProbabilityFitDetectorOptions</code></pre>
  </div>




  <dl class="typelist inheritance">
    <dt>Inheritance</dt>
    <dd>
      <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
      <div><span class="xref">CalibratedProbabilityFitDetectorOptions</span></div>
    </dd>
  </dl>



  <dl class="typelist inheritedMembers">
    <dt>Inherited Members</dt>
    <dd>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </dd></dl>




  <h2 id="AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions_remarks">Remarks</h2>
  <div class="markdown level0 remarks"><p>
Probability calibration measures whether a model's confidence (predicted probability) aligns with its actual accuracy.
For example, when a well-calibrated model predicts events with 80% confidence, those events should occur about 80% of the time.
This detector helps identify models that are overconfident or underconfident in their predictions.
</p>
<p><b>For Beginners:</b> This class contains settings for a tool that checks if your AI model's confidence levels 
are trustworthy. Imagine a weather forecaster who predicts a 70% chance of rain - if it actually rains on 70% of the 
days when they make this prediction, they're well-calibrated. Similarly, we want AI models that say "I'm 90% sure" 
to be right about 90% of the time. This detector helps identify if your model is overconfident (saying it's very sure 
when it shouldn't be) or underconfident (not expressing enough confidence when it should).</p>
</div>


  <h2 class="section" id="properties">Properties
</h2>


  <a id="AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions_GoodFitThreshold_" data-uid="AiDotNet.Models.Options.CalibratedProbabilityFitDetectorOptions.GoodFitThreshold*"></a>

  <h3 id="AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions_GoodFitThreshold" data-uid="AiDotNet.Models.Options.CalibratedProbabilityFitDetectorOptions.GoodFitThreshold">
  GoodFitThreshold
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/CalibratedProbabilityFitDetectorOptions.cs/#L53"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the maximum calibration error threshold for a model to be considered well-calibrated.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double GoodFitThreshold { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The good fit threshold as a decimal between 0 and 1, defaulting to 0.05 (5%).</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions_GoodFitThreshold_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This threshold represents the maximum acceptable average difference between predicted probabilities and 
actual outcomes for a model to be considered well-calibrated. Lower values indicate stricter requirements.
</p>
<p><b>For Beginners:</b> This setting determines how close your model's confidence needs to match reality 
for us to consider it "well-calibrated." The default value (0.05) means that, on average, your model's predicted 
probabilities should be within 5 percentage points of the actual outcomes. For example, when your model predicts 
a 75% chance, the actual frequency should be between 70% and 80% for good calibration. A lower threshold means 
we're demanding more precision from your model.</p>
</div>




  <a id="AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions_MaxCalibrationError_" data-uid="AiDotNet.Models.Options.CalibratedProbabilityFitDetectorOptions.MaxCalibrationError*"></a>

  <h3 id="AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions_MaxCalibrationError" data-uid="AiDotNet.Models.Options.CalibratedProbabilityFitDetectorOptions.MaxCalibrationError">
  MaxCalibrationError
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/CalibratedProbabilityFitDetectorOptions.cs/#L87"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the maximum allowed calibration error before the detector reports a critical issue.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double MaxCalibrationError { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The maximum calibration error as a decimal between 0 and 1, defaulting to 1.0 (100%).</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions_MaxCalibrationError_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
This value represents an upper bound on acceptable calibration error. If the calibration error exceeds this value,
it indicates a fundamental problem with the model's probability estimates that requires immediate attention.
</p>
<p><b>For Beginners:</b> This is a safety limit that flags severely miscalibrated models. The default value (1.0) 
is the maximum possible error - it would mean your model is completely wrong about its probabilities (like consistently 
predicting 100% chance when the actual frequency is 0%). In practice, you might want to set this lower, perhaps to 0.5, 
to catch serious calibration problems earlier. Think of it as a "red alert" threshold that tells you when your model's 
confidence levels are fundamentally unreliable.</p>
</div>




  <a id="AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions_NumCalibrationBins_" data-uid="AiDotNet.Models.Options.CalibratedProbabilityFitDetectorOptions.NumCalibrationBins*"></a>

  <h3 id="AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions_NumCalibrationBins" data-uid="AiDotNet.Models.Options.CalibratedProbabilityFitDetectorOptions.NumCalibrationBins">
  NumCalibrationBins
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/CalibratedProbabilityFitDetectorOptions.cs/#L36"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the number of bins used to group predictions for calibration assessment.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int NumCalibrationBins { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></dt>
    <dd><p>The number of calibration bins, defaulting to 10.</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions_NumCalibrationBins_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
Predictions are grouped into bins (e.g., 0-0.1, 0.1-0.2, etc.) to compare predicted probabilities 
with actual outcomes. More bins provide finer granularity but require more data for reliable estimates.
</p>
<p><b>For Beginners:</b> To check calibration, we group predictions into "bins" based on their confidence levels. 
The default setting (10) means we'll create 10 equal-sized groups: predictions with 0-10% confidence, 10-20% confidence, 
and so on. For each group, we check if the actual success rate matches the predicted confidence. More bins give you 
more detailed analysis but require more data to be reliable - like how a poll of 1,000 people gives more reliable 
results than a poll of 100 people.</p>
</div>




  <a id="AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions_OverfitThreshold_" data-uid="AiDotNet.Models.Options.CalibratedProbabilityFitDetectorOptions.OverfitThreshold*"></a>

  <h3 id="AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions_OverfitThreshold" data-uid="AiDotNet.Models.Options.CalibratedProbabilityFitDetectorOptions.OverfitThreshold">
  OverfitThreshold
  <a class="header-action link-secondary" title="View source" href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/CalibratedProbabilityFitDetectorOptions.cs/#L70"><i class="bi bi-code-slash"></i></a>
  </h3>

  <div class="markdown level1 summary"><p>Gets or sets the calibration error threshold above which a model is considered poorly calibrated.</p>
</div>
  <div class="markdown level1 conceptual"></div>

  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public double OverfitThreshold { get; set; }</code></pre>
  </div>





  <h4 class="section">Property Value</h4>
  <dl class="parameters">
    <dt><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.double">double</a></dt>
    <dd><p>The overfit threshold as a decimal between 0 and 1, defaulting to 0.15 (15%).</p>
</dd>
  </dl>




  <h4 class="section" id="AiDotNet_Models_Options_CalibratedProbabilityFitDetectorOptions_OverfitThreshold_remarks">Remarks</h4>
  <div class="markdown level1 remarks"><p>
If the average difference between predicted probabilities and actual outcomes exceeds this threshold,
the model is considered to have significant calibration issues that should be addressed.
</p>
<p><b>For Beginners:</b> While the GoodFitThreshold tells us when calibration is good, this setting tells 
us when calibration is definitely problematic. The default value (0.15) means that if your model's predicted 
probabilities differ from actual outcomes by more than 15 percentage points on average, we'll flag it as having 
poor calibration. For instance, if your model consistently predicts a 60% chance but the actual frequency is 80% 
or 40%, that's a sign that your model's confidence levels need adjustment.</p>
</div>





</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/ooples/AiDotNet/blob/master/src/Models/Options/CalibratedProbabilityFitDetectorOptions.cs/#L19" class="edit-link">Edit this page</a>
        </div>


      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          AiDotNet - Enterprise AI/ML Library for .NET
        </div>
      </div>
    </footer>
  </body>
</html>
