using AiDotNet.Extensions;
using AiDotNet.Models.Options;

namespace AiDotNet.CausalDiscovery.Functional;

/// <summary>
/// ICA-LiNGAM — Linear Non-Gaussian Acyclic Model using Independent Component Analysis.
/// </summary>
/// <remarks>
/// <para>
/// ICA-LiNGAM exploits the identifiability of the linear model X = BX + e when the noise e
/// is non-Gaussian. Using ICA (Independent Component Analysis), it recovers the mixing matrix
/// and derives the causal ordering and edge weights.
/// </para>
/// <para>
/// <b>Key insight:</b> In a linear Gaussian model, the causal direction is not identifiable
/// from observational data alone. But with non-Gaussian noise, the ICA decomposition uniquely
/// determines the causal structure — this is the LiNGAM identifiability result.
/// </para>
/// <para>
/// <b>Algorithm:</b>
/// <list type="number">
/// <item>Standardize data to zero mean, unit variance</item>
/// <item>Apply ICA (FastICA) to recover independent components S and mixing matrix A</item>
/// <item>Recover B = I - inv(A) (causal adjacency matrix)</item>
/// <item>Find a permutation that makes B lower-triangular (causal order)</item>
/// <item>Prune small coefficients</item>
/// </list>
/// </para>
/// <para>
/// <b>For Beginners:</b> If you have data generated by a linear causal model with noise
/// that isn't perfectly bell-shaped (non-Gaussian), ICA-LiNGAM can figure out the complete
/// causal structure — not just which edges exist, but which direction they go.
/// </para>
/// <para>
/// Reference: Shimizu et al. (2006), "A Linear Non-Gaussian Acyclic Model for Causal Discovery",
/// Journal of Machine Learning Research.
/// </para>
/// </remarks>
/// <typeparam name="T">The numeric type used for calculations.</typeparam>
public class ICALiNGAMAlgorithm<T> : FunctionalBase<T>
{
    /// <inheritdoc/>
    public override string Name => "ICA-LiNGAM";

    /// <inheritdoc/>
    public override bool SupportsNonlinear => false;

    private double _threshold = 0.1;

    /// <summary>
    /// Initializes ICA-LiNGAM with optional configuration.
    /// </summary>
    public ICALiNGAMAlgorithm(CausalDiscoveryOptions? options = null)
    {
        if (options?.EdgeThreshold.HasValue == true) _threshold = options.EdgeThreshold.Value;
    }

    /// <inheritdoc/>
    protected override Matrix<T> DiscoverStructureCore(Matrix<T> data)
    {
        int n = data.Rows;
        int d = data.Columns;
        var standardized = StandardizeData(data);

        // Approximate ICA via FastICA-like deflation
        // FastICA requires transcendental functions (tanh) in tight inner loops,
        // so it operates on Matrix<T> but converts elements via NumOps as needed
        var W = FastICA(standardized, n, d);

        // Recover B = I - inv(W)
        var invW = InvertMatrix(W, d);
        if (invW == null) return new Matrix<T>(d, d);

        var B = new Matrix<T>(d, d);
        for (int i = 0; i < d; i++)
            for (int j = 0; j < d; j++)
                B[i, j] = NumOps.Subtract(
                    i == j ? NumOps.One : NumOps.Zero,
                    invW[i, j]);

        // Find permutation to make B approximately lower triangular
        var order = FindCausalOrder(B, d);

        // Permute and threshold
        var result = new Matrix<T>(d, d);
        for (int i = 0; i < d; i++)
        {
            for (int j = 0; j < d; j++)
            {
                T val = B[order[i], order[j]];
                double valD = NumOps.ToDouble(val);
                if (i != j && Math.Abs(valD) >= _threshold)
                    result[order[i], order[j]] = val;
            }
        }

        return result;
    }

    private Matrix<T> FastICA(Matrix<T> data, int n, int d)
    {
        var rng = new Random(42);
        var W = new Matrix<T>(d, d);

        // Initialize W as identity + small random perturbation
        for (int i = 0; i < d; i++)
        {
            W[i, i] = NumOps.One;
            for (int j = 0; j < d; j++)
                W[i, j] = NumOps.Add(W[i, j], NumOps.FromDouble(0.01 * (rng.NextDouble() - 0.5)));
        }

        // Deflation-based FastICA
        for (int p = 0; p < d; p++)
        {
            var w = new Vector<T>(d);
            for (int j = 0; j < d; j++) w[j] = NumOps.FromDouble(rng.NextDouble() - 0.5);
            NormalizeVector(w);

            for (int iter = 0; iter < 200; iter++)
            {
                var wNew = new Vector<T>(d);

                // E{X * g(w^T X)} - E{g'(w^T X)} * w, using g(u) = tanh(u)
                T meanGPrime = NumOps.Zero;
                T nT = NumOps.FromDouble(n);
                for (int i = 0; i < n; i++)
                {
                    T u = NumOps.Zero;
                    for (int j = 0; j < d; j++)
                        u = NumOps.Add(u, NumOps.Multiply(w[j], data[i, j]));

                    double uD = NumOps.ToDouble(u);
                    T g = NumOps.FromDouble(Math.Tanh(uD));
                    T gPrime = NumOps.Subtract(NumOps.One, NumOps.Multiply(g, g));
                    meanGPrime = NumOps.Add(meanGPrime, gPrime);

                    for (int j = 0; j < d; j++)
                        wNew[j] = NumOps.Add(wNew[j], NumOps.Multiply(data[i, j], g));
                }

                meanGPrime = NumOps.Divide(meanGPrime, nT);
                for (int j = 0; j < d; j++)
                    wNew[j] = NumOps.Subtract(
                        NumOps.Divide(wNew[j], nT),
                        NumOps.Multiply(meanGPrime, w[j]));

                // Orthogonalize against previous components
                for (int k = 0; k < p; k++)
                {
                    T dot = NumOps.Zero;
                    for (int j = 0; j < d; j++)
                        dot = NumOps.Add(dot, NumOps.Multiply(wNew[j], W[k, j]));
                    for (int j = 0; j < d; j++)
                        wNew[j] = NumOps.Subtract(wNew[j], NumOps.Multiply(dot, W[k, j]));
                }

                NormalizeVector(wNew);

                // Check convergence
                double diff = 0;
                for (int j = 0; j < d; j++)
                    diff += Math.Abs(Math.Abs(NumOps.ToDouble(wNew[j])) - Math.Abs(NumOps.ToDouble(w[j])));
                w = wNew;
                if (diff < 1e-6) break;
            }

            for (int j = 0; j < d; j++) W[p, j] = w[j];
        }

        return W;
    }

    private void NormalizeVector(Vector<T> v)
    {
        T norm = NumOps.Zero;
        for (int j = 0; j < v.Length; j++)
            norm = NumOps.Add(norm, NumOps.Multiply(v[j], v[j]));
        norm = NumOps.Sqrt(norm);

        if (NumOps.ToDouble(norm) > 1e-15)
            for (int j = 0; j < v.Length; j++)
                v[j] = NumOps.Divide(v[j], norm);
    }

    private int[] FindCausalOrder(Matrix<T> B, int d)
    {
        var rowSums = new double[d];
        for (int i = 0; i < d; i++)
            for (int j = i + 1; j < d; j++)
                rowSums[i] += Math.Abs(NumOps.ToDouble(B[i, j]));

        return Enumerable.Range(0, d).OrderBy(i => rowSums[i]).ToArray();
    }

    private Matrix<T>? InvertMatrix(Matrix<T> matrix, int d)
    {
        // Build augmented matrix [M | I] using generic T
        var aug = new Matrix<T>(d, 2 * d);
        for (int i = 0; i < d; i++)
        {
            for (int j = 0; j < d; j++) aug[i, j] = matrix[i, j];
            aug[i, i + d] = NumOps.One;
        }

        for (int col = 0; col < d; col++)
        {
            int maxRow = col;
            for (int row = col + 1; row < d; row++)
                if (Math.Abs(NumOps.ToDouble(aug[row, col])) > Math.Abs(NumOps.ToDouble(aug[maxRow, col])))
                    maxRow = row;
            if (Math.Abs(NumOps.ToDouble(aug[maxRow, col])) < 1e-12) return null;
            if (maxRow != col)
                for (int j = 0; j < 2 * d; j++)
                    (aug[col, j], aug[maxRow, j]) = (aug[maxRow, j], aug[col, j]);
            T pivot = aug[col, col];
            for (int j = 0; j < 2 * d; j++) aug[col, j] = NumOps.Divide(aug[col, j], pivot);
            for (int row = 0; row < d; row++)
                if (row != col)
                {
                    T factor = aug[row, col];
                    for (int j = 0; j < 2 * d; j++)
                        aug[row, j] = NumOps.Subtract(aug[row, j], NumOps.Multiply(factor, aug[col, j]));
                }
        }

        var result = new Matrix<T>(d, d);
        for (int i = 0; i < d; i++)
            for (int j = 0; j < d; j++) result[i, j] = aug[i, j + d];
        return result;
    }
}
