#if !NET462
using System;
using AiDotNet.Tensors.Helpers;
using AiDotNet.Tensors.LinearAlgebra;
using AiDotNet.Tensors.Operators;
using ILGPU;
using ILGPU.Algorithms;
using ILGPU.Runtime;
using ILGPU.Runtime.OpenCL;

namespace AiDotNet.Tensors.Engines;

/// <summary>
/// Delegate for Conv2D GPU kernel with float precision (18 parameters exceeds Action limit).
/// </summary>
internal delegate void Conv2DKernelFloat(AcceleratorStream stream, Index1D index, ArrayView<float> input, ArrayView<float> kernel, ArrayView<float> output,
    int batch, int inChannels, int height, int width, int outChannels,
    int outputHeight, int outputWidth, int kernelHeight, int kernelWidth, int stride, int padding, int dilation);

/// <summary>
/// Delegate for Conv2D GPU kernel with double precision (18 parameters exceeds Action limit).
/// </summary>
internal delegate void Conv2DKernelDouble(AcceleratorStream stream, Index1D index, ArrayView<double> input, ArrayView<double> kernel, ArrayView<double> output,
    int batch, int inChannels, int height, int width, int outChannels,
    int outputHeight, int outputWidth, int kernelHeight, int kernelWidth, int stride, int padding, int dilation);

/// <summary>
/// Parameter struct for Conv2D kernel (groups 12 scalar parameters to simplify kernel signature).
/// </summary>
internal readonly struct Conv2DParams
{
    public readonly int Batch;
    public readonly int InChannels;
    public readonly int Height;
    public readonly int Width;
    public readonly int OutChannels;
    public readonly int OutputHeight;
    public readonly int OutputWidth;
    public readonly int KernelHeight;
    public readonly int KernelWidth;
    public readonly int Stride;
    public readonly int Padding;
    public readonly int Dilation;

    public Conv2DParams(int batch, int inChannels, int height, int width, int outChannels,
        int outputHeight, int outputWidth, int kernelHeight, int kernelWidth,
        int stride, int padding, int dilation)
    {
        Batch = batch;
        InChannels = inChannels;
        Height = height;
        Width = width;
        OutChannels = outChannels;
        OutputHeight = outputHeight;
        OutputWidth = outputWidth;
        KernelHeight = kernelHeight;
        KernelWidth = kernelWidth;
        Stride = stride;
        Padding = padding;
        Dilation = dilation;
    }
}

/// <summary>
/// Static helper class for Conv2D kernel methods (required for explicit compilation).
/// </summary>
internal static class Conv2DKernels
{
    /// <summary>
    /// Conv2D kernel implementation for float precision.
    /// </summary>
    public static void Conv2DKernelFloatImpl(Index1D index, ArrayView<float> input, ArrayView<float> kernel, ArrayView<float> output,
        Conv2DParams parameters)
    {
        // Convert flat index to 4D coordinates
        int ow = (int)index % parameters.OutputWidth;
        int temp = (int)index / parameters.OutputWidth;
        int oh = temp % parameters.OutputHeight;
        temp /= parameters.OutputHeight;
        int oc = temp % parameters.OutChannels;
        int b = temp / parameters.OutChannels;

        float sum = 0;

        // Sum over all input channels
        for (int ic = 0; ic < parameters.InChannels; ic++)
        {
            // Sum over kernel window
            for (int kh = 0; kh < parameters.KernelHeight; kh++)
            {
                for (int kw = 0; kw < parameters.KernelWidth; kw++)
                {
                    int ih = oh * parameters.Stride + kh * parameters.Dilation - parameters.Padding;
                    int iw = ow * parameters.Stride + kw * parameters.Dilation - parameters.Padding;

                    if (ih >= 0 && ih < parameters.Height && iw >= 0 && iw < parameters.Width)
                    {
                        int inputIdx = ((b * parameters.InChannels + ic) * parameters.Height + ih) * parameters.Width + iw;
                        int kernelIdx = ((oc * parameters.InChannels + ic) * parameters.KernelHeight + kh) * parameters.KernelWidth + kw;
                        sum += input[inputIdx] * kernel[kernelIdx];
                    }
                }
            }
        }

        output[index] = sum;
    }

    /// <summary>
    /// Conv2D kernel implementation for double precision.
    /// </summary>
    public static void Conv2DKernelDoubleImpl(Index1D index, ArrayView<double> input, ArrayView<double> kernel, ArrayView<double> output,
        Conv2DParams parameters)
    {
        // Convert flat index to 4D coordinates
        int ow = (int)index % parameters.OutputWidth;
        int temp = (int)index / parameters.OutputWidth;
        int oh = temp % parameters.OutputHeight;
        temp /= parameters.OutputHeight;
        int oc = temp % parameters.OutChannels;
        int b = temp / parameters.OutChannels;

        double sum = 0;

        // Sum over all input channels
        for (int ic = 0; ic < parameters.InChannels; ic++)
        {
            // Sum over kernel window
            for (int kh = 0; kh < parameters.KernelHeight; kh++)
            {
                for (int kw = 0; kw < parameters.KernelWidth; kw++)
                {
                    int ih = oh * parameters.Stride + kh * parameters.Dilation - parameters.Padding;
                    int iw = ow * parameters.Stride + kw * parameters.Dilation - parameters.Padding;

                    if (ih >= 0 && ih < parameters.Height && iw >= 0 && iw < parameters.Width)
                    {
                        int inputIdx = ((b * parameters.InChannels + ic) * parameters.Height + ih) * parameters.Width + iw;
                        int kernelIdx = ((oc * parameters.InChannels + ic) * parameters.KernelHeight + kh) * parameters.KernelWidth + kw;
                        sum += input[inputIdx] * kernel[kernelIdx];
                    }
                }
            }
        }

        output[index] = sum;
    }
}

/// <summary>
/// Parameter struct for LocallyConnectedConv2D kernel.
/// LocallyConnected layers have position-specific weights (6D tensor).
/// </summary>
internal readonly struct LocallyConnectedConv2DParams
{
    public readonly int Batch;
    public readonly int InChannels;
    public readonly int InputHeight;
    public readonly int InputWidth;
    public readonly int OutChannels;
    public readonly int OutputHeight;
    public readonly int OutputWidth;
    public readonly int KernelHeight;
    public readonly int KernelWidth;
    public readonly int StrideH;
    public readonly int StrideW;

    public LocallyConnectedConv2DParams(int batch, int inChannels, int inputHeight, int inputWidth,
        int outChannels, int outputHeight, int outputWidth, int kernelHeight, int kernelWidth,
        int strideH, int strideW)
    {
        Batch = batch;
        InChannels = inChannels;
        InputHeight = inputHeight;
        InputWidth = inputWidth;
        OutChannels = outChannels;
        OutputHeight = outputHeight;
        OutputWidth = outputWidth;
        KernelHeight = kernelHeight;
        KernelWidth = kernelWidth;
        StrideH = strideH;
        StrideW = strideW;
    }
}

/// <summary>
/// Static helper class for LocallyConnectedConv2D kernel methods.
/// </summary>
internal static class LocallyConnectedConv2DKernels
{
    /// <summary>
    /// LocallyConnectedConv2D forward kernel for float precision.
    /// Each output position has its own unique weights (position-specific).
    /// weights shape: [outputHeight, outputWidth, outChannels, inChannels, kernelHeight, kernelWidth]
    /// </summary>
    public static void ForwardKernelFloatImpl(Index1D index, ArrayView<float> input, ArrayView<float> weights,
        ArrayView<float> bias, ArrayView<float> output, LocallyConnectedConv2DParams p, int hasBias)
    {
        // Convert flat index to 4D output coordinates: [b, oc, oh, ow]
        int ow = (int)index % p.OutputWidth;
        int temp = (int)index / p.OutputWidth;
        int oh = temp % p.OutputHeight;
        temp /= p.OutputHeight;
        int oc = temp % p.OutChannels;
        int b = temp / p.OutChannels;

        float sum = 0;

        // Sum over input channels and kernel window
        for (int ic = 0; ic < p.InChannels; ic++)
        {
            for (int kh = 0; kh < p.KernelHeight; kh++)
            {
                for (int kw = 0; kw < p.KernelWidth; kw++)
                {
                    int ih = oh * p.StrideH + kh;
                    int iw = ow * p.StrideW + kw;

                    if (ih >= 0 && ih < p.InputHeight && iw >= 0 && iw < p.InputWidth)
                    {
                        // input index: [b, ic, ih, iw]
                        int inputIdx = ((b * p.InChannels + ic) * p.InputHeight + ih) * p.InputWidth + iw;

                        // weights index: [oh, ow, oc, ic, kh, kw]
                        int weightIdx = ((((oh * p.OutputWidth + ow) * p.OutChannels + oc) * p.InChannels + ic) * p.KernelHeight + kh) * p.KernelWidth + kw;

                        sum += input[inputIdx] * weights[weightIdx];
                    }
                }
            }
        }

        // Add bias if provided - bias is per-channel: [oc]
        if (hasBias != 0)
        {
            sum += bias[oc];
        }

        output[index] = sum;
    }

    /// <summary>
    /// LocallyConnectedConv2D forward kernel for double precision.
    /// </summary>
    public static void ForwardKernelDoubleImpl(Index1D index, ArrayView<double> input, ArrayView<double> weights,
        ArrayView<double> bias, ArrayView<double> output, LocallyConnectedConv2DParams p, int hasBias)
    {
        int ow = (int)index % p.OutputWidth;
        int temp = (int)index / p.OutputWidth;
        int oh = temp % p.OutputHeight;
        temp /= p.OutputHeight;
        int oc = temp % p.OutChannels;
        int b = temp / p.OutChannels;

        double sum = 0;

        for (int ic = 0; ic < p.InChannels; ic++)
        {
            for (int kh = 0; kh < p.KernelHeight; kh++)
            {
                for (int kw = 0; kw < p.KernelWidth; kw++)
                {
                    int ih = oh * p.StrideH + kh;
                    int iw = ow * p.StrideW + kw;

                    if (ih >= 0 && ih < p.InputHeight && iw >= 0 && iw < p.InputWidth)
                    {
                        int inputIdx = ((b * p.InChannels + ic) * p.InputHeight + ih) * p.InputWidth + iw;
                        int weightIdx = ((((oh * p.OutputWidth + ow) * p.OutChannels + oc) * p.InChannels + ic) * p.KernelHeight + kh) * p.KernelWidth + kw;
                        sum += input[inputIdx] * weights[weightIdx];
                    }
                }
            }
        }

        // Add bias if provided - bias is per-channel: [oc]
        if (hasBias != 0)
        {
            sum += bias[oc];
        }

        output[index] = sum;
    }

    /// <summary>
    /// LocallyConnectedConv2D backward input kernel for float precision.
    /// Computes gradient with respect to input tensor.
    /// </summary>
    public static void BackwardInputKernelFloatImpl(Index1D index, ArrayView<float> gradOutput, ArrayView<float> weights,
        ArrayView<float> gradInput, LocallyConnectedConv2DParams p)
    {
        // Convert flat index to 4D input coordinates: [b, ic, ih, iw]
        int iw = (int)index % p.InputWidth;
        int temp = (int)index / p.InputWidth;
        int ih = temp % p.InputHeight;
        temp /= p.InputHeight;
        int ic = temp % p.InChannels;
        int b = temp / p.InChannels;

        float sum = 0;

        // For each output position that this input contributes to
        for (int oc = 0; oc < p.OutChannels; oc++)
        {
            for (int oh = 0; oh < p.OutputHeight; oh++)
            {
                for (int ow = 0; ow < p.OutputWidth; ow++)
                {
                    // Check if this input position contributes to this output position
                    int kh = ih - oh * p.StrideH;
                    int kw = iw - ow * p.StrideW;

                    if (kh >= 0 && kh < p.KernelHeight && kw >= 0 && kw < p.KernelWidth)
                    {
                        // gradOutput index: [b, oc, oh, ow]
                        int gradOutIdx = ((b * p.OutChannels + oc) * p.OutputHeight + oh) * p.OutputWidth + ow;

                        // weights index: [oh, ow, oc, ic, kh, kw]
                        int weightIdx = ((((oh * p.OutputWidth + ow) * p.OutChannels + oc) * p.InChannels + ic) * p.KernelHeight + kh) * p.KernelWidth + kw;

                        sum += gradOutput[gradOutIdx] * weights[weightIdx];
                    }
                }
            }
        }

        gradInput[index] = sum;
    }

    /// <summary>
    /// LocallyConnectedConv2D backward input kernel for double precision.
    /// </summary>
    public static void BackwardInputKernelDoubleImpl(Index1D index, ArrayView<double> gradOutput, ArrayView<double> weights,
        ArrayView<double> gradInput, LocallyConnectedConv2DParams p)
    {
        int iw = (int)index % p.InputWidth;
        int temp = (int)index / p.InputWidth;
        int ih = temp % p.InputHeight;
        temp /= p.InputHeight;
        int ic = temp % p.InChannels;
        int b = temp / p.InChannels;

        double sum = 0;

        for (int oc = 0; oc < p.OutChannels; oc++)
        {
            for (int oh = 0; oh < p.OutputHeight; oh++)
            {
                for (int ow = 0; ow < p.OutputWidth; ow++)
                {
                    int kh = ih - oh * p.StrideH;
                    int kw = iw - ow * p.StrideW;

                    if (kh >= 0 && kh < p.KernelHeight && kw >= 0 && kw < p.KernelWidth)
                    {
                        int gradOutIdx = ((b * p.OutChannels + oc) * p.OutputHeight + oh) * p.OutputWidth + ow;
                        int weightIdx = ((((oh * p.OutputWidth + ow) * p.OutChannels + oc) * p.InChannels + ic) * p.KernelHeight + kh) * p.KernelWidth + kw;
                        sum += gradOutput[gradOutIdx] * weights[weightIdx];
                    }
                }
            }
        }

        gradInput[index] = sum;
    }

    /// <summary>
    /// LocallyConnectedConv2D backward weights kernel for float precision.
    /// Uses atomic add for thread-safe accumulation across batch dimension.
    /// </summary>
    public static void BackwardWeightsKernelFloatImpl(Index1D index, ArrayView<float> gradOutput, ArrayView<float> input,
        ArrayView<float> gradWeights, LocallyConnectedConv2DParams p)
    {
        // Compute weight gradient for one position: [oh, ow, oc, ic, kh, kw]
        int kw = (int)index % p.KernelWidth;
        int temp = (int)index / p.KernelWidth;
        int kh = temp % p.KernelHeight;
        temp /= p.KernelHeight;
        int ic = temp % p.InChannels;
        temp /= p.InChannels;
        int oc = temp % p.OutChannels;
        temp /= p.OutChannels;
        int ow = temp % p.OutputWidth;
        int oh = temp / p.OutputWidth;

        float sum = 0;

        // Sum over batch dimension
        for (int b = 0; b < p.Batch; b++)
        {
            int ih = oh * p.StrideH + kh;
            int iw = ow * p.StrideW + kw;

            if (ih >= 0 && ih < p.InputHeight && iw >= 0 && iw < p.InputWidth)
            {
                int gradOutIdx = ((b * p.OutChannels + oc) * p.OutputHeight + oh) * p.OutputWidth + ow;
                int inputIdx = ((b * p.InChannels + ic) * p.InputHeight + ih) * p.InputWidth + iw;
                sum += gradOutput[gradOutIdx] * input[inputIdx];
            }
        }

        gradWeights[index] = sum;
    }

    /// <summary>
    /// LocallyConnectedConv2D backward weights kernel for double precision.
    /// </summary>
    public static void BackwardWeightsKernelDoubleImpl(Index1D index, ArrayView<double> gradOutput, ArrayView<double> input,
        ArrayView<double> gradWeights, LocallyConnectedConv2DParams p)
    {
        int kw = (int)index % p.KernelWidth;
        int temp = (int)index / p.KernelWidth;
        int kh = temp % p.KernelHeight;
        temp /= p.KernelHeight;
        int ic = temp % p.InChannels;
        temp /= p.InChannels;
        int oc = temp % p.OutChannels;
        temp /= p.OutChannels;
        int ow = temp % p.OutputWidth;
        int oh = temp / p.OutputWidth;

        double sum = 0;

        for (int b = 0; b < p.Batch; b++)
        {
            int ih = oh * p.StrideH + kh;
            int iw = ow * p.StrideW + kw;

            if (ih >= 0 && ih < p.InputHeight && iw >= 0 && iw < p.InputWidth)
            {
                int gradOutIdx = ((b * p.OutChannels + oc) * p.OutputHeight + oh) * p.OutputWidth + ow;
                int inputIdx = ((b * p.InChannels + ic) * p.InputHeight + ih) * p.InputWidth + iw;
                sum += gradOutput[gradOutIdx] * input[inputIdx];
            }
        }

        gradWeights[index] = sum;
    }

    /// <summary>
    /// LocallyConnectedConv2D backward bias kernel for float precision.
    /// Sums gradOutput over batch dimension for each position [oh, ow, oc].
    /// </summary>
    public static void BackwardBiasKernelFloatImpl(Index1D index, ArrayView<float> gradOutput, ArrayView<float> gradBias,
        LocallyConnectedConv2DParams p)
    {
        // index maps to [oh, ow, oc] flat index
        int oc = (int)index % p.OutChannels;
        int temp = (int)index / p.OutChannels;
        int ow = temp % p.OutputWidth;
        int oh = temp / p.OutputWidth;

        float sum = 0;

        // Sum over batch dimension
        for (int b = 0; b < p.Batch; b++)
        {
            // gradOutput layout: [batch, outChannels, outputHeight, outputWidth]
            int gradOutIdx = ((b * p.OutChannels + oc) * p.OutputHeight + oh) * p.OutputWidth + ow;
            sum += gradOutput[gradOutIdx];
        }

        gradBias[index] = sum;
    }

    /// <summary>
    /// LocallyConnectedConv2D backward bias kernel for double precision.
    /// </summary>
    public static void BackwardBiasKernelDoubleImpl(Index1D index, ArrayView<double> gradOutput, ArrayView<double> gradBias,
        LocallyConnectedConv2DParams p)
    {
        // index maps to [oh, ow, oc] flat index
        int oc = (int)index % p.OutChannels;
        int temp = (int)index / p.OutChannels;
        int ow = temp % p.OutputWidth;
        int oh = temp / p.OutputWidth;

        double sum = 0;

        // Sum over batch dimension
        for (int b = 0; b < p.Batch; b++)
        {
            int gradOutIdx = ((b * p.OutChannels + oc) * p.OutputHeight + oh) * p.OutputWidth + ow;
            sum += gradOutput[gradOutIdx];
        }

        gradBias[index] = sum;
    }
}

/// <summary>
/// Parameter struct for Conv3D kernel (groups 15 scalar parameters for volumetric convolution).
/// </summary>
internal readonly struct Conv3DParams
{
    public readonly int Batch;
    public readonly int InChannels;
    public readonly int Depth;
    public readonly int Height;
    public readonly int Width;
    public readonly int OutChannels;
    public readonly int OutputDepth;
    public readonly int OutputHeight;
    public readonly int OutputWidth;
    public readonly int KernelDepth;
    public readonly int KernelHeight;
    public readonly int KernelWidth;
    public readonly int StrideD;
    public readonly int StrideH;
    public readonly int StrideW;
    public readonly int PadD;
    public readonly int PadH;
    public readonly int PadW;
    public readonly int DilationD;
    public readonly int DilationH;
    public readonly int DilationW;

    public Conv3DParams(int batch, int inChannels, int depth, int height, int width, int outChannels,
        int outputDepth, int outputHeight, int outputWidth, int kernelDepth, int kernelHeight, int kernelWidth,
        int strideD, int strideH, int strideW, int padD, int padH, int padW, int dilationD, int dilationH, int dilationW)
    {
        Batch = batch;
        InChannels = inChannels;
        Depth = depth;
        Height = height;
        Width = width;
        OutChannels = outChannels;
        OutputDepth = outputDepth;
        OutputHeight = outputHeight;
        OutputWidth = outputWidth;
        KernelDepth = kernelDepth;
        KernelHeight = kernelHeight;
        KernelWidth = kernelWidth;
        StrideD = strideD;
        StrideH = strideH;
        StrideW = strideW;
        PadD = padD;
        PadH = padH;
        PadW = padW;
        DilationD = dilationD;
        DilationH = dilationH;
        DilationW = dilationW;
    }
}

/// <summary>
/// Static helper class for Conv3D kernel methods (required for explicit compilation).
/// </summary>
internal static class Conv3DKernels
{
    /// <summary>
    /// Conv3D forward kernel implementation for float precision.
    /// Input: [batch, inChannels, depth, height, width]
    /// Kernel: [outChannels, inChannels, kernelD, kernelH, kernelW]
    /// Output: [batch, outChannels, outputD, outputH, outputW]
    /// </summary>
    public static void Conv3DKernelFloatImpl(Index1D index, ArrayView<float> input, ArrayView<float> kernel, ArrayView<float> output,
        Conv3DParams p)
    {
        // Convert flat index to 5D coordinates: [b, oc, od, oh, ow]
        int ow = (int)index % p.OutputWidth;
        int temp = (int)index / p.OutputWidth;
        int oh = temp % p.OutputHeight;
        temp /= p.OutputHeight;
        int od = temp % p.OutputDepth;
        temp /= p.OutputDepth;
        int oc = temp % p.OutChannels;
        int b = temp / p.OutChannels;

        float sum = 0;

        // Sum over input channels and kernel volume
        for (int ic = 0; ic < p.InChannels; ic++)
        {
            for (int kd = 0; kd < p.KernelDepth; kd++)
            {
                for (int kh = 0; kh < p.KernelHeight; kh++)
                {
                    for (int kw = 0; kw < p.KernelWidth; kw++)
                    {
                        int id = od * p.StrideD + kd * p.DilationD - p.PadD;
                        int ih = oh * p.StrideH + kh * p.DilationH - p.PadH;
                        int iw = ow * p.StrideW + kw * p.DilationW - p.PadW;

                        if (id >= 0 && id < p.Depth && ih >= 0 && ih < p.Height && iw >= 0 && iw < p.Width)
                        {
                            // input index: [b, ic, id, ih, iw]
                            int inputIdx = (((b * p.InChannels + ic) * p.Depth + id) * p.Height + ih) * p.Width + iw;
                            // kernel index: [oc, ic, kd, kh, kw]
                            int kernelIdx = (((oc * p.InChannels + ic) * p.KernelDepth + kd) * p.KernelHeight + kh) * p.KernelWidth + kw;
                            sum += input[inputIdx] * kernel[kernelIdx];
                        }
                    }
                }
            }
        }

        output[index] = sum;
    }

    /// <summary>
    /// Conv3D forward kernel implementation for double precision.
    /// </summary>
    public static void Conv3DKernelDoubleImpl(Index1D index, ArrayView<double> input, ArrayView<double> kernel, ArrayView<double> output,
        Conv3DParams p)
    {
        int ow = (int)index % p.OutputWidth;
        int temp = (int)index / p.OutputWidth;
        int oh = temp % p.OutputHeight;
        temp /= p.OutputHeight;
        int od = temp % p.OutputDepth;
        temp /= p.OutputDepth;
        int oc = temp % p.OutChannels;
        int b = temp / p.OutChannels;

        double sum = 0;

        for (int ic = 0; ic < p.InChannels; ic++)
        {
            for (int kd = 0; kd < p.KernelDepth; kd++)
            {
                for (int kh = 0; kh < p.KernelHeight; kh++)
                {
                    for (int kw = 0; kw < p.KernelWidth; kw++)
                    {
                        int id = od * p.StrideD + kd * p.DilationD - p.PadD;
                        int ih = oh * p.StrideH + kh * p.DilationH - p.PadH;
                        int iw = ow * p.StrideW + kw * p.DilationW - p.PadW;

                        if (id >= 0 && id < p.Depth && ih >= 0 && ih < p.Height && iw >= 0 && iw < p.Width)
                        {
                            int inputIdx = (((b * p.InChannels + ic) * p.Depth + id) * p.Height + ih) * p.Width + iw;
                            int kernelIdx = (((oc * p.InChannels + ic) * p.KernelDepth + kd) * p.KernelHeight + kh) * p.KernelWidth + kw;
                            sum += input[inputIdx] * kernel[kernelIdx];
                        }
                    }
                }
            }
        }

        output[index] = sum;
    }
}

/// <summary>
/// Parameter struct for Pool3D kernel (for MaxPool3D and AvgPool3D).
/// </summary>
internal readonly struct Pool3DParams
{
    public readonly int Batch;
    public readonly int Channels;
    public readonly int Depth;
    public readonly int Height;
    public readonly int Width;
    public readonly int OutputDepth;
    public readonly int OutputHeight;
    public readonly int OutputWidth;
    public readonly int PoolD;
    public readonly int PoolH;
    public readonly int PoolW;
    public readonly int StrideD;
    public readonly int StrideH;
    public readonly int StrideW;
    public readonly int PadD;
    public readonly int PadH;
    public readonly int PadW;

    public Pool3DParams(int batch, int channels, int depth, int height, int width,
        int outputDepth, int outputHeight, int outputWidth,
        int poolD, int poolH, int poolW, int strideD, int strideH, int strideW,
        int padD, int padH, int padW)
    {
        Batch = batch;
        Channels = channels;
        Depth = depth;
        Height = height;
        Width = width;
        OutputDepth = outputDepth;
        OutputHeight = outputHeight;
        OutputWidth = outputWidth;
        PoolD = poolD;
        PoolH = poolH;
        PoolW = poolW;
        StrideD = strideD;
        StrideH = strideH;
        StrideW = strideW;
        PadD = padD;
        PadH = padH;
        PadW = padW;
    }
}

/// <summary>
/// Static helper class for Pool3D kernel methods.
/// </summary>
internal static class Pool3DKernels
{
    /// <summary>
    /// MaxPool3D forward kernel for float precision.
    /// </summary>
    public static void MaxPool3DKernelFloatImpl(Index1D index, ArrayView<float> input, ArrayView<float> output, Pool3DParams p)
    {
        int ow = (int)index % p.OutputWidth;
        int temp = (int)index / p.OutputWidth;
        int oh = temp % p.OutputHeight;
        temp /= p.OutputHeight;
        int od = temp % p.OutputDepth;
        temp /= p.OutputDepth;
        int c = temp % p.Channels;
        int b = temp / p.Channels;

        float maxVal = float.NegativeInfinity;

        for (int pd = 0; pd < p.PoolD; pd++)
        {
            for (int ph = 0; ph < p.PoolH; ph++)
            {
                for (int pw = 0; pw < p.PoolW; pw++)
                {
                    int id = od * p.StrideD + pd - p.PadD;
                    int ih = oh * p.StrideH + ph - p.PadH;
                    int iw = ow * p.StrideW + pw - p.PadW;

                    if (id >= 0 && id < p.Depth && ih >= 0 && ih < p.Height && iw >= 0 && iw < p.Width)
                    {
                        int inputIdx = (((b * p.Channels + c) * p.Depth + id) * p.Height + ih) * p.Width + iw;
                        float val = input[inputIdx];
                        if (val > maxVal) maxVal = val;
                    }
                }
            }
        }

        output[index] = maxVal;
    }

    /// <summary>
    /// MaxPool3D forward kernel for double precision.
    /// </summary>
    public static void MaxPool3DKernelDoubleImpl(Index1D index, ArrayView<double> input, ArrayView<double> output, Pool3DParams p)
    {
        int ow = (int)index % p.OutputWidth;
        int temp = (int)index / p.OutputWidth;
        int oh = temp % p.OutputHeight;
        temp /= p.OutputHeight;
        int od = temp % p.OutputDepth;
        temp /= p.OutputDepth;
        int c = temp % p.Channels;
        int b = temp / p.Channels;

        double maxVal = double.NegativeInfinity;

        for (int pd = 0; pd < p.PoolD; pd++)
        {
            for (int ph = 0; ph < p.PoolH; ph++)
            {
                for (int pw = 0; pw < p.PoolW; pw++)
                {
                    int id = od * p.StrideD + pd - p.PadD;
                    int ih = oh * p.StrideH + ph - p.PadH;
                    int iw = ow * p.StrideW + pw - p.PadW;

                    if (id >= 0 && id < p.Depth && ih >= 0 && ih < p.Height && iw >= 0 && iw < p.Width)
                    {
                        int inputIdx = (((b * p.Channels + c) * p.Depth + id) * p.Height + ih) * p.Width + iw;
                        double val = input[inputIdx];
                        if (val > maxVal) maxVal = val;
                    }
                }
            }
        }

        output[index] = maxVal;
    }

    /// <summary>
    /// AvgPool3D forward kernel for float precision.
    /// </summary>
    public static void AvgPool3DKernelFloatImpl(Index1D index, ArrayView<float> input, ArrayView<float> output, Pool3DParams p)
    {
        int ow = (int)index % p.OutputWidth;
        int temp = (int)index / p.OutputWidth;
        int oh = temp % p.OutputHeight;
        temp /= p.OutputHeight;
        int od = temp % p.OutputDepth;
        temp /= p.OutputDepth;
        int c = temp % p.Channels;
        int b = temp / p.Channels;

        float sum = 0;
        int count = 0;

        for (int pd = 0; pd < p.PoolD; pd++)
        {
            for (int ph = 0; ph < p.PoolH; ph++)
            {
                for (int pw = 0; pw < p.PoolW; pw++)
                {
                    int id = od * p.StrideD + pd - p.PadD;
                    int ih = oh * p.StrideH + ph - p.PadH;
                    int iw = ow * p.StrideW + pw - p.PadW;

                    if (id >= 0 && id < p.Depth && ih >= 0 && ih < p.Height && iw >= 0 && iw < p.Width)
                    {
                        int inputIdx = (((b * p.Channels + c) * p.Depth + id) * p.Height + ih) * p.Width + iw;
                        sum += input[inputIdx];
                        count++;
                    }
                }
            }
        }

        output[index] = count > 0 ? sum / count : 0;
    }

    /// <summary>
    /// AvgPool3D forward kernel for double precision.
    /// </summary>
    public static void AvgPool3DKernelDoubleImpl(Index1D index, ArrayView<double> input, ArrayView<double> output, Pool3DParams p)
    {
        int ow = (int)index % p.OutputWidth;
        int temp = (int)index / p.OutputWidth;
        int oh = temp % p.OutputHeight;
        temp /= p.OutputHeight;
        int od = temp % p.OutputDepth;
        temp /= p.OutputDepth;
        int c = temp % p.Channels;
        int b = temp / p.Channels;

        double sum = 0;
        int count = 0;

        for (int pd = 0; pd < p.PoolD; pd++)
        {
            for (int ph = 0; ph < p.PoolH; ph++)
            {
                for (int pw = 0; pw < p.PoolW; pw++)
                {
                    int id = od * p.StrideD + pd - p.PadD;
                    int ih = oh * p.StrideH + ph - p.PadH;
                    int iw = ow * p.StrideW + pw - p.PadW;

                    if (id >= 0 && id < p.Depth && ih >= 0 && ih < p.Height && iw >= 0 && iw < p.Width)
                    {
                        int inputIdx = (((b * p.Channels + c) * p.Depth + id) * p.Height + ih) * p.Width + iw;
                        sum += input[inputIdx];
                        count++;
                    }
                }
            }
        }

        output[index] = count > 0 ? sum / count : 0;
    }
}

/// <summary>
/// Parameter struct for PositionalEncoding GPU kernel.
/// </summary>
internal readonly struct PositionalEncodingParams
{
    /// <summary>Number of input points.</summary>
    public readonly int NumPoints;
    /// <summary>Input dimension (typically 3 for xyz).</summary>
    public readonly int InputDim;
    /// <summary>Number of frequency bands for encoding.</summary>
    public readonly int NumFrequencies;
    /// <summary>Output dimension per input value (2 * NumFrequencies for sin+cos).</summary>
    public readonly int EncodingDim;

    /// <summary>
    /// Initializes positional encoding parameters.
    /// </summary>
    public PositionalEncodingParams(int numPoints, int inputDim, int numFrequencies)
    {
        NumPoints = numPoints;
        InputDim = inputDim;
        NumFrequencies = numFrequencies;
        EncodingDim = 2 * numFrequencies;
    }
}

/// <summary>
/// GPU kernel implementations for NeRF positional encoding.
/// </summary>
internal static class PositionalEncodingKernels
{
    /// <summary>
    /// PositionalEncoding forward kernel for float precision.
    /// Encodes each input coordinate using sinusoidal functions at multiple frequencies.
    /// Output layout: [numPoints, inputDim * (1 + 2 * numFrequencies)]
    /// For each input value x, outputs: [x, sin(2^0 * pi * x), cos(2^0 * pi * x), ..., sin(2^(L-1) * pi * x), cos(2^(L-1) * pi * x)]
    /// </summary>
    public static void PositionalEncodingForwardFloat(
        Index1D index,
        ArrayView<float> input,
        ArrayView<float> output,
        PositionalEncodingParams p)
    {
        int totalOutputPerPoint = p.InputDim * (1 + p.EncodingDim);
        int pointIdx = (int)index / totalOutputPerPoint;
        int outputOffset = (int)index % totalOutputPerPoint;

        if (pointIdx >= p.NumPoints) return;

        int dimIdx = outputOffset / (1 + p.EncodingDim);
        int encodingIdx = outputOffset % (1 + p.EncodingDim);

        int inputIdx = pointIdx * p.InputDim + dimIdx;
        float x = input[inputIdx];

        if (encodingIdx == 0)
        {
            // Identity component
            output[index] = x;
        }
        else
        {
            int freqIdx = (encodingIdx - 1) / 2;
            bool isSin = (encodingIdx - 1) % 2 == 0;
            float freq = XMath.Pow(2.0f, freqIdx) * 3.14159265358979f;
            float angle = freq * x;
            output[index] = isSin ? XMath.Sin(angle) : XMath.Cos(angle);
        }
    }

    /// <summary>
    /// PositionalEncoding forward kernel for double precision.
    /// </summary>
    public static void PositionalEncodingForwardDouble(
        Index1D index,
        ArrayView<double> input,
        ArrayView<double> output,
        PositionalEncodingParams p)
    {
        int totalOutputPerPoint = p.InputDim * (1 + p.EncodingDim);
        int pointIdx = (int)index / totalOutputPerPoint;
        int outputOffset = (int)index % totalOutputPerPoint;

        if (pointIdx >= p.NumPoints) return;

        int dimIdx = outputOffset / (1 + p.EncodingDim);
        int encodingIdx = outputOffset % (1 + p.EncodingDim);

        int inputIdx = pointIdx * p.InputDim + dimIdx;
        double x = input[inputIdx];

        if (encodingIdx == 0)
        {
            output[index] = x;
        }
        else
        {
            int freqIdx = (encodingIdx - 1) / 2;
            bool isSin = (encodingIdx - 1) % 2 == 0;
            double freq = XMath.Pow(2.0, freqIdx) * 3.14159265358979;
            double angle = freq * x;
            output[index] = isSin ? XMath.Sin(angle) : XMath.Cos(angle);
        }
    }

    /// <summary>
    /// PositionalEncoding backward kernel for float precision.
    /// Computes gradient w.r.t. input positions from encoded gradient.
    /// </summary>
    public static void PositionalEncodingBackwardFloat(
        Index1D index,
        ArrayView<float> positions,
        ArrayView<float> encodedGrad,
        ArrayView<float> positionsGrad,
        PositionalEncodingParams p)
    {
        int pointIdx = (int)index / p.InputDim;
        int dimIdx = (int)index % p.InputDim;

        if (pointIdx >= p.NumPoints) return;

        int totalOutputPerPoint = p.InputDim * (1 + p.EncodingDim);
        int inputIdx = pointIdx * p.InputDim + dimIdx;
        float x = positions[inputIdx];

        float grad = 0.0f;

        // Gradient from identity component
        int identityIdx = pointIdx * totalOutputPerPoint + dimIdx * (1 + p.EncodingDim);
        grad += encodedGrad[identityIdx];

        // Gradient from frequency components
        for (int f = 0; f < p.NumFrequencies; f++)
        {
            float freq = XMath.Pow(2.0f, f) * 3.14159265358979f;
            float angle = freq * x;

            int sinIdx = identityIdx + 1 + 2 * f;
            int cosIdx = identityIdx + 2 + 2 * f;

            // d(sin(freq*x))/dx = freq * cos(freq*x)
            grad += encodedGrad[sinIdx] * freq * XMath.Cos(angle);
            // d(cos(freq*x))/dx = -freq * sin(freq*x)
            grad += encodedGrad[cosIdx] * (-freq) * XMath.Sin(angle);
        }

        positionsGrad[index] = grad;
    }

    /// <summary>
    /// PositionalEncoding backward kernel for double precision.
    /// </summary>
    public static void PositionalEncodingBackwardDouble(
        Index1D index,
        ArrayView<double> positions,
        ArrayView<double> encodedGrad,
        ArrayView<double> positionsGrad,
        PositionalEncodingParams p)
    {
        int pointIdx = (int)index / p.InputDim;
        int dimIdx = (int)index % p.InputDim;

        if (pointIdx >= p.NumPoints) return;

        int totalOutputPerPoint = p.InputDim * (1 + p.EncodingDim);
        int inputIdx = pointIdx * p.InputDim + dimIdx;
        double x = positions[inputIdx];

        double grad = 0.0;

        int identityIdx = pointIdx * totalOutputPerPoint + dimIdx * (1 + p.EncodingDim);
        grad += encodedGrad[identityIdx];

        for (int f = 0; f < p.NumFrequencies; f++)
        {
            double freq = XMath.Pow(2.0, f) * 3.14159265358979;
            double angle = freq * x;

            int sinIdx = identityIdx + 1 + 2 * f;
            int cosIdx = identityIdx + 2 + 2 * f;

            grad += encodedGrad[sinIdx] * freq * XMath.Cos(angle);
            grad += encodedGrad[cosIdx] * (-freq) * XMath.Sin(angle);
        }

        positionsGrad[index] = grad;
    }
}

/// <summary>
/// Parameter struct for VolumeRendering GPU kernel.
/// </summary>
internal readonly struct VolumeRenderingParams
{
    /// <summary>Number of rays being rendered.</summary>
    public readonly int NumRays;
    /// <summary>Number of samples along each ray.</summary>
    public readonly int NumSamples;
    /// <summary>Number of color channels (typically 3 for RGB).</summary>
    public readonly int NumChannels;

    /// <summary>
    /// Initializes volume rendering parameters.
    /// </summary>
    public VolumeRenderingParams(int numRays, int numSamples, int numChannels)
    {
        NumRays = numRays;
        NumSamples = numSamples;
        NumChannels = numChannels;
    }
}

/// <summary>
/// GPU kernel implementations for NeRF volume rendering.
/// </summary>
internal static class VolumeRenderingKernels
{
    /// <summary>
    /// Volume rendering forward kernel for float precision.
    /// Implements the classical volume rendering equation from NeRF.
    /// C(r) = sum_i(T_i * alpha_i * c_i) where T_i = prod_j&lt;i(1 - alpha_j)
    /// alpha_i = 1 - exp(-sigma_i * delta_i)
    /// </summary>
    public static void VolumeRenderingForwardFloat(
        Index1D index,
        ArrayView<float> rgb,        // [numRays, numSamples, numChannels]
        ArrayView<float> density,    // [numRays, numSamples]
        ArrayView<float> tValues,    // [numRays, numSamples]
        ArrayView<float> output,     // [numRays, numChannels]
        VolumeRenderingParams p)
    {
        int rayIdx = (int)index / p.NumChannels;
        int channelIdx = (int)index % p.NumChannels;

        if (rayIdx >= p.NumRays) return;

        float accumulated = 0.0f;
        float transmittance = 1.0f;

        for (int s = 0; s < p.NumSamples - 1; s++)
        {
            int rgbIdx = (rayIdx * p.NumSamples + s) * p.NumChannels + channelIdx;
            int densityIdx = rayIdx * p.NumSamples + s;
            int tIdx = rayIdx * p.NumSamples + s;
            int tNextIdx = rayIdx * p.NumSamples + s + 1;

            float sigma = density[densityIdx];
            float delta = tValues[tNextIdx] - tValues[tIdx];
            float c = rgb[rgbIdx];

            // alpha = 1 - exp(-sigma * delta)
            float alpha = 1.0f - XMath.Exp(-sigma * delta);

            accumulated += transmittance * alpha * c;
            transmittance *= (1.0f - alpha);

            // Early termination if transmittance is negligible
            if (transmittance < 1e-4f) break;
        }

        output[index] = accumulated;
    }

    /// <summary>
    /// Volume rendering forward kernel for double precision.
    /// </summary>
    public static void VolumeRenderingForwardDouble(
        Index1D index,
        ArrayView<double> rgb,
        ArrayView<double> density,
        ArrayView<double> tValues,
        ArrayView<double> output,
        VolumeRenderingParams p)
    {
        int rayIdx = (int)index / p.NumChannels;
        int channelIdx = (int)index % p.NumChannels;

        if (rayIdx >= p.NumRays) return;

        double accumulated = 0.0;
        double transmittance = 1.0;

        for (int s = 0; s < p.NumSamples - 1; s++)
        {
            int rgbIdx = (rayIdx * p.NumSamples + s) * p.NumChannels + channelIdx;
            int densityIdx = rayIdx * p.NumSamples + s;
            int tIdx = rayIdx * p.NumSamples + s;
            int tNextIdx = rayIdx * p.NumSamples + s + 1;

            double sigma = density[densityIdx];
            double delta = tValues[tNextIdx] - tValues[tIdx];
            double c = rgb[rgbIdx];

            double alpha = 1.0 - XMath.Exp(-sigma * delta);

            accumulated += transmittance * alpha * c;
            transmittance *= (1.0 - alpha);

            if (transmittance < 1e-8) break;
        }

        output[index] = accumulated;
    }
}

/// <summary>
/// GPU kernel implementations for trilinear interpolation (hash encoding in NeRF).
/// </summary>
internal static class TrilinearInterpolateKernels
{
    /// <summary>
    /// Trilinear interpolation kernel for float precision.
    /// Grid is [D, H, W, C], positions is [N, 3], output is [N, C]
    /// Each thread computes one output element (one channel for one position).
    /// </summary>
    public static void TrilinearInterpolateFloatImpl(
        Index1D index,
        ArrayView<float> grid,       // [D, H, W, C] flattened
        ArrayView<float> positions,  // [N, 3] flattened
        ArrayView<float> output,     // [N, C] flattened
        int depth, int height, int width, int channels)
    {
        int n = (int)index / channels;
        int c = (int)index % channels;
        int numPositions = (int)output.Length / channels;

        if (n >= numPositions) return;

        // Get position (z, y, x) in [0, dim-1] range
        float z = positions[n * 3 + 0] * (depth - 1);
        float y = positions[n * 3 + 1] * (height - 1);
        float x = positions[n * 3 + 2] * (width - 1);

        // Clamp to valid range
        z = XMath.Max(0f, XMath.Min(depth - 1.001f, z));
        y = XMath.Max(0f, XMath.Min(height - 1.001f, y));
        x = XMath.Max(0f, XMath.Min(width - 1.001f, x));

        // Get integer indices and fractional parts
        int z0 = (int)XMath.Floor(z);
        int y0 = (int)XMath.Floor(y);
        int x0 = (int)XMath.Floor(x);
        int z1 = z0 + 1;
        int y1 = y0 + 1;
        int x1 = x0 + 1;

        // Clamp upper indices
        z1 = XMath.Min(z1, depth - 1);
        y1 = XMath.Min(y1, height - 1);
        x1 = XMath.Min(x1, width - 1);

        float zd = z - z0;
        float yd = y - y0;
        float xd = x - x0;

        // Compute weights for 8 corners
        float w000 = (1 - zd) * (1 - yd) * (1 - xd);
        float w001 = (1 - zd) * (1 - yd) * xd;
        float w010 = (1 - zd) * yd * (1 - xd);
        float w011 = (1 - zd) * yd * xd;
        float w100 = zd * (1 - yd) * (1 - xd);
        float w101 = zd * (1 - yd) * xd;
        float w110 = zd * yd * (1 - xd);
        float w111 = zd * yd * xd;

        // Get grid values at 8 corners (grid layout is [D, H, W, C])
        int stride_d = height * width * channels;
        int stride_h = width * channels;
        int stride_w = channels;

        float v000 = grid[z0 * stride_d + y0 * stride_h + x0 * stride_w + c];
        float v001 = grid[z0 * stride_d + y0 * stride_h + x1 * stride_w + c];
        float v010 = grid[z0 * stride_d + y1 * stride_h + x0 * stride_w + c];
        float v011 = grid[z0 * stride_d + y1 * stride_h + x1 * stride_w + c];
        float v100 = grid[z1 * stride_d + y0 * stride_h + x0 * stride_w + c];
        float v101 = grid[z1 * stride_d + y0 * stride_h + x1 * stride_w + c];
        float v110 = grid[z1 * stride_d + y1 * stride_h + x0 * stride_w + c];
        float v111 = grid[z1 * stride_d + y1 * stride_h + x1 * stride_w + c];

        // Interpolate
        output[index] = w000 * v000 + w001 * v001 + w010 * v010 + w011 * v011 +
                        w100 * v100 + w101 * v101 + w110 * v110 + w111 * v111;
    }

    /// <summary>
    /// Trilinear interpolation kernel for double precision.
    /// </summary>
    public static void TrilinearInterpolateDoubleImpl(
        Index1D index,
        ArrayView<double> grid,       // [D, H, W, C] flattened
        ArrayView<double> positions,  // [N, 3] flattened
        ArrayView<double> output,     // [N, C] flattened
        int depth, int height, int width, int channels)
    {
        int n = (int)index / channels;
        int c = (int)index % channels;
        int numPositions = (int)output.Length / channels;

        if (n >= numPositions) return;

        // Get position (z, y, x) in [0, dim-1] range
        double z = positions[n * 3 + 0] * (depth - 1);
        double y = positions[n * 3 + 1] * (height - 1);
        double x = positions[n * 3 + 2] * (width - 1);

        // Clamp to valid range
        z = XMath.Max(0.0, XMath.Min(depth - 1.001, z));
        y = XMath.Max(0.0, XMath.Min(height - 1.001, y));
        x = XMath.Max(0.0, XMath.Min(width - 1.001, x));

        // Get integer indices and fractional parts
        int z0 = (int)XMath.Floor(z);
        int y0 = (int)XMath.Floor(y);
        int x0 = (int)XMath.Floor(x);
        int z1 = z0 + 1;
        int y1 = y0 + 1;
        int x1 = x0 + 1;

        // Clamp upper indices
        z1 = XMath.Min(z1, depth - 1);
        y1 = XMath.Min(y1, height - 1);
        x1 = XMath.Min(x1, width - 1);

        double zd = z - z0;
        double yd = y - y0;
        double xd = x - x0;

        // Compute weights for 8 corners
        double w000 = (1 - zd) * (1 - yd) * (1 - xd);
        double w001 = (1 - zd) * (1 - yd) * xd;
        double w010 = (1 - zd) * yd * (1 - xd);
        double w011 = (1 - zd) * yd * xd;
        double w100 = zd * (1 - yd) * (1 - xd);
        double w101 = zd * (1 - yd) * xd;
        double w110 = zd * yd * (1 - xd);
        double w111 = zd * yd * xd;

        // Get grid values at 8 corners (grid layout is [D, H, W, C])
        int stride_d = height * width * channels;
        int stride_h = width * channels;
        int stride_w = channels;

        double v000 = grid[z0 * stride_d + y0 * stride_h + x0 * stride_w + c];
        double v001 = grid[z0 * stride_d + y0 * stride_h + x1 * stride_w + c];
        double v010 = grid[z0 * stride_d + y1 * stride_h + x0 * stride_w + c];
        double v011 = grid[z0 * stride_d + y1 * stride_h + x1 * stride_w + c];
        double v100 = grid[z1 * stride_d + y0 * stride_h + x0 * stride_w + c];
        double v101 = grid[z1 * stride_d + y0 * stride_h + x1 * stride_w + c];
        double v110 = grid[z1 * stride_d + y1 * stride_h + x0 * stride_w + c];
        double v111 = grid[z1 * stride_d + y1 * stride_h + x1 * stride_w + c];

        // Interpolate
        output[index] = w000 * v000 + w001 * v001 + w010 * v010 + w011 * v011 +
                        w100 * v100 + w101 * v101 + w110 * v110 + w111 * v111;
    }

    /// <summary>
    /// Backward pass kernel for trilinear interpolation (float precision).
    /// Scatters gradients from output back to grid using atomic operations.
    /// Each thread handles one (position, channel) pair.
    /// </summary>
    public static void TrilinearInterpolateBackwardFloatImpl(
        Index1D index,
        ArrayView<float> gradOutput,  // [N, C] flattened - input gradients
        ArrayView<float> positions,   // [N, 3] flattened - interpolation positions
        ArrayView<float> gradGrid,    // [D, H, W, C] flattened - output gradients (accumulated atomically)
        int depth, int height, int width, int channels)
    {
        int n = (int)index / channels;
        int c = (int)index % channels;
        int numPositions = (int)gradOutput.Length / channels;

        if (n >= numPositions) return;

        float grad = gradOutput[index];

        // Get position (z, y, x) in [0, dim-1] range
        float z = positions[n * 3 + 0] * (depth - 1);
        float y = positions[n * 3 + 1] * (height - 1);
        float x = positions[n * 3 + 2] * (width - 1);

        // Clamp to valid range
        z = XMath.Max(0f, XMath.Min(depth - 1.001f, z));
        y = XMath.Max(0f, XMath.Min(height - 1.001f, y));
        x = XMath.Max(0f, XMath.Min(width - 1.001f, x));

        // Get integer indices and fractional parts
        int z0 = (int)XMath.Floor(z);
        int y0 = (int)XMath.Floor(y);
        int x0 = (int)XMath.Floor(x);
        int z1 = z0 + 1;
        int y1 = y0 + 1;
        int x1 = x0 + 1;

        // Clamp upper indices
        z1 = XMath.Min(z1, depth - 1);
        y1 = XMath.Min(y1, height - 1);
        x1 = XMath.Min(x1, width - 1);

        float zd = z - z0;
        float yd = y - y0;
        float xd = x - x0;

        // Compute weights for 8 corners (same as forward pass)
        float w000 = (1 - zd) * (1 - yd) * (1 - xd);
        float w001 = (1 - zd) * (1 - yd) * xd;
        float w010 = (1 - zd) * yd * (1 - xd);
        float w011 = (1 - zd) * yd * xd;
        float w100 = zd * (1 - yd) * (1 - xd);
        float w101 = zd * (1 - yd) * xd;
        float w110 = zd * yd * (1 - xd);
        float w111 = zd * yd * xd;

        // Compute grid indices (grid layout is [D, H, W, C])
        int stride_d = height * width * channels;
        int stride_h = width * channels;
        int stride_w = channels;

        // Scatter gradient to 8 corners using atomic add
        Atomic.Add(ref gradGrid[z0 * stride_d + y0 * stride_h + x0 * stride_w + c], w000 * grad);
        Atomic.Add(ref gradGrid[z0 * stride_d + y0 * stride_h + x1 * stride_w + c], w001 * grad);
        Atomic.Add(ref gradGrid[z0 * stride_d + y1 * stride_h + x0 * stride_w + c], w010 * grad);
        Atomic.Add(ref gradGrid[z0 * stride_d + y1 * stride_h + x1 * stride_w + c], w011 * grad);
        Atomic.Add(ref gradGrid[z1 * stride_d + y0 * stride_h + x0 * stride_w + c], w100 * grad);
        Atomic.Add(ref gradGrid[z1 * stride_d + y0 * stride_h + x1 * stride_w + c], w101 * grad);
        Atomic.Add(ref gradGrid[z1 * stride_d + y1 * stride_h + x0 * stride_w + c], w110 * grad);
        Atomic.Add(ref gradGrid[z1 * stride_d + y1 * stride_h + x1 * stride_w + c], w111 * grad);
    }

    /// <summary>
    /// Backward pass kernel for trilinear interpolation (double precision).
    /// Scatters gradients from output back to grid using atomic operations.
    /// </summary>
    public static void TrilinearInterpolateBackwardDoubleImpl(
        Index1D index,
        ArrayView<double> gradOutput,  // [N, C] flattened - input gradients
        ArrayView<double> positions,   // [N, 3] flattened - interpolation positions
        ArrayView<double> gradGrid,    // [D, H, W, C] flattened - output gradients (accumulated atomically)
        int depth, int height, int width, int channels)
    {
        int n = (int)index / channels;
        int c = (int)index % channels;
        int numPositions = (int)gradOutput.Length / channels;

        if (n >= numPositions) return;

        double grad = gradOutput[index];

        // Get position (z, y, x) in [0, dim-1] range
        double z = positions[n * 3 + 0] * (depth - 1);
        double y = positions[n * 3 + 1] * (height - 1);
        double x = positions[n * 3 + 2] * (width - 1);

        // Clamp to valid range
        z = XMath.Max(0.0, XMath.Min(depth - 1.001, z));
        y = XMath.Max(0.0, XMath.Min(height - 1.001, y));
        x = XMath.Max(0.0, XMath.Min(width - 1.001, x));

        // Get integer indices and fractional parts
        int z0 = (int)XMath.Floor(z);
        int y0 = (int)XMath.Floor(y);
        int x0 = (int)XMath.Floor(x);
        int z1 = z0 + 1;
        int y1 = y0 + 1;
        int x1 = x0 + 1;

        // Clamp upper indices
        z1 = XMath.Min(z1, depth - 1);
        y1 = XMath.Min(y1, height - 1);
        x1 = XMath.Min(x1, width - 1);

        double zd = z - z0;
        double yd = y - y0;
        double xd = x - x0;

        // Compute weights for 8 corners (same as forward pass)
        double w000 = (1 - zd) * (1 - yd) * (1 - xd);
        double w001 = (1 - zd) * (1 - yd) * xd;
        double w010 = (1 - zd) * yd * (1 - xd);
        double w011 = (1 - zd) * yd * xd;
        double w100 = zd * (1 - yd) * (1 - xd);
        double w101 = zd * (1 - yd) * xd;
        double w110 = zd * yd * (1 - xd);
        double w111 = zd * yd * xd;

        // Compute grid indices (grid layout is [D, H, W, C])
        int stride_d = height * width * channels;
        int stride_h = width * channels;
        int stride_w = channels;

        // Scatter gradient to 8 corners using atomic add
        Atomic.Add(ref gradGrid[z0 * stride_d + y0 * stride_h + x0 * stride_w + c], w000 * grad);
        Atomic.Add(ref gradGrid[z0 * stride_d + y0 * stride_h + x1 * stride_w + c], w001 * grad);
        Atomic.Add(ref gradGrid[z0 * stride_d + y1 * stride_h + x0 * stride_w + c], w010 * grad);
        Atomic.Add(ref gradGrid[z0 * stride_d + y1 * stride_h + x1 * stride_w + c], w011 * grad);
        Atomic.Add(ref gradGrid[z1 * stride_d + y0 * stride_h + x0 * stride_w + c], w100 * grad);
        Atomic.Add(ref gradGrid[z1 * stride_d + y0 * stride_h + x1 * stride_w + c], w101 * grad);
        Atomic.Add(ref gradGrid[z1 * stride_d + y1 * stride_h + x0 * stride_w + c], w110 * grad);
        Atomic.Add(ref gradGrid[z1 * stride_d + y1 * stride_h + x1 * stride_w + c], w111 * grad);
    }
}

/// <summary>
/// GPU-based execution engine using ILGPU for hardware acceleration.
/// </summary>
/// <remarks>
/// <para>
/// GpuEngine provides GPU acceleration for supported numeric types (currently float).
/// Operations on unsupported types automatically fallback to CpuEngine.
/// </para>
/// <para><b>For Beginners:</b> This is the "turbo mode" for your calculations!
///
/// GpuEngine characteristics:
/// - 10-100x faster for large operations (> 100K elements)
/// - Works with float (more types coming soon)
/// - Automatically falls back to CPU for unsupported types
/// - Requires compatible GPU (NVIDIA CUDA, AMD OpenCL, or Intel)
///
/// When to use:
/// - Large neural networks (millions of parameters)
/// - Big datasets (100K+ samples)
/// - Float precision is sufficient
/// - You have a compatible GPU
///
/// The engine handles all the complexity - you just write normal code!
/// </para>
/// <para><b>Thread Safety (Phase B: US-GPU-019):</b>
///
/// GpuEngine is fully thread-safe for concurrent operations:
/// - Multiple threads can call operations simultaneously
/// - Kernel execution is synchronized internally
/// - GPU health tracking uses atomic operations
/// - Memory pools are thread-safe (ConcurrentBag-based)
///
/// Performance notes:
/// - Concurrent small operations may serialize due to synchronization overhead
/// - Large operations (> 100K elements) benefit from parallelism
/// - Consider using separate GpuEngine instances for independent workloads
/// </para>
/// </remarks>
public class GpuEngine : IEngine, IDisposable
{
    private readonly Context? _context;
    private readonly Accelerator? _accelerator;
    private readonly CpuEngine _cpuFallback;
    private readonly AdaptiveThresholds _thresholds;
    private bool _disposed;

    // Thread-safe GPU health tracking (Phase B: US-GPU-019, US-GPU-020)
    // Volatile ensures visibility across threads without full locking
    private volatile bool _gpuHealthy = true;
    private volatile bool _gpuPermanentlyDisabled = false;

    // GPU recovery tracking (Phase B: US-GPU-020)
    private volatile int _consecutiveFailures = 0;
    private long _lastFailureTimeTicks = DateTime.MinValue.Ticks;
    private const int MaxRecoveryAttempts = 3;
    private static readonly TimeSpan RecoveryBackoffPeriod = TimeSpan.FromSeconds(30);

    // Synchronization lock for GPU operations (Phase B: US-GPU-019)
    // ILGPU accelerator is not thread-safe, so we serialize kernel launches
    private readonly object _gpuLock = new object();

    // Lock for GPU recovery operations (Phase B: US-GPU-020)
    private readonly object _recoveryLock = new object();

    // Memory pools (Phase B: US-GPU-002, US-GPU-005)
    private readonly GpuMemoryPool<float>? _memoryPoolFloat;
    private readonly GpuMemoryPool<double>? _memoryPoolDouble;
    private readonly GpuMemoryPool<int>? _memoryPoolInt;
    private readonly GpuMemoryPool<long>? _memoryPoolLong;

    // Kernel cache for float operations (Phase B: US-GPU-001)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>? _addKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>? _subtractKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>? _multiplyKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, float, ArrayView<float>>? _multiplyScalarKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>? _divideKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, float, ArrayView<float>>? _divideScalarKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _sqrtKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, float, ArrayView<float>>? _powerKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>? _maxKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>? _minKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _absKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _expKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _logKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _signKernelFloat;

    // Activation function kernels (Phase B: US-GPU-004 - GPU Acceleration)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _tanhKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _sigmoidKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _reluKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _geluKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _mishKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _swishKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, float, ArrayView<float>>? _eluKernelFloat;

    // Trigonometric function kernels (Phase SIMD)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _sinKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _cosKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _tanKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _sinKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _cosKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _tanKernelDouble;

    // Hyperbolic function kernels (Phase SIMD)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _sinhKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _coshKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _sinhKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _coshKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _tanhKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _sigmoidKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _reluKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _geluKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _mishKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _swishKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, double, ArrayView<double>>? _eluKernelDouble;

    // Kernel cache for double operations (Phase B: US-GPU-005)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>? _addKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>? _subtractKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>? _multiplyKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, double, ArrayView<double>>? _multiplyScalarKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>? _divideKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, double, ArrayView<double>>? _divideScalarKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _sqrtKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, double, ArrayView<double>>? _powerKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>? _maxKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>? _minKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _absKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _expKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _logKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _signKernelDouble;

    // Kernel cache for int operations (Phase B: US-GPU-005)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<int>, ArrayView<int>, ArrayView<int>>? _addKernelInt;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<int>, ArrayView<int>, ArrayView<int>>? _subtractKernelInt;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<int>, ArrayView<int>, ArrayView<int>>? _multiplyKernelInt;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<int>, int, ArrayView<int>>? _multiplyScalarKernelInt;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<int>, ArrayView<int>, ArrayView<int>>? _divideKernelInt;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<int>, int, ArrayView<int>>? _divideScalarKernelInt;

    // Kernel cache for long operations (Phase B: US-GPU-005)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<long>, ArrayView<long>, ArrayView<long>>? _addKernelLong;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<long>, ArrayView<long>, ArrayView<long>>? _subtractKernelLong;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<long>, ArrayView<long>, ArrayView<long>>? _multiplyKernelLong;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<long>, long, ArrayView<long>>? _multiplyScalarKernelLong;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<long>, ArrayView<long>, ArrayView<long>>? _divideKernelLong;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<long>, long, ArrayView<long>>? _divideScalarKernelLong;

    // Kernel cache for matrix operations - float (Phase B: Epic 2)
    private readonly Action<AcceleratorStream, Index2D, ArrayView2D<float, Stride2D.DenseY>, ArrayView2D<float, Stride2D.DenseY>, ArrayView2D<float, Stride2D.DenseY>, int>? _matrixMultiplyKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView2D<float, Stride2D.DenseX>, ArrayView<float>, ArrayView<float>, int, int>? _matrixVectorMultiplyKernelFloat;
    private readonly Action<AcceleratorStream, Index2D, ArrayView2D<float, Stride2D.DenseX>, ArrayView2D<float, Stride2D.DenseX>>? _matrixTransposeKernelFloat;
    private readonly Action<AcceleratorStream, Index2D, ArrayView2D<float, Stride2D.DenseX>, ArrayView2D<float, Stride2D.DenseX>, ArrayView2D<float, Stride2D.DenseX>>? _matrixAddKernelFloat;
    private readonly Action<AcceleratorStream, Index2D, ArrayView2D<float, Stride2D.DenseX>, float, ArrayView2D<float, Stride2D.DenseX>>? _matrixMultiplyScalarKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _swapRowsKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView2D<float, Stride2D.DenseX>, ArrayView<float>, int, int>? _swapColumnsKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView2D<float, Stride2D.DenseX>, ArrayView<float>, int, int>? _getColumnKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView2D<float, Stride2D.DenseX>, ArrayView<float>, int, int>? _setColumnKernelFloat;
    private readonly Action<AcceleratorStream, Index2D, ArrayView<float>, ArrayView<float>, ArrayView2D<float, Stride2D.DenseX>, int, int>? _outerProductKernelFloat;

    // Kernel cache for matrix operations - double (Phase B: Epic 2)
    private readonly Action<AcceleratorStream, Index2D, ArrayView2D<double, Stride2D.DenseY>, ArrayView2D<double, Stride2D.DenseY>, ArrayView2D<double, Stride2D.DenseY>, int>? _matrixMultiplyKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView2D<double, Stride2D.DenseX>, ArrayView<double>, ArrayView<double>, int, int>? _matrixVectorMultiplyKernelDouble;
    private readonly Action<AcceleratorStream, Index2D, ArrayView2D<double, Stride2D.DenseX>, ArrayView2D<double, Stride2D.DenseX>>? _matrixTransposeKernelDouble;
    private readonly Action<AcceleratorStream, Index2D, ArrayView2D<double, Stride2D.DenseX>, ArrayView2D<double, Stride2D.DenseX>, ArrayView2D<double, Stride2D.DenseX>>? _matrixAddKernelDouble;
    private readonly Action<AcceleratorStream, Index2D, ArrayView2D<double, Stride2D.DenseX>, double, ArrayView2D<double, Stride2D.DenseX>>? _matrixMultiplyScalarKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _swapRowsKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView2D<double, Stride2D.DenseX>, ArrayView<double>, int, int>? _swapColumnsKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView2D<double, Stride2D.DenseX>, ArrayView<double>, int, int>? _getColumnKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView2D<double, Stride2D.DenseX>, ArrayView<double>, int, int>? _setColumnKernelDouble;
    private readonly Action<AcceleratorStream, Index2D, ArrayView<double>, ArrayView<double>, ArrayView2D<double, Stride2D.DenseX>, int, int>? _outerProductKernelDouble;

    // Kernel cache for tensor operations - float (Phase B: Epic 3)
    private readonly Action<AcceleratorStream, Index3D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int>? _batchMatMulKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>? _tensorAddKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>? _tensorSubtractKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>? _tensorMultiplyKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, float, ArrayView<float>>? _tensorMultiplyScalarKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>? _tensorDivideKernelFloat;
    // TensorAddMany/TensorMultiplyMany use reduction pattern with existing binary kernels - no additional kernel needed
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int>? _maxPool2DKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int>? _avgPool2DKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, Conv2DParams>? _conv2DKernelFloat;

    // Kernel cache for tensor operations - double (Phase B: Epic 3)
    private readonly Action<AcceleratorStream, Index3D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int>? _batchMatMulKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>? _tensorAddKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>? _tensorSubtractKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>? _tensorMultiplyKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, double, ArrayView<double>>? _tensorMultiplyScalarKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>? _tensorDivideKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int>? _maxPool2DKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int>? _avgPool2DKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, Conv2DParams>? _conv2DKernelDouble;

    // Broadcast add kernels for Conv2D bias addition (shape [B,C,H,W] + [C])
    // Parameters: result, input, bias, batchSize, channels, height, width
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int>? _conv2DBiasAddKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int>? _conv2DBiasAddKernelDouble;

    // Conv3D and Pool3D GPU kernels for volumetric operations
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, Conv3DParams>? _conv3DKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, Conv3DParams>? _conv3DKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, Pool3DParams>? _maxPool3DKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, Pool3DParams>? _maxPool3DKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, Pool3DParams>? _avgPool3DKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, Pool3DParams>? _avgPool3DKernelDouble;

    // NeRF GPU kernels - Positional Encoding and Volume Rendering (3D AI Phase 3)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, PositionalEncodingParams>? _positionalEncodingForwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, PositionalEncodingParams>? _positionalEncodingForwardKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, PositionalEncodingParams>? _positionalEncodingBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, PositionalEncodingParams>? _positionalEncodingBackwardKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, VolumeRenderingParams>? _volumeRenderingForwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, VolumeRenderingParams>? _volumeRenderingForwardKernelDouble;

    // Production GPU kernels - Mathematical functions (Phase C: Production Ready)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _log2KernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _log2KernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _exp2KernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _exp2KernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _exp10KernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _exp10KernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _expM1KernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _expM1KernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _log1PKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _log1PKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _negateKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _negateKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, float, ArrayView<float>>? _powerScalarKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, double, ArrayView<double>>? _powerScalarKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, float, ArrayView<float>>? _scalarMinusTensorKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, double, ArrayView<double>>? _scalarMinusTensorKernelDouble;

    // Production GPU kernels - Utility functions (Phase C: Production Ready)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, float, float, ArrayView<float>>? _clampKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, double, double, ArrayView<double>>? _clampKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, float, ArrayView<float>>? _lerpKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, double, ArrayView<double>>? _lerpKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _reciprocalKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _reciprocalKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _rsqrtKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _rsqrtKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>? _minMagnitudeKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>? _minMagnitudeKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>? _maxMagnitudeKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>? _maxMagnitudeKernelDouble;

    // Production GPU kernels - Rounding operations (Phase C: Production Ready)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _roundKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _roundKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _floorKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _floorKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _ceilingKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _ceilingKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _truncateKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _truncateKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _fracKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _fracKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int>? _trilinearInterpolateKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int>? _trilinearInterpolateKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int>? _trilinearInterpolateBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int>? _trilinearInterpolateBackwardKernelDouble;

    // Production GPU kernels - Fill operations (Phase C: Production Ready)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, float>? _fillKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, double>? _fillKernelDouble;

    // Production GPU kernels - Reduction partial sums (Phase C: Production Ready)
    // Block size for reduction kernels
    private const int ReductionBlockSize = 256;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int>? _partialSumKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int>? _partialSumKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int>? _partialDotProductKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int>? _partialDotProductKernelDouble;

    // Axis-wise reduction kernels (outerSize, reduceSize, innerSize pattern)
    // For reducing along axis: output[outer, inner] = sum(input[outer, :, inner])
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int>? _reduceSumAxisKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int>? _reduceSumAxisKernelDouble;

    // Partial max/min reduction kernels for TensorMaxValue/TensorMinValue
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int>? _partialMaxKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int>? _partialMaxKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int>? _partialMinKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int>? _partialMinKernelDouble;

    // Production GPU kernels - Vector softmax (Phase C: Production Ready)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, float, float>? _softmaxKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, double, double>? _softmaxKernelDouble;

    // Production GPU kernels - Extended Tensor Operations (Phase D: Full Production)
    // TensorMatMul - 2D tensor matrix multiplication
    private readonly Action<AcceleratorStream, Index2D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int>? _tensorMatMulKernelFloat;
    private readonly Action<AcceleratorStream, Index2D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int>? _tensorMatMulKernelDouble;

    // TensorTranspose - 2D tensor transposition
    private readonly Action<AcceleratorStream, Index2D, ArrayView<float>, ArrayView<float>, int, int>? _tensorTransposeKernelFloat;
    private readonly Action<AcceleratorStream, Index2D, ArrayView<double>, ArrayView<double>, int, int>? _tensorTransposeKernelDouble;

    // Tensor Softmax along axis (outerSize, axisSize, innerSize)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int>? _tensorSoftmaxKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int>? _tensorSoftmaxKernelDouble;

    // BatchNorm forward (input, output, gamma, beta, mean, variance, epsilon, batch, features)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, float, int, int>? _batchNormKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, double, int, int>? _batchNormKernelDouble;

    // LayerNorm forward (input, output, gamma, beta, mean, variance, epsilon, batch, features)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, float, int, int>? _layerNormKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, double, int, int>? _layerNormKernelDouble;

    // Upsample (nearest neighbor)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int>? _upsampleKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int>? _upsampleKernelDouble;

    // PixelShuffle (depth-to-space)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int>? _pixelShuffleKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int>? _pixelShuffleKernelDouble;

    // Conv2D backward kernels (input gradient: gradOutput, kernel -> gradInput)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, Conv2DParams>? _conv2DBackwardInputKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, Conv2DParams>? _conv2DBackwardInputKernelDouble;

    // Conv2D backward kernel weights (kernel gradient: gradOutput, input -> gradKernel)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, Conv2DParams>? _conv2DBackwardKernelKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, Conv2DParams>? _conv2DBackwardKernelKernelDouble;

    // MaxPool2D backward (gradOutput, maxIndices -> gradInput)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<int>, ArrayView<float>, int, int, int, int, int, int>? _maxPool2DBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<int>, ArrayView<double>, int, int, int, int, int, int>? _maxPool2DBackwardKernelDouble;

    // MaxPool2D with indices (input -> output, maxIndices)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<int>, int, int, int, int, int, int, int, int, int>? _maxPool2DWithIndicesKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<int>, int, int, int, int, int, int, int, int, int>? _maxPool2DWithIndicesKernelDouble;

    // AvgPool2D backward (gradOutput -> gradInput)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int>? _avgPool2DBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int>? _avgPool2DBackwardKernelDouble;

    // Softmax backward (gradOutput, output -> gradInput)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int>? _softmaxBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int>? _softmaxBackwardKernelDouble;

    // Upsample backward (nearest neighbor)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int>? _upsampleBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int>? _upsampleBackwardKernelDouble;

    // PixelShuffle backward (space-to-depth)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int>? _pixelShuffleBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int>? _pixelShuffleBackwardKernelDouble;

    // ReduceSum along axis (for ReduceMean computation)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int>? _reduceSumKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int>? _reduceSumKernelDouble;

    // Crop kernel (extract region from tensor)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int>? _cropKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int>? _cropKernelDouble;

    // Pad kernel (add padding to tensor)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, float>? _padKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, double>? _padKernelDouble;

    // Trigonometric kernels
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _asinKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _asinKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _acosKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _acosKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _atanKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _atanKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _asinhKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _asinhKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _acoshKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _acoshKernelDouble;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>>? _atanhKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>>? _atanhKernelDouble;

    // DepthwiseConv2D kernels (input -> output)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int, int>? _depthwiseConv2DKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int, int>? _depthwiseConv2DKernelDouble;

    // DepthwiseConv2D backward input kernels
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int, int>? _depthwiseConv2DBackwardInputKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int, int>? _depthwiseConv2DBackwardInputKernelDouble;

    // DepthwiseConv2D backward kernel kernels
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int, int>? _depthwiseConv2DBackwardKernelKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int, int>? _depthwiseConv2DBackwardKernelKernelDouble;

    // ConvTranspose2D kernels
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int, int, int>? _convTranspose2DKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int, int, int>? _convTranspose2DKernelDouble;

    // ConvTranspose2D backward input kernels
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int, int>? _convTranspose2DBackwardInputKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int, int>? _convTranspose2DBackwardInputKernelDouble;

    // ConvTranspose2D backward kernel kernels
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int, int>? _convTranspose2DBackwardKernelKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int, int>? _convTranspose2DBackwardKernelKernelDouble;

    // BatchNorm backward kernels (gradInput, partial sums for gradGamma/gradBeta)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, float, int, int>? _batchNormBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, double, int, int>? _batchNormBackwardKernelDouble;

    // LayerNorm backward kernels
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, float, int, int>? _layerNormBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, double, int, int>? _layerNormBackwardKernelDouble;

    // ReduceMax kernels (output, indices)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<int>, int, int, int>? _reduceMaxKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<int>, int, int, int>? _reduceMaxKernelDouble;

    // ReduceMaxBackward kernels
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<int>, ArrayView<float>, int, int, int>? _reduceMaxBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<int>, ArrayView<double>, int, int, int>? _reduceMaxBackwardKernelDouble;

    // ReduceMean kernels
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int>? _reduceMeanKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int>? _reduceMeanKernelDouble;

    // ReduceMeanBackward kernels
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int>? _reduceMeanBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int>? _reduceMeanBackwardKernelDouble;

    // GumbelSoftmax kernels (input, gumbelNoise, output, temperature, outerSize, axisSize, innerSize)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, float, int, int, int>? _gumbelSoftmaxKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, double, int, int, int>? _gumbelSoftmaxKernelDouble;

    // GumbelSoftmax backward kernels (gradOutput, output, gradInput, temperature, outerSize, axisSize, innerSize)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, float, int, int, int>? _gumbelSoftmaxBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, double, int, int, int>? _gumbelSoftmaxBackwardKernelDouble;

    // TaylorSoftmax kernels (input, output, order, outerSize, axisSize, innerSize)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int>? _taylorSoftmaxKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int>? _taylorSoftmaxKernelDouble;

    // TaylorSoftmax backward kernels (gradOutput, input, output, gradInput, order, outerSize, axisSize, innerSize)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int>? _taylorSoftmaxBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int>? _taylorSoftmaxBackwardKernelDouble;

    // Sparsemax kernels (input, output, outerSize, axisSize, innerSize)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int>? _sparsemaxKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int>? _sparsemaxKernelDouble;

    // Sparsemax backward kernels (gradOutput, output, gradInput, outerSize, axisSize, innerSize)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int>? _sparsemaxBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int>? _sparsemaxBackwardKernelDouble;

    // SphericalSoftmax kernels (input, output, outerSize, axisSize, innerSize)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int, int, int>? _sphericalSoftmaxKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int, int, int>? _sphericalSoftmaxKernelDouble;

    // SphericalSoftmax backward kernels (gradOutput, input, output, gradInput, outerSize, axisSize, innerSize)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int>? _sphericalSoftmaxBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int>? _sphericalSoftmaxBackwardKernelDouble;

    // TensorSumOfSquares kernels - partial sum of squared values for L2 regularization
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, int>? _partialSumOfSquaresKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, int>? _partialSumOfSquaresKernelDouble;

    // TensorEmbeddingLookup kernels - gather rows from embedding table (embeddings, indices, output, embeddingDim)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<int>, ArrayView<float>, int>? _embeddingLookupKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<int>, ArrayView<double>, int>? _embeddingLookupKernelDouble;

    // TensorEmbeddingLookupBackward kernels - scatter-add gradients to embedding table
    // Uses atomics for thread-safe accumulation when same index appears multiple times
    // (gradOutput, indices, gradEmbeddings, embeddingDim, numIndices)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<int>, ArrayView<float>, int, int>? _embeddingLookupBackwardKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<int>, ArrayView<double>, int, int>? _embeddingLookupBackwardKernelDouble;

    // LocallyConnectedConv2D kernels - forward pass with position-specific weights
    // (input, weights, bias, output, params, hasBias)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, LocallyConnectedConv2DParams, int>? _locallyConnectedConv2DKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, LocallyConnectedConv2DParams, int>? _locallyConnectedConv2DKernelDouble;

    // LocallyConnectedConv2D backward input kernels - gradient w.r.t input
    // (gradOutput, weights, gradInput, params)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, LocallyConnectedConv2DParams>? _locallyConnectedConv2DBackwardInputKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, LocallyConnectedConv2DParams>? _locallyConnectedConv2DBackwardInputKernelDouble;

    // LocallyConnectedConv2D backward weights kernels - gradient w.r.t weights
    // (gradOutput, input, gradWeights, params)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, LocallyConnectedConv2DParams>? _locallyConnectedConv2DBackwardWeightsKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, LocallyConnectedConv2DParams>? _locallyConnectedConv2DBackwardWeightsKernelDouble;

    // LocallyConnectedConv2D backward bias kernels - gradient w.r.t bias
    // (gradOutput, gradBias, params)
    private readonly Action<AcceleratorStream, Index1D, ArrayView<float>, ArrayView<float>, LocallyConnectedConv2DParams>? _locallyConnectedConv2DBackwardBiasKernelFloat;
    private readonly Action<AcceleratorStream, Index1D, ArrayView<double>, ArrayView<double>, LocallyConnectedConv2DParams>? _locallyConnectedConv2DBackwardBiasKernelDouble;

    /// <inheritdoc/>
    public string Name => _accelerator != null
        ? $"GPU Engine ({_accelerator.Name})"
        : "GPU Engine (Not Available)";

    /// <inheritdoc/>
    public bool SupportsGpu => _accelerator != null;

    #region Type Acceleration Support Helpers

    /// <summary>
    /// Checks if the specified type supports GPU acceleration based on INumericOperations.
    /// Uses cached acceleration support from MathHelper to avoid repeated type checks.
    /// </summary>
    /// <typeparam name="T">The numeric type to check.</typeparam>
    /// <returns>True if the type supports GPU acceleration; otherwise, false.</returns>
    private static bool IsGpuAcceleratedType<T>() where T : unmanaged
    {
        // Use the cached acceleration support from INumericOperations
        return MathHelper.SupportsGpuAcceleration<T>();
    }

    /// <summary>
    /// Checks if a type supports GPU acceleration for basic operations (add, subtract, multiply, divide).
    /// Basic operations are supported for all GPU-accelerated types (float, double, int, long).
    /// </summary>
    private static bool SupportsGpuBasicOps<T>() where T : unmanaged =>
        MathHelper.SupportsGpuAcceleration<T>();

    /// <summary>
    /// Checks if a type supports GPU acceleration for math operations (sqrt, power, exp, log).
    /// Math operations require floating-point types (float, double).
    /// </summary>
    private static bool SupportsGpuMathOps<T>() where T : unmanaged =>
        MathHelper.SupportsGpuAcceleration<T>() && MathHelper.IsFloatingPoint<T>();

    /// <summary>
    /// Checks if a type supports GPU acceleration for activation functions.
    /// Activation functions require floating-point types (float, double).
    /// </summary>
    private static bool SupportsGpuActivations<T>() where T : unmanaged =>
        MathHelper.SupportsGpuAcceleration<T>() && MathHelper.IsFloatingPoint<T>();

    /// <summary>
    /// Gets the appropriate memory pool for the specified type.
    /// Memory pools are cached per-type for efficient GPU memory management.
    /// </summary>
    private GpuMemoryPool<T>? GetMemoryPool<T>() where T : unmanaged
    {
        if (typeof(T) == typeof(float)) return (GpuMemoryPool<T>?)(object?)_memoryPoolFloat;
        if (typeof(T) == typeof(double)) return (GpuMemoryPool<T>?)(object?)_memoryPoolDouble;
        if (typeof(T) == typeof(int)) return (GpuMemoryPool<T>?)(object?)_memoryPoolInt;
        if (typeof(T) == typeof(long)) return (GpuMemoryPool<T>?)(object?)_memoryPoolLong;
        return null;
    }

    /// <summary>
    /// Determines if GPU acceleration should be used for the given operation size and type.
    /// Considers GPU health, minimum size threshold, and type support.
    /// </summary>
    private bool ShouldUseGpu<T>(int size, int threshold) where T : unmanaged =>
        SupportsGpu && _gpuHealthy && size >= threshold && IsGpuAcceleratedType<T>();

    internal GpuTensor<float>? TryCreatePersistentTensor(Tensor<float> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));
        if (!SupportsGpu || !_gpuHealthy)
            return null;

        try
        {
            var accelerator = _accelerator ?? throw new InvalidOperationException("GPU not initialized");
            var pool = _memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized");

            var gpuTensor = new GpuTensor<float>(accelerator, pool, tensor.Shape);
            gpuTensor.CopyFromCpu(tensor.AsSpan());
            return gpuTensor;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return null;
        }
    }

    internal GpuTensor<double>? TryCreatePersistentTensor(Tensor<double> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));
        if (!SupportsGpu || !_gpuHealthy)
            return null;

        try
        {
            var accelerator = _accelerator ?? throw new InvalidOperationException("GPU not initialized");
            var pool = _memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized");

            var gpuTensor = new GpuTensor<double>(accelerator, pool, tensor.Shape);
            gpuTensor.CopyFromCpu(tensor.AsSpan());
            return gpuTensor;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return null;
        }
    }

    #endregion

    /// <summary>
    /// Initializes a new instance of the GpuEngine class with default adaptive thresholds.
    /// </summary>
    /// <remarks>
    /// <para>
    /// The constructor attempts to initialize GPU acceleration. If no compatible GPU
    /// is found, the engine will still work but operations will fallback to CPU.
    /// </para>
    /// </remarks>
    public GpuEngine()
        : this(AdaptiveThresholds.Default)
    {
    }

    /// <summary>
    /// Initializes a new instance of the GpuEngine class with custom adaptive thresholds.
    /// </summary>
    /// <param name="thresholds">Custom thresholds for adaptive CPU/GPU routing.</param>
    /// <remarks>
    /// <para>
    /// Use this constructor to fine-tune performance for your specific hardware.
    /// See <see cref="AdaptiveThresholds"/> for preset configurations.
    /// </para>
    /// </remarks>
    public GpuEngine(AdaptiveThresholds thresholds)
    {
        _thresholds = thresholds ?? AdaptiveThresholds.Default;
        _cpuFallback = new CpuEngine();

        try
        {
            // Create ILGPU context
            _context = Context.Create(builder => builder.Default().EnableAlgorithms());

            // Try to get preferred device (GPU over CPU)
            var device = _context.GetPreferredDevice(preferCPU: false);

            if (device.AcceleratorType != AcceleratorType.CPU)
            {
                _accelerator = device.CreateAccelerator(_context);
                Console.WriteLine($"[GpuEngine] Initialized: {_accelerator.Name}");

                // Pre-compile all kernels for float operations (Phase B: US-GPU-001)
                Console.WriteLine("[GpuEngine] Pre-compiling GPU kernels...");

                _addKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>(
                    (index, a, b, result) => result[index] = a[index] + b[index]);

                _subtractKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>(
                    (index, a, b, result) => result[index] = a[index] - b[index]);

                _multiplyKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>(
                    (index, a, b, result) => result[index] = a[index] * b[index]);

                _multiplyScalarKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, float, ArrayView<float>>(
                    (index, vec, scalar, result) => result[index] = vec[index] * scalar);

                _divideKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>(
                    (index, a, b, result) => result[index] = a[index] / b[index]);

                _divideScalarKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, float, ArrayView<float>>(
                    (index, vec, scalar, result) => result[index] = vec[index] / scalar);

                _sqrtKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, vec, result) => result[index] = XMath.Sqrt(vec[index]));

                _powerKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, float, ArrayView<float>>(
                    (index, vec, exp, result) => result[index] = XMath.Pow(vec[index], exp));

                _maxKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>(
                    (index, a, b, result) => result[index] = XMath.Max(a[index], b[index]));

                _minKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>(
                    (index, a, b, result) => result[index] = XMath.Min(a[index], b[index]));

                _absKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, vec, result) => result[index] = XMath.Abs(vec[index]));

                _expKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, vec, result) => result[index] = XMath.Exp(vec[index]));

                _logKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, vec, result) => result[index] = XMath.Log(vec[index]));

                _signKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, vec, result) => result[index] = vec[index] > 0 ? 1.0f : (vec[index] < 0 ? -1.0f : 0.0f));

                // Activation function kernels (Phase B: US-GPU-004)
                _tanhKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Tanh(input[index]));

                _sigmoidKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = 1.0f / (1.0f + XMath.Exp(-input[index])));

                _reluKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Max(0.0f, input[index]));

                _geluKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) =>
                    {
                        float x = input[index];
                        float sqrt2OverPi = 0.7978845608028654f;
                        float x_cubed = x * x * x;
                        float inner = x + 0.044715f * x_cubed;
                        float tanh_arg = sqrt2OverPi * inner;
                        float tanh_val = XMath.Tanh(tanh_arg);
                        result[index] = 0.5f * x * (1.0f + tanh_val);
                    });

                _mishKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) =>
                    {
                        float x = input[index];
                        float softplus = XMath.Log(1.0f + XMath.Exp(x));
                        result[index] = x * XMath.Tanh(softplus);
                    });

                _swishKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) =>
                    {
                        float x = input[index];
                        result[index] = x / (1.0f + XMath.Exp(-x));
                    });

                _eluKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, float, ArrayView<float>>(
                    (index, input, alpha, result) =>
                    {
                        float x = input[index];
                        result[index] = x > 0.0f ? x : alpha * (XMath.Exp(x) - 1.0f);
                    });

                // Trigonometric function kernels (Phase SIMD)
                _sinKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Sin(input[index]));

                _cosKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Cos(input[index]));

                _tanKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Tan(input[index]));

                // Hyperbolic function kernels (Phase SIMD)
                _sinhKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Sinh(input[index]));

                _coshKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Cosh(input[index]));

                // Exponential function kernels (Phase SIMD)
                _expKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Exp(input[index]));

                _logKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Log(input[index]));

                Console.WriteLine("[GpuEngine] Float kernels pre-compiled");

                // Double activation function kernels
                _sigmoidKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) =>
                    {
                        double x = input[index];
                        result[index] = 1.0 / (1.0 + XMath.Exp(-x));
                    });

                _reluKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) =>
                    {
                        result[index] = XMath.Max(0.0, input[index]);
                    });

                _geluKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) =>
                    {
                        double x = input[index];
                        result[index] = 0.5 * x * (1.0 + XMath.Tanh(0.7978845608028654 * (x + 0.044715 * x * x * x)));
                    });

                _mishKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) =>
                    {
                        double x = input[index];
                        double softplus = XMath.Log(1.0 + XMath.Exp(x));
                        result[index] = x * XMath.Tanh(softplus);
                    });

                _swishKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) =>
                    {
                        double x = input[index];
                        result[index] = x / (1.0 + XMath.Exp(-x));
                    });

                _eluKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, double, ArrayView<double>>(
                    (index, input, alpha, result) =>
                    {
                        double x = input[index];
                        result[index] = x > 0.0 ? x : alpha * (XMath.Exp(x) - 1.0);
                    });

                Console.WriteLine("[GpuEngine] Double activation kernels pre-compiled");

                // Pre-compile kernels for double operations (Phase B: US-GPU-005)
                _addKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>(
                    (index, a, b, result) => result[index] = a[index] + b[index]);
                _subtractKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>(
                    (index, a, b, result) => result[index] = a[index] - b[index]);
                _multiplyKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>(
                    (index, a, b, result) => result[index] = a[index] * b[index]);
                _multiplyScalarKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, double, ArrayView<double>>(
                    (index, vec, scalar, result) => result[index] = vec[index] * scalar);
                _divideKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>(
                    (index, a, b, result) => result[index] = a[index] / b[index]);
                _divideScalarKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, double, ArrayView<double>>(
                    (index, vec, scalar, result) => result[index] = vec[index] / scalar);
                _sqrtKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, vec, result) => result[index] = XMath.Sqrt(vec[index]));
                _powerKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, double, ArrayView<double>>(
                    (index, vec, exp, result) => result[index] = XMath.Pow(vec[index], exp));

                _maxKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>(
                    (index, a, b, result) => result[index] = XMath.Max(a[index], b[index]));

                _minKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>(
                    (index, a, b, result) => result[index] = XMath.Min(a[index], b[index]));

                _absKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, vec, result) => result[index] = XMath.Abs(vec[index]));

                _expKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, vec, result) => result[index] = XMath.Exp(vec[index]));

                _logKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, vec, result) => result[index] = XMath.Log(vec[index]));

                _signKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, vec, result) => result[index] = vec[index] > 0 ? 1.0 : (vec[index] < 0 ? -1.0 : 0.0));

                // Trigonometric function kernels (Phase SIMD)
                _sinKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Sin(input[index]));

                _cosKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Cos(input[index]));

                _tanKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Tan(input[index]));

                // Hyperbolic function kernels (Phase SIMD)
                _sinhKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Sinh(input[index]));

                _coshKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Cosh(input[index]));

                _tanhKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Tanh(input[index]));

                Console.WriteLine("[GpuEngine] Double kernels pre-compiled");

                // Pre-compile kernels for int operations (Phase B: US-GPU-005)
                _addKernelInt = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<int>, ArrayView<int>, ArrayView<int>>(
                    (index, a, b, result) => result[index] = a[index] + b[index]);
                _subtractKernelInt = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<int>, ArrayView<int>, ArrayView<int>>(
                    (index, a, b, result) => result[index] = a[index] - b[index]);
                _multiplyKernelInt = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<int>, ArrayView<int>, ArrayView<int>>(
                    (index, a, b, result) => result[index] = a[index] * b[index]);
                _multiplyScalarKernelInt = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<int>, int, ArrayView<int>>(
                    (index, vec, scalar, result) => result[index] = vec[index] * scalar);
                _divideKernelInt = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<int>, ArrayView<int>, ArrayView<int>>(
                    (index, a, b, result) => result[index] = a[index] / b[index]);
                _divideScalarKernelInt = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<int>, int, ArrayView<int>>(
                    (index, vec, scalar, result) => result[index] = vec[index] / scalar);
                Console.WriteLine("[GpuEngine] Int kernels pre-compiled");

                // Pre-compile kernels for long operations (Phase B: US-GPU-005)
                _addKernelLong = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<long>, ArrayView<long>, ArrayView<long>>(
                    (index, a, b, result) => result[index] = a[index] + b[index]);
                _subtractKernelLong = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<long>, ArrayView<long>, ArrayView<long>>(
                    (index, a, b, result) => result[index] = a[index] - b[index]);
                _multiplyKernelLong = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<long>, ArrayView<long>, ArrayView<long>>(
                    (index, a, b, result) => result[index] = a[index] * b[index]);
                _multiplyScalarKernelLong = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<long>, long, ArrayView<long>>(
                    (index, vec, scalar, result) => result[index] = vec[index] * scalar);
                _divideKernelLong = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<long>, ArrayView<long>, ArrayView<long>>(
                    (index, a, b, result) => result[index] = a[index] / b[index]);
                _divideScalarKernelLong = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<long>, long, ArrayView<long>>(
                    (index, vec, scalar, result) => result[index] = vec[index] / scalar);
                Console.WriteLine("[GpuEngine] Long kernels pre-compiled");

                // Pre-compile kernels for matrix operations - float (Phase B: Epic 2)
                _matrixMultiplyKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index2D, ArrayView2D<float, Stride2D.DenseY>, ArrayView2D<float, Stride2D.DenseY>, ArrayView2D<float, Stride2D.DenseY>, int>(
                    (index, a, b, result, k) =>
                    {
                        float sum = 0;
                        for (int i = 0; i < k; i++)
                            sum += a[index.X, i] * b[i, index.Y];
                        result[index] = sum;
                    });

                _matrixVectorMultiplyKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView2D<float, Stride2D.DenseX>, ArrayView<float>, ArrayView<float>, int, int>(
                    (index, matrix, vector, result, rows, cols) =>
                    {
                        float sum = 0;
                        for (int j = 0; j < cols; j++)
                            sum += matrix[index, j] * vector[j];
                        result[index] = sum;
                    });

                _matrixTransposeKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index2D, ArrayView2D<float, Stride2D.DenseX>, ArrayView2D<float, Stride2D.DenseX>>(
                    (index, input, output) => output[index.Y, index.X] = input[index]);

                _matrixAddKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index2D, ArrayView2D<float, Stride2D.DenseX>, ArrayView2D<float, Stride2D.DenseX>, ArrayView2D<float, Stride2D.DenseX>>(
                    (index, a, b, result) => result[index] = a[index] + b[index]);

                _matrixMultiplyScalarKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index2D, ArrayView2D<float, Stride2D.DenseX>, float, ArrayView2D<float, Stride2D.DenseX>>(
                    (index, matrix, scalar, result) => result[index] = matrix[index] * scalar);

                // Swap rows kernel (Phase B: Matrix operations)
                _swapRowsKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, row1, row2) =>
                    {
                        float temp = row1[index];
                        row1[index] = row2[index];
                        row2[index] = temp;
                    });

                // Swap columns kernel (Phase B: Matrix operations)
                _swapColumnsKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView2D<float, Stride2D.DenseX>, ArrayView<float>, int, int>(
                    (index, matrix, tempCol, col1, col2) =>
                    {
                        // Each thread handles one row
                        float temp = matrix[index, col1];
                        matrix[index, col1] = matrix[index, col2];
                        matrix[index, col2] = temp;
                    });

                // Get column kernel (Phase B: Matrix operations)
                _getColumnKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView2D<float, Stride2D.DenseX>, ArrayView<float>, int, int>(
                    (index, matrix, result, col, rows) =>
                    {
                        result[index] = matrix[index, col];
                    });

                // Set column kernel (Phase B: Matrix operations)
                _setColumnKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView2D<float, Stride2D.DenseX>, ArrayView<float>, int, int>(
                    (index, matrix, values, col, rows) =>
                    {
                        matrix[index, col] = values[index];
                    });

                // Outer product kernel (Phase B: Matrix operations)
                _outerProductKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index2D, ArrayView<float>, ArrayView<float>, ArrayView2D<float, Stride2D.DenseX>, int, int>(
                    (index, a, b, result, aLen, bLen) =>
                    {
                        result[index] = a[index.X] * b[index.Y];
                    });
                Console.WriteLine("[GpuEngine] Float matrix kernels pre-compiled");

                // Pre-compile kernels for matrix operations - double (Phase B: Epic 2)
                _matrixMultiplyKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index2D, ArrayView2D<double, Stride2D.DenseY>, ArrayView2D<double, Stride2D.DenseY>, ArrayView2D<double, Stride2D.DenseY>, int>(
                    (index, a, b, result, k) =>
                    {
                        double sum = 0;
                        for (int i = 0; i < k; i++)
                            sum += a[index.X, i] * b[i, index.Y];
                        result[index] = sum;
                    });

                _matrixVectorMultiplyKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView2D<double, Stride2D.DenseX>, ArrayView<double>, ArrayView<double>, int, int>(
                    (index, matrix, vector, result, rows, cols) =>
                    {
                        double sum = 0;
                        for (int j = 0; j < cols; j++)
                            sum += matrix[index, j] * vector[j];
                        result[index] = sum;
                    });

                _matrixTransposeKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index2D, ArrayView2D<double, Stride2D.DenseX>, ArrayView2D<double, Stride2D.DenseX>>(
                    (index, input, output) => output[index.Y, index.X] = input[index]);

                _matrixAddKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index2D, ArrayView2D<double, Stride2D.DenseX>, ArrayView2D<double, Stride2D.DenseX>, ArrayView2D<double, Stride2D.DenseX>>(
                    (index, a, b, result) => result[index] = a[index] + b[index]);

                _matrixMultiplyScalarKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index2D, ArrayView2D<double, Stride2D.DenseX>, double, ArrayView2D<double, Stride2D.DenseX>>(
                    (index, matrix, scalar, result) => result[index] = matrix[index] * scalar);

                // Swap rows kernel (Phase B: Matrix operations)
                _swapRowsKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, row1, row2) =>
                    {
                        double temp = row1[index];
                        row1[index] = row2[index];
                        row2[index] = temp;
                    });

                // Swap columns kernel (Phase B: Matrix operations)
                _swapColumnsKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView2D<double, Stride2D.DenseX>, ArrayView<double>, int, int>(
                    (index, matrix, tempCol, col1, col2) =>
                    {
                        // Each thread handles one row
                        double temp = matrix[index, col1];
                        matrix[index, col1] = matrix[index, col2];
                        matrix[index, col2] = temp;
                    });

                // Get column kernel (Phase B: Matrix operations)
                _getColumnKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView2D<double, Stride2D.DenseX>, ArrayView<double>, int, int>(
                    (index, matrix, result, col, rows) =>
                    {
                        result[index] = matrix[index, col];
                    });

                // Set column kernel (Phase B: Matrix operations)
                _setColumnKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView2D<double, Stride2D.DenseX>, ArrayView<double>, int, int>(
                    (index, matrix, values, col, rows) =>
                    {
                        matrix[index, col] = values[index];
                    });

                // Outer product kernel (Phase B: Matrix operations)
                _outerProductKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index2D, ArrayView<double>, ArrayView<double>, ArrayView2D<double, Stride2D.DenseX>, int, int>(
                    (index, a, b, result, aLen, bLen) =>
                    {
                        result[index] = a[index.X] * b[index.Y];
                    });
                Console.WriteLine("[GpuEngine] Double matrix kernels pre-compiled");

                // Pre-compile kernels for tensor operations - float (Phase B: Epic 3)
                _batchMatMulKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index3D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int>(
                    (index, a, b, result, m, k, n) =>
                    {
                        int batch = index.X;
                        int i = index.Y;
                        int j = index.Z;

                        // Compute flat indices for 3D tensors stored in row-major order
                        // Tensor shape: [batchSize, rows, cols]
                        // Flat index: batch * (rows * cols) + row * cols + col
                        float sum = 0;
                        for (int p = 0; p < k; p++)
                        {
                            int aIndex = batch * (m * k) + i * k + p;
                            int bIndex = batch * (k * n) + p * n + j;
                            sum += a[aIndex] * b[bIndex];
                        }

                        int resultIndex = batch * (m * n) + i * n + j;
                        result[resultIndex] = sum;
                    });

                // Pre-compile kernels for tensor operations - double (Phase B: Epic 3)
                _batchMatMulKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index3D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int>(
                    (index, a, b, result, m, k, n) =>
                    {
                        int batch = index.X;
                        int i = index.Y;
                        int j = index.Z;

                        // Compute flat indices for 3D tensors stored in row-major order
                        double sum = 0;
                        for (int p = 0; p < k; p++)
                        {
                            int aIndex = batch * (m * k) + i * k + p;
                            int bIndex = batch * (k * n) + p * n + j;
                            sum += a[aIndex] * b[bIndex];
                        }

                        int resultIndex = batch * (m * n) + i * n + j;
                        result[resultIndex] = sum;
                    });

                // Pre-compile tensor element-wise kernels - float (Phase B: Epic 3, US-GPU-014)
                _tensorAddKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>(
                    (index, a, b, result) => result[index] = a[index] + b[index]);

                _tensorSubtractKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>(
                    (index, a, b, result) => result[index] = a[index] - b[index]);

                _tensorMultiplyKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>(
                    (index, a, b, result) => result[index] = a[index] * b[index]);

                _tensorMultiplyScalarKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, float, ArrayView<float>>(
                    (index, tensor, scalar, result) => result[index] = tensor[index] * scalar);

                _tensorDivideKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>(
                    (index, a, b, result) => result[index] = a[index] / b[index]);

                // Pre-compile tensor element-wise kernels - double (Phase B: Epic 3, US-GPU-014)
                _tensorAddKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>(
                    (index, a, b, result) => result[index] = a[index] + b[index]);

                _tensorSubtractKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>(
                    (index, a, b, result) => result[index] = a[index] - b[index]);

                _tensorMultiplyKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>(
                    (index, a, b, result) => result[index] = a[index] * b[index]);

                _tensorMultiplyScalarKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, double, ArrayView<double>>(
                    (index, tensor, scalar, result) => result[index] = tensor[index] * scalar);

                _tensorDivideKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>(
                    (index, a, b, result) => result[index] = a[index] / b[index]);

                // Pre-compile Conv2D bias add kernels for broadcast add (shape [B,C,H,W] + [C])
                // This is a specialized broadcast add for adding per-channel bias to Conv2D output
                _conv2DBiasAddKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int>(
                    (index, input, bias, result, batchSize, channels, height, width) =>
                    {
                        // Convert flat index to 4D coordinates: [b, c, h, w]
                        int w = (int)index % width;
                        int temp = (int)index / width;
                        int h = temp % height;
                        temp /= height;
                        int c = temp % channels;
                        // b = temp / channels (not needed for computation)

                        // Add bias[c] to input[index]
                        result[index] = input[index] + bias[c];
                    });

                _conv2DBiasAddKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int>(
                    (index, input, bias, result, batchSize, channels, height, width) =>
                    {
                        // Convert flat index to 4D coordinates: [b, c, h, w]
                        int w = (int)index % width;
                        int temp = (int)index / width;
                        int h = temp % height;
                        temp /= height;
                        int c = temp % channels;
                        // b = temp / channels (not needed for computation)

                        // Add bias[c] to input[index]
                        result[index] = input[index] + bias[c];
                    });

                // Pre-compile pooling kernels - float (Phase B: Epic 3, US-GPU-012)
                _maxPool2DKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int>(
                    (index, input, output, batch, channels, height, width, outputHeight, outputWidth, poolSize, stride, padding) =>
                    {
                        // Convert flat index to 4D coordinates
                        int ow = (int)index % outputWidth;
                        int temp = (int)index / outputWidth;
                        int oh = temp % outputHeight;
                        temp /= outputHeight;
                        int c = temp % channels;
                        int b = temp / channels;

                        float maxVal = float.NegativeInfinity;

                        for (int kh = 0; kh < poolSize; kh++)
                        {
                            for (int kw = 0; kw < poolSize; kw++)
                            {
                                int ih = oh * stride + kh - padding;
                                int iw = ow * stride + kw - padding;

                                if (ih >= 0 && ih < height && iw >= 0 && iw < width)
                                {
                                    int inputIdx = ((b * channels + c) * height + ih) * width + iw;
                                    float val = input[inputIdx];
                                    if (val > maxVal) maxVal = val;
                                }
                            }
                        }

                        output[index] = maxVal;
                    });

                _avgPool2DKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int>(
                    (index, input, output, batch, channels, height, width, outputHeight, outputWidth, poolSize, stride, padding) =>
                    {
                        // Convert flat index to 4D coordinates
                        int ow = (int)index % outputWidth;
                        int temp = (int)index / outputWidth;
                        int oh = temp % outputHeight;
                        temp /= outputHeight;
                        int c = temp % channels;
                        int b = temp / channels;

                        float sum = 0;
                        int count = 0;

                        for (int kh = 0; kh < poolSize; kh++)
                        {
                            for (int kw = 0; kw < poolSize; kw++)
                            {
                                int ih = oh * stride + kh - padding;
                                int iw = ow * stride + kw - padding;

                                if (ih >= 0 && ih < height && iw >= 0 && iw < width)
                                {
                                    int inputIdx = ((b * channels + c) * height + ih) * width + iw;
                                    sum += input[inputIdx];
                                    count++;
                                }
                            }
                        }

                        output[index] = count > 0 ? sum / count : 0;
                    });

                // Pre-compile pooling kernels - double (Phase B: Epic 3, US-GPU-012)
                _maxPool2DKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int>(
                    (index, input, output, batch, channels, height, width, outputHeight, outputWidth, poolSize, stride, padding) =>
                    {
                        // Convert flat index to 4D coordinates
                        int ow = (int)index % outputWidth;
                        int temp = (int)index / outputWidth;
                        int oh = temp % outputHeight;
                        temp /= outputHeight;
                        int c = temp % channels;
                        int b = temp / channels;

                        double maxVal = double.NegativeInfinity;

                        for (int kh = 0; kh < poolSize; kh++)
                        {
                            for (int kw = 0; kw < poolSize; kw++)
                            {
                                int ih = oh * stride + kh - padding;
                                int iw = ow * stride + kw - padding;

                                if (ih >= 0 && ih < height && iw >= 0 && iw < width)
                                {
                                    int inputIdx = ((b * channels + c) * height + ih) * width + iw;
                                    double val = input[inputIdx];
                                    if (val > maxVal) maxVal = val;
                                }
                            }
                        }

                        output[index] = maxVal;
                    });

                _avgPool2DKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int>(
                    (index, input, output, batch, channels, height, width, outputHeight, outputWidth, poolSize, stride, padding) =>
                    {
                        // Convert flat index to 4D coordinates
                        int ow = (int)index % outputWidth;
                        int temp = (int)index / outputWidth;
                        int oh = temp % outputHeight;
                        temp /= outputHeight;
                        int c = temp % channels;
                        int b = temp / channels;

                        double sum = 0;
                        int count = 0;

                        for (int kh = 0; kh < poolSize; kh++)
                        {
                            for (int kw = 0; kw < poolSize; kw++)
                            {
                                int ih = oh * stride + kh - padding;
                                int iw = ow * stride + kw - padding;

                                if (ih >= 0 && ih < height && iw >= 0 && iw < width)
                                {
                                    int inputIdx = ((b * channels + c) * height + ih) * width + iw;
                                    sum += input[inputIdx];
                                    count++;
                                }
                            }
                        }

                        output[index] = count > 0 ? sum / count : 0;
                    });

                // Pre-compile Conv2D kernels - float (Phase B: Epic 3, US-GPU-011)
                // Using Conv2DParams struct reduces parameters from 16 to 5 (under Action<> limit)
                _conv2DKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, Conv2DParams>(
                    Conv2DKernels.Conv2DKernelFloatImpl);

                // Pre-compile Conv2D kernels - double (Phase B: Epic 3, US-GPU-011)
                // Using Conv2DParams struct reduces parameters from 16 to 5 (under Action<> limit)
                _conv2DKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, Conv2DParams>(
                    Conv2DKernels.Conv2DKernelDoubleImpl);

                // Pre-compile Conv3D kernels for volumetric convolution
                _conv3DKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, Conv3DParams>(
                    Conv3DKernels.Conv3DKernelFloatImpl);
                _conv3DKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, Conv3DParams>(
                    Conv3DKernels.Conv3DKernelDoubleImpl);

                // Pre-compile Pool3D kernels for volumetric pooling
                _maxPool3DKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, Pool3DParams>(
                    Pool3DKernels.MaxPool3DKernelFloatImpl);
                _maxPool3DKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, Pool3DParams>(
                    Pool3DKernels.MaxPool3DKernelDoubleImpl);
                _avgPool3DKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, Pool3DParams>(
                    Pool3DKernels.AvgPool3DKernelFloatImpl);
                _avgPool3DKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, Pool3DParams>(
                    Pool3DKernels.AvgPool3DKernelDoubleImpl);

                // Pre-compile NeRF GPU kernels - Positional Encoding and Volume Rendering (3D AI Phase 3)
                _positionalEncodingForwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, PositionalEncodingParams>(
                    PositionalEncodingKernels.PositionalEncodingForwardFloat);
                _positionalEncodingForwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, PositionalEncodingParams>(
                    PositionalEncodingKernels.PositionalEncodingForwardDouble);
                _positionalEncodingBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, PositionalEncodingParams>(
                    PositionalEncodingKernels.PositionalEncodingBackwardFloat);
                _positionalEncodingBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, PositionalEncodingParams>(
                    PositionalEncodingKernels.PositionalEncodingBackwardDouble);
                _volumeRenderingForwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, VolumeRenderingParams>(
                    VolumeRenderingKernels.VolumeRenderingForwardFloat);
                _volumeRenderingForwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, VolumeRenderingParams>(
                    VolumeRenderingKernels.VolumeRenderingForwardDouble);

                Console.WriteLine("[GpuEngine] Tensor kernels pre-compiled");

                // Pre-compile production GPU kernels - Mathematical functions (Phase C: Production Ready)
                _log2KernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Log2(input[index]));
                _log2KernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Log2(input[index]));
                _exp2KernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Exp2(input[index]));
                _exp2KernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Exp2(input[index]));
                _exp10KernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Pow(10.0f, input[index]));
                _exp10KernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Pow(10.0, input[index]));
                _expM1KernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Exp(input[index]) - 1.0f);
                _expM1KernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Exp(input[index]) - 1.0);
                _log1PKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Log(1.0f + input[index]));
                _log1PKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Log(1.0 + input[index]));
                _negateKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = -input[index]);
                _negateKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = -input[index]);
                _powerScalarKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, float, ArrayView<float>>(
                    (index, input, exponent, result) => result[index] = XMath.Pow(input[index], exponent));
                _powerScalarKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, double, ArrayView<double>>(
                    (index, input, exponent, result) => result[index] = XMath.Pow(input[index], exponent));
                _scalarMinusTensorKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, float, ArrayView<float>>(
                    (index, input, scalar, result) => result[index] = scalar - input[index]);
                _scalarMinusTensorKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, double, ArrayView<double>>(
                    (index, input, scalar, result) => result[index] = scalar - input[index]);
                Console.WriteLine("[GpuEngine] Mathematical kernels pre-compiled");

                // Pre-compile production GPU kernels - Utility functions (Phase C: Production Ready)
                _clampKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, float, float, ArrayView<float>>(
                    (index, input, min, max, result) => result[index] = XMath.Clamp(input[index], min, max));
                _clampKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, double, double, ArrayView<double>>(
                    (index, input, min, max, result) => result[index] = XMath.Clamp(input[index], min, max));
                _lerpKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, float, ArrayView<float>>(
                    (index, a, b, t, result) => result[index] = a[index] + t * (b[index] - a[index]));
                _lerpKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, double, ArrayView<double>>(
                    (index, a, b, t, result) => result[index] = a[index] + t * (b[index] - a[index]));
                _reciprocalKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = 1.0f / input[index]);
                _reciprocalKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = 1.0 / input[index]);
                _rsqrtKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Rsqrt(input[index]));
                _rsqrtKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = 1.0 / XMath.Sqrt(input[index]));
                _minMagnitudeKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>(
                    (index, a, b, result) =>
                    {
                        float absA = XMath.Abs(a[index]);
                        float absB = XMath.Abs(b[index]);
                        result[index] = absA <= absB ? a[index] : b[index];
                    });
                _minMagnitudeKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>(
                    (index, a, b, result) =>
                    {
                        double absA = XMath.Abs(a[index]);
                        double absB = XMath.Abs(b[index]);
                        result[index] = absA <= absB ? a[index] : b[index];
                    });
                _maxMagnitudeKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>>(
                    (index, a, b, result) =>
                    {
                        float absA = XMath.Abs(a[index]);
                        float absB = XMath.Abs(b[index]);
                        result[index] = absA >= absB ? a[index] : b[index];
                    });
                _maxMagnitudeKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>>(
                    (index, a, b, result) =>
                    {
                        double absA = XMath.Abs(a[index]);
                        double absB = XMath.Abs(b[index]);
                        result[index] = absA >= absB ? a[index] : b[index];
                    });
                Console.WriteLine("[GpuEngine] Utility kernels pre-compiled");

                // Pre-compile production GPU kernels - Rounding operations (Phase C: Production Ready)
                _roundKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Round(input[index]));
                _roundKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Round(input[index]));
                _floorKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Floor(input[index]));
                _floorKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Floor(input[index]));
                _ceilingKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Ceiling(input[index]));
                _ceilingKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Ceiling(input[index]));
                _truncateKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = XMath.Truncate(input[index]));
                _truncateKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = XMath.Truncate(input[index]));
                _fracKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, result) => result[index] = input[index] - XMath.Floor(input[index]));
                _fracKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, result) => result[index] = input[index] - XMath.Floor(input[index]));
                _trilinearInterpolateKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int>(
                    TrilinearInterpolateKernels.TrilinearInterpolateFloatImpl);
                _trilinearInterpolateKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int>(
                    TrilinearInterpolateKernels.TrilinearInterpolateDoubleImpl);
                _trilinearInterpolateBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int>(
                    TrilinearInterpolateKernels.TrilinearInterpolateBackwardFloatImpl);
                _trilinearInterpolateBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int>(
                    TrilinearInterpolateKernels.TrilinearInterpolateBackwardDoubleImpl);
                Console.WriteLine("[GpuEngine] Rounding and trilinear interpolation kernels pre-compiled");

                // Pre-compile production GPU kernels - Fill operations (Phase C: Production Ready)
                _fillKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, float>(
                    (index, result, value) => result[index] = value);
                _fillKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, double>(
                    (index, result, value) => result[index] = value);
                Console.WriteLine("[GpuEngine] Fill kernels pre-compiled");

                // Pre-compile production GPU kernels - Reduction partial sums (Phase C: Production Ready)
                // Each thread computes partial sum for a chunk of elements
                _partialSumKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int>(
                    (blockIdx, input, partialSums, length) =>
                    {
                        int startIdx = (int)blockIdx * ReductionBlockSize;
                        float sum = 0.0f;
                        for (int i = 0; i < ReductionBlockSize && startIdx + i < length; i++)
                            sum += input[startIdx + i];
                        partialSums[blockIdx] = sum;
                    });
                _partialSumKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int>(
                    (blockIdx, input, partialSums, length) =>
                    {
                        int startIdx = (int)blockIdx * ReductionBlockSize;
                        double sum = 0.0;
                        for (int i = 0; i < ReductionBlockSize && startIdx + i < length; i++)
                            sum += input[startIdx + i];
                        partialSums[blockIdx] = sum;
                    });
                _partialDotProductKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int>(
                    (blockIdx, a, b, partialSums, length) =>
                    {
                        int startIdx = (int)blockIdx * ReductionBlockSize;
                        float sum = 0.0f;
                        for (int i = 0; i < ReductionBlockSize && startIdx + i < length; i++)
                            sum += a[startIdx + i] * b[startIdx + i];
                        partialSums[blockIdx] = sum;
                    });
                _partialDotProductKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int>(
                    (blockIdx, a, b, partialSums, length) =>
                    {
                        int startIdx = (int)blockIdx * ReductionBlockSize;
                        double sum = 0.0;
                        for (int i = 0; i < ReductionBlockSize && startIdx + i < length; i++)
                            sum += a[startIdx + i] * b[startIdx + i];
                        partialSums[blockIdx] = sum;
                    });

                // Axis-wise reduction kernels - reduces along middle dimension
                // Input layout: [outerSize, reduceSize, innerSize] flattened
                // Output layout: [outerSize, innerSize] flattened
                // Each thread computes one output element by summing along reduceSize
                _reduceSumAxisKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int>(
                    (outputIdx, input, output, outerSize, reduceSize, innerSize) =>
                    {
                        int outer = (int)outputIdx / innerSize;
                        int inner = (int)outputIdx % innerSize;
                        float sum = 0.0f;
                        int baseIdx = outer * reduceSize * innerSize + inner;
                        for (int r = 0; r < reduceSize; r++)
                            sum += input[baseIdx + r * innerSize];
                        output[outputIdx] = sum;
                    });
                _reduceSumAxisKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int>(
                    (outputIdx, input, output, outerSize, reduceSize, innerSize) =>
                    {
                        int outer = (int)outputIdx / innerSize;
                        int inner = (int)outputIdx % innerSize;
                        double sum = 0.0;
                        int baseIdx = outer * reduceSize * innerSize + inner;
                        for (int r = 0; r < reduceSize; r++)
                            sum += input[baseIdx + r * innerSize];
                        output[outputIdx] = sum;
                    });

                // Partial max reduction kernels - each block computes max of ReductionBlockSize elements
                _partialMaxKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int>(
                    (blockIdx, input, partialMaxes, length) =>
                    {
                        int startIdx = (int)blockIdx * ReductionBlockSize;
                        if (startIdx >= length) return;
                        float maxVal = input[startIdx];
                        for (int i = 1; i < ReductionBlockSize && startIdx + i < length; i++)
                        {
                            float val = input[startIdx + i];
                            if (val > maxVal) maxVal = val;
                        }
                        partialMaxes[blockIdx] = maxVal;
                    });
                _partialMaxKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int>(
                    (blockIdx, input, partialMaxes, length) =>
                    {
                        int startIdx = (int)blockIdx * ReductionBlockSize;
                        if (startIdx >= length) return;
                        double maxVal = input[startIdx];
                        for (int i = 1; i < ReductionBlockSize && startIdx + i < length; i++)
                        {
                            double val = input[startIdx + i];
                            if (val > maxVal) maxVal = val;
                        }
                        partialMaxes[blockIdx] = maxVal;
                    });

                // Partial min reduction kernels
                _partialMinKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int>(
                    (blockIdx, input, partialMins, length) =>
                    {
                        int startIdx = (int)blockIdx * ReductionBlockSize;
                        if (startIdx >= length) return;
                        float minVal = input[startIdx];
                        for (int i = 1; i < ReductionBlockSize && startIdx + i < length; i++)
                        {
                            float val = input[startIdx + i];
                            if (val < minVal) minVal = val;
                        }
                        partialMins[blockIdx] = minVal;
                    });
                _partialMinKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int>(
                    (blockIdx, input, partialMins, length) =>
                    {
                        int startIdx = (int)blockIdx * ReductionBlockSize;
                        if (startIdx >= length) return;
                        double minVal = input[startIdx];
                        for (int i = 1; i < ReductionBlockSize && startIdx + i < length; i++)
                        {
                            double val = input[startIdx + i];
                            if (val < minVal) minVal = val;
                        }
                        partialMins[blockIdx] = minVal;
                    });
                Console.WriteLine("[GpuEngine] Reduction kernels pre-compiled");

                // Pre-compile production GPU kernels - Vector softmax (Phase C: Production Ready)
                // Softmax kernel takes pre-computed max and sum for numerical stability
                _softmaxKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, float, float>(
                    (index, input, result, maxVal, expSum) =>
                    {
                        result[index] = XMath.Exp(input[index] - maxVal) / expSum;
                    });
                _softmaxKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, double, double>(
                    (index, input, result, maxVal, expSum) =>
                    {
                        result[index] = XMath.Exp(input[index] - maxVal) / expSum;
                    });
                Console.WriteLine("[GpuEngine] Softmax kernels pre-compiled");

                // Pre-compile production GPU kernels - Extended Tensor Operations (Phase D: Full Production)
                // TensorMatMul - 2D tensor matrix multiplication (reuses matrix multiply logic)
                _tensorMatMulKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index2D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int>(
                    (index, a, b, result, k) =>
                    {
                        int m = index.X;
                        int n = index.Y;
                        float sum = 0;
                        for (int i = 0; i < k; i++)
                            sum += a[m * k + i] * b[i * n + index.Y]; // Use flat array indexing
                        result[index.X * n + index.Y] = sum;
                    });
                _tensorMatMulKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index2D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int>(
                    (index, a, b, result, k) =>
                    {
                        int m = index.X;
                        int n = index.Y;
                        double sum = 0;
                        for (int i = 0; i < k; i++)
                            sum += a[m * k + i] * b[i * n + index.Y];
                        result[index.X * n + index.Y] = sum;
                    });
                Console.WriteLine("[GpuEngine] TensorMatMul kernels pre-compiled");

                // TensorTranspose - 2D tensor transposition
                _tensorTransposeKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index2D, ArrayView<float>, ArrayView<float>, int, int>(
                    (index, input, output, rows, cols) =>
                    {
                        // input[row, col] -> output[col, row]
                        output[index.Y * rows + index.X] = input[index.X * cols + index.Y];
                    });
                _tensorTransposeKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index2D, ArrayView<double>, ArrayView<double>, int, int>(
                    (index, input, output, rows, cols) =>
                    {
                        output[index.Y * rows + index.X] = input[index.X * cols + index.Y];
                    });
                Console.WriteLine("[GpuEngine] TensorTranspose kernels pre-compiled");

                // Upsample (nearest neighbor) - for spatial upsampling in neural networks
                _upsampleKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int>(
                    (flatIdx, input, output, batch, channels, height, width, scaleH, scaleW) =>
                    {
                        int newHeight = height * scaleH;
                        int newWidth = width * scaleW;
                        int ow = (int)flatIdx % newWidth;
                        int temp = (int)flatIdx / newWidth;
                        int oh = temp % newHeight;
                        temp /= newHeight;
                        int c = temp % channels;
                        int b = temp / channels;
                        int ih = oh / scaleH;
                        int iw = ow / scaleW;
                        int inputIdx = ((b * channels + c) * height + ih) * width + iw;
                        output[flatIdx] = input[inputIdx];
                    });
                _upsampleKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int>(
                    (flatIdx, input, output, batch, channels, height, width, scaleH, scaleW) =>
                    {
                        int newHeight = height * scaleH;
                        int newWidth = width * scaleW;
                        int ow = (int)flatIdx % newWidth;
                        int temp = (int)flatIdx / newWidth;
                        int oh = temp % newHeight;
                        temp /= newHeight;
                        int c = temp % channels;
                        int b = temp / channels;
                        int ih = oh / scaleH;
                        int iw = ow / scaleW;
                        int inputIdx = ((b * channels + c) * height + ih) * width + iw;
                        output[flatIdx] = input[inputIdx];
                    });
                Console.WriteLine("[GpuEngine] Upsample kernels pre-compiled");

                // PixelShuffle (depth-to-space) - for super-resolution networks
                _pixelShuffleKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int>(
                    (flatIdx, input, output, batch, channels, height, width, upscaleFactor) =>
                    {
                        int r = upscaleFactor;
                        int newChannels = channels / (r * r);
                        int newHeight = height * r;
                        int newWidth = width * r;
                        // output index -> input index mapping
                        int ow = (int)flatIdx % newWidth;
                        int temp = (int)flatIdx / newWidth;
                        int oh = temp % newHeight;
                        temp /= newHeight;
                        int oc = temp % newChannels;
                        int b = temp / newChannels;
                        int ih = oh / r;
                        int iw = ow / r;
                        int subH = oh % r;
                        int subW = ow % r;
                        int ic = oc * r * r + subH * r + subW;
                        int inputIdx = ((b * channels + ic) * height + ih) * width + iw;
                        output[flatIdx] = input[inputIdx];
                    });
                _pixelShuffleKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int>(
                    (flatIdx, input, output, batch, channels, height, width, upscaleFactor) =>
                    {
                        int r = upscaleFactor;
                        int newChannels = channels / (r * r);
                        int newHeight = height * r;
                        int newWidth = width * r;
                        int ow = (int)flatIdx % newWidth;
                        int temp = (int)flatIdx / newWidth;
                        int oh = temp % newHeight;
                        temp /= newHeight;
                        int oc = temp % newChannels;
                        int b = temp / newChannels;
                        int ih = oh / r;
                        int iw = ow / r;
                        int subH = oh % r;
                        int subW = ow % r;
                        int ic = oc * r * r + subH * r + subW;
                        int inputIdx = ((b * channels + ic) * height + ih) * width + iw;
                        output[flatIdx] = input[inputIdx];
                    });
                Console.WriteLine("[GpuEngine] PixelShuffle kernels pre-compiled");

                // TensorSoftmax along axis - processes softmax with strided memory layout
                // Parameters: input, output, outerSize, axisSize, innerSize
                // Each thread handles one (outer, inner) pair and computes softmax across axis
                _tensorSoftmaxKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int>(
                    (flatIdx, input, output, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        // Find max for numerical stability
                        float maxVal = float.MinValue;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            if (input[idx] > maxVal) maxVal = input[idx];
                        }

                        // Compute exp and sum
                        float sum = 0.0f;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            float expVal = XMath.Exp(input[idx] - maxVal);
                            output[idx] = expVal;
                            sum += expVal;
                        }

                        // Normalize
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            output[idx] /= sum;
                        }
                    });
                _tensorSoftmaxKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int>(
                    (flatIdx, input, output, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        double maxVal = double.MinValue;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            if (input[idx] > maxVal) maxVal = input[idx];
                        }

                        double sum = 0.0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            double expVal = XMath.Exp(input[idx] - maxVal);
                            output[idx] = expVal;
                            sum += expVal;
                        }

                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            output[idx] /= sum;
                        }
                    });
                Console.WriteLine("[GpuEngine] TensorSoftmax kernels pre-compiled");

                // GumbelSoftmax forward kernel - applies Gumbel noise and temperature-scaled softmax
                // input: logits, gumbelNoise: pre-generated Gumbel noise, output: result
                _gumbelSoftmaxKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, float, int, int, int>(
                    (flatIdx, input, gumbelNoise, output, temperature, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        // Find max for numerical stability
                        float maxVal = float.MinValue;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            float perturbed = (input[idx] + gumbelNoise[idx]) / temperature;
                            if (perturbed > maxVal) maxVal = perturbed;
                        }

                        // Compute exp and sum
                        float sum = 0.0f;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            float perturbed = (input[idx] + gumbelNoise[idx]) / temperature;
                            float expVal = XMath.Exp(perturbed - maxVal);
                            output[idx] = expVal;
                            sum += expVal;
                        }

                        // Normalize
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            output[idx] /= sum;
                        }
                    });
                _gumbelSoftmaxKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, double, int, int, int>(
                    (flatIdx, input, gumbelNoise, output, temperature, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        double maxVal = double.MinValue;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            double perturbed = (input[idx] + gumbelNoise[idx]) / temperature;
                            if (perturbed > maxVal) maxVal = perturbed;
                        }

                        double sum = 0.0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            double perturbed = (input[idx] + gumbelNoise[idx]) / temperature;
                            double expVal = XMath.Exp(perturbed - maxVal);
                            output[idx] = expVal;
                            sum += expVal;
                        }

                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            output[idx] /= sum;
                        }
                    });
                Console.WriteLine("[GpuEngine] GumbelSoftmax kernels pre-compiled");

                // GumbelSoftmax backward kernel - gradient flows through softmax scaled by 1/temperature
                _gumbelSoftmaxBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, float, int, int, int>(
                    (flatIdx, gradOutput, output, gradInput, temperature, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        // Compute dot product of gradient and output
                        float dotProduct = 0.0f;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            dotProduct += gradOutput[idx] * output[idx];
                        }

                        // Softmax gradient scaled by 1/temperature
                        float scale = 1.0f / temperature;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            gradInput[idx] = output[idx] * (gradOutput[idx] - dotProduct) * scale;
                        }
                    });
                _gumbelSoftmaxBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, double, int, int, int>(
                    (flatIdx, gradOutput, output, gradInput, temperature, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        double dotProduct = 0.0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            dotProduct += gradOutput[idx] * output[idx];
                        }

                        double scale = 1.0 / temperature;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            gradInput[idx] = output[idx] * (gradOutput[idx] - dotProduct) * scale;
                        }
                    });
                Console.WriteLine("[GpuEngine] GumbelSoftmax backward kernels pre-compiled");

                // TaylorSoftmax forward kernel - uses Taylor series approximation of exp
                _taylorSoftmaxKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int>(
                    (flatIdx, input, output, order, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        // Find max for numerical stability
                        float maxVal = float.MinValue;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            if (input[idx] > maxVal) maxVal = input[idx];
                        }

                        // Compute Taylor exp approximation and sum
                        float sum = 0.0f;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            float x = input[idx] - maxVal;

                            // Taylor: 1 + x + x^2/2! + x^3/3! + ...
                            float taylorExp = 1.0f;
                            float xPower = 1.0f;
                            float factorial = 1.0f;
                            for (int n = 1; n <= order; n++)
                            {
                                xPower *= x;
                                factorial *= n;
                                taylorExp += xPower / factorial;
                            }

                            // Ensure non-negative
                            if (taylorExp < 1e-10f) taylorExp = 1e-10f;
                            output[idx] = taylorExp;
                            sum += taylorExp;
                        }

                        // Normalize
                        if (sum < 1e-10f) sum = 1e-10f;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            output[idx] /= sum;
                        }
                    });
                _taylorSoftmaxKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int>(
                    (flatIdx, input, output, order, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        double maxVal = double.MinValue;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            if (input[idx] > maxVal) maxVal = input[idx];
                        }

                        double sum = 0.0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            double x = input[idx] - maxVal;

                            double taylorExp = 1.0;
                            double xPower = 1.0;
                            double factorial = 1.0;
                            for (int n = 1; n <= order; n++)
                            {
                                xPower *= x;
                                factorial *= n;
                                taylorExp += xPower / factorial;
                            }

                            if (taylorExp < 1e-10) taylorExp = 1e-10;
                            output[idx] = taylorExp;
                            sum += taylorExp;
                        }

                        if (sum < 1e-10) sum = 1e-10;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            output[idx] /= sum;
                        }
                    });
                Console.WriteLine("[GpuEngine] TaylorSoftmax kernels pre-compiled");

                // TaylorSoftmax backward kernel
                _taylorSoftmaxBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int>(
                    (flatIdx, gradOutput, input, output, gradInput, order, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        // Find max for stability (same as forward)
                        float maxVal = float.MinValue;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            if (input[idx] > maxVal) maxVal = input[idx];
                        }

                        // Compute dot product
                        float dotProduct = 0.0f;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            dotProduct += gradOutput[idx] * output[idx];
                        }

                        // Compute gradient with g'(x)/g(x) factor
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            float x = input[idx] - maxVal;

                            // Compute g(x) and g'(x)
                            float g = 1.0f;
                            float gPrime = 1.0f;
                            float xPower = 1.0f;
                            float factorial = 1.0f;
                            for (int n = 1; n <= order; n++)
                            {
                                xPower *= x;
                                factorial *= n;
                                g += xPower / factorial;
                            }
                            // g'(x) = 1 + x + x^2/2! + ... (order-1 terms)
                            xPower = 1.0f;
                            factorial = 1.0f;
                            for (int n = 1; n < order; n++)
                            {
                                xPower *= x;
                                factorial *= n;
                                gPrime += xPower / factorial;
                            }

                            float softmaxGrad = output[idx] * (gradOutput[idx] - dotProduct);
                            float ratio = (g > 1e-10f) ? gPrime / g : 0.0f;
                            gradInput[idx] = softmaxGrad * ratio;
                        }
                    });
                _taylorSoftmaxBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int>(
                    (flatIdx, gradOutput, input, output, gradInput, order, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        double maxVal = double.MinValue;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            if (input[idx] > maxVal) maxVal = input[idx];
                        }

                        double dotProduct = 0.0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            dotProduct += gradOutput[idx] * output[idx];
                        }

                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            double x = input[idx] - maxVal;

                            double g = 1.0;
                            double gPrime = 1.0;
                            double xPower = 1.0;
                            double factorial = 1.0;
                            for (int n = 1; n <= order; n++)
                            {
                                xPower *= x;
                                factorial *= n;
                                g += xPower / factorial;
                            }
                            xPower = 1.0;
                            factorial = 1.0;
                            for (int n = 1; n < order; n++)
                            {
                                xPower *= x;
                                factorial *= n;
                                gPrime += xPower / factorial;
                            }

                            double softmaxGrad = output[idx] * (gradOutput[idx] - dotProduct);
                            double ratio = (g > 1e-10) ? gPrime / g : 0.0;
                            gradInput[idx] = softmaxGrad * ratio;
                        }
                    });
                Console.WriteLine("[GpuEngine] TaylorSoftmax backward kernels pre-compiled");

                // Sparsemax forward kernel
                _sparsemaxKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int>(
                    (flatIdx, input, output, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        // Copy values and sort (bubble sort for GPU - small axisSize expected)
                        // Use local array for sorting
                        float cumSum = 0.0f;
                        int k = 0;
                        float threshold = 0.0f;

                        // Find max k values using selection approach
                        for (int kCand = 1; kCand <= axisSize; kCand++)
                        {
                            // Find k-th largest value
                            float kthLargest = float.MinValue;
                            for (int i = 0; i < axisSize; i++)
                            {
                                int idx = (outer * axisSize + i) * innerSize + inner;
                                float val = input[idx];
                                int larger = 0;
                                for (int j = 0; j < axisSize; j++)
                                {
                                    int jdx = (outer * axisSize + j) * innerSize + inner;
                                    if (input[jdx] > val || (input[jdx] == val && j < i)) larger++;
                                }
                                if (larger == kCand - 1)
                                {
                                    kthLargest = val;
                                    break;
                                }
                            }

                            cumSum += kthLargest;
                            // t_k = 1 + k * z_k - cumSum
                            float t = 1.0f + kCand * kthLargest - cumSum;
                            if (t > 0)
                            {
                                k = kCand;
                                threshold = (cumSum - 1.0f) / k;
                            }
                        }

                        // Compute output
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            float val = input[idx] - threshold;
                            output[idx] = val > 0 ? val : 0.0f;
                        }
                    });
                _sparsemaxKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int>(
                    (flatIdx, input, output, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        double cumSum = 0.0;
                        int k = 0;
                        double threshold = 0.0;

                        for (int kCand = 1; kCand <= axisSize; kCand++)
                        {
                            double kthLargest = double.MinValue;
                            for (int i = 0; i < axisSize; i++)
                            {
                                int idx = (outer * axisSize + i) * innerSize + inner;
                                double val = input[idx];
                                int larger = 0;
                                for (int j = 0; j < axisSize; j++)
                                {
                                    int jdx = (outer * axisSize + j) * innerSize + inner;
                                    if (input[jdx] > val || (input[jdx] == val && j < i)) larger++;
                                }
                                if (larger == kCand - 1)
                                {
                                    kthLargest = val;
                                    break;
                                }
                            }

                            cumSum += kthLargest;
                            double t = 1.0 + kCand * kthLargest - cumSum;
                            if (t > 0)
                            {
                                k = kCand;
                                threshold = (cumSum - 1.0) / k;
                            }
                        }

                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            double val = input[idx] - threshold;
                            output[idx] = val > 0 ? val : 0.0;
                        }
                    });
                Console.WriteLine("[GpuEngine] Sparsemax kernels pre-compiled");

                // Sparsemax backward kernel
                _sparsemaxBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int>(
                    (flatIdx, gradOutput, output, gradInput, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        // Find support set and compute mean gradient
                        float sumGrad = 0.0f;
                        int supportSize = 0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            if (output[idx] > 0)
                            {
                                sumGrad += gradOutput[idx];
                                supportSize++;
                            }
                        }

                        float meanGrad = supportSize > 0 ? sumGrad / supportSize : 0.0f;

                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            if (output[idx] > 0)
                                gradInput[idx] = gradOutput[idx] - meanGrad;
                            else
                                gradInput[idx] = 0.0f;
                        }
                    });
                _sparsemaxBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int>(
                    (flatIdx, gradOutput, output, gradInput, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        double sumGrad = 0.0;
                        int supportSize = 0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            if (output[idx] > 0)
                            {
                                sumGrad += gradOutput[idx];
                                supportSize++;
                            }
                        }

                        double meanGrad = supportSize > 0 ? sumGrad / supportSize : 0.0;

                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            if (output[idx] > 0)
                                gradInput[idx] = gradOutput[idx] - meanGrad;
                            else
                                gradInput[idx] = 0.0;
                        }
                    });
                Console.WriteLine("[GpuEngine] Sparsemax backward kernels pre-compiled");

                // SphericalSoftmax forward kernel - L2 normalize then softmax
                _sphericalSoftmaxKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int>(
                    (flatIdx, input, output, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        // Compute L2 norm
                        float sumSquares = 0.0f;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            sumSquares += input[idx] * input[idx];
                        }
                        float norm = XMath.Sqrt(sumSquares);
                        if (norm < 1e-10f) norm = 1e-10f;

                        // Normalize and find max
                        float maxVal = float.MinValue;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            float normalized = input[idx] / norm;
                            output[idx] = normalized; // Temporarily store normalized
                            if (normalized > maxVal) maxVal = normalized;
                        }

                        // Compute softmax
                        float sum = 0.0f;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            float expVal = XMath.Exp(output[idx] - maxVal);
                            output[idx] = expVal;
                            sum += expVal;
                        }

                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            output[idx] /= sum;
                        }
                    });
                _sphericalSoftmaxKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int>(
                    (flatIdx, input, output, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        double sumSquares = 0.0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            sumSquares += input[idx] * input[idx];
                        }
                        double norm = XMath.Sqrt(sumSquares);
                        if (norm < 1e-10) norm = 1e-10;

                        double maxVal = double.MinValue;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            double normalized = input[idx] / norm;
                            output[idx] = normalized;
                            if (normalized > maxVal) maxVal = normalized;
                        }

                        double sum = 0.0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            double expVal = XMath.Exp(output[idx] - maxVal);
                            output[idx] = expVal;
                            sum += expVal;
                        }

                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            output[idx] /= sum;
                        }
                    });
                Console.WriteLine("[GpuEngine] SphericalSoftmax kernels pre-compiled");

                // SphericalSoftmax backward kernel
                _sphericalSoftmaxBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int>(
                    (flatIdx, gradOutput, input, output, gradInput, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        // Compute norm
                        float sumSquares = 0.0f;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            sumSquares += input[idx] * input[idx];
                        }
                        float norm = XMath.Sqrt(sumSquares);
                        if (norm < 1e-10f) norm = 1e-10f;
                        float normCubed = norm * norm * norm;

                        // Softmax backward: compute g_z
                        float dotProduct = 0.0f;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            dotProduct += gradOutput[idx] * output[idx];
                        }

                        // Compute x dot g_z
                        float xDotGz = 0.0f;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            float gZ = output[idx] * (gradOutput[idx] - dotProduct);
                            xDotGz += input[idx] * gZ;
                        }

                        // Final gradient
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            float gZ = output[idx] * (gradOutput[idx] - dotProduct);
                            gradInput[idx] = gZ / norm - input[idx] * xDotGz / normCubed;
                        }
                    });
                _sphericalSoftmaxBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int>(
                    (flatIdx, gradOutput, input, output, gradInput, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        double sumSquares = 0.0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            sumSquares += input[idx] * input[idx];
                        }
                        double norm = XMath.Sqrt(sumSquares);
                        if (norm < 1e-10) norm = 1e-10;
                        double normCubed = norm * norm * norm;

                        double dotProduct = 0.0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            dotProduct += gradOutput[idx] * output[idx];
                        }

                        double xDotGz = 0.0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            double gZ = output[idx] * (gradOutput[idx] - dotProduct);
                            xDotGz += input[idx] * gZ;
                        }

                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            double gZ = output[idx] * (gradOutput[idx] - dotProduct);
                            gradInput[idx] = gZ / norm - input[idx] * xDotGz / normCubed;
                        }
                    });
                Console.WriteLine("[GpuEngine] SphericalSoftmax backward kernels pre-compiled");

                // TensorSumOfSquares kernels - partial sum of squared values
                // Each block computes sum of squares for ReductionBlockSize elements
                _partialSumOfSquaresKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int>(
                    (blockIdx, input, partialSums, length) =>
                    {
                        int startIdx = (int)blockIdx * ReductionBlockSize;
                        float sum = 0.0f;
                        for (int i = 0; i < ReductionBlockSize && startIdx + i < length; i++)
                        {
                            float val = input[startIdx + i];
                            sum += val * val;
                        }
                        partialSums[blockIdx] = sum;
                    });
                _partialSumOfSquaresKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int>(
                    (blockIdx, input, partialSums, length) =>
                    {
                        int startIdx = (int)blockIdx * ReductionBlockSize;
                        double sum = 0.0;
                        for (int i = 0; i < ReductionBlockSize && startIdx + i < length; i++)
                        {
                            double val = input[startIdx + i];
                            sum += val * val;
                        }
                        partialSums[blockIdx] = sum;
                    });
                Console.WriteLine("[GpuEngine] TensorSumOfSquares kernels pre-compiled");

                // TensorEmbeddingLookup kernels - gather rows from embedding table
                // Each thread copies one element: output[i * embDim + d] = embeddings[indices[i] * embDim + d]
                // flatIdx iterates over (numIndices * embeddingDim)
                _embeddingLookupKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<int>, ArrayView<float>, int>(
                    (flatIdx, embeddings, indices, output, embeddingDim) =>
                    {
                        int idx = (int)flatIdx / embeddingDim;
                        int d = (int)flatIdx % embeddingDim;
                        int tokenIdx = indices[idx];
                        output[flatIdx] = embeddings[tokenIdx * embeddingDim + d];
                    });
                _embeddingLookupKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<int>, ArrayView<double>, int>(
                    (flatIdx, embeddings, indices, output, embeddingDim) =>
                    {
                        int idx = (int)flatIdx / embeddingDim;
                        int d = (int)flatIdx % embeddingDim;
                        int tokenIdx = indices[idx];
                        output[flatIdx] = embeddings[tokenIdx * embeddingDim + d];
                    });
                Console.WriteLine("[GpuEngine] TensorEmbeddingLookup kernels pre-compiled");

                // TensorEmbeddingLookupBackward kernels - scatter-add gradients
                // Uses atomic add for thread-safe accumulation when same index appears multiple times
                // Each thread adds one gradient element: gradEmbeddings[indices[i] * embDim + d] += gradOutput[i * embDim + d]
                _embeddingLookupBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<int>, ArrayView<float>, int, int>(
                    (flatIdx, gradOutput, indices, gradEmbeddings, embeddingDim, numIndices) =>
                    {
                        int idx = (int)flatIdx / embeddingDim;
                        int d = (int)flatIdx % embeddingDim;
                        if (idx >= numIndices) return;
                        int tokenIdx = indices[idx];
                        // Atomic add for thread-safe accumulation
                        Atomic.Add(ref gradEmbeddings[tokenIdx * embeddingDim + d], gradOutput[flatIdx]);
                    });
                _embeddingLookupBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<int>, ArrayView<double>, int, int>(
                    (flatIdx, gradOutput, indices, gradEmbeddings, embeddingDim, numIndices) =>
                    {
                        int idx = (int)flatIdx / embeddingDim;
                        int d = (int)flatIdx % embeddingDim;
                        if (idx >= numIndices) return;
                        int tokenIdx = indices[idx];
                        // Atomic add for thread-safe accumulation
                        Atomic.Add(ref gradEmbeddings[tokenIdx * embeddingDim + d], gradOutput[flatIdx]);
                    });
                Console.WriteLine("[GpuEngine] TensorEmbeddingLookupBackward kernels pre-compiled");

                // BatchNorm forward - normalizes across batch dimension
                // Parameters: input, output, gamma, beta, mean, variance, epsilon, batch, features
                // Each thread processes one element: output = gamma * (input - mean) / sqrt(var + eps) + beta
                _batchNormKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>,
                    ArrayView<float>, ArrayView<float>, float, int, int>(
                    (flatIdx, input, output, gamma, beta, mean, variance, epsilon, batch, features) =>
                    {
                        int b = (int)flatIdx / features;
                        int f = (int)flatIdx % features;
                        if (b >= batch) return;

                        float normalized = (input[flatIdx] - mean[f]) / XMath.Sqrt(variance[f] + epsilon);
                        output[flatIdx] = gamma[f] * normalized + beta[f];
                    });
                _batchNormKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>,
                    ArrayView<double>, ArrayView<double>, double, int, int>(
                    (flatIdx, input, output, gamma, beta, mean, variance, epsilon, batch, features) =>
                    {
                        int b = (int)flatIdx / features;
                        int f = (int)flatIdx % features;
                        if (b >= batch) return;

                        double normalized = (input[flatIdx] - mean[f]) / XMath.Sqrt(variance[f] + epsilon);
                        output[flatIdx] = gamma[f] * normalized + beta[f];
                    });
                Console.WriteLine("[GpuEngine] BatchNorm kernels pre-compiled");

                // LayerNorm forward - normalizes across feature dimension per sample
                // Parameters: input, output, gamma, beta, mean, variance, epsilon, batch, features
                // Each thread processes one element: output = gamma * (input - mean) / sqrt(var + eps) + beta
                // Note: mean/variance are per-batch (computed over features), gamma/beta are per-feature
                _layerNormKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>,
                    ArrayView<float>, ArrayView<float>, float, int, int>(
                    (flatIdx, input, output, gamma, beta, mean, variance, epsilon, batch, features) =>
                    {
                        int b = (int)flatIdx / features;
                        int f = (int)flatIdx % features;
                        if (b >= batch) return;

                        // LayerNorm: mean/variance indexed by batch, gamma/beta indexed by feature
                        float normalized = (input[flatIdx] - mean[b]) / XMath.Sqrt(variance[b] + epsilon);
                        output[flatIdx] = gamma[f] * normalized + beta[f];
                    });
                _layerNormKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>,
                    ArrayView<double>, ArrayView<double>, double, int, int>(
                    (flatIdx, input, output, gamma, beta, mean, variance, epsilon, batch, features) =>
                    {
                        int b = (int)flatIdx / features;
                        int f = (int)flatIdx % features;
                        if (b >= batch) return;

                        double normalized = (input[flatIdx] - mean[b]) / XMath.Sqrt(variance[b] + epsilon);
                        output[flatIdx] = gamma[f] * normalized + beta[f];
                    });
                Console.WriteLine("[GpuEngine] LayerNorm kernels pre-compiled");

                // Conv2D backward input gradient kernel
                _conv2DBackwardInputKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, Conv2DParams>(
                    (flatIdx, gradOutput, kernel, gradInput, p) =>
                    {
                        // flatIdx indexes into gradInput: [batch, inChannels, height, width]
                        int iw = (int)flatIdx % p.Width;
                        int temp = (int)flatIdx / p.Width;
                        int ih = temp % p.Height;
                        temp /= p.Height;
                        int ic = temp % p.InChannels;
                        int b = temp / p.InChannels;

                        float sum = 0;
                        // Sum contributions from all output positions that used this input
                        for (int oc = 0; oc < p.OutChannels; oc++)
                        {
                            for (int kh = 0; kh < p.KernelHeight; kh++)
                            {
                                for (int kw = 0; kw < p.KernelWidth; kw++)
                                {
                                    int oh = ih + p.Padding - kh * p.Dilation;
                                    int ow = iw + p.Padding - kw * p.Dilation;
                                    if (oh % p.Stride == 0 && ow % p.Stride == 0)
                                    {
                                        oh /= p.Stride;
                                        ow /= p.Stride;
                                        if (oh >= 0 && oh < p.OutputHeight && ow >= 0 && ow < p.OutputWidth)
                                        {
                                            int gradOutIdx = ((b * p.OutChannels + oc) * p.OutputHeight + oh) * p.OutputWidth + ow;
                                            int kernelIdx = ((oc * p.InChannels + ic) * p.KernelHeight + kh) * p.KernelWidth + kw;
                                            sum += gradOutput[gradOutIdx] * kernel[kernelIdx];
                                        }
                                    }
                                }
                            }
                        }
                        gradInput[flatIdx] = sum;
                    });
                _conv2DBackwardInputKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, Conv2DParams>(
                    (flatIdx, gradOutput, kernel, gradInput, p) =>
                    {
                        int iw = (int)flatIdx % p.Width;
                        int temp = (int)flatIdx / p.Width;
                        int ih = temp % p.Height;
                        temp /= p.Height;
                        int ic = temp % p.InChannels;
                        int b = temp / p.InChannels;

                        double sum = 0;
                        for (int oc = 0; oc < p.OutChannels; oc++)
                        {
                            for (int kh = 0; kh < p.KernelHeight; kh++)
                            {
                                for (int kw = 0; kw < p.KernelWidth; kw++)
                                {
                                    int oh = ih + p.Padding - kh * p.Dilation;
                                    int ow = iw + p.Padding - kw * p.Dilation;
                                    if (oh % p.Stride == 0 && ow % p.Stride == 0)
                                    {
                                        oh /= p.Stride;
                                        ow /= p.Stride;
                                        if (oh >= 0 && oh < p.OutputHeight && ow >= 0 && ow < p.OutputWidth)
                                        {
                                            int gradOutIdx = ((b * p.OutChannels + oc) * p.OutputHeight + oh) * p.OutputWidth + ow;
                                            int kernelIdx = ((oc * p.InChannels + ic) * p.KernelHeight + kh) * p.KernelWidth + kw;
                                            sum += gradOutput[gradOutIdx] * kernel[kernelIdx];
                                        }
                                    }
                                }
                            }
                        }
                        gradInput[flatIdx] = sum;
                    });
                Console.WriteLine("[GpuEngine] Conv2DBackwardInput kernels pre-compiled");

                // Conv2D backward kernel gradient
                _conv2DBackwardKernelKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, Conv2DParams>(
                    (flatIdx, gradOutput, input, gradKernel, p) =>
                    {
                        // flatIdx indexes into gradKernel: [outChannels, inChannels, kernelHeight, kernelWidth]
                        int kw = (int)flatIdx % p.KernelWidth;
                        int temp = (int)flatIdx / p.KernelWidth;
                        int kh = temp % p.KernelHeight;
                        temp /= p.KernelHeight;
                        int ic = temp % p.InChannels;
                        int oc = temp / p.InChannels;

                        float sum = 0;
                        for (int b = 0; b < p.Batch; b++)
                        {
                            for (int oh = 0; oh < p.OutputHeight; oh++)
                            {
                                for (int ow = 0; ow < p.OutputWidth; ow++)
                                {
                                    int ih = oh * p.Stride + kh * p.Dilation - p.Padding;
                                    int iw = ow * p.Stride + kw * p.Dilation - p.Padding;
                                    if (ih >= 0 && ih < p.Height && iw >= 0 && iw < p.Width)
                                    {
                                        int gradOutIdx = ((b * p.OutChannels + oc) * p.OutputHeight + oh) * p.OutputWidth + ow;
                                        int inputIdx = ((b * p.InChannels + ic) * p.Height + ih) * p.Width + iw;
                                        sum += gradOutput[gradOutIdx] * input[inputIdx];
                                    }
                                }
                            }
                        }
                        gradKernel[flatIdx] = sum;
                    });
                _conv2DBackwardKernelKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, Conv2DParams>(
                    (flatIdx, gradOutput, input, gradKernel, p) =>
                    {
                        int kw = (int)flatIdx % p.KernelWidth;
                        int temp = (int)flatIdx / p.KernelWidth;
                        int kh = temp % p.KernelHeight;
                        temp /= p.KernelHeight;
                        int ic = temp % p.InChannels;
                        int oc = temp / p.InChannels;

                        double sum = 0;
                        for (int b = 0; b < p.Batch; b++)
                        {
                            for (int oh = 0; oh < p.OutputHeight; oh++)
                            {
                                for (int ow = 0; ow < p.OutputWidth; ow++)
                                {
                                    int ih = oh * p.Stride + kh * p.Dilation - p.Padding;
                                    int iw = ow * p.Stride + kw * p.Dilation - p.Padding;
                                    if (ih >= 0 && ih < p.Height && iw >= 0 && iw < p.Width)
                                    {
                                        int gradOutIdx = ((b * p.OutChannels + oc) * p.OutputHeight + oh) * p.OutputWidth + ow;
                                        int inputIdx = ((b * p.InChannels + ic) * p.Height + ih) * p.Width + iw;
                                        sum += gradOutput[gradOutIdx] * input[inputIdx];
                                    }
                                }
                            }
                        }
                        gradKernel[flatIdx] = sum;
                    });
                Console.WriteLine("[GpuEngine] Conv2DBackwardKernel kernels pre-compiled");

                // MaxPool2D backward kernel
                _maxPool2DBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<int>, ArrayView<float>, int, int, int, int, int, int>(
                    (flatIdx, gradOutput, maxIndices, gradInput, batch, channels, inH, inW, outH, outW) =>
                    {
                        // Each thread processes one output gradient element and scatters to input
                        int ow = (int)flatIdx % outW;
                        int temp = (int)flatIdx / outW;
                        int oh = temp % outH;
                        temp /= outH;
                        int c = temp % channels;
                        int b = temp / channels;

                        // Get the index where max was found (stored as flat index in input)
                        int maxIdx = maxIndices[flatIdx];
                        // Atomically add gradient to input at max location
                        // Note: ILGPU doesn't have atomic add for float, so this is approximate
                        gradInput[maxIdx] += gradOutput[flatIdx];
                    });
                _maxPool2DBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<int>, ArrayView<double>, int, int, int, int, int, int>(
                    (flatIdx, gradOutput, maxIndices, gradInput, batch, channels, inH, inW, outH, outW) =>
                    {
                        int ow = (int)flatIdx % outW;
                        int temp = (int)flatIdx / outW;
                        int oh = temp % outH;
                        temp /= outH;
                        int c = temp % channels;
                        int b = temp / channels;

                        int maxIdx = maxIndices[flatIdx];
                        gradInput[maxIdx] += gradOutput[flatIdx];
                    });
                Console.WriteLine("[GpuEngine] MaxPool2DBackward kernels pre-compiled");

                // MaxPool2D with indices kernel
                _maxPool2DWithIndicesKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<int>, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, input, output, maxIndices, batch, channels, inH, inW, outH, outW, poolH, poolW, stride) =>
                    {
                        // Each thread processes one output element
                        int ow = (int)flatIdx % outW;
                        int temp = (int)flatIdx / outW;
                        int oh = temp % outH;
                        temp /= outH;
                        int c = temp % channels;
                        int b = temp / channels;

                        float maxVal = float.MinValue;
                        int maxIdx = 0;
                        int ihStart = oh * stride;
                        int iwStart = ow * stride;

                        for (int ph = 0; ph < poolH; ph++)
                        {
                            for (int pw = 0; pw < poolW; pw++)
                            {
                                int ih = ihStart + ph;
                                int iw = iwStart + pw;
                                if (ih < inH && iw < inW)
                                {
                                    int inputIdx = ((b * channels + c) * inH + ih) * inW + iw;
                                    float val = input[inputIdx];
                                    if (val > maxVal)
                                    {
                                        maxVal = val;
                                        maxIdx = inputIdx;
                                    }
                                }
                            }
                        }
                        output[flatIdx] = maxVal;
                        maxIndices[flatIdx] = maxIdx;
                    });
                _maxPool2DWithIndicesKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<int>, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, input, output, maxIndices, batch, channels, inH, inW, outH, outW, poolH, poolW, stride) =>
                    {
                        int ow = (int)flatIdx % outW;
                        int temp = (int)flatIdx / outW;
                        int oh = temp % outH;
                        temp /= outH;
                        int c = temp % channels;
                        int b = temp / channels;

                        double maxVal = double.MinValue;
                        int maxIdx = 0;
                        int ihStart = oh * stride;
                        int iwStart = ow * stride;

                        for (int ph = 0; ph < poolH; ph++)
                        {
                            for (int pw = 0; pw < poolW; pw++)
                            {
                                int ih = ihStart + ph;
                                int iw = iwStart + pw;
                                if (ih < inH && iw < inW)
                                {
                                    int inputIdx = ((b * channels + c) * inH + ih) * inW + iw;
                                    double val = input[inputIdx];
                                    if (val > maxVal)
                                    {
                                        maxVal = val;
                                        maxIdx = inputIdx;
                                    }
                                }
                            }
                        }
                        output[flatIdx] = maxVal;
                        maxIndices[flatIdx] = maxIdx;
                    });
                Console.WriteLine("[GpuEngine] MaxPool2DWithIndices kernels pre-compiled");

                // AvgPool2D backward kernel
                _avgPool2DBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, gradOutput, gradInput, batch, channels, inH, inW, outH, outW, poolH, poolW, stride) =>
                    {
                        // Each thread processes one input gradient element
                        int iw = (int)flatIdx % inW;
                        int temp = (int)flatIdx / inW;
                        int ih = temp % inH;
                        temp /= inH;
                        int c = temp % channels;
                        int b = temp / channels;

                        float sum = 0;
                        float scale = 1.0f / (poolH * poolW);
                        // Find all output positions that included this input
                        for (int oh = 0; oh < outH; oh++)
                        {
                            for (int ow = 0; ow < outW; ow++)
                            {
                                int ihStart = oh * stride;
                                int iwStart = ow * stride;
                                if (ih >= ihStart && ih < ihStart + poolH && iw >= iwStart && iw < iwStart + poolW)
                                {
                                    int outIdx = ((b * channels + c) * outH + oh) * outW + ow;
                                    sum += gradOutput[outIdx] * scale;
                                }
                            }
                        }
                        gradInput[flatIdx] = sum;
                    });
                _avgPool2DBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, gradOutput, gradInput, batch, channels, inH, inW, outH, outW, poolH, poolW, stride) =>
                    {
                        int iw = (int)flatIdx % inW;
                        int temp = (int)flatIdx / inW;
                        int ih = temp % inH;
                        temp /= inH;
                        int c = temp % channels;
                        int b = temp / channels;

                        double sum = 0;
                        double scale = 1.0 / (poolH * poolW);
                        for (int oh = 0; oh < outH; oh++)
                        {
                            for (int ow = 0; ow < outW; ow++)
                            {
                                int ihStart = oh * stride;
                                int iwStart = ow * stride;
                                if (ih >= ihStart && ih < ihStart + poolH && iw >= iwStart && iw < iwStart + poolW)
                                {
                                    int outIdx = ((b * channels + c) * outH + oh) * outW + ow;
                                    sum += gradOutput[outIdx] * scale;
                                }
                            }
                        }
                        gradInput[flatIdx] = sum;
                    });
                Console.WriteLine("[GpuEngine] AvgPool2DBackward kernels pre-compiled");

                // DepthwiseConv2D kernel
                _depthwiseConv2DKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, input, kernel, output, batch, channels, inH, inW, outH, outW, kH, kW, stride, padding) =>
                    {
                        int ow = (int)flatIdx % outW;
                        int temp = (int)flatIdx / outW;
                        int oh = temp % outH;
                        temp /= outH;
                        int c = temp % channels;
                        int b = temp / channels;

                        float sum = 0;
                        for (int kh = 0; kh < kH; kh++)
                        {
                            for (int kw = 0; kw < kW; kw++)
                            {
                                int ih = oh * stride + kh - padding;
                                int iw = ow * stride + kw - padding;
                                if (ih >= 0 && ih < inH && iw >= 0 && iw < inW)
                                {
                                    int inputIdx = ((b * channels + c) * inH + ih) * inW + iw;
                                    int kernelIdx = (c * kH + kh) * kW + kw;
                                    sum += input[inputIdx] * kernel[kernelIdx];
                                }
                            }
                        }
                        output[flatIdx] = sum;
                    });
                _depthwiseConv2DKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, input, kernel, output, batch, channels, inH, inW, outH, outW, kH, kW, stride, padding) =>
                    {
                        int ow = (int)flatIdx % outW;
                        int temp = (int)flatIdx / outW;
                        int oh = temp % outH;
                        temp /= outH;
                        int c = temp % channels;
                        int b = temp / channels;

                        double sum = 0;
                        for (int kh = 0; kh < kH; kh++)
                        {
                            for (int kw = 0; kw < kW; kw++)
                            {
                                int ih = oh * stride + kh - padding;
                                int iw = ow * stride + kw - padding;
                                if (ih >= 0 && ih < inH && iw >= 0 && iw < inW)
                                {
                                    int inputIdx = ((b * channels + c) * inH + ih) * inW + iw;
                                    int kernelIdx = (c * kH + kh) * kW + kw;
                                    sum += input[inputIdx] * kernel[kernelIdx];
                                }
                            }
                        }
                        output[flatIdx] = sum;
                    });
                Console.WriteLine("[GpuEngine] DepthwiseConv2D kernels pre-compiled");

                // DepthwiseConv2D backward input kernel
                _depthwiseConv2DBackwardInputKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, gradOutput, kernel, gradInput, batch, channels, inH, inW, outH, outW, kH, kW, stride, padding) =>
                    {
                        int iw = (int)flatIdx % inW;
                        int temp = (int)flatIdx / inW;
                        int ih = temp % inH;
                        temp /= inH;
                        int c = temp % channels;
                        int b = temp / channels;

                        float sum = 0;
                        for (int kh = 0; kh < kH; kh++)
                        {
                            for (int kw = 0; kw < kW; kw++)
                            {
                                int oh = ih + padding - kh;
                                int ow = iw + padding - kw;
                                if (oh >= 0 && oh % stride == 0 && ow >= 0 && ow % stride == 0)
                                {
                                    oh /= stride;
                                    ow /= stride;
                                    if (oh < outH && ow < outW)
                                    {
                                        int gradOutIdx = ((b * channels + c) * outH + oh) * outW + ow;
                                        int kernelIdx = (c * kH + kh) * kW + kw;
                                        sum += gradOutput[gradOutIdx] * kernel[kernelIdx];
                                    }
                                }
                            }
                        }
                        gradInput[flatIdx] = sum;
                    });
                _depthwiseConv2DBackwardInputKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, gradOutput, kernel, gradInput, batch, channels, inH, inW, outH, outW, kH, kW, stride, padding) =>
                    {
                        int iw = (int)flatIdx % inW;
                        int temp = (int)flatIdx / inW;
                        int ih = temp % inH;
                        temp /= inH;
                        int c = temp % channels;
                        int b = temp / channels;

                        double sum = 0;
                        for (int kh = 0; kh < kH; kh++)
                        {
                            for (int kw = 0; kw < kW; kw++)
                            {
                                int oh = ih + padding - kh;
                                int ow = iw + padding - kw;
                                if (oh >= 0 && oh % stride == 0 && ow >= 0 && ow % stride == 0)
                                {
                                    oh /= stride;
                                    ow /= stride;
                                    if (oh < outH && ow < outW)
                                    {
                                        int gradOutIdx = ((b * channels + c) * outH + oh) * outW + ow;
                                        int kernelIdx = (c * kH + kh) * kW + kw;
                                        sum += gradOutput[gradOutIdx] * kernel[kernelIdx];
                                    }
                                }
                            }
                        }
                        gradInput[flatIdx] = sum;
                    });
                Console.WriteLine("[GpuEngine] DepthwiseConv2DBackwardInput kernels pre-compiled");

                // DepthwiseConv2D backward kernel kernel
                _depthwiseConv2DBackwardKernelKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, gradOutput, input, gradKernel, batch, channels, inH, inW, outH, outW, kH, kW, stride, padding) =>
                    {
                        int kw = (int)flatIdx % kW;
                        int temp = (int)flatIdx / kW;
                        int kh = temp % kH;
                        int c = temp / kH;

                        float sum = 0;
                        for (int b = 0; b < batch; b++)
                        {
                            for (int oh = 0; oh < outH; oh++)
                            {
                                for (int ow = 0; ow < outW; ow++)
                                {
                                    int ih = oh * stride + kh - padding;
                                    int iw = ow * stride + kw - padding;
                                    if (ih >= 0 && ih < inH && iw >= 0 && iw < inW)
                                    {
                                        int inputIdx = ((b * channels + c) * inH + ih) * inW + iw;
                                        int gradOutIdx = ((b * channels + c) * outH + oh) * outW + ow;
                                        sum += input[inputIdx] * gradOutput[gradOutIdx];
                                    }
                                }
                            }
                        }
                        gradKernel[flatIdx] = sum;
                    });
                _depthwiseConv2DBackwardKernelKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, gradOutput, input, gradKernel, batch, channels, inH, inW, outH, outW, kH, kW, stride, padding) =>
                    {
                        int kw = (int)flatIdx % kW;
                        int temp = (int)flatIdx / kW;
                        int kh = temp % kH;
                        int c = temp / kH;

                        double sum = 0;
                        for (int b = 0; b < batch; b++)
                        {
                            for (int oh = 0; oh < outH; oh++)
                            {
                                for (int ow = 0; ow < outW; ow++)
                                {
                                    int ih = oh * stride + kh - padding;
                                    int iw = ow * stride + kw - padding;
                                    if (ih >= 0 && ih < inH && iw >= 0 && iw < inW)
                                    {
                                        int inputIdx = ((b * channels + c) * inH + ih) * inW + iw;
                                        int gradOutIdx = ((b * channels + c) * outH + oh) * outW + ow;
                                        sum += input[inputIdx] * gradOutput[gradOutIdx];
                                    }
                                }
                            }
                        }
                        gradKernel[flatIdx] = sum;
                    });
                Console.WriteLine("[GpuEngine] DepthwiseConv2DBackwardKernel kernels pre-compiled");

                // ConvTranspose2D kernel
                _convTranspose2DKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, input, kernel, output, batch, channels, inH, inW, outH, outW, outChannels, kH, kW, stride, padding) =>
                    {
                        int ow = (int)flatIdx % outW;
                        int temp = (int)flatIdx / outW;
                        int oh = temp % outH;
                        temp /= outH;
                        int oc = temp % outChannels;
                        int b = temp / outChannels;

                        float sum = 0;
                        for (int ic = 0; ic < channels; ic++)
                        {
                            for (int kh = 0; kh < kH; kh++)
                            {
                                for (int kw = 0; kw < kW; kw++)
                                {
                                    int ih = (oh + padding - kh);
                                    int iw = (ow + padding - kw);
                                    if (ih >= 0 && ih % stride == 0 && iw >= 0 && iw % stride == 0)
                                    {
                                        ih /= stride;
                                        iw /= stride;
                                        if (ih < inH && iw < inW)
                                        {
                                            int inputIdx = ((b * channels + ic) * inH + ih) * inW + iw;
                                            int kernelIdx = ((ic * outChannels + oc) * kH + kh) * kW + kw;
                                            sum += input[inputIdx] * kernel[kernelIdx];
                                        }
                                    }
                                }
                            }
                        }
                        output[flatIdx] = sum;
                    });
                _convTranspose2DKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, input, kernel, output, batch, channels, inH, inW, outH, outW, outChannels, kH, kW, stride, padding) =>
                    {
                        int ow = (int)flatIdx % outW;
                        int temp = (int)flatIdx / outW;
                        int oh = temp % outH;
                        temp /= outH;
                        int oc = temp % outChannels;
                        int b = temp / outChannels;

                        double sum = 0;
                        for (int ic = 0; ic < channels; ic++)
                        {
                            for (int kh = 0; kh < kH; kh++)
                            {
                                for (int kw = 0; kw < kW; kw++)
                                {
                                    int ih = (oh + padding - kh);
                                    int iw = (ow + padding - kw);
                                    if (ih >= 0 && ih % stride == 0 && iw >= 0 && iw % stride == 0)
                                    {
                                        ih /= stride;
                                        iw /= stride;
                                        if (ih < inH && iw < inW)
                                        {
                                            int inputIdx = ((b * channels + ic) * inH + ih) * inW + iw;
                                            int kernelIdx = ((ic * outChannels + oc) * kH + kh) * kW + kw;
                                            sum += input[inputIdx] * kernel[kernelIdx];
                                        }
                                    }
                                }
                            }
                        }
                        output[flatIdx] = sum;
                    });
                Console.WriteLine("[GpuEngine] ConvTranspose2D kernels pre-compiled");

                // ConvTranspose2D backward input kernel (essentially a regular Conv2D)
                _convTranspose2DBackwardInputKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, gradOutput, kernel, gradInput, batch, channels, inH, inW, outH, outW, outChannels, kH, kW, stride) =>
                    {
                        int iw = (int)flatIdx % inW;
                        int temp = (int)flatIdx / inW;
                        int ih = temp % inH;
                        temp /= inH;
                        int c = temp % channels;
                        int b = temp / channels;

                        float sum = 0;
                        for (int oc = 0; oc < outChannels; oc++)
                        {
                            for (int kh = 0; kh < kH; kh++)
                            {
                                for (int kw = 0; kw < kW; kw++)
                                {
                                    int oh = ih * stride + kh;
                                    int ow = iw * stride + kw;
                                    if (oh < outH && ow < outW)
                                    {
                                        int gradOutIdx = ((b * outChannels + oc) * outH + oh) * outW + ow;
                                        int kernelIdx = ((c * outChannels + oc) * kH + kh) * kW + kw;
                                        sum += gradOutput[gradOutIdx] * kernel[kernelIdx];
                                    }
                                }
                            }
                        }
                        gradInput[flatIdx] = sum;
                    });
                _convTranspose2DBackwardInputKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, gradOutput, kernel, gradInput, batch, channels, inH, inW, outH, outW, outChannels, kH, kW, stride) =>
                    {
                        int iw = (int)flatIdx % inW;
                        int temp = (int)flatIdx / inW;
                        int ih = temp % inH;
                        temp /= inH;
                        int c = temp % channels;
                        int b = temp / channels;

                        double sum = 0;
                        for (int oc = 0; oc < outChannels; oc++)
                        {
                            for (int kh = 0; kh < kH; kh++)
                            {
                                for (int kw = 0; kw < kW; kw++)
                                {
                                    int oh = ih * stride + kh;
                                    int ow = iw * stride + kw;
                                    if (oh < outH && ow < outW)
                                    {
                                        int gradOutIdx = ((b * outChannels + oc) * outH + oh) * outW + ow;
                                        int kernelIdx = ((c * outChannels + oc) * kH + kh) * kW + kw;
                                        sum += gradOutput[gradOutIdx] * kernel[kernelIdx];
                                    }
                                }
                            }
                        }
                        gradInput[flatIdx] = sum;
                    });
                Console.WriteLine("[GpuEngine] ConvTranspose2DBackwardInput kernels pre-compiled");

                // ConvTranspose2D backward kernel kernel
                _convTranspose2DBackwardKernelKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, gradOutput, input, gradKernel, batch, channels, inH, inW, outH, outW, outChannels, kH, kW, stride) =>
                    {
                        int kw = (int)flatIdx % kW;
                        int temp = (int)flatIdx / kW;
                        int kh = temp % kH;
                        temp /= kH;
                        int oc = temp % outChannels;
                        int c = temp / outChannels;

                        float sum = 0;
                        for (int b = 0; b < batch; b++)
                        {
                            for (int ih = 0; ih < inH; ih++)
                            {
                                for (int iw = 0; iw < inW; iw++)
                                {
                                    int oh = ih * stride + kh;
                                    int ow = iw * stride + kw;
                                    if (oh < outH && ow < outW)
                                    {
                                        int inputIdx = ((b * channels + c) * inH + ih) * inW + iw;
                                        int gradOutIdx = ((b * outChannels + oc) * outH + oh) * outW + ow;
                                        sum += input[inputIdx] * gradOutput[gradOutIdx];
                                    }
                                }
                            }
                        }
                        gradKernel[flatIdx] = sum;
                    });
                _convTranspose2DBackwardKernelKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, int, int>(
                    (flatIdx, gradOutput, input, gradKernel, batch, channels, inH, inW, outH, outW, outChannels, kH, kW, stride) =>
                    {
                        int kw = (int)flatIdx % kW;
                        int temp = (int)flatIdx / kW;
                        int kh = temp % kH;
                        temp /= kH;
                        int oc = temp % outChannels;
                        int c = temp / outChannels;

                        double sum = 0;
                        for (int b = 0; b < batch; b++)
                        {
                            for (int ih = 0; ih < inH; ih++)
                            {
                                for (int iw = 0; iw < inW; iw++)
                                {
                                    int oh = ih * stride + kh;
                                    int ow = iw * stride + kw;
                                    if (oh < outH && ow < outW)
                                    {
                                        int inputIdx = ((b * channels + c) * inH + ih) * inW + iw;
                                        int gradOutIdx = ((b * outChannels + oc) * outH + oh) * outW + ow;
                                        sum += input[inputIdx] * gradOutput[gradOutIdx];
                                    }
                                }
                            }
                        }
                        gradKernel[flatIdx] = sum;
                    });
                Console.WriteLine("[GpuEngine] ConvTranspose2DBackwardKernel kernels pre-compiled");

                // BatchNorm backward kernel - computes gradInput, gradGamma, gradBeta
                _batchNormBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, float, int, int>(
                    (flatIdx, gradOutput, input, gamma, mean, variance, gradInput, gradGamma, gradBeta, epsilon, batchSize, featureSize) =>
                    {
                        int f = (int)flatIdx % featureSize;
                        int b = (int)flatIdx / featureSize;
                        if (b >= batchSize) return;

                        float m = mean[f];
                        float v = variance[f];
                        float g = gamma[f];
                        float invStd = 1.0f / XMath.Sqrt(v + epsilon);

                        float x = input[flatIdx];
                        float xNorm = (x - m) * invStd;
                        float dy = gradOutput[flatIdx];

                        // gradInput = gamma * invStd * (gradOutput - mean(gradOutput) - xNorm * mean(gradOutput * xNorm))
                        // For simplicity, compute per-element contribution
                        gradInput[flatIdx] = g * invStd * dy;

                        // Atomic add for gradGamma and gradBeta (accumulated across batch)
                        Atomic.Add(ref gradGamma[f], dy * xNorm);
                        Atomic.Add(ref gradBeta[f], dy);
                    });
                _batchNormBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, double, int, int>(
                    (flatIdx, gradOutput, input, gamma, mean, variance, gradInput, gradGamma, gradBeta, epsilon, batchSize, featureSize) =>
                    {
                        int f = (int)flatIdx % featureSize;
                        int b = (int)flatIdx / featureSize;
                        if (b >= batchSize) return;

                        double m = mean[f];
                        double v = variance[f];
                        double g = gamma[f];
                        double invStd = 1.0 / XMath.Sqrt(v + epsilon);

                        double x = input[flatIdx];
                        double xNorm = (x - m) * invStd;
                        double dy = gradOutput[flatIdx];

                        gradInput[flatIdx] = g * invStd * dy;
                        Atomic.Add(ref gradGamma[f], dy * xNorm);
                        Atomic.Add(ref gradBeta[f], dy);
                    });
                Console.WriteLine("[GpuEngine] BatchNormBackward kernels pre-compiled");

                // LayerNorm backward kernel
                _layerNormBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>, float, int, int>(
                    (flatIdx, gradOutput, input, gamma, mean, variance, gradInput, gradGamma, gradBeta, epsilon, batchSize, featureSize) =>
                    {
                        int f = (int)flatIdx % featureSize;
                        int b = (int)flatIdx / featureSize;
                        if (b >= batchSize) return;

                        float m = mean[b];
                        float v = variance[b];
                        float g = gamma[f];
                        float invStd = 1.0f / XMath.Sqrt(v + epsilon);

                        float x = input[flatIdx];
                        float xNorm = (x - m) * invStd;
                        float dy = gradOutput[flatIdx];

                        gradInput[flatIdx] = g * invStd * dy;
                        Atomic.Add(ref gradGamma[f], dy * xNorm);
                        Atomic.Add(ref gradBeta[f], dy);
                    });
                _layerNormBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>, double, int, int>(
                    (flatIdx, gradOutput, input, gamma, mean, variance, gradInput, gradGamma, gradBeta, epsilon, batchSize, featureSize) =>
                    {
                        int f = (int)flatIdx % featureSize;
                        int b = (int)flatIdx / featureSize;
                        if (b >= batchSize) return;

                        double m = mean[b];
                        double v = variance[b];
                        double g = gamma[f];
                        double invStd = 1.0 / XMath.Sqrt(v + epsilon);

                        double x = input[flatIdx];
                        double xNorm = (x - m) * invStd;
                        double dy = gradOutput[flatIdx];

                        gradInput[flatIdx] = g * invStd * dy;
                        Atomic.Add(ref gradGamma[f], dy * xNorm);
                        Atomic.Add(ref gradBeta[f], dy);
                    });
                Console.WriteLine("[GpuEngine] LayerNormBackward kernels pre-compiled");

                // ReduceMax kernel - finds max along reduction axis
                _reduceMaxKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<int>, int, int, int>(
                    (flatIdx, input, output, indices, outerSize, reduceSize, innerSize) =>
                    {
                        int inner = (int)flatIdx % innerSize;
                        int outer = (int)flatIdx / innerSize;
                        if (outer >= outerSize) return;

                        float maxVal = float.MinValue;
                        int maxIdx = 0;
                        for (int r = 0; r < reduceSize; r++)
                        {
                            int inputIdx = (outer * reduceSize + r) * innerSize + inner;
                            float val = input[inputIdx];
                            if (val > maxVal)
                            {
                                maxVal = val;
                                maxIdx = r;
                            }
                        }
                        output[flatIdx] = maxVal;
                        indices[flatIdx] = maxIdx;
                    });
                _reduceMaxKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<int>, int, int, int>(
                    (flatIdx, input, output, indices, outerSize, reduceSize, innerSize) =>
                    {
                        int inner = (int)flatIdx % innerSize;
                        int outer = (int)flatIdx / innerSize;
                        if (outer >= outerSize) return;

                        double maxVal = double.MinValue;
                        int maxIdx = 0;
                        for (int r = 0; r < reduceSize; r++)
                        {
                            int inputIdx = (outer * reduceSize + r) * innerSize + inner;
                            double val = input[inputIdx];
                            if (val > maxVal)
                            {
                                maxVal = val;
                                maxIdx = r;
                            }
                        }
                        output[flatIdx] = maxVal;
                        indices[flatIdx] = maxIdx;
                    });
                Console.WriteLine("[GpuEngine] ReduceMax kernels pre-compiled");

                // ReduceMaxBackward kernel
                _reduceMaxBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<int>, ArrayView<float>, int, int, int>(
                    (flatIdx, gradOutput, indices, gradInput, outerSize, reduceSize, innerSize) =>
                    {
                        int r = (int)flatIdx % reduceSize;
                        int temp = (int)flatIdx / reduceSize;
                        int inner = temp % innerSize;
                        int outer = temp / innerSize;
                        if (outer >= outerSize) return;

                        int outIdx = outer * innerSize + inner;
                        int maxIdx = indices[outIdx];
                        gradInput[flatIdx] = (r == maxIdx) ? gradOutput[outIdx] : 0;
                    });
                _reduceMaxBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<int>, ArrayView<double>, int, int, int>(
                    (flatIdx, gradOutput, indices, gradInput, outerSize, reduceSize, innerSize) =>
                    {
                        int r = (int)flatIdx % reduceSize;
                        int temp = (int)flatIdx / reduceSize;
                        int inner = temp % innerSize;
                        int outer = temp / innerSize;
                        if (outer >= outerSize) return;

                        int outIdx = outer * innerSize + inner;
                        int maxIdx = indices[outIdx];
                        gradInput[flatIdx] = (r == maxIdx) ? gradOutput[outIdx] : 0;
                    });
                Console.WriteLine("[GpuEngine] ReduceMaxBackward kernels pre-compiled");

                // ReduceMean kernel
                _reduceMeanKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int>(
                    (flatIdx, input, output, outerSize, reduceSize, innerSize) =>
                    {
                        int inner = (int)flatIdx % innerSize;
                        int outer = (int)flatIdx / innerSize;
                        if (outer >= outerSize) return;

                        float sum = 0;
                        for (int r = 0; r < reduceSize; r++)
                        {
                            int inputIdx = (outer * reduceSize + r) * innerSize + inner;
                            sum += input[inputIdx];
                        }
                        output[flatIdx] = sum / reduceSize;
                    });
                _reduceMeanKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int>(
                    (flatIdx, input, output, outerSize, reduceSize, innerSize) =>
                    {
                        int inner = (int)flatIdx % innerSize;
                        int outer = (int)flatIdx / innerSize;
                        if (outer >= outerSize) return;

                        double sum = 0;
                        for (int r = 0; r < reduceSize; r++)
                        {
                            int inputIdx = (outer * reduceSize + r) * innerSize + inner;
                            sum += input[inputIdx];
                        }
                        output[flatIdx] = sum / reduceSize;
                    });
                Console.WriteLine("[GpuEngine] ReduceMean kernels pre-compiled");

                // ReduceMeanBackward kernel
                _reduceMeanBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int>(
                    (flatIdx, gradOutput, gradInput, outerSize, reduceSize, innerSize) =>
                    {
                        int r = (int)flatIdx % reduceSize;
                        int temp = (int)flatIdx / reduceSize;
                        int inner = temp % innerSize;
                        int outer = temp / innerSize;
                        if (outer >= outerSize) return;

                        int outIdx = outer * innerSize + inner;
                        gradInput[flatIdx] = gradOutput[outIdx] / reduceSize;
                    });
                _reduceMeanBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int>(
                    (flatIdx, gradOutput, gradInput, outerSize, reduceSize, innerSize) =>
                    {
                        int r = (int)flatIdx % reduceSize;
                        int temp = (int)flatIdx / reduceSize;
                        int inner = temp % innerSize;
                        int outer = temp / innerSize;
                        if (outer >= outerSize) return;

                        int outIdx = outer * innerSize + inner;
                        gradInput[flatIdx] = gradOutput[outIdx] / reduceSize;
                    });
                Console.WriteLine("[GpuEngine] ReduceMeanBackward kernels pre-compiled");

                // Softmax backward kernel
                _softmaxBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, int, int, int>(
                    (flatIdx, gradOutput, output, gradInput, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        // Compute dot product: sum(gradOutput * output) along axis
                        float dotProduct = 0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            dotProduct += gradOutput[idx] * output[idx];
                        }

                        // gradInput = output * (gradOutput - dotProduct)
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            gradInput[idx] = output[idx] * (gradOutput[idx] - dotProduct);
                        }
                    });
                _softmaxBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, int, int, int>(
                    (flatIdx, gradOutput, output, gradInput, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        double dotProduct = 0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            dotProduct += gradOutput[idx] * output[idx];
                        }

                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            gradInput[idx] = output[idx] * (gradOutput[idx] - dotProduct);
                        }
                    });
                Console.WriteLine("[GpuEngine] SoftmaxBackward kernels pre-compiled");

                // Upsample backward kernel (nearest neighbor)
                _upsampleBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int>(
                    (flatIdx, gradOutput, gradInput, batch, channels, inH, inW, scaleH, scaleW) =>
                    {
                        // Each input gradient element receives sum of corresponding output gradients
                        int iw = (int)flatIdx % inW;
                        int temp = (int)flatIdx / inW;
                        int ih = temp % inH;
                        temp /= inH;
                        int c = temp % channels;
                        int b = temp / channels;

                        int outH = inH * scaleH;
                        int outW = inW * scaleW;
                        float sum = 0;
                        for (int sh = 0; sh < scaleH; sh++)
                        {
                            for (int sw = 0; sw < scaleW; sw++)
                            {
                                int oh = ih * scaleH + sh;
                                int ow = iw * scaleW + sw;
                                int outIdx = ((b * channels + c) * outH + oh) * outW + ow;
                                sum += gradOutput[outIdx];
                            }
                        }
                        gradInput[flatIdx] = sum;
                    });
                _upsampleBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int>(
                    (flatIdx, gradOutput, gradInput, batch, channels, inH, inW, scaleH, scaleW) =>
                    {
                        int iw = (int)flatIdx % inW;
                        int temp = (int)flatIdx / inW;
                        int ih = temp % inH;
                        temp /= inH;
                        int c = temp % channels;
                        int b = temp / channels;

                        int outH = inH * scaleH;
                        int outW = inW * scaleW;
                        double sum = 0;
                        for (int sh = 0; sh < scaleH; sh++)
                        {
                            for (int sw = 0; sw < scaleW; sw++)
                            {
                                int oh = ih * scaleH + sh;
                                int ow = iw * scaleW + sw;
                                int outIdx = ((b * channels + c) * outH + oh) * outW + ow;
                                sum += gradOutput[outIdx];
                            }
                        }
                        gradInput[flatIdx] = sum;
                    });
                Console.WriteLine("[GpuEngine] UpsampleBackward kernels pre-compiled");

                // PixelShuffle backward kernel (space-to-depth)
                _pixelShuffleBackwardKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int>(
                    (flatIdx, gradOutput, gradInput, batch, channels, height, width, upscaleFactor) =>
                    {
                        int r = upscaleFactor;
                        int newChannels = channels / (r * r);
                        int newHeight = height * r;
                        int newWidth = width * r;
                        // Reverse mapping: input[b,c,h,w] <- output[b,newC,newH,newW]
                        int iw = (int)flatIdx % width;
                        int temp = (int)flatIdx / width;
                        int ih = temp % height;
                        temp /= height;
                        int ic = temp % channels;
                        int b = temp / channels;

                        int oc = ic / (r * r);
                        int subIdx = ic % (r * r);
                        int subH = subIdx / r;
                        int subW = subIdx % r;
                        int oh = ih * r + subH;
                        int ow = iw * r + subW;
                        int outIdx = ((b * newChannels + oc) * newHeight + oh) * newWidth + ow;
                        gradInput[flatIdx] = gradOutput[outIdx];
                    });
                _pixelShuffleBackwardKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int>(
                    (flatIdx, gradOutput, gradInput, batch, channels, height, width, upscaleFactor) =>
                    {
                        int r = upscaleFactor;
                        int newChannels = channels / (r * r);
                        int newHeight = height * r;
                        int newWidth = width * r;
                        int iw = (int)flatIdx % width;
                        int temp = (int)flatIdx / width;
                        int ih = temp % height;
                        temp /= height;
                        int ic = temp % channels;
                        int b = temp / channels;

                        int oc = ic / (r * r);
                        int subIdx = ic % (r * r);
                        int subH = subIdx / r;
                        int subW = subIdx % r;
                        int oh = ih * r + subH;
                        int ow = iw * r + subW;
                        int outIdx = ((b * newChannels + oc) * newHeight + oh) * newWidth + ow;
                        gradInput[flatIdx] = gradOutput[outIdx];
                    });
                Console.WriteLine("[GpuEngine] PixelShuffleBackward kernels pre-compiled");

                // ReduceSum kernel
                _reduceSumKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int>(
                    (flatIdx, input, output, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        float sum = 0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            sum += input[idx];
                        }
                        output[flatIdx] = sum;
                    });
                _reduceSumKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int>(
                    (flatIdx, input, output, outerSize, axisSize, innerSize) =>
                    {
                        int outer = (int)flatIdx / innerSize;
                        int inner = (int)flatIdx % innerSize;
                        if (outer >= outerSize) return;

                        double sum = 0;
                        for (int i = 0; i < axisSize; i++)
                        {
                            int idx = (outer * axisSize + i) * innerSize + inner;
                            sum += input[idx];
                        }
                        output[flatIdx] = sum;
                    });
                Console.WriteLine("[GpuEngine] ReduceSum kernels pre-compiled");

                // Crop kernel
                _cropKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int>(
                    (flatIdx, input, output, batch, channels, inH, inW, top, left, cropH, cropW) =>
                    {
                        int ow = (int)flatIdx % cropW;
                        int temp = (int)flatIdx / cropW;
                        int oh = temp % cropH;
                        temp /= cropH;
                        int c = temp % channels;
                        int b = temp / channels;

                        int ih = oh + top;
                        int iw = ow + left;
                        int inIdx = ((b * channels + c) * inH + ih) * inW + iw;
                        output[flatIdx] = input[inIdx];
                    });
                _cropKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int>(
                    (flatIdx, input, output, batch, channels, inH, inW, top, left, cropH, cropW) =>
                    {
                        int ow = (int)flatIdx % cropW;
                        int temp = (int)flatIdx / cropW;
                        int oh = temp % cropH;
                        temp /= cropH;
                        int c = temp % channels;
                        int b = temp / channels;

                        int ih = oh + top;
                        int iw = ow + left;
                        int inIdx = ((b * channels + c) * inH + ih) * inW + iw;
                        output[flatIdx] = input[inIdx];
                    });
                Console.WriteLine("[GpuEngine] Crop kernels pre-compiled");

                // Pad kernel
                _padKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, int, int, int, int, int, int, int, int, float>(
                    (flatIdx, input, output, batch, channels, inH, inW, padTop, padBottom, padLeft, padRight, padValue) =>
                    {
                        int outH = inH + padTop + padBottom;
                        int outW = inW + padLeft + padRight;
                        int ow = (int)flatIdx % outW;
                        int temp = (int)flatIdx / outW;
                        int oh = temp % outH;
                        temp /= outH;
                        int c = temp % channels;
                        int b = temp / channels;

                        int ih = oh - padTop;
                        int iw = ow - padLeft;
                        if (ih >= 0 && ih < inH && iw >= 0 && iw < inW)
                        {
                            int inIdx = ((b * channels + c) * inH + ih) * inW + iw;
                            output[flatIdx] = input[inIdx];
                        }
                        else
                        {
                            output[flatIdx] = padValue;
                        }
                    });
                _padKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, int, int, int, int, int, int, int, int, double>(
                    (flatIdx, input, output, batch, channels, inH, inW, padTop, padBottom, padLeft, padRight, padValue) =>
                    {
                        int outH = inH + padTop + padBottom;
                        int outW = inW + padLeft + padRight;
                        int ow = (int)flatIdx % outW;
                        int temp = (int)flatIdx / outW;
                        int oh = temp % outH;
                        temp /= outH;
                        int c = temp % channels;
                        int b = temp / channels;

                        int ih = oh - padTop;
                        int iw = ow - padLeft;
                        if (ih >= 0 && ih < inH && iw >= 0 && iw < inW)
                        {
                            int inIdx = ((b * channels + c) * inH + ih) * inW + iw;
                            output[flatIdx] = input[inIdx];
                        }
                        else
                        {
                            output[flatIdx] = padValue;
                        }
                    });
                Console.WriteLine("[GpuEngine] Pad kernels pre-compiled");

                // Trigonometric kernels
                _asinKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, output) => output[index] = XMath.Asin(input[index]));
                _asinKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, output) => output[index] = XMath.Asin(input[index]));

                _acosKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, output) => output[index] = XMath.Acos(input[index]));
                _acosKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, output) => output[index] = XMath.Acos(input[index]));

                _atanKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, output) => output[index] = XMath.Atan(input[index]));
                _atanKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, output) => output[index] = XMath.Atan(input[index]));

                // Note: XMath doesn't have Asinh, Acosh, Atanh - using mathematical identities
                // asinh(x) = ln(x + sqrt(x^2 + 1))
                _asinhKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, output) =>
                    {
                        var x = input[index];
                        output[index] = XMath.Log(x + XMath.Sqrt(x * x + 1.0f));
                    });
                _asinhKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, output) =>
                    {
                        var x = input[index];
                        output[index] = XMath.Log(x + XMath.Sqrt(x * x + 1.0));
                    });

                // acosh(x) = ln(x + sqrt(x^2 - 1))
                _acoshKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, output) =>
                    {
                        var x = input[index];
                        output[index] = XMath.Log(x + XMath.Sqrt(x * x - 1.0f));
                    });
                _acoshKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, output) =>
                    {
                        var x = input[index];
                        output[index] = XMath.Log(x + XMath.Sqrt(x * x - 1.0));
                    });

                // atanh(x) = 0.5 * ln((1 + x) / (1 - x))
                _atanhKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>>(
                    (index, input, output) =>
                    {
                        var x = input[index];
                        output[index] = 0.5f * XMath.Log((1.0f + x) / (1.0f - x));
                    });
                _atanhKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>>(
                    (index, input, output) =>
                    {
                        var x = input[index];
                        output[index] = 0.5 * XMath.Log((1.0 + x) / (1.0 - x));
                    });
                Console.WriteLine("[GpuEngine] Trigonometric kernels pre-compiled");

                // LocallyConnectedConv2D kernels - position-specific weights (6D weight tensor)
                // Forward: output[b,oc,oh,ow] = sum over ic,kh,kw of input * weights[oh,ow,oc,ic,kh,kw] + bias
                _locallyConnectedConv2DKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>, ArrayView<float>,
                    LocallyConnectedConv2DParams, int>(LocallyConnectedConv2DKernels.ForwardKernelFloatImpl);
                _locallyConnectedConv2DKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>, ArrayView<double>,
                    LocallyConnectedConv2DParams, int>(LocallyConnectedConv2DKernels.ForwardKernelDoubleImpl);

                // BackwardInput: gradInput[b,ic,ih,iw] = sum of gradOutput * weights
                _locallyConnectedConv2DBackwardInputKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>,
                    LocallyConnectedConv2DParams>(LocallyConnectedConv2DKernels.BackwardInputKernelFloatImpl);
                _locallyConnectedConv2DBackwardInputKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>,
                    LocallyConnectedConv2DParams>(LocallyConnectedConv2DKernels.BackwardInputKernelDoubleImpl);

                // BackwardWeights: gradWeights[oh,ow,oc,ic,kh,kw] += sum over b of gradOutput * input
                _locallyConnectedConv2DBackwardWeightsKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>, ArrayView<float>,
                    LocallyConnectedConv2DParams>(LocallyConnectedConv2DKernels.BackwardWeightsKernelFloatImpl);
                _locallyConnectedConv2DBackwardWeightsKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>, ArrayView<double>,
                    LocallyConnectedConv2DParams>(LocallyConnectedConv2DKernels.BackwardWeightsKernelDoubleImpl);

                // BackwardBias: gradBias[oh,ow,oc] = sum over b of gradOutput[b,oc,oh,ow]
                _locallyConnectedConv2DBackwardBiasKernelFloat = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<float>, ArrayView<float>,
                    LocallyConnectedConv2DParams>(LocallyConnectedConv2DKernels.BackwardBiasKernelFloatImpl);
                _locallyConnectedConv2DBackwardBiasKernelDouble = _accelerator.LoadAutoGroupedKernel<
                    Index1D, ArrayView<double>, ArrayView<double>,
                    LocallyConnectedConv2DParams>(LocallyConnectedConv2DKernels.BackwardBiasKernelDoubleImpl);
                Console.WriteLine("[GpuEngine] LocallyConnectedConv2D kernels pre-compiled");

                Console.WriteLine("[GpuEngine] All kernel pre-compilation complete");

                // Initialize memory pools (Phase B: US-GPU-002, US-GPU-005)
                _memoryPoolFloat = new GpuMemoryPool<float>(_accelerator);
                _memoryPoolDouble = new GpuMemoryPool<double>(_accelerator);
                _memoryPoolInt = new GpuMemoryPool<int>(_accelerator);
                _memoryPoolLong = new GpuMemoryPool<long>(_accelerator);
                Console.WriteLine("[GpuEngine] Memory pools initialized");
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or DllNotFoundException or PlatformNotSupportedException or OutOfMemoryException or CLException)
        {
            _gpuHealthy = false;
            Console.WriteLine($"[GpuEngine] GPU initialization failed: {ex.Message}");
            Console.WriteLine("[GpuEngine] Operations will fallback to CPU");
        }
    }

    /// <inheritdoc/>
    public Vector<T> Add<T>(Vector<T> a, Vector<T> b)
    {
        // Adaptive execution: check size threshold (Phase B: US-GPU-004)
        if (a.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.Add(a, b); // CPU for small operations
        }

        // Check GPU health before attempting GPU operations (Phase B: US-GPU-006)
        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)AddGpu((Vector<float>)(object)a, (Vector<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)AddGpuDouble((Vector<double>)(object)a, (Vector<double>)(object)b);
            if (typeof(T) == typeof(int))
                return (Vector<T>)(object)AddGpuInt((Vector<int>)(object)a, (Vector<int>)(object)b);
            if (typeof(T) == typeof(long))
                return (Vector<T>)(object)AddGpuLong((Vector<long>)(object)a, (Vector<long>)(object)b);
        }

        // Fallback to CPU for unsupported types or unhealthy GPU
        return _cpuFallback.Add(a, b);
    }

    /// <inheritdoc/>
    public Vector<T> Subtract<T>(Vector<T> a, Vector<T> b)
    {
        if (a.Length < _thresholds.VectorSubtract)
            return _cpuFallback.Subtract(a, b);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)SubtractGpu((Vector<float>)(object)a, (Vector<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)SubtractGpuDouble((Vector<double>)(object)a, (Vector<double>)(object)b);
            if (typeof(T) == typeof(int))
                return (Vector<T>)(object)SubtractGpuInt((Vector<int>)(object)a, (Vector<int>)(object)b);
            if (typeof(T) == typeof(long))
                return (Vector<T>)(object)SubtractGpuLong((Vector<long>)(object)a, (Vector<long>)(object)b);
        }

        return _cpuFallback.Subtract(a, b);
    }

    /// <inheritdoc/>
    public Vector<T> Multiply<T>(Vector<T> a, Vector<T> b)
    {
        if (a.Length < _thresholds.VectorMultiply)
            return _cpuFallback.Multiply(a, b);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)MultiplyGpu((Vector<float>)(object)a, (Vector<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)MultiplyGpuDouble((Vector<double>)(object)a, (Vector<double>)(object)b);
            if (typeof(T) == typeof(int))
                return (Vector<T>)(object)MultiplyGpuInt((Vector<int>)(object)a, (Vector<int>)(object)b);
            if (typeof(T) == typeof(long))
                return (Vector<T>)(object)MultiplyGpuLong((Vector<long>)(object)a, (Vector<long>)(object)b);
        }

        return _cpuFallback.Multiply(a, b);
    }

    /// <inheritdoc/>
    public Vector<T> Multiply<T>(Vector<T> vector, T scalar)
    {
        if (vector.Length < _thresholds.VectorMultiply)
            return _cpuFallback.Multiply(vector, scalar);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)MultiplyScalarGpu((Vector<float>)(object)vector, (float)(object)scalar!);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)MultiplyScalarGpuDouble((Vector<double>)(object)vector, (double)(object)scalar!);
            if (typeof(T) == typeof(int))
                return (Vector<T>)(object)MultiplyScalarGpuInt((Vector<int>)(object)vector, (int)(object)scalar!);
            if (typeof(T) == typeof(long))
                return (Vector<T>)(object)MultiplyScalarGpuLong((Vector<long>)(object)vector, (long)(object)scalar!);
        }

        return _cpuFallback.Multiply(vector, scalar);
    }

    /// <inheritdoc/>
    public Vector<T> Divide<T>(Vector<T> a, Vector<T> b)
    {
        if (a.Length < _thresholds.VectorDivide)
            return _cpuFallback.Divide(a, b);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)DivideGpu((Vector<float>)(object)a, (Vector<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)DivideGpuDouble((Vector<double>)(object)a, (Vector<double>)(object)b);
            if (typeof(T) == typeof(int))
                return (Vector<T>)(object)DivideGpuInt((Vector<int>)(object)a, (Vector<int>)(object)b);
            if (typeof(T) == typeof(long))
                return (Vector<T>)(object)DivideGpuLong((Vector<long>)(object)a, (Vector<long>)(object)b);
        }

        return _cpuFallback.Divide(a, b);
    }

    /// <inheritdoc/>
    public Vector<T> Divide<T>(Vector<T> vector, T scalar)
    {
        if (vector.Length < _thresholds.VectorDivide)
            return _cpuFallback.Divide(vector, scalar);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)DivideScalarGpu((Vector<float>)(object)vector, (float)(object)scalar!);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)DivideScalarGpuDouble((Vector<double>)(object)vector, (double)(object)scalar!);
            if (typeof(T) == typeof(int))
                return (Vector<T>)(object)DivideScalarGpuInt((Vector<int>)(object)vector, (int)(object)scalar!);
            if (typeof(T) == typeof(long))
                return (Vector<T>)(object)DivideScalarGpuLong((Vector<long>)(object)vector, (long)(object)scalar!);
        }

        return _cpuFallback.Divide(vector, scalar);
    }

    /// <inheritdoc/>
    public Vector<T> Sqrt<T>(Vector<T> vector)
    {
        if (vector.Length < _thresholds.VectorSqrt)
            return _cpuFallback.Sqrt(vector);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)SqrtGpu((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)SqrtGpuDouble((Vector<double>)(object)vector);
        }

        return _cpuFallback.Sqrt(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Power<T>(Vector<T> vector, T exponent)
    {
        if (vector.Length < _thresholds.VectorPower)
            return _cpuFallback.Power(vector, exponent);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)PowerGpu((Vector<float>)(object)vector, (float)(object)exponent!);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)PowerGpuDouble((Vector<double>)(object)vector, (double)(object)exponent!);
        }

        return _cpuFallback.Power(vector, exponent);
    }

    /// <inheritdoc/>
    public Vector<T> Max<T>(Vector<T> a, Vector<T> b)
    {
        if (a.Length < _thresholds.VectorAdd) // Reuse VectorAdd threshold
            return _cpuFallback.Max(a, b);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)MaxGpu((Vector<float>)(object)a, (Vector<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)MaxGpuDouble((Vector<double>)(object)a, (Vector<double>)(object)b);
        }

        return _cpuFallback.Max(a, b);
    }

    /// <inheritdoc/>
    public Vector<T> Min<T>(Vector<T> a, Vector<T> b)
    {
        if (a.Length < _thresholds.VectorAdd) // Reuse VectorAdd threshold
            return _cpuFallback.Min(a, b);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)MinGpu((Vector<float>)(object)a, (Vector<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)MinGpuDouble((Vector<double>)(object)a, (Vector<double>)(object)b);
        }

        return _cpuFallback.Min(a, b);
    }

    /// <inheritdoc/>
    public Vector<T> Abs<T>(Vector<T> vector)
    {
        if (vector.Length < _thresholds.VectorSqrt) // Reuse VectorSqrt threshold
            return _cpuFallback.Abs(vector);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)AbsGpu((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)AbsGpuDouble((Vector<double>)(object)vector);
        }

        return _cpuFallback.Abs(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Exp<T>(Vector<T> vector)
    {
        if (vector.Length < _thresholds.VectorSqrt) // Reuse VectorSqrt threshold
            return _cpuFallback.Exp(vector);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)ExpGpu((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)ExpGpuDouble((Vector<double>)(object)vector);
        }

        return _cpuFallback.Exp(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Log<T>(Vector<T> vector)
    {
        if (vector.Length < _thresholds.VectorSqrt) // Reuse VectorSqrt threshold
            return _cpuFallback.Log(vector);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)LogGpu((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)LogGpuDouble((Vector<double>)(object)vector);
        }

        return _cpuFallback.Log(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Sign<T>(Vector<T> vector)
    {
        if (vector.Length < _thresholds.VectorSqrt) // Reuse VectorSqrt threshold
            return _cpuFallback.Sign(vector);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)SignGpu((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)SignGpuDouble((Vector<double>)(object)vector);
        }

        return _cpuFallback.Sign(vector);
    }

    #region Reduction Operations

    /// <inheritdoc/>
    public T Sum<T>(Vector<T> vector)
    {
        // GPU reduction for large vectors
        if (vector.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (T)(object)SumGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (T)(object)SumGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Sum(vector);
    }

    /// <inheritdoc/>
    public T DotProduct<T>(Vector<T> a, Vector<T> b)
    {
        // GPU dot product for large vectors
        if (a.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (T)(object)DotProductGpuFloat((Vector<float>)(object)a, (Vector<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (T)(object)DotProductGpuDouble((Vector<double>)(object)a, (Vector<double>)(object)b);
        }
        return _cpuFallback.DotProduct(a, b);
    }

    /// <inheritdoc/>
    public T Mean<T>(Vector<T> vector)
    {
        // GPU mean = sum / length
        if (vector.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                float sum = SumGpuFloat((Vector<float>)(object)vector);
                return (T)(object)(sum / vector.Length);
            }
            if (typeof(T) == typeof(double))
            {
                double sum = SumGpuDouble((Vector<double>)(object)vector);
                return (T)(object)(sum / vector.Length);
            }
        }
        return _cpuFallback.Mean(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Softmax<T>(Vector<T> vector)
    {
        // GPU softmax with numerical stability
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)SoftmaxGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)SoftmaxGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Softmax(vector);
    }

    /// <inheritdoc/>
    public T CosineSimilarity<T>(Vector<T> a, Vector<T> b)
    {
        // GPU cosine similarity using dot product and norms
        if (a.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                float dot = DotProductGpuFloat((Vector<float>)(object)a, (Vector<float>)(object)b);
                float normA = NormGpuFloat((Vector<float>)(object)a);
                float normB = NormGpuFloat((Vector<float>)(object)b);
                if (normA == 0 || normB == 0) return (T)(object)0.0f;
                return (T)(object)(dot / (normA * normB));
            }
            if (typeof(T) == typeof(double))
            {
                double dot = DotProductGpuDouble((Vector<double>)(object)a, (Vector<double>)(object)b);
                double normA = NormGpuDouble((Vector<double>)(object)a);
                double normB = NormGpuDouble((Vector<double>)(object)b);
                if (normA == 0 || normB == 0) return (T)(object)0.0;
                return (T)(object)(dot / (normA * normB));
            }
        }
        return _cpuFallback.CosineSimilarity(a, b);
    }

    /// <inheritdoc/>
    public Vector<T> Log2<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)Log2GpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)Log2GpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Log2(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Exp2<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)Exp2GpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)Exp2GpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Exp2(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Exp10<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)Exp10GpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)Exp10GpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Exp10(vector);
    }

    /// <inheritdoc/>
    public Vector<T> ExpM1<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)ExpM1GpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)ExpM1GpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.ExpM1(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Log1P<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)Log1PGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)Log1PGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Log1P(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Negate<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)NegateGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)NegateGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Negate(vector);
    }

    /// <inheritdoc/>
    public T Product<T>(Vector<T> vector)
    {
        // Product on GPU uses log-sum-exp for numerical stability: prod = exp(sum(log(|x|))) * sign
        // Only for large vectors since log/exp overhead is significant
        if (vector.Length >= _thresholds.VectorAdd * 2 && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (T)(object)ProductGpu((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (T)(object)ProductGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Product(vector);
    }

    private float ProductGpu(Vector<float> vector)
    {
        try
        {
            // For GPU product, we use: prod = sign * exp(sum(log(|x|)))
            // This avoids overflow/underflow issues with direct multiplication
            var span = vector.AsSpan();
            int sign = 1;
            bool hasZero = false;

            // Quick scan for zeros and sign (CPU, fast for most vectors)
            for (int i = 0; i < span.Length; i++)
            {
                if (span[i] == 0) { hasZero = true; break; }
                if (span[i] < 0) sign = -sign;
            }

            if (hasZero) return 0.0f;

            // Use GPU for log, sum, then CPU for exp
            var absVector = new Vector<float>(vector.Length);
            var absSpan = absVector.AsWritableSpan();
            for (int i = 0; i < span.Length; i++)
                absSpan[i] = Math.Abs(span[i]);

            var logVector = Log(absVector);
            float logSum = Sum(logVector);
            return sign * (float)Math.Exp(logSum);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU Product failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Product(vector);
        }
    }

    private double ProductGpuDouble(Vector<double> vector)
    {
        try
        {
            var span = vector.AsSpan();
            int sign = 1;
            bool hasZero = false;

            for (int i = 0; i < span.Length; i++)
            {
                if (span[i] == 0) { hasZero = true; break; }
                if (span[i] < 0) sign = -sign;
            }

            if (hasZero) return 0.0;

            var absVector = new Vector<double>(vector.Length);
            var absSpan = absVector.AsWritableSpan();
            for (int i = 0; i < span.Length; i++)
                absSpan[i] = Math.Abs(span[i]);

            var logVector = Log(absVector);
            double logSum = Sum(logVector);
            return sign * Math.Exp(logSum);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU Product (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Product(vector);
        }
    }

    /// <inheritdoc/>
    public T StdDev<T>(Vector<T> vector)
    {
        // GPU standard deviation using mean and variance
        if (vector.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                float mean = (float)(object)Mean(vector)!;
                float variance = StdDevGpuFloat((Vector<float>)(object)vector, mean);
                return (T)(object)variance;
            }
            if (typeof(T) == typeof(double))
            {
                double mean = (double)(object)Mean(vector)!;
                double variance = StdDevGpuDouble((Vector<double>)(object)vector, mean);
                return (T)(object)variance;
            }
        }
        return _cpuFallback.StdDev(vector);
    }

    /// <inheritdoc/>
    public T Norm<T>(Vector<T> vector)
    {
        // GPU L2 norm: sqrt(sum(x^2))
        if (vector.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (T)(object)NormGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (T)(object)NormGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Norm(vector);
    }

    /// <inheritdoc/>
    public T Distance<T>(Vector<T> a, Vector<T> b)
    {
        // GPU Euclidean distance: sqrt(sum((a-b)^2))
        if (a.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (T)(object)DistanceGpuFloat((Vector<float>)(object)a, (Vector<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (T)(object)DistanceGpuDouble((Vector<double>)(object)a, (Vector<double>)(object)b);
        }
        return _cpuFallback.Distance(a, b);
    }

    /// <inheritdoc/>
    public Vector<T> MinMagnitude<T>(Vector<T> a, Vector<T> b)
    {
        if (a.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)MinMagnitudeGpuFloat((Vector<float>)(object)a, (Vector<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)MinMagnitudeGpuDouble((Vector<double>)(object)a, (Vector<double>)(object)b);
        }
        return _cpuFallback.MinMagnitude(a, b);
    }

    /// <inheritdoc/>
    public Vector<T> MaxMagnitude<T>(Vector<T> a, Vector<T> b)
    {
        if (a.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)MaxMagnitudeGpuFloat((Vector<float>)(object)a, (Vector<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)MaxMagnitudeGpuDouble((Vector<double>)(object)a, (Vector<double>)(object)b);
        }
        return _cpuFallback.MaxMagnitude(a, b);
    }

    /// <inheritdoc/>
    public Vector<T> Clamp<T>(Vector<T> vector, T min, T max)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)ClampGpuFloat((Vector<float>)(object)vector, (float)(object)min!, (float)(object)max!);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)ClampGpuDouble((Vector<double>)(object)vector, (double)(object)min!, (double)(object)max!);
        }
        return _cpuFallback.Clamp(vector, min, max);
    }

    /// <inheritdoc/>
    public Vector<T> Lerp<T>(Vector<T> a, Vector<T> b, T t)
    {
        if (a.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)LerpGpuFloat((Vector<float>)(object)a, (Vector<float>)(object)b, (float)(object)t!);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)LerpGpuDouble((Vector<double>)(object)a, (Vector<double>)(object)b, (double)(object)t!);
        }
        return _cpuFallback.Lerp(a, b, t);
    }

    /// <inheritdoc/>
    public Vector<T> Reciprocal<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)ReciprocalGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)ReciprocalGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Reciprocal(vector);
    }

    /// <inheritdoc/>
    public Vector<T> ReciprocalSqrt<T>(Vector<T> vector)
    {
        // Hardware rsqrt is critical for normalization layers
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)ReciprocalSqrtGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)ReciprocalSqrtGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.ReciprocalSqrt(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Sin<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)SinGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)SinGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Sin(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Cos<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)CosGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)CosGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Cos(vector);
    }

    /// <inheritdoc/>
    public void SinCos<T>(Vector<T> vector, out Vector<T> sinResult, out Vector<T> cosResult)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                sinResult = (Vector<T>)(object)SinGpuFloat((Vector<float>)(object)vector);
                cosResult = (Vector<T>)(object)CosGpuFloat((Vector<float>)(object)vector);
                return;
            }
            if (typeof(T) == typeof(double))
            {
                sinResult = (Vector<T>)(object)SinGpuDouble((Vector<double>)(object)vector);
                cosResult = (Vector<T>)(object)CosGpuDouble((Vector<double>)(object)vector);
                return;
            }
        }
        _cpuFallback.SinCos(vector, out sinResult, out cosResult);
    }

    /// <inheritdoc/>
    public Vector<T> Sinh<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)SinhGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)SinhGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Sinh(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Cosh<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)CoshGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)CoshGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Cosh(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Asinh<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)AsinhGpuVectorFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)AsinhGpuVectorDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Asinh(vector);
    }

    private Vector<float> AsinhGpuVectorFloat(Vector<float> vector)
    {
        var result = new float[vector.Length];
        AsinhGpuFloat(vector.AsSpan(), result);
        return new Vector<float>(result);
    }

    private Vector<double> AsinhGpuVectorDouble(Vector<double> vector)
    {
        var result = new double[vector.Length];
        AsinhGpuDouble(vector.AsSpan(), result);
        return new Vector<double>(result);
    }

    /// <inheritdoc/>
    public Vector<T> Acosh<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)AcoshGpuVectorFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)AcoshGpuVectorDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Acosh(vector);
    }

    private Vector<float> AcoshGpuVectorFloat(Vector<float> vector)
    {
        var result = new float[vector.Length];
        AcoshGpuFloat(vector.AsSpan(), result);
        return new Vector<float>(result);
    }

    private Vector<double> AcoshGpuVectorDouble(Vector<double> vector)
    {
        var result = new double[vector.Length];
        AcoshGpuDouble(vector.AsSpan(), result);
        return new Vector<double>(result);
    }

    /// <inheritdoc/>
    public Vector<T> Atanh<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)AtanhGpuVectorFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)AtanhGpuVectorDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Atanh(vector);
    }

    private Vector<float> AtanhGpuVectorFloat(Vector<float> vector)
    {
        var result = new float[vector.Length];
        AtanhGpuFloat(vector.AsSpan(), result);
        return new Vector<float>(result);
    }

    private Vector<double> AtanhGpuVectorDouble(Vector<double> vector)
    {
        var result = new double[vector.Length];
        AtanhGpuDouble(vector.AsSpan(), result);
        return new Vector<double>(result);
    }

    /// <inheritdoc/>
    public Vector<T> Round<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)RoundGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)RoundGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Round(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Floor<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)FloorGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)FloorGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Floor(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Ceiling<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)CeilingGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)CeilingGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Ceiling(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Truncate<T>(Vector<T> vector)
    {
        if (vector.Length >= _thresholds.VectorSqrt && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)TruncateGpuFloat((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)TruncateGpuDouble((Vector<double>)(object)vector);
        }
        return _cpuFallback.Truncate(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Fill<T>(int length, T value)
    {
        if (length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)FillGpuFloat(length, (float)(object)value!);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)FillGpuDouble(length, (double)(object)value!);
        }
        return _cpuFallback.Fill(length, value);
    }

    /// <inheritdoc/>
    public Vector<T> FillZero<T>(int length)
    {
        if (length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)FillGpuFloat(length, 0.0f);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)FillGpuDouble(length, 0.0);
        }
        return _cpuFallback.FillZero<T>(length);
    }

    /// <inheritdoc/>
    public Vector<T> GenerateDropoutMask<T>(int length, T dropoutRate, T scale, int? seed = null)
    {
        // GPU random number generation requires cuRAND integration
        // CPU fallback maintains reproducibility with seed
        return _cpuFallback.GenerateDropoutMask(length, dropoutRate, scale, seed);
    }

    /// <inheritdoc/>
    public void CopyVectorToTensor<T>(Vector<T> source, Tensor<T> destination)
    {
        // Direct memory copy handled by CPU for cross-type flexibility
        _cpuFallback.CopyVectorToTensor(source, destination);
    }

    /// <inheritdoc/>
    public Vector<T> GenerateGaussianNoise<T>(int length, T mean, T standardDeviation, int? seed = null)
    {
        // GPU random number generation requires cuRAND integration
        // CPU fallback maintains reproducibility with seed
        return _cpuFallback.GenerateGaussianNoise(length, mean, standardDeviation, seed);
    }

    #endregion

    #region Activation Functions

    /// <inheritdoc/>
    public Vector<T> Tanh<T>(Vector<T> vector)
    {
        if (vector.Length < _thresholds.VectorSqrt)
            return _cpuFallback.Tanh(vector);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)TanhGpu((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)TanhGpuDouble((Vector<double>)(object)vector);
        }

        return _cpuFallback.Tanh(vector);
    }

    /// <inheritdoc/>
    public Vector<T> Sigmoid<T>(Vector<T> vector)
    {
        if (vector.Length < _thresholds.VectorSqrt)
            return _cpuFallback.Sigmoid(vector);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)SigmoidGpu((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)SigmoidGpuDouble((Vector<double>)(object)vector);
        }

        return _cpuFallback.Sigmoid(vector);
    }

    /// <inheritdoc/>
    public Vector<T> ReLU<T>(Vector<T> vector)
    {
        if (vector.Length < _thresholds.VectorSqrt)
            return _cpuFallback.ReLU(vector);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)ReLUGpu((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)ReLUGpuDouble((Vector<double>)(object)vector);
        }

        return _cpuFallback.ReLU(vector);
    }

    /// <inheritdoc/>
    public Tensor<T> Tanh<T>(Tensor<T> tensor)
    {
        if (tensor.Length < _thresholds.MatrixMultiply)
            return _cpuFallback.Tanh(tensor);

        if (SupportsGpu && _gpuHealthy)
        {
            var flatVector = tensor.ToVector();
            if (typeof(T) == typeof(float))
            {
                var result = TanhGpu((Vector<float>)(object)flatVector);
                return new Tensor<T>(tensor.Shape, (Vector<T>)(object)result);
            }
            if (typeof(T) == typeof(double))
            {
                var result = TanhGpuDouble((Vector<double>)(object)flatVector);
                return new Tensor<T>(tensor.Shape, (Vector<T>)(object)result);
            }
        }

        return _cpuFallback.Tanh(tensor);
    }

    /// <inheritdoc/>
    public Tensor<T> Sigmoid<T>(Tensor<T> tensor)
    {
        if (tensor.Length < _thresholds.MatrixMultiply)
            return _cpuFallback.Sigmoid(tensor);

        if (SupportsGpu && _gpuHealthy)
        {
            var flatVector = tensor.ToVector();
            if (typeof(T) == typeof(float))
            {
                var result = SigmoidGpu((Vector<float>)(object)flatVector);
                return new Tensor<T>(tensor.Shape, (Vector<T>)(object)result);
            }
            if (typeof(T) == typeof(double))
            {
                var result = SigmoidGpuDouble((Vector<double>)(object)flatVector);
                return new Tensor<T>(tensor.Shape, (Vector<T>)(object)result);
            }
        }

        return _cpuFallback.Sigmoid(tensor);
    }

    /// <inheritdoc/>
    public Tensor<T> ReLU<T>(Tensor<T> tensor)
    {
        if (tensor.Length < _thresholds.MatrixMultiply)
            return _cpuFallback.ReLU(tensor);

        if (SupportsGpu && _gpuHealthy)
        {
            var flatVector = tensor.ToVector();
            if (typeof(T) == typeof(float))
            {
                var result = ReLUGpu((Vector<float>)(object)flatVector);
                return new Tensor<T>(tensor.Shape, (Vector<T>)(object)result);
            }
            if (typeof(T) == typeof(double))
            {
                var result = ReLUGpuDouble((Vector<double>)(object)flatVector);
                return new Tensor<T>(tensor.Shape, (Vector<T>)(object)result);
            }
        }

        return _cpuFallback.ReLU(tensor);
    }

    /// <inheritdoc/>
    public Vector<T> GELU<T>(Vector<T> vector)
    {
        if (vector.Length < _thresholds.VectorSqrt)
            return _cpuFallback.GELU(vector);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)GELUGpu((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)GELUGpuDouble((Vector<double>)(object)vector);
        }

        return _cpuFallback.GELU(vector);
    }

    /// <inheritdoc/>
    public Tensor<T> GELU<T>(Tensor<T> tensor)
    {
        if (tensor.Length < _thresholds.MatrixMultiply)
            return _cpuFallback.GELU(tensor);

        if (SupportsGpu && _gpuHealthy)
        {
            var flatVector = tensor.ToVector();
            if (typeof(T) == typeof(float))
            {
                var result = GELUGpu((Vector<float>)(object)flatVector);
                return new Tensor<T>(tensor.Shape, (Vector<T>)(object)result);
            }
            if (typeof(T) == typeof(double))
            {
                var result = GELUGpuDouble((Vector<double>)(object)flatVector);
                return new Tensor<T>(tensor.Shape, (Vector<T>)(object)result);
            }
        }

        return _cpuFallback.GELU(tensor);
    }

    /// <inheritdoc/>
    public Vector<T> Mish<T>(Vector<T> vector)
    {
        if (vector.Length < _thresholds.VectorSqrt)
            return _cpuFallback.Mish(vector);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)MishGpu((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)MishGpuDouble((Vector<double>)(object)vector);
        }

        return _cpuFallback.Mish(vector);
    }

    /// <inheritdoc/>
    public Tensor<T> Mish<T>(Tensor<T> tensor)
    {
        if (tensor.Length < _thresholds.MatrixMultiply)
            return _cpuFallback.Mish(tensor);

        if (SupportsGpu && _gpuHealthy)
        {
            var flatVector = tensor.ToVector();
            if (typeof(T) == typeof(float))
            {
                var result = MishGpu((Vector<float>)(object)flatVector);
                return new Tensor<T>(tensor.Shape, (Vector<T>)(object)result);
            }
            if (typeof(T) == typeof(double))
            {
                var result = MishGpuDouble((Vector<double>)(object)flatVector);
                return new Tensor<T>(tensor.Shape, (Vector<T>)(object)result);
            }
        }

        return _cpuFallback.Mish(tensor);
    }

    /// <inheritdoc/>
    public Vector<T> Swish<T>(Vector<T> vector)
    {
        if (vector.Length < _thresholds.VectorSqrt)
            return _cpuFallback.Swish(vector);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)SwishGpu((Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)SwishGpuDouble((Vector<double>)(object)vector);
        }

        return _cpuFallback.Swish(vector);
    }

    /// <inheritdoc/>
    public Tensor<T> Swish<T>(Tensor<T> tensor)
    {
        if (tensor.Length < _thresholds.MatrixMultiply)
            return _cpuFallback.Swish(tensor);

        if (SupportsGpu && _gpuHealthy)
        {
            var flatVector = tensor.ToVector();
            if (typeof(T) == typeof(float))
            {
                var result = SwishGpu((Vector<float>)(object)flatVector);
                return new Tensor<T>(tensor.Shape, (Vector<T>)(object)result);
            }
            if (typeof(T) == typeof(double))
            {
                var result = SwishGpuDouble((Vector<double>)(object)flatVector);
                return new Tensor<T>(tensor.Shape, (Vector<T>)(object)result);
            }
        }

        return _cpuFallback.Swish(tensor);
    }

    /// <inheritdoc/>
    public Vector<T> ELU<T>(Vector<T> vector, double alpha = 1.0)
    {
        if (vector.Length < _thresholds.VectorSqrt)
            return _cpuFallback.ELU(vector, alpha);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)ELUGpu((Vector<float>)(object)vector, (float)alpha);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)ELUGpuDouble((Vector<double>)(object)vector, alpha);
        }

        return _cpuFallback.ELU(vector, alpha);
    }

    /// <inheritdoc/>
    public Tensor<T> ELU<T>(Tensor<T> tensor, double alpha = 1.0)
    {
        if (tensor.Length < _thresholds.MatrixMultiply)
            return _cpuFallback.ELU(tensor, alpha);

        if (SupportsGpu && _gpuHealthy)
        {
            var flatVector = tensor.ToVector();
            if (typeof(T) == typeof(float))
            {
                var result = ELUGpu((Vector<float>)(object)flatVector, (float)alpha);
                return new Tensor<T>(tensor.Shape, (Vector<T>)(object)result);
            }
            if (typeof(T) == typeof(double))
            {
                var result = ELUGpuDouble((Vector<double>)(object)flatVector, alpha);
                return new Tensor<T>(tensor.Shape, (Vector<T>)(object)result);
            }
        }

        return _cpuFallback.ELU(tensor, alpha);
    }

    #endregion

    #region GPU Kernels (Float Implementation)

    // Note: These are simple, unoptimized kernels for the prototype.
    // Production implementation would use optimized ILGPU.Algorithms or custom kernels.

    private Vector<float> AddGpu(Vector<float> a, Vector<float> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<float>(a.Length);

        // Rent GPU memory from pool (Phase B: US-GPU-002)
        var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            // Zero-copy: Use span instead of ToArray() (Phase B: US-GPU-003)
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                // Use pre-compiled cached kernel (Phase B: US-GPU-001)
                (_addKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            // Zero-copy: Write directly to result's internal storage (Phase B: US-GPU-003)
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());

            return result;
        }
        catch (OutOfMemoryException ex)
        {
            // GPU memory exhausted - fallback to CPU (Phase B: US-GPU-006)
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Add(a, b);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            // Critical GPU failure - record and potentially recover (Phase B: US-GPU-006, US-GPU-020)
            RecordGpuFailure(ex);
            return _cpuFallback.Add(a, b);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            // GPU operation failed - fallback to CPU (Phase B: US-GPU-006)
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Add(a, b);
        }
        finally
        {
            // Return buffers to pool for reuse
            _memoryPoolFloat.Return(gpuA);
            _memoryPoolFloat.Return(gpuB);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> SubtractGpu(Vector<float> a, Vector<float> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<float>(a.Length);
        var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            (_subtractKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_subtractKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolFloat.Return(gpuA);
            _memoryPoolFloat.Return(gpuB);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> MultiplyGpu(Vector<float> a, Vector<float> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<float>(a.Length);
        var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            (_multiplyKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_multiplyKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolFloat.Return(gpuA);
            _memoryPoolFloat.Return(gpuB);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> MultiplyScalarGpu(Vector<float> vector, float scalar)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());
            (_multiplyScalarKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, scalar, gpuResult.View);
            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_multiplyScalarKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, scalar, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> DivideGpu(Vector<float> a, Vector<float> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<float>(a.Length);
        var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            (_divideKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_divideKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolFloat.Return(gpuA);
            _memoryPoolFloat.Return(gpuB);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> DivideScalarGpu(Vector<float> vector, float scalar)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());
            (_divideScalarKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, scalar, gpuResult.View);
            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_divideScalarKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, scalar, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> SqrtGpu(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());
            (_sqrtKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_sqrtKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> PowerGpu(Vector<float> vector, float exponent)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());
            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_powerKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, exponent, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> MaxGpu(Vector<float> a, Vector<float> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<float>(a.Length);
        var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_maxKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Max(a, b);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuA);
            _memoryPoolFloat.Return(gpuB);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> MinGpu(Vector<float> a, Vector<float> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<float>(a.Length);
        var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_minKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Min(a, b);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuA);
            _memoryPoolFloat.Return(gpuB);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> AbsGpu(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_absKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Abs(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> ExpGpu(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_expKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Exp(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> LogGpu(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_logKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Log(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> SignGpu(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_signKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Sign(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    // Activation function GPU implementations (Phase B: US-GPU-004)
    private Vector<float> TanhGpu(Vector<float> input)
    {
        var result = new Vector<float>(input.Length);
        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            // Zero-copy: Use span instead of ToArray()
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

            // Thread-safe kernel execution
            lock (_gpuLock)
            {
                (_tanhKernelFloat ?? throw new InvalidOperationException("Tanh kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            // Zero-copy: Write directly to result
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());

            return result;
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Tanh(input);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Tanh(input);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Tanh(input);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> SigmoidGpu(Vector<float> input)
    {
        var result = new Vector<float>(input.Length);
        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

            lock (_gpuLock)
            {
                (_sigmoidKernelFloat ?? throw new InvalidOperationException("Sigmoid kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());

            return result;
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Sigmoid(input);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Sigmoid(input);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Sigmoid(input);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> ReLUGpu(Vector<float> input)
    {
        var result = new Vector<float>(input.Length);
        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

            lock (_gpuLock)
            {
                (_reluKernelFloat ?? throw new InvalidOperationException("ReLU kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());

            return result;
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ReLU(input);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.ReLU(input);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ReLU(input);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> GELUGpu(Vector<float> input)
    {
        var result = new Vector<float>(input.Length);
        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

            lock (_gpuLock)
            {
                (_geluKernelFloat ?? throw new InvalidOperationException("GELU kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());

            return result;
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.GELU(input);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.GELU(input);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.GELU(input);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> MishGpu(Vector<float> input)
    {
        var result = new Vector<float>(input.Length);
        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

            lock (_gpuLock)
            {
                (_mishKernelFloat ?? throw new InvalidOperationException("Mish kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());

            return result;
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Mish(input);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Mish(input);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Mish(input);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> SwishGpu(Vector<float> input)
    {
        var result = new Vector<float>(input.Length);
        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

            lock (_gpuLock)
            {
                (_swishKernelFloat ?? throw new InvalidOperationException("Swish kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());

            return result;
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Swish(input);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Swish(input);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Swish(input);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> ELUGpu(Vector<float> input, float alpha)
    {
        var result = new Vector<float>(input.Length);
        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

            lock (_gpuLock)
            {
                (_eluKernelFloat ?? throw new InvalidOperationException("ELU kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    alpha,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());

            return result;
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ELU(input, alpha);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.ELU(input, alpha);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ELU(input, alpha);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    // Double activation function GPU implementations
    private Vector<double> TanhGpuDouble(Vector<double> input)
    {
        var result = new Vector<double>(input.Length);
        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
            lock (_gpuLock)
            {
                (_tanhKernelDouble ?? throw new InvalidOperationException("Tanh kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length, gpuInput.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> SigmoidGpuDouble(Vector<double> input)
    {
        var result = new Vector<double>(input.Length);
        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
            lock (_gpuLock)
            {
                (_sigmoidKernelDouble ?? throw new InvalidOperationException("Sigmoid kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length, gpuInput.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> ReLUGpuDouble(Vector<double> input)
    {
        var result = new Vector<double>(input.Length);
        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
            lock (_gpuLock)
            {
                (_reluKernelDouble ?? throw new InvalidOperationException("ReLU kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length, gpuInput.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> GELUGpuDouble(Vector<double> input)
    {
        var result = new Vector<double>(input.Length);
        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
            lock (_gpuLock)
            {
                (_geluKernelDouble ?? throw new InvalidOperationException("GELU kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length, gpuInput.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> MishGpuDouble(Vector<double> input)
    {
        var result = new Vector<double>(input.Length);
        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
            lock (_gpuLock)
            {
                (_mishKernelDouble ?? throw new InvalidOperationException("Mish kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length, gpuInput.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> SwishGpuDouble(Vector<double> input)
    {
        var result = new Vector<double>(input.Length);
        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
            lock (_gpuLock)
            {
                (_swishKernelDouble ?? throw new InvalidOperationException("Swish kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length, gpuInput.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> ELUGpuDouble(Vector<double> input, double alpha)
    {
        var result = new Vector<double>(input.Length);
        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
            lock (_gpuLock)
            {
                (_eluKernelDouble ?? throw new InvalidOperationException("ELU kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length, gpuInput.View, alpha, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private void SinGpuFloat(ReadOnlySpan<float> input, Span<float> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_sinKernelFloat ?? throw new InvalidOperationException("Sin kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinOperatorFloat>(input, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private void CosGpuFloat(ReadOnlySpan<float> input, Span<float> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_cosKernelFloat ?? throw new InvalidOperationException("Cos kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<CosOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<CosOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<CosOperatorFloat>(input, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private void SinGpuDouble(ReadOnlySpan<double> input, Span<double> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_sinKernelDouble ?? throw new InvalidOperationException("Sin kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinOperatorDouble>(input, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private void CosGpuDouble(ReadOnlySpan<double> input, Span<double> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_cosKernelDouble ?? throw new InvalidOperationException("Cos kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<CosOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<CosOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<CosOperatorDouble>(input, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private void TanGpuFloat(ReadOnlySpan<float> input, Span<float> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_tanKernelFloat ?? throw new InvalidOperationException("Tan kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanOperatorFloat>(input, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private void TanGpuDouble(ReadOnlySpan<double> input, Span<double> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_tanKernelDouble ?? throw new InvalidOperationException("Tan kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanOperatorDouble>(input, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private void ExpGpuFloat(ReadOnlySpan<float> input, Span<float> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_expKernelFloat ?? throw new InvalidOperationException("Exp kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<ExpOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<ExpOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<ExpOperatorFloat>(input, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private void LogGpuFloat(ReadOnlySpan<float> input, Span<float> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_logKernelFloat ?? throw new InvalidOperationException("Log kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<LogOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<LogOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<LogOperatorFloat>(input, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private void ExpGpuDouble(ReadOnlySpan<double> input, Span<double> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_expKernelDouble ?? throw new InvalidOperationException("Exp kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<ExpOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<ExpOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<ExpOperatorDouble>(input, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private void LogGpuDouble(ReadOnlySpan<double> input, Span<double> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_logKernelDouble ?? throw new InvalidOperationException("Log kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<LogOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<LogOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<LogOperatorDouble>(input, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private void SqrtGpuFloat(ReadOnlySpan<float> input, Span<float> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_sqrtKernelFloat ?? throw new InvalidOperationException("Sqrt kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<SqrtOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<SqrtOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<SqrtOperatorFloat>(input, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private void SqrtGpuDouble(ReadOnlySpan<double> input, Span<double> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_sqrtKernelDouble ?? throw new InvalidOperationException("Sqrt kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<SqrtOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<SqrtOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<SqrtOperatorDouble>(input, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private void AbsGpuFloat(ReadOnlySpan<float> input, Span<float> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_absKernelFloat ?? throw new InvalidOperationException("Abs kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AbsOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<AbsOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AbsOperatorFloat>(input, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private void AbsGpuDouble(ReadOnlySpan<double> input, Span<double> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_absKernelDouble ?? throw new InvalidOperationException("Abs kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AbsOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<AbsOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AbsOperatorDouble>(input, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private void SinhGpuFloat(ReadOnlySpan<float> input, Span<float> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_sinhKernelFloat ?? throw new InvalidOperationException("Sinh kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinhOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinhOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinhOperatorFloat>(input, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private void SinhGpuDouble(ReadOnlySpan<double> input, Span<double> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_sinhKernelDouble ?? throw new InvalidOperationException("Sinh kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinhOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinhOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinhOperatorDouble>(input, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private void CoshGpuFloat(ReadOnlySpan<float> input, Span<float> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_coshKernelFloat ?? throw new InvalidOperationException("Cosh kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<CoshOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<CoshOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<CoshOperatorFloat>(input, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private void CoshGpuDouble(ReadOnlySpan<double> input, Span<double> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_coshKernelDouble ?? throw new InvalidOperationException("Cosh kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<CoshOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<CoshOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<CoshOperatorDouble>(input, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private void TanhGpuFloat(ReadOnlySpan<float> input, Span<float> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_tanhKernelFloat ?? throw new InvalidOperationException("Tanh kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanhOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanhOperatorFloat>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanhOperatorFloat>(input, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private void TanhGpuDouble(ReadOnlySpan<double> input, Span<double> destination)
    {
        if (input.Length != destination.Length)
            throw new ArgumentException("Input and destination lengths must match");

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input);

            lock (_gpuLock)
            {
                (_tanhKernelDouble ?? throw new InvalidOperationException("Tanh kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    input.Length,
                    gpuInput.View,
                    gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(destination);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanhOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanhOperatorDouble>(input, destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU operation failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanhOperatorDouble>(input, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    // Float GPU helper methods for Phase C production operations
    private Vector<float> Log2GpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_log2KernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Log2(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> Exp2GpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_exp2KernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Exp2(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> Exp10GpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_exp10KernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Exp10(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> ExpM1GpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_expM1KernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.ExpM1(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> Log1PGpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_log1PKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Log1P(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> NegateGpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_negateKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Negate(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> ClampGpuFloat(Vector<float> vector, float min, float max)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_clampKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, min, max, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Clamp(vector, min, max);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> LerpGpuFloat(Vector<float> a, Vector<float> b, float t)
    {
        var result = new Vector<float>(a.Length);
        var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            lock (_gpuLock)
            {
                (_lerpKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, t, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Lerp(a, b, t);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuA);
            _memoryPoolFloat.Return(gpuB);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> ReciprocalGpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_reciprocalKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Reciprocal(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> ReciprocalSqrtGpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_rsqrtKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.ReciprocalSqrt(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> MinMagnitudeGpuFloat(Vector<float> a, Vector<float> b)
    {
        var result = new Vector<float>(a.Length);
        var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            lock (_gpuLock)
            {
                (_minMagnitudeKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.MinMagnitude(a, b);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuA);
            _memoryPoolFloat.Return(gpuB);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> MaxMagnitudeGpuFloat(Vector<float> a, Vector<float> b)
    {
        var result = new Vector<float>(a.Length);
        var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            lock (_gpuLock)
            {
                (_maxMagnitudeKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.MaxMagnitude(a, b);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuA);
            _memoryPoolFloat.Return(gpuB);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> RoundGpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_roundKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Round(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> FloorGpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_floorKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Floor(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> CeilingGpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_ceilingKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Ceiling(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> TruncateGpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_truncateKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Truncate(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> FillGpuFloat(int length, float value)
    {
        var result = new Vector<float>(length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);

        try
        {
            lock (_gpuLock)
            {
                (_fillKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, length, gpuResult.View, value);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Fill(length, value);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private float NormGpuFloat(Vector<float> vector)
    {
        // Use partial sums for L2 norm: sqrt(sum(x^2))
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var numBlocks = (vector.Length + ReductionBlockSize - 1) / ReductionBlockSize;
        var gpuPartialSums = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                // Compute partial dot products (x dot x = sum of squares)
                (_partialDotProductKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, numBlocks, gpuVector.View, gpuVector.View, gpuPartialSums.View, vector.Length);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            // Sum partial results on CPU
            var partialSums = new float[numBlocks];
            gpuPartialSums.View.BaseView.CopyToCPU(partialSums);
            float sumOfSquares = 0;
            for (int i = 0; i < numBlocks; i++)
                sumOfSquares += partialSums[i];
            return (float)Math.Sqrt(sumOfSquares);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Norm(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuPartialSums);
        }
    }

    private float StdDevGpuFloat(Vector<float> vector, float mean)
    {
        // Compute variance: sum((x - mean)^2) / n, then sqrt
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuTemp = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var numBlocks = (vector.Length + ReductionBlockSize - 1) / ReductionBlockSize;
        var gpuPartialSums = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                // Compute (x - mean)^2 in temp buffer using available kernels
                // This is a simplified approach - for production, a dedicated variance kernel would be more efficient
                (_partialSumKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, numBlocks, gpuVector.View, gpuPartialSums.View, vector.Length);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            // Compute variance on CPU with the mean
            var data = vector.AsSpan();
            float sumSquaredDiff = 0;
            for (int i = 0; i < vector.Length; i++)
            {
                float diff = data[i] - mean;
                sumSquaredDiff += diff * diff;
            }
            return (float)Math.Sqrt(sumSquaredDiff / vector.Length);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.StdDev(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuTemp);
            _memoryPoolFloat.Return(gpuPartialSums);
        }
    }

    private float DistanceGpuFloat(Vector<float> a, Vector<float> b)
    {
        // Euclidean distance: sqrt(sum((a-b)^2))
        var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuDiff = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var numBlocks = (a.Length + ReductionBlockSize - 1) / ReductionBlockSize;
        var gpuPartialSums = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            lock (_gpuLock)
            {
                // Compute a - b
                (_subtractKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuDiff.View);
                // Compute sum of (a-b)^2
                (_partialDotProductKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, numBlocks, gpuDiff.View, gpuDiff.View, gpuPartialSums.View, a.Length);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            // Sum partial results on CPU
            var partialSums = new float[numBlocks];
            gpuPartialSums.View.BaseView.CopyToCPU(partialSums);
            float sumOfSquares = 0;
            for (int i = 0; i < numBlocks; i++)
                sumOfSquares += partialSums[i];
            return (float)Math.Sqrt(sumOfSquares);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Distance(a, b);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuA);
            _memoryPoolFloat.Return(gpuB);
            _memoryPoolFloat.Return(gpuDiff);
            _memoryPoolFloat.Return(gpuPartialSums);
        }
    }

    private Vector<float> SinGpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_sinKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Sin(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> CosGpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_cosKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Cos(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> SinhGpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_sinhKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Sinh(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Vector<float> CoshGpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_coshKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Cosh(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private float SumGpuFloat(Vector<float> vector)
    {
        // Use partial sums reduction
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var numBlocks = (vector.Length + ReductionBlockSize - 1) / ReductionBlockSize;
        var gpuPartialSums = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_partialSumKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, numBlocks, gpuVector.View, gpuPartialSums.View, vector.Length);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            // Sum partial results on CPU
            var partialSums = new float[numBlocks];
            gpuPartialSums.View.BaseView.CopyToCPU(partialSums);
            float sum = 0;
            for (int i = 0; i < numBlocks; i++)
                sum += partialSums[i];
            return sum;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Sum(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuPartialSums);
        }
    }

    private float DotProductGpuFloat(Vector<float> a, Vector<float> b)
    {
        // Use partial dot product reduction
        var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var numBlocks = (a.Length + ReductionBlockSize - 1) / ReductionBlockSize;
        var gpuPartialSums = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            lock (_gpuLock)
            {
                (_partialDotProductKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, numBlocks, gpuA.View, gpuB.View, gpuPartialSums.View, a.Length);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            // Sum partial results on CPU
            var partialSums = new float[numBlocks];
            gpuPartialSums.View.BaseView.CopyToCPU(partialSums);
            float dot = 0;
            for (int i = 0; i < numBlocks; i++)
                dot += partialSums[i];
            return dot;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.DotProduct(a, b);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuA);
            _memoryPoolFloat.Return(gpuB);
            _memoryPoolFloat.Return(gpuPartialSums);
        }
    }

    private Vector<float> SoftmaxGpuFloat(Vector<float> vector)
    {
        var result = new Vector<float>(vector.Length);
        var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            // Compute max for numerical stability
            float maxVal = float.MinValue;
            var span = vector.AsSpan();
            for (int i = 0; i < span.Length; i++)
                if (span[i] > maxVal) maxVal = span[i];

            // Compute sum(exp(x - max))
            float sumExp = 0;
            for (int i = 0; i < span.Length; i++)
                sumExp += (float)Math.Exp(span[i] - maxVal);

            lock (_gpuLock)
            {
                (_softmaxKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View, maxVal, sumExp);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Softmax(vector);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuVector);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    #endregion

    #region GPU Kernels (Double, Int, Long Implementation - Phase B: US-GPU-005)

    // GPU operations for double type
    private Vector<double> AddGpuDouble(Vector<double> a, Vector<double> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<double>(a.Length);
        var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            (_addKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_addKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuA);
            _memoryPoolDouble.Return(gpuB);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> SubtractGpuDouble(Vector<double> a, Vector<double> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<double>(a.Length);
        var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            lock (_gpuLock)
            {
                (_subtractKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuA);
            _memoryPoolDouble.Return(gpuB);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> MultiplyGpuDouble(Vector<double> a, Vector<double> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<double>(a.Length);
        var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            lock (_gpuLock)
            {
                (_multiplyKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuA);
            _memoryPoolDouble.Return(gpuB);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> MultiplyScalarGpuDouble(Vector<double> vector, double scalar)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());
            lock (_gpuLock)
            {
                (_multiplyScalarKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, scalar, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> DivideGpuDouble(Vector<double> a, Vector<double> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<double>(a.Length);
        var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            lock (_gpuLock)
            {
                (_divideKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuA);
            _memoryPoolDouble.Return(gpuB);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> DivideScalarGpuDouble(Vector<double> vector, double scalar)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());
            lock (_gpuLock)
            {
                (_divideScalarKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, scalar, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> SqrtGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());
            lock (_gpuLock)
            {
                (_sqrtKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> PowerGpuDouble(Vector<double> vector, double exponent)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());
            lock (_gpuLock)
            {
                (_powerKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, exponent, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> MaxGpuDouble(Vector<double> a, Vector<double> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<double>(a.Length);
        var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_maxKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Max(a, b);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuA);
            _memoryPoolDouble.Return(gpuB);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> MinGpuDouble(Vector<double> a, Vector<double> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<double>(a.Length);
        var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_minKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Min(a, b);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuA);
            _memoryPoolDouble.Return(gpuB);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> AbsGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_absKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Abs(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> ExpGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_expKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Exp(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> LogGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_logKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Log(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> SignGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_signKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Sign(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    // Double GPU helper methods for Phase C production operations
    private Vector<double> Log2GpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_log2KernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Log2(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> Exp2GpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_exp2KernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Exp2(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> Exp10GpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_exp10KernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Exp10(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> ExpM1GpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_expM1KernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.ExpM1(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> Log1PGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_log1PKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Log1P(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> NegateGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_negateKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Negate(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> ClampGpuDouble(Vector<double> vector, double min, double max)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_clampKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, min, max, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Clamp(vector, min, max);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> LerpGpuDouble(Vector<double> a, Vector<double> b, double t)
    {
        var result = new Vector<double>(a.Length);
        var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            lock (_gpuLock)
            {
                (_lerpKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, t, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Lerp(a, b, t);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuA);
            _memoryPoolDouble.Return(gpuB);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> ReciprocalGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_reciprocalKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Reciprocal(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> ReciprocalSqrtGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_rsqrtKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.ReciprocalSqrt(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> MinMagnitudeGpuDouble(Vector<double> a, Vector<double> b)
    {
        var result = new Vector<double>(a.Length);
        var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            lock (_gpuLock)
            {
                (_minMagnitudeKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.MinMagnitude(a, b);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuA);
            _memoryPoolDouble.Return(gpuB);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> MaxMagnitudeGpuDouble(Vector<double> a, Vector<double> b)
    {
        var result = new Vector<double>(a.Length);
        var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            lock (_gpuLock)
            {
                (_maxMagnitudeKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.MaxMagnitude(a, b);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuA);
            _memoryPoolDouble.Return(gpuB);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> RoundGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_roundKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Round(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> FloorGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_floorKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Floor(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> CeilingGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_ceilingKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Ceiling(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> TruncateGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_truncateKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Truncate(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> FillGpuDouble(int length, double value)
    {
        var result = new Vector<double>(length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);

        try
        {
            lock (_gpuLock)
            {
                (_fillKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, length, gpuResult.View, value);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Fill(length, value);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private double NormGpuDouble(Vector<double> vector)
    {
        // Use partial sums for L2 norm: sqrt(sum(x^2))
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var numBlocks = (vector.Length + ReductionBlockSize - 1) / ReductionBlockSize;
        var gpuPartialSums = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                // Compute partial dot products (x dot x = sum of squares)
                (_partialDotProductKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, numBlocks, gpuVector.View, gpuVector.View, gpuPartialSums.View, vector.Length);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            // Sum partial results on CPU
            var partialSums = new double[numBlocks];
            gpuPartialSums.View.BaseView.CopyToCPU(partialSums);
            double sumOfSquares = 0;
            for (int i = 0; i < numBlocks; i++)
                sumOfSquares += partialSums[i];
            return Math.Sqrt(sumOfSquares);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Norm(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuPartialSums);
        }
    }

    private double StdDevGpuDouble(Vector<double> vector, double mean)
    {
        // Compute variance: sum((x - mean)^2) / n, then sqrt
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuTemp = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var numBlocks = (vector.Length + ReductionBlockSize - 1) / ReductionBlockSize;
        var gpuPartialSums = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                // This is a simplified approach - for production, a dedicated variance kernel would be more efficient
                (_partialSumKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, numBlocks, gpuVector.View, gpuPartialSums.View, vector.Length);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            // Compute variance on CPU with the mean
            var data = vector.AsSpan();
            double sumSquaredDiff = 0;
            for (int i = 0; i < vector.Length; i++)
            {
                double diff = data[i] - mean;
                sumSquaredDiff += diff * diff;
            }
            return Math.Sqrt(sumSquaredDiff / vector.Length);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.StdDev(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuTemp);
            _memoryPoolDouble.Return(gpuPartialSums);
        }
    }

    private double DistanceGpuDouble(Vector<double> a, Vector<double> b)
    {
        // Euclidean distance: sqrt(sum((a-b)^2))
        var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var gpuDiff = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var numBlocks = (a.Length + ReductionBlockSize - 1) / ReductionBlockSize;
        var gpuPartialSums = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            lock (_gpuLock)
            {
                // Compute a - b
                (_subtractKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuDiff.View);
                // Compute sum of (a-b)^2
                (_partialDotProductKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, numBlocks, gpuDiff.View, gpuDiff.View, gpuPartialSums.View, a.Length);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            // Sum partial results on CPU
            var partialSums = new double[numBlocks];
            gpuPartialSums.View.BaseView.CopyToCPU(partialSums);
            double sumOfSquares = 0;
            for (int i = 0; i < numBlocks; i++)
                sumOfSquares += partialSums[i];
            return Math.Sqrt(sumOfSquares);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Distance(a, b);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuA);
            _memoryPoolDouble.Return(gpuB);
            _memoryPoolDouble.Return(gpuDiff);
            _memoryPoolDouble.Return(gpuPartialSums);
        }
    }

    private Vector<double> SinGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_sinKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Sin(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> CosGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_cosKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Cos(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> SinhGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_sinhKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Sinh(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private Vector<double> CoshGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_coshKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Cosh(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    private double SumGpuDouble(Vector<double> vector)
    {
        // Use partial sums reduction
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var numBlocks = (vector.Length + ReductionBlockSize - 1) / ReductionBlockSize;
        var gpuPartialSums = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            lock (_gpuLock)
            {
                (_partialSumKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, numBlocks, gpuVector.View, gpuPartialSums.View, vector.Length);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            // Sum partial results on CPU
            var partialSums = new double[numBlocks];
            gpuPartialSums.View.BaseView.CopyToCPU(partialSums);
            double sum = 0;
            for (int i = 0; i < numBlocks; i++)
                sum += partialSums[i];
            return sum;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Sum(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuPartialSums);
        }
    }

    private double DotProductGpuDouble(Vector<double> a, Vector<double> b)
    {
        // Use partial dot product reduction
        var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
        var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
        var numBlocks = (a.Length + ReductionBlockSize - 1) / ReductionBlockSize;
        var gpuPartialSums = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

            lock (_gpuLock)
            {
                (_partialDotProductKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, numBlocks, gpuA.View, gpuB.View, gpuPartialSums.View, a.Length);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            // Sum partial results on CPU
            var partialSums = new double[numBlocks];
            gpuPartialSums.View.BaseView.CopyToCPU(partialSums);
            double dot = 0;
            for (int i = 0; i < numBlocks; i++)
                dot += partialSums[i];
            return dot;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.DotProduct(a, b);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuA);
            _memoryPoolDouble.Return(gpuB);
            _memoryPoolDouble.Return(gpuPartialSums);
        }
    }

    private Vector<double> SoftmaxGpuDouble(Vector<double> vector)
    {
        var result = new Vector<double>(vector.Length);
        var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

            // Compute max for numerical stability
            double maxVal = double.MinValue;
            var span = vector.AsSpan();
            for (int i = 0; i < span.Length; i++)
                if (span[i] > maxVal) maxVal = span[i];

            // Compute sum(exp(x - max))
            double sumExp = 0;
            for (int i = 0; i < span.Length; i++)
                sumExp += Math.Exp(span[i] - maxVal);

            lock (_gpuLock)
            {
                (_softmaxKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, gpuResult.View, maxVal, sumExp);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Softmax(vector);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuVector);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    // GPU operations for int type
    private Vector<int> AddGpuInt(Vector<int> a, Vector<int> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<int>(a.Length);
        var gpuA = _memoryPoolInt!.Rent(a.Length);
        var gpuB = _memoryPoolInt.Rent(b.Length);
        var gpuResult = _memoryPoolInt.Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            (_addKernelInt ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_addKernelInt ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolInt.Return(gpuA);
            _memoryPoolInt.Return(gpuB);
            _memoryPoolInt.Return(gpuResult);
        }
    }

    // GPU operations for long type
    private Vector<long> AddGpuLong(Vector<long> a, Vector<long> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<long>(a.Length);
        var gpuA = _memoryPoolLong!.Rent(a.Length);
        var gpuB = _memoryPoolLong.Rent(b.Length);
        var gpuResult = _memoryPoolLong.Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            (_addKernelLong ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
            // Thread-safe kernel execution (Phase B: US-GPU-019)
            lock (_gpuLock)
            {
                (_addKernelLong ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolLong.Return(gpuA);
            _memoryPoolLong.Return(gpuB);
            _memoryPoolLong.Return(gpuResult);
        }
    }

    // Int GPU operations for Subtract, Multiply, Divide
    private Vector<int> SubtractGpuInt(Vector<int> a, Vector<int> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<int>(a.Length);
        var gpuA = _memoryPoolInt!.Rent(a.Length);
        var gpuB = _memoryPoolInt.Rent(b.Length);
        var gpuResult = _memoryPoolInt.Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            lock (_gpuLock)
            {
                (_subtractKernelInt ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolInt.Return(gpuA);
            _memoryPoolInt.Return(gpuB);
            _memoryPoolInt.Return(gpuResult);
        }
    }

    private Vector<int> MultiplyGpuInt(Vector<int> a, Vector<int> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<int>(a.Length);
        var gpuA = _memoryPoolInt!.Rent(a.Length);
        var gpuB = _memoryPoolInt.Rent(b.Length);
        var gpuResult = _memoryPoolInt.Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            lock (_gpuLock)
            {
                (_multiplyKernelInt ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolInt.Return(gpuA);
            _memoryPoolInt.Return(gpuB);
            _memoryPoolInt.Return(gpuResult);
        }
    }

    private Vector<int> MultiplyScalarGpuInt(Vector<int> vector, int scalar)
    {
        var result = new Vector<int>(vector.Length);
        var gpuVector = _memoryPoolInt!.Rent(vector.Length);
        var gpuResult = _memoryPoolInt.Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());
            lock (_gpuLock)
            {
                (_multiplyScalarKernelInt ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, scalar, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolInt.Return(gpuVector);
            _memoryPoolInt.Return(gpuResult);
        }
    }

    private Vector<int> DivideGpuInt(Vector<int> a, Vector<int> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<int>(a.Length);
        var gpuA = _memoryPoolInt!.Rent(a.Length);
        var gpuB = _memoryPoolInt.Rent(b.Length);
        var gpuResult = _memoryPoolInt.Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            lock (_gpuLock)
            {
                (_divideKernelInt ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolInt.Return(gpuA);
            _memoryPoolInt.Return(gpuB);
            _memoryPoolInt.Return(gpuResult);
        }
    }

    private Vector<int> DivideScalarGpuInt(Vector<int> vector, int scalar)
    {
        var result = new Vector<int>(vector.Length);
        var gpuVector = _memoryPoolInt!.Rent(vector.Length);
        var gpuResult = _memoryPoolInt.Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());
            lock (_gpuLock)
            {
                (_divideScalarKernelInt ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, scalar, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolInt.Return(gpuVector);
            _memoryPoolInt.Return(gpuResult);
        }
    }

    // Long GPU operations for Subtract, Multiply, Divide
    private Vector<long> SubtractGpuLong(Vector<long> a, Vector<long> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<long>(a.Length);
        var gpuA = _memoryPoolLong!.Rent(a.Length);
        var gpuB = _memoryPoolLong.Rent(b.Length);
        var gpuResult = _memoryPoolLong.Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            lock (_gpuLock)
            {
                (_subtractKernelLong ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolLong.Return(gpuA);
            _memoryPoolLong.Return(gpuB);
            _memoryPoolLong.Return(gpuResult);
        }
    }

    private Vector<long> MultiplyGpuLong(Vector<long> a, Vector<long> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<long>(a.Length);
        var gpuA = _memoryPoolLong!.Rent(a.Length);
        var gpuB = _memoryPoolLong.Rent(b.Length);
        var gpuResult = _memoryPoolLong.Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            lock (_gpuLock)
            {
                (_multiplyKernelLong ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolLong.Return(gpuA);
            _memoryPoolLong.Return(gpuB);
            _memoryPoolLong.Return(gpuResult);
        }
    }

    private Vector<long> MultiplyScalarGpuLong(Vector<long> vector, long scalar)
    {
        var result = new Vector<long>(vector.Length);
        var gpuVector = _memoryPoolLong!.Rent(vector.Length);
        var gpuResult = _memoryPoolLong.Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());
            lock (_gpuLock)
            {
                (_multiplyScalarKernelLong ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, scalar, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolLong.Return(gpuVector);
            _memoryPoolLong.Return(gpuResult);
        }
    }

    private Vector<long> DivideGpuLong(Vector<long> a, Vector<long> b)
    {
        if (a.Length != b.Length)
            throw new ArgumentException("Vector lengths must match");

        var result = new Vector<long>(a.Length);
        var gpuA = _memoryPoolLong!.Rent(a.Length);
        var gpuB = _memoryPoolLong.Rent(b.Length);
        var gpuResult = _memoryPoolLong.Rent(a.Length);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
            gpuB.View.BaseView.CopyFromCPU(b.AsSpan());
            lock (_gpuLock)
            {
                (_divideKernelLong ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolLong.Return(gpuA);
            _memoryPoolLong.Return(gpuB);
            _memoryPoolLong.Return(gpuResult);
        }
    }

    private Vector<long> DivideScalarGpuLong(Vector<long> vector, long scalar)
    {
        var result = new Vector<long>(vector.Length);
        var gpuVector = _memoryPoolLong!.Rent(vector.Length);
        var gpuResult = _memoryPoolLong.Rent(vector.Length);

        try
        {
            gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());
            lock (_gpuLock)
            {
                (_divideScalarKernelLong ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, vector.Length, gpuVector.View, scalar, gpuResult.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        finally
        {
            _memoryPoolLong.Return(gpuVector);
            _memoryPoolLong.Return(gpuResult);
        }
    }

    #endregion

    #region Matrix Operations (Phase B: Epic 2)

    /// <inheritdoc/>
    public Matrix<T> MatrixMultiply<T>(Matrix<T> a, Matrix<T> b)
    {
        // Adaptive execution: check matrix size threshold (Phase B: US-GPU-004)
        if (Math.Max(a.Rows, Math.Max(a.Columns, b.Columns)) < _thresholds.MatrixMultiply)
        {
            return _cpuFallback.MatrixMultiply(a, b);
        }

        // Check GPU health and type support (Phase B: US-GPU-006)
        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Matrix<T>)(object)MatrixMultiplyGpu((Matrix<float>)(object)a, (Matrix<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Matrix<T>)(object)MatrixMultiplyGpuDouble((Matrix<double>)(object)a, (Matrix<double>)(object)b);
        }

        // Fallback to CPU for unsupported types or unhealthy GPU
        return _cpuFallback.MatrixMultiply(a, b);
    }

    /// <inheritdoc/>
    public Vector<T> MatrixVectorMultiply<T>(Matrix<T> matrix, Vector<T> vector)
    {
        // Adaptive execution
        if (Math.Max(matrix.Rows, matrix.Columns) < _thresholds.MatrixVectorMultiply)
        {
            return _cpuFallback.MatrixVectorMultiply(matrix, vector);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Vector<T>)(object)MatrixVectorMultiplyGpu((Matrix<float>)(object)matrix, (Vector<float>)(object)vector);
            if (typeof(T) == typeof(double))
                return (Vector<T>)(object)MatrixVectorMultiplyGpuDouble((Matrix<double>)(object)matrix, (Vector<double>)(object)vector);
        }

        return _cpuFallback.MatrixVectorMultiply(matrix, vector);
    }

    /// <inheritdoc/>
    public Matrix<T> MatrixTranspose<T>(Matrix<T> matrix)
    {
        // Transpose is memory-bound, benefit from GPU at smaller sizes
        if (Math.Max(matrix.Rows, matrix.Columns) < _thresholds.MatrixMultiply / 2)
        {
            return _cpuFallback.MatrixTranspose(matrix);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Matrix<T>)(object)MatrixTransposeGpu((Matrix<float>)(object)matrix);
            if (typeof(T) == typeof(double))
                return (Matrix<T>)(object)MatrixTransposeGpuDouble((Matrix<double>)(object)matrix);
        }

        return _cpuFallback.MatrixTranspose(matrix);
    }

    /// <inheritdoc/>
    public Matrix<T> MatrixAdd<T>(Matrix<T> a, Matrix<T> b)
    {
        // Element-wise operations benefit from GPU at similar thresholds to vector ops
        if (a.Rows * a.Columns < _thresholds.VectorAdd)
        {
            return _cpuFallback.MatrixAdd(a, b);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Matrix<T>)(object)MatrixAddGpu((Matrix<float>)(object)a, (Matrix<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Matrix<T>)(object)MatrixAddGpuDouble((Matrix<double>)(object)a, (Matrix<double>)(object)b);
        }

        return _cpuFallback.MatrixAdd(a, b);
    }

    /// <inheritdoc/>
    public Matrix<T> MatrixMultiplyScalar<T>(Matrix<T> matrix, T scalar)
    {
        if (matrix.Rows * matrix.Columns < _thresholds.VectorMultiply)
        {
            return _cpuFallback.MatrixMultiplyScalar(matrix, scalar);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                object? scalarObj = (object?)scalar;
                if (scalarObj == null) throw new ArgumentNullException(nameof(scalar));
                return (Matrix<T>)(object)MatrixMultiplyScalarGpu((Matrix<float>)(object)matrix, (float)scalarObj);
            }
            if (typeof(T) == typeof(double))
            {
                object? scalarObj = (object?)scalar;
                if (scalarObj == null) throw new ArgumentNullException(nameof(scalar));
                return (Matrix<T>)(object)MatrixMultiplyScalarGpuDouble((Matrix<double>)(object)matrix, (double)scalarObj);
            }
        }

        return _cpuFallback.MatrixMultiplyScalar(matrix, scalar);
    }

    public Matrix<T> MatrixSubtract<T>(Matrix<T> a, Matrix<T> b)
    {
        if (a.Rows * a.Columns < _thresholds.VectorSubtract)
        {
            return _cpuFallback.MatrixSubtract(a, b);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Matrix<T>)(object)MatrixSubtractGpu((Matrix<float>)(object)a, (Matrix<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Matrix<T>)(object)MatrixSubtractGpuDouble((Matrix<double>)(object)a, (Matrix<double>)(object)b);
        }

        return _cpuFallback.MatrixSubtract(a, b);
    }

    private Matrix<float> MatrixSubtractGpu(Matrix<float> a, Matrix<float> b)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));
        if (a.Rows != b.Rows || a.Columns != b.Columns)
        {
            throw new ArgumentException($"Matrix dimensions must match for subtraction.");
        }

        try
        {
            var result = new Matrix<float>(a.Rows, a.Columns);
            int size = a.Rows * a.Columns;

            var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(size);
            var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(size);
            var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(size);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                lock (_gpuLock)
                {
                    (_tensorSubtractKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        size, gpuA.View, gpuB.View, gpuResult.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuA);
                _memoryPoolFloat.Return(gpuB);
                _memoryPoolFloat.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU matrix subtract failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixSubtract(a, b);
        }
    }

    private Matrix<double> MatrixSubtractGpuDouble(Matrix<double> a, Matrix<double> b)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));
        if (a.Rows != b.Rows || a.Columns != b.Columns)
        {
            throw new ArgumentException($"Matrix dimensions must match for subtraction.");
        }

        try
        {
            var result = new Matrix<double>(a.Rows, a.Columns);
            int size = a.Rows * a.Columns;

            var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(size);
            var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(size);
            var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(size);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                lock (_gpuLock)
                {
                    (_tensorSubtractKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        size, gpuA.View, gpuB.View, gpuResult.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuA);
                _memoryPoolDouble.Return(gpuB);
                _memoryPoolDouble.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU matrix subtract (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixSubtract(a, b);
        }
    }

    public T MatrixSumOfSquares<T>(Matrix<T> matrix)
    {
        if (matrix.Rows * matrix.Columns < _thresholds.MatrixMultiply)
        {
            return _cpuFallback.MatrixSumOfSquares(matrix);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (T)(object)MatrixSumOfSquaresGpu((Matrix<float>)(object)matrix);
            if (typeof(T) == typeof(double))
                return (T)(object)MatrixSumOfSquaresGpuDouble((Matrix<double>)(object)matrix);
        }

        return _cpuFallback.MatrixSumOfSquares(matrix);
    }

    private float MatrixSumOfSquaresGpu(Matrix<float> matrix)
    {
        try
        {
            int length = matrix.Rows * matrix.Columns;
            int numBlocks = (length + ReductionBlockSize - 1) / ReductionBlockSize;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
            var gpuPartials = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(matrix.AsSpan());

                lock (_gpuLock)
                {
                    (_partialSumOfSquaresKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numBlocks, gpuInput.View, gpuPartials.View, length);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var partials = new float[numBlocks];
                gpuPartials.View.BaseView.CopyToCPU(partials);

                float sum = 0;
                for (int i = 0; i < numBlocks; i++) sum += partials[i];
                return sum;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuPartials);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU MatrixSumOfSquares failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixSumOfSquares(matrix);
        }
    }

    private double MatrixSumOfSquaresGpuDouble(Matrix<double> matrix)
    {
        try
        {
            int length = matrix.Rows * matrix.Columns;
            int numBlocks = (length + ReductionBlockSize - 1) / ReductionBlockSize;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
            var gpuPartials = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(matrix.AsSpan());

                lock (_gpuLock)
                {
                    (_partialSumOfSquaresKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numBlocks, gpuInput.View, gpuPartials.View, length);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var partials = new double[numBlocks];
                gpuPartials.View.BaseView.CopyToCPU(partials);

                double sum = 0;
                for (int i = 0; i < numBlocks; i++) sum += partials[i];
                return sum;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuPartials);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU MatrixSumOfSquares (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixSumOfSquares(matrix);
        }
    }

    public void SwapColumns<T>(Matrix<T> matrix, int col1, int col2)
    {
        // GPU kernel implementation for column swapping
        if (typeof(T) == typeof(float))
        {
            var matrixFloat = matrix as Matrix<float>;
            if (matrixFloat != null && _accelerator != null)
            {
                SwapColumnsGpu(matrixFloat, col1, col2);
                return;
            }
        }
        else if (typeof(T) == typeof(double))
        {
            var matrixDouble = matrix as Matrix<double>;
            if (matrixDouble != null && _accelerator != null)
            {
                SwapColumnsGpuDouble(matrixDouble, col1, col2);
                return;
            }
        }

        _cpuFallback.SwapColumns(matrix, col1, col2);
    }

    private void SwapColumnsGpu(Matrix<float> matrix, int col1, int col2)
    {
        try
        {
            int rows = matrix.Rows, cols = matrix.Columns;

            // Rent GPU memory for the matrix
            var gpuMatrix = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);
            var gpuTemp = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows);

            try
            {
                // Copy matrix to GPU
                gpuMatrix.View.BaseView.CopyFromCPU(matrix.AsSpan());

                // Create 2D view
                var view2D = gpuMatrix.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));

                // Execute swap columns kernel
                lock (_gpuLock)
                {
                    (_swapColumnsKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))
                        ((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, rows, view2D, gpuTemp.View, col1, col2);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Copy result back
                gpuMatrix.View.BaseView.CopyToCPU(matrix.AsWritableSpan());
            }
            finally
            {
                _memoryPoolFloat.Return(gpuMatrix);
                _memoryPoolFloat.Return(gpuTemp);
            }
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted for swap columns: {ex.Message}. Falling back to CPU.");
            // CPU fallback
            for (int i = 0; i < matrix.Rows; i++)
            {
                float temp = matrix[i, col1];
                matrix[i, col1] = matrix[i, col2];
                matrix[i, col2] = temp;
            }
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            // CPU fallback
            for (int i = 0; i < matrix.Rows; i++)
            {
                float temp = matrix[i, col1];
                matrix[i, col1] = matrix[i, col2];
                matrix[i, col2] = temp;
            }
        }
    }

    private void SwapColumnsGpuDouble(Matrix<double> matrix, int col1, int col2)
    {
        try
        {
            int rows = matrix.Rows, cols = matrix.Columns;

            // Rent GPU memory for the matrix
            var gpuMatrix = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);
            var gpuTemp = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows);

            try
            {
                // Copy matrix to GPU
                gpuMatrix.View.BaseView.CopyFromCPU(matrix.AsSpan());

                // Create 2D view
                var view2D = gpuMatrix.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));

                // Execute swap columns kernel
                lock (_gpuLock)
                {
                    (_swapColumnsKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))
                        ((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, rows, view2D, gpuTemp.View, col1, col2);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Copy result back
                gpuMatrix.View.BaseView.CopyToCPU(matrix.AsWritableSpan());
            }
            finally
            {
                _memoryPoolDouble.Return(gpuMatrix);
                _memoryPoolDouble.Return(gpuTemp);
            }
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted for swap columns: {ex.Message}. Falling back to CPU.");
            // CPU fallback
            for (int i = 0; i < matrix.Rows; i++)
            {
                double temp = matrix[i, col1];
                matrix[i, col1] = matrix[i, col2];
                matrix[i, col2] = temp;
            }
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            // CPU fallback
            for (int i = 0; i < matrix.Rows; i++)
            {
                double temp = matrix[i, col1];
                matrix[i, col1] = matrix[i, col2];
                matrix[i, col2] = temp;
            }
        }
    }

    public void SwapRows<T>(Matrix<T> matrix, int row1, int row2)
    {
        // GPU kernel implementation for row swapping
        if (typeof(T) == typeof(float))
        {
            var matrixFloat = matrix as Matrix<float>;
            if (matrixFloat != null && _accelerator != null)
            {
                SwapRowsGpu(matrixFloat, row1, row2);
                return;
            }
        }
        else if (typeof(T) == typeof(double))
        {
            var matrixDouble = matrix as Matrix<double>;
            if (matrixDouble != null && _accelerator != null)
            {
                SwapRowsGpuDouble(matrixDouble, row1, row2);
                return;
            }
        }

        _cpuFallback.SwapRows(matrix, row1, row2);
    }

    private void SwapRowsGpu(Matrix<float> matrix, int row1, int row2)
    {
        try
        {
            int cols = matrix.Columns;

            // Rent GPU memory for the two rows
            var gpuRow1 = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(cols);
            var gpuRow2 = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(cols);

            try
            {
                // Copy rows to GPU
                gpuRow1.View.BaseView.CopyFromCPU(matrix.GetRowSpan(row1));
                gpuRow2.View.BaseView.CopyFromCPU(matrix.GetRowSpan(row2));

                // Execute swap kernel
                lock (_gpuLock)
                {
                    (_swapRowsKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))
                        ((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, cols, gpuRow1.View, gpuRow2.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Copy swapped rows back (row1 gets gpuRow2, row2 gets gpuRow1)
                gpuRow2.View.BaseView.CopyToCPU(matrix.GetRowSpan(row1));
                gpuRow1.View.BaseView.CopyToCPU(matrix.GetRowSpan(row2));
            }
            finally
            {
                _memoryPoolFloat.Return(gpuRow1);
                _memoryPoolFloat.Return(gpuRow2);
            }
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted for swap rows: {ex.Message}. Falling back to CPU.");
            // CPU fallback
            var span1 = matrix.GetRowSpan(row1);
            var span2 = matrix.GetRowSpan(row2);
            var tempRow = new float[matrix.Columns];
            span1.CopyTo(tempRow);
            span2.CopyTo(span1);
            tempRow.AsSpan().CopyTo(span2);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            // CPU fallback
            var span1 = matrix.GetRowSpan(row1);
            var span2 = matrix.GetRowSpan(row2);
            var tempRow = new float[matrix.Columns];
            span1.CopyTo(tempRow);
            span2.CopyTo(span1);
            tempRow.AsSpan().CopyTo(span2);
        }
    }

    private void SwapRowsGpuDouble(Matrix<double> matrix, int row1, int row2)
    {
        try
        {
            int cols = matrix.Columns;

            // Rent GPU memory for the two rows
            var gpuRow1 = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(cols);
            var gpuRow2 = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(cols);

            try
            {
                // Copy rows to GPU
                gpuRow1.View.BaseView.CopyFromCPU(matrix.GetRowSpan(row1));
                gpuRow2.View.BaseView.CopyFromCPU(matrix.GetRowSpan(row2));

                // Execute swap kernel
                lock (_gpuLock)
                {
                    (_swapRowsKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))
                        ((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, cols, gpuRow1.View, gpuRow2.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Copy swapped rows back (row1 gets gpuRow2, row2 gets gpuRow1)
                gpuRow2.View.BaseView.CopyToCPU(matrix.GetRowSpan(row1));
                gpuRow1.View.BaseView.CopyToCPU(matrix.GetRowSpan(row2));
            }
            finally
            {
                _memoryPoolDouble.Return(gpuRow1);
                _memoryPoolDouble.Return(gpuRow2);
            }
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted for swap rows: {ex.Message}. Falling back to CPU.");
            // CPU fallback
            var span1 = matrix.GetRowSpan(row1);
            var span2 = matrix.GetRowSpan(row2);
            var tempRow = new double[matrix.Columns];
            span1.CopyTo(tempRow);
            span2.CopyTo(span1);
            tempRow.AsSpan().CopyTo(span2);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            // CPU fallback
            var span1 = matrix.GetRowSpan(row1);
            var span2 = matrix.GetRowSpan(row2);
            var tempRow = new double[matrix.Columns];
            span1.CopyTo(tempRow);
            span2.CopyTo(span1);
            tempRow.AsSpan().CopyTo(span2);
        }
    }

    public Matrix<T> OuterProduct<T>(Vector<T> a, Vector<T> b)
    {
        // GPU kernel implementation for outer product
        if (typeof(T) == typeof(float))
        {
            var aFloat = a as Vector<float>;
            var bFloat = b as Vector<float>;
            if (aFloat != null && bFloat != null && _accelerator != null)
            {
                return (OuterProductGpu(aFloat, bFloat) as Matrix<T>)!;
            }
        }
        else if (typeof(T) == typeof(double))
        {
            var aDouble = a as Vector<double>;
            var bDouble = b as Vector<double>;
            if (aDouble != null && bDouble != null && _accelerator != null)
            {
                return (OuterProductGpuDouble(aDouble, bDouble) as Matrix<T>)!;
            }
        }

        return _cpuFallback.OuterProduct(a, b);
    }

    private Matrix<float> OuterProductGpu(Vector<float> a, Vector<float> b)
    {
        try
        {
            var result = new Matrix<float>(a.Length, b.Length);
            int m = a.Length, n = b.Length;

            // Rent GPU memory
            var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(m);
            var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(n);
            var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(m * n);

            try
            {
                // Copy vectors to GPU
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                // Create 2D view for result
                var viewResult = gpuResult.View.As2DView<Stride2D.DenseX>(new Index2D(m, n), new Stride2D.DenseX(n));

                // Execute outer product kernel
                lock (_gpuLock)
                {
                    (_outerProductKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))
                        ((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(m, n), gpuA.View, gpuB.View, viewResult, m, n);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Copy result back
                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuA);
                _memoryPoolFloat.Return(gpuB);
                _memoryPoolFloat.Return(gpuResult);
            }
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted for outer product: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.OuterProduct(a, b);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.OuterProduct(a, b);
        }
    }

    private Matrix<double> OuterProductGpuDouble(Vector<double> a, Vector<double> b)
    {
        try
        {
            var result = new Matrix<double>(a.Length, b.Length);
            int m = a.Length, n = b.Length;

            // Rent GPU memory
            var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(m);
            var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(n);
            var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(m * n);

            try
            {
                // Copy vectors to GPU
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                // Create 2D view for result
                var viewResult = gpuResult.View.As2DView<Stride2D.DenseX>(new Index2D(m, n), new Stride2D.DenseX(n));

                // Execute outer product kernel
                lock (_gpuLock)
                {
                    (_outerProductKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))
                        ((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(m, n), gpuA.View, gpuB.View, viewResult, m, n);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Copy result back
                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuA);
                _memoryPoolDouble.Return(gpuB);
                _memoryPoolDouble.Return(gpuResult);
            }
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted for outer product: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.OuterProduct(a, b);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.OuterProduct(a, b);
        }
    }

    public Vector<T> GetColumn<T>(Matrix<T> matrix, int columnIndex)
    {
        // Optimized column extraction using GetColumnAsArray
        if (typeof(T) == typeof(float))
        {
            var matrixFloat = matrix as Matrix<float>;
            if (matrixFloat != null)
            {
                var columnArray = matrixFloat.GetColumnAsArray(columnIndex);
                return (new Vector<float>(columnArray) as Vector<T>)!;
            }
        }
        else if (typeof(T) == typeof(double))
        {
            var matrixDouble = matrix as Matrix<double>;
            if (matrixDouble != null)
            {
                var columnArray = matrixDouble.GetColumnAsArray(columnIndex);
                return (new Vector<double>(columnArray) as Vector<T>)!;
            }
        }

        return _cpuFallback.GetColumn(matrix, columnIndex);
    }

    public Vector<T> GetRow<T>(Matrix<T> matrix, int rowIndex)
    {
        // Optimized using GetRowSpan for zero-copy access
        if (typeof(T) == typeof(float))
        {
            var matrixFloat = matrix as Matrix<float>;
            if (matrixFloat != null)
            {
                var rowSpan = matrixFloat.GetRowReadOnlySpan(rowIndex);
                return (new Vector<float>(rowSpan.ToArray()) as Vector<T>)!;
            }
        }
        else if (typeof(T) == typeof(double))
        {
            var matrixDouble = matrix as Matrix<double>;
            if (matrixDouble != null)
            {
                var rowSpan = matrixDouble.GetRowReadOnlySpan(rowIndex);
                return (new Vector<double>(rowSpan.ToArray()) as Vector<T>)!;
            }
        }

        return _cpuFallback.GetRow(matrix, rowIndex);
    }

    public void SetColumn<T>(Matrix<T> matrix, int columnIndex, Vector<T> values)
    {
        // Optimized column setting using direct indexer
        if (typeof(T) == typeof(float))
        {
            var matrixFloat = matrix as Matrix<float>;
            var valuesFloat = values as Vector<float>;
            if (matrixFloat != null && valuesFloat != null)
            {
                for (int i = 0; i < matrixFloat.Rows; i++)
                {
                    matrixFloat[i, columnIndex] = valuesFloat[i];
                }
                return;
            }
        }
        else if (typeof(T) == typeof(double))
        {
            var matrixDouble = matrix as Matrix<double>;
            var valuesDouble = values as Vector<double>;
            if (matrixDouble != null && valuesDouble != null)
            {
                for (int i = 0; i < matrixDouble.Rows; i++)
                {
                    matrixDouble[i, columnIndex] = valuesDouble[i];
                }
                return;
            }
        }

        _cpuFallback.SetColumn(matrix, columnIndex, values);
    }

    public void SetRow<T>(Matrix<T> matrix, int rowIndex, Vector<T> values)
    {
        // Optimized using GetRowSpan for zero-copy access
        if (typeof(T) == typeof(float))
        {
            var matrixFloat = matrix as Matrix<float>;
            var valuesFloat = values as Vector<float>;
            if (matrixFloat != null && valuesFloat != null)
            {
                var rowSpan = matrixFloat.GetRowSpan(rowIndex);
                valuesFloat.AsSpan().CopyTo(rowSpan);
                return;
            }
        }
        else if (typeof(T) == typeof(double))
        {
            var matrixDouble = matrix as Matrix<double>;
            var valuesDouble = values as Vector<double>;
            if (matrixDouble != null && valuesDouble != null)
            {
                var rowSpan = matrixDouble.GetRowSpan(rowIndex);
                valuesDouble.AsSpan().CopyTo(rowSpan);
                return;
            }
        }

        _cpuFallback.SetRow(matrix, rowIndex, values);
    }

    // GPU implementations for float matrices

    private Matrix<float> MatrixMultiplyGpu(Matrix<float> a, Matrix<float> b)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));
        if (a.Columns != b.Rows)
        {
            throw new ArgumentException(
                $"Matrix dimensions incompatible for multiplication. " +
                $"First matrix is {a.Rows}x{a.Columns}, second is {b.Rows}x{b.Columns}.");
        }

        try
        {
            var result = new Matrix<float>(a.Rows, b.Columns);
            int m = a.Rows, k = a.Columns, n = b.Columns;

            // Allocate GPU buffers using memory pool (Phase B: US-GPU-002)
            var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(m * k);
            var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(k * n);
            var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(m * n);

            try
            {
                // Zero-copy transfer (Phase B: US-GPU-003)
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                // Create 2D views
                var viewA = gpuA.View.As2DView<Stride2D.DenseY>(new Index2D(m, k), new Stride2D.DenseY(k));
                var viewB = gpuB.View.As2DView<Stride2D.DenseY>(new Index2D(k, n), new Stride2D.DenseY(n));
                var viewResult = gpuResult.View.As2DView<Stride2D.DenseY>(new Index2D(m, n), new Stride2D.DenseY(n));

                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    // Execute pre-compiled kernel (Phase B: US-GPU-001, US-GPU-007)
                    (_matrixMultiplyKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(m, n), viewA, viewB, viewResult, k);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Zero-copy result transfer
                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuA);
                _memoryPoolFloat.Return(gpuB);
                _memoryPoolFloat.Return(gpuResult);
            }
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted for matrix multiply: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixMultiply(a, b);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.MatrixMultiply(a, b);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU matrix multiply failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixMultiply(a, b);
        }
    }

    private Vector<float> MatrixVectorMultiplyGpu(Matrix<float> matrix, Vector<float> vector)
    {
        if (matrix == null) throw new ArgumentNullException(nameof(matrix));
        if (vector == null) throw new ArgumentNullException(nameof(vector));
        if (matrix.Columns != vector.Length)
        {
            throw new ArgumentException(
                $"Matrix-vector dimensions incompatible. Matrix is {matrix.Rows}x{matrix.Columns}, vector has {vector.Length} elements.");
        }

        try
        {
            var result = new Vector<float>(matrix.Rows);
            int rows = matrix.Rows, cols = matrix.Columns;

            var gpuMatrix = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);
            var gpuVector = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(cols);
            var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows);

            try
            {
                gpuMatrix.View.BaseView.CopyFromCPU(matrix.AsSpan());
                gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

                var viewMatrix = gpuMatrix.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));
                (_matrixVectorMultiplyKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, rows, viewMatrix, gpuVector.View, gpuResult.View, rows, cols);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_matrixVectorMultiplyKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, rows, viewMatrix, gpuVector.View, gpuResult.View, rows, cols);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuMatrix);
                _memoryPoolFloat.Return(gpuVector);
                _memoryPoolFloat.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU matrix-vector multiply failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixVectorMultiply(matrix, vector);
        }
    }

    private Matrix<float> MatrixTransposeGpu(Matrix<float> matrix)
    {
        if (matrix == null) throw new ArgumentNullException(nameof(matrix));

        try
        {
            var result = new Matrix<float>(matrix.Columns, matrix.Rows);
            int rows = matrix.Rows, cols = matrix.Columns;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(matrix.AsSpan());

                var viewInput = gpuInput.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));
                var viewOutput = gpuOutput.View.As2DView<Stride2D.DenseX>(new Index2D(cols, rows), new Stride2D.DenseX(rows));

                (_matrixTransposeKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(rows, cols), viewInput, viewOutput);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_matrixTransposeKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(rows, cols), viewInput, viewOutput);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU matrix transpose failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixTranspose(matrix);
        }
    }

    private Matrix<float> MatrixAddGpu(Matrix<float> a, Matrix<float> b)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));
        if (a.Rows != b.Rows || a.Columns != b.Columns)
        {
            throw new ArgumentException($"Matrix dimensions must match for addition.");
        }

        try
        {
            var result = new Matrix<float>(a.Rows, a.Columns);
            int rows = a.Rows, cols = a.Columns;

            var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);
            var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);
            var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                var viewA = gpuA.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));
                var viewB = gpuB.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));
                var viewResult = gpuResult.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));

                (_matrixAddKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(rows, cols), viewA, viewB, viewResult);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_matrixAddKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(rows, cols), viewA, viewB, viewResult);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuA);
                _memoryPoolFloat.Return(gpuB);
                _memoryPoolFloat.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU matrix add failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixAdd(a, b);
        }
    }

    private Matrix<float> MatrixMultiplyScalarGpu(Matrix<float> matrix, float scalar)
    {
        if (matrix == null) throw new ArgumentNullException(nameof(matrix));

        try
        {
            var result = new Matrix<float>(matrix.Rows, matrix.Columns);
            int rows = matrix.Rows, cols = matrix.Columns;

            var gpuMatrix = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);
            var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);

            try
            {
                gpuMatrix.View.BaseView.CopyFromCPU(matrix.AsSpan());

                var viewMatrix = gpuMatrix.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));
                var viewResult = gpuResult.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));

                (_matrixMultiplyScalarKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(rows, cols), viewMatrix, scalar, viewResult);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_matrixMultiplyScalarKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(rows, cols), viewMatrix, scalar, viewResult);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuMatrix);
                _memoryPoolFloat.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU matrix scalar multiply failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixMultiplyScalar(matrix, scalar);
        }
    }

    // GPU implementations for double matrices

    private Matrix<double> MatrixMultiplyGpuDouble(Matrix<double> a, Matrix<double> b)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));
        if (a.Columns != b.Rows)
        {
            throw new ArgumentException(
                $"Matrix dimensions incompatible for multiplication. " +
                $"First matrix is {a.Rows}x{a.Columns}, second is {b.Rows}x{b.Columns}.");
        }

        try
        {
            var result = new Matrix<double>(a.Rows, b.Columns);
            int m = a.Rows, k = a.Columns, n = b.Columns;

            var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(m * k);
            var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(k * n);
            var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(m * n);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                var viewA = gpuA.View.As2DView<Stride2D.DenseY>(new Index2D(m, k), new Stride2D.DenseY(k));
                var viewB = gpuB.View.As2DView<Stride2D.DenseY>(new Index2D(k, n), new Stride2D.DenseY(n));
                var viewResult = gpuResult.View.As2DView<Stride2D.DenseY>(new Index2D(m, n), new Stride2D.DenseY(n));

                (_matrixMultiplyKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(m, n), viewA, viewB, viewResult, k);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_matrixMultiplyKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(m, n), viewA, viewB, viewResult, k);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuA);
                _memoryPoolDouble.Return(gpuB);
                _memoryPoolDouble.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU matrix multiply (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixMultiply(a, b);
        }
    }

    private Vector<double> MatrixVectorMultiplyGpuDouble(Matrix<double> matrix, Vector<double> vector)
    {
        if (matrix == null) throw new ArgumentNullException(nameof(matrix));
        if (vector == null) throw new ArgumentNullException(nameof(vector));
        if (matrix.Columns != vector.Length)
        {
            throw new ArgumentException(
                $"Matrix-vector dimensions incompatible. Matrix is {matrix.Rows}x{matrix.Columns}, vector has {vector.Length} elements.");
        }

        try
        {
            var result = new Vector<double>(matrix.Rows);
            int rows = matrix.Rows, cols = matrix.Columns;

            var gpuMatrix = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);
            var gpuVector = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(cols);
            var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows);

            try
            {
                gpuMatrix.View.BaseView.CopyFromCPU(matrix.AsSpan());
                gpuVector.View.BaseView.CopyFromCPU(vector.AsSpan());

                var viewMatrix = gpuMatrix.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));
                (_matrixVectorMultiplyKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, rows, viewMatrix, gpuVector.View, gpuResult.View, rows, cols);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_matrixVectorMultiplyKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, rows, viewMatrix, gpuVector.View, gpuResult.View, rows, cols);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuMatrix);
                _memoryPoolDouble.Return(gpuVector);
                _memoryPoolDouble.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU matrix-vector multiply (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixVectorMultiply(matrix, vector);
        }
    }

    private Matrix<double> MatrixTransposeGpuDouble(Matrix<double> matrix)
    {
        if (matrix == null) throw new ArgumentNullException(nameof(matrix));

        try
        {
            var result = new Matrix<double>(matrix.Columns, matrix.Rows);
            int rows = matrix.Rows, cols = matrix.Columns;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(matrix.AsSpan());

                var viewInput = gpuInput.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));
                var viewOutput = gpuOutput.View.As2DView<Stride2D.DenseX>(new Index2D(cols, rows), new Stride2D.DenseX(rows));

                (_matrixTransposeKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(rows, cols), viewInput, viewOutput);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_matrixTransposeKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(rows, cols), viewInput, viewOutput);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU matrix transpose (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixTranspose(matrix);
        }
    }

    private Matrix<double> MatrixAddGpuDouble(Matrix<double> a, Matrix<double> b)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));
        if (a.Rows != b.Rows || a.Columns != b.Columns)
        {
            throw new ArgumentException($"Matrix dimensions must match for addition.");
        }

        try
        {
            var result = new Matrix<double>(a.Rows, a.Columns);
            int rows = a.Rows, cols = a.Columns;

            var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);
            var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);
            var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                var viewA = gpuA.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));
                var viewB = gpuB.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));
                var viewResult = gpuResult.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));

                (_matrixAddKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(rows, cols), viewA, viewB, viewResult);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_matrixAddKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(rows, cols), viewA, viewB, viewResult);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuA);
                _memoryPoolDouble.Return(gpuB);
                _memoryPoolDouble.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU matrix add (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixAdd(a, b);
        }
    }

    private Matrix<double> MatrixMultiplyScalarGpuDouble(Matrix<double> matrix, double scalar)
    {
        if (matrix == null) throw new ArgumentNullException(nameof(matrix));

        try
        {
            var result = new Matrix<double>(matrix.Rows, matrix.Columns);
            int rows = matrix.Rows, cols = matrix.Columns;

            var gpuMatrix = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);
            var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(rows * cols);

            try
            {
                gpuMatrix.View.BaseView.CopyFromCPU(matrix.AsSpan());

                var viewMatrix = gpuMatrix.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));
                var viewResult = gpuResult.View.As2DView<Stride2D.DenseX>(new Index2D(rows, cols), new Stride2D.DenseX(cols));

                (_matrixMultiplyScalarKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(rows, cols), viewMatrix, scalar, viewResult);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_matrixMultiplyScalarKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index2D(rows, cols), viewMatrix, scalar, viewResult);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuMatrix);
                _memoryPoolDouble.Return(gpuResult);
            }
        }
        catch (InvalidOperationException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU matrix scalar multiply (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixMultiplyScalar(matrix, scalar);
        }
        catch (ArgumentException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU matrix scalar multiply (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixMultiplyScalar(matrix, scalar);
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU matrix scalar multiply (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MatrixMultiplyScalar(matrix, scalar);
        }
    }

    #endregion

    #region Tensor Operations (Phase B: Epic 3)

    /// <inheritdoc/>
    public Tensor<T> BatchMatMul<T>(Tensor<T> a, Tensor<T> b)
    {
        // Adaptive execution: check size threshold (Phase B: US-GPU-004)
        if (Math.Max(a.Shape[1], a.Shape[2]) < _thresholds.BatchMatMul)
        {
            return _cpuFallback.BatchMatMul(a, b);
        }

        // Check GPU health and type support (Phase B: US-GPU-006)
        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)BatchMatMulGpu((Tensor<float>)(object)a, (Tensor<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)BatchMatMulGpuDouble((Tensor<double>)(object)a, (Tensor<double>)(object)b);
        }

        // Fallback to CPU for unsupported types or unhealthy GPU
        return _cpuFallback.BatchMatMul(a, b);
    }

    private Tensor<float> BatchMatMulGpu(Tensor<float> a, Tensor<float> b)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));
        if (a.Rank != 3 || b.Rank != 3)
        {
            throw new ArgumentException(
                $"BatchMatMul requires 3D tensors. Got ranks {a.Rank} and {b.Rank}.");
        }

        int batchSize = a.Shape[0];
        int m = a.Shape[1];
        int k = a.Shape[2];
        int k2 = b.Shape[1];
        int n = b.Shape[2];

        if (b.Shape[0] != batchSize)
        {
            throw new ArgumentException(
                $"Batch sizes must match. Got {batchSize} and {b.Shape[0]}.");
        }
        if (k != k2)
        {
            throw new ArgumentException(
                $"Matrix dimensions incompatible for multiplication. " +
                $"First tensor has shape [{batchSize}, {m}, {k}], " +
                $"second has shape [{b.Shape[0]}, {k2}, {n}]. " +
                $"Inner dimensions must match ({k} != {k2}).");
        }

        try
        {
            var result = new Tensor<float>(new[] { batchSize, m, n });

            // Allocate GPU buffers using memory pool (Phase B: US-GPU-002)
            var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(batchSize * m * k);
            var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(batchSize * k * n);
            var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(batchSize * m * n);

            try
            {
                // Zero-copy transfer (Phase B: US-GPU-003)
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                // Execute pre-compiled kernel (Phase B: US-GPU-001, US-GPU-013)
                (_batchMatMulKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index3D(batchSize, m, n), gpuA.View, gpuB.View, gpuResult.View, m, k, n);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_batchMatMulKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index3D(batchSize, m, n), gpuA.View, gpuB.View, gpuResult.View, m, k, n);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Zero-copy result transfer
                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuA);
                _memoryPoolFloat.Return(gpuB);
                _memoryPoolFloat.Return(gpuResult);
            }
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted for batch matmul: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.BatchMatMul(a, b);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.BatchMatMul(a, b);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU batch matmul failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.BatchMatMul(a, b);
        }
    }

    private Tensor<double> BatchMatMulGpuDouble(Tensor<double> a, Tensor<double> b)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));
        if (a.Rank != 3 || b.Rank != 3)
        {
            throw new ArgumentException(
                $"BatchMatMul requires 3D tensors. Got ranks {a.Rank} and {b.Rank}.");
        }

        int batchSize = a.Shape[0];
        int m = a.Shape[1];
        int k = a.Shape[2];
        int k2 = b.Shape[1];
        int n = b.Shape[2];

        if (b.Shape[0] != batchSize)
        {
            throw new ArgumentException(
                $"Batch sizes must match. Got {batchSize} and {b.Shape[0]}.");
        }
        if (k != k2)
        {
            throw new ArgumentException(
                $"Matrix dimensions incompatible for multiplication. " +
                $"First tensor has shape [{batchSize}, {m}, {k}], " +
                $"second has shape [{b.Shape[0]}, {k2}, {n}]. " +
                $"Inner dimensions must match ({k} != {k2}).");
        }

        try
        {
            var result = new Tensor<double>(new[] { batchSize, m, n });

            // Allocate GPU buffers using memory pool (Phase B: US-GPU-002)
            var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(batchSize * m * k);
            var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(batchSize * k * n);
            var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(batchSize * m * n);

            try
            {
                // Zero-copy transfer (Phase B: US-GPU-003)
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                // Execute pre-compiled kernel (Phase B: US-GPU-001, US-GPU-013)
                (_batchMatMulKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index3D(batchSize, m, n), gpuA.View, gpuB.View, gpuResult.View, m, k, n);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_batchMatMulKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, new Index3D(batchSize, m, n), gpuA.View, gpuB.View, gpuResult.View, m, k, n);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Zero-copy result transfer
                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuA);
                _memoryPoolDouble.Return(gpuB);
                _memoryPoolDouble.Return(gpuResult);
            }
        }
        catch (OutOfMemoryException ex)
        {
            Console.WriteLine($"[GpuEngine] GPU memory exhausted for batch matmul (double): {ex.Message}. Falling back to CPU.");
            return _cpuFallback.BatchMatMul(a, b);
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.BatchMatMul(a, b);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU batch matmul (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.BatchMatMul(a, b);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorAdd<T>(Tensor<T> a, Tensor<T> b)
    {
        // Adaptive execution: use vector threshold (Phase B: US-GPU-004)
        if (a.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorAdd(a, b);
        }

        // Check GPU health and type support (Phase B: US-GPU-006)
        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorAddGpu((Tensor<float>)(object)a, (Tensor<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorAddGpuDouble((Tensor<double>)(object)a, (Tensor<double>)(object)b);
        }

        return _cpuFallback.TensorAdd(a, b);
    }

    private Tensor<float> TensorAddGpu(Tensor<float> a, Tensor<float> b)
    {
        ValidateTensorShapes(a, b);

        try
        {
            var result = new Tensor<float>(a.Shape);
            var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
            var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
            var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                (_tensorAddKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_tensorAddKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuA);
                _memoryPoolFloat.Return(gpuB);
                _memoryPoolFloat.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU tensor add failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorAdd(a, b);
        }
    }

    private Tensor<double> TensorAddGpuDouble(Tensor<double> a, Tensor<double> b)
    {
        ValidateTensorShapes(a, b);

        try
        {
            var result = new Tensor<double>(a.Shape);
            var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
            var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
            var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                (_tensorAddKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_tensorAddKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuA);
                _memoryPoolDouble.Return(gpuB);
                _memoryPoolDouble.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU tensor add (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorAdd(a, b);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorBroadcastAdd<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));

        // Fast path: same shapes - use regular TensorAdd
        if (a.Shape.SequenceEqual(b.Shape))
        {
            return TensorAdd(a, b);
        }

        // Check for common Conv2D bias pattern: [B,C,H,W] + [C] or [1,C,1,1]
        // This is by far the most common broadcast add case in neural networks
        if (a.Rank == 4 && (b.Rank == 1 || (b.Rank == 4 && b.Shape[0] == 1 && b.Shape[2] == 1 && b.Shape[3] == 1)))
        {
            int channels = a.Shape[1];
            int biasChannels = b.Rank == 1 ? b.Shape[0] : b.Shape[1];

            if (channels == biasChannels && a.Length >= _thresholds.VectorAdd)
            {
                if (SupportsGpu && _gpuHealthy)
                {
                    if (typeof(T) == typeof(float))
                        return (Tensor<T>)(object)Conv2DBiasAddGpu((Tensor<float>)(object)a, (Tensor<float>)(object)b);
                    if (typeof(T) == typeof(double))
                        return (Tensor<T>)(object)Conv2DBiasAddGpuDouble((Tensor<double>)(object)a, (Tensor<double>)(object)b);
                }
            }
        }

        // General case: fallback to CPU which uses Tensor.BroadcastAdd
        return _cpuFallback.TensorBroadcastAdd(a, b);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorBroadcastMultiply<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));

        // Fast path: same shapes - use regular TensorMultiply
        if (a.Shape.SequenceEqual(b.Shape))
        {
            return TensorMultiply(a, b);
        }

        // General case: fallback to CPU which uses Tensor.BroadcastMultiply
        return _cpuFallback.TensorBroadcastMultiply(a, b);
    }

    private Tensor<float> Conv2DBiasAddGpu(Tensor<float> input, Tensor<float> bias)
    {
        try
        {
            int batchSize = input.Shape[0];
            int channels = input.Shape[1];
            int height = input.Shape[2];
            int width = input.Shape[3];

            // Flatten bias if it's 4D [1,C,1,1]
            int biasLength = bias.Rank == 1 ? bias.Length : channels;
            var flatBias = bias.Rank == 1 ? bias : bias.Reshape([channels]);

            var result = new Tensor<float>(input.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuBias = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(biasLength);
            var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuBias.View.BaseView.CopyFromCPU(flatBias.AsSpan());

                lock (_gpuLock)
                {
                    (_conv2DBiasAddKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        input.Length, gpuInput.View, gpuBias.View, gpuResult.View,
                        batchSize, channels, height, width);
                    _accelerator.Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuBias);
                _memoryPoolFloat.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU Conv2D bias add (float) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorBroadcastAdd(input, bias);
        }
    }

    private Tensor<double> Conv2DBiasAddGpuDouble(Tensor<double> input, Tensor<double> bias)
    {
        try
        {
            int batchSize = input.Shape[0];
            int channels = input.Shape[1];
            int height = input.Shape[2];
            int width = input.Shape[3];

            // Flatten bias if it's 4D [1,C,1,1]
            int biasLength = bias.Rank == 1 ? bias.Length : channels;
            var flatBias = bias.Rank == 1 ? bias : bias.Reshape([channels]);

            var result = new Tensor<double>(input.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuBias = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(biasLength);
            var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuBias.View.BaseView.CopyFromCPU(flatBias.AsSpan());

                lock (_gpuLock)
                {
                    (_conv2DBiasAddKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        input.Length, gpuInput.View, gpuBias.View, gpuResult.View,
                        batchSize, channels, height, width);
                    _accelerator.Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuBias);
                _memoryPoolDouble.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU Conv2D bias add (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorBroadcastAdd(input, bias);
        }
    }

    /// <inheritdoc/>
    /// <remarks>
    /// GPU-optimized implementation using reduction pattern:
    /// 1. Upload all tensors to GPU memory once
    /// 2. Perform pairwise additions keeping intermediate results on GPU
    /// 3. Download final result once
    /// This minimizes CPU<->GPU transfers compared to calling TensorAdd repeatedly.
    /// </remarks>
    public Tensor<T> TensorAddMany<T>(params Tensor<T>[] tensors)
    {
        if (tensors == null) throw new ArgumentNullException(nameof(tensors));
        if (tensors.Length < 2)
            throw new ArgumentException("TensorAddMany requires at least 2 tensors.", nameof(tensors));

        // For small tensors or few tensors, CPU may be faster due to transfer overhead
        if (tensors[0].Length < _thresholds.VectorAdd || tensors.Length < 3)
        {
            return _cpuFallback.TensorAddMany(tensors);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var floatTensors = tensors.Cast<Tensor<float>>().ToArray();
                return (Tensor<T>)(object)TensorAddManyGpu(floatTensors);
            }
            if (typeof(T) == typeof(double))
            {
                var doubleTensors = tensors.Cast<Tensor<double>>().ToArray();
                return (Tensor<T>)(object)TensorAddManyGpuDouble(doubleTensors);
            }
        }

        return _cpuFallback.TensorAddMany(tensors);
    }

    private Tensor<float> TensorAddManyGpu(Tensor<float>[] tensors)
    {
        // Validate all shapes match
        var referenceShape = tensors[0].Shape;
        for (int t = 1; t < tensors.Length; t++)
        {
            ValidateTensorShapes(tensors[0], tensors[t]);
        }

        try
        {
            int length = tensors[0].Length;
            var result = new Tensor<float>(referenceShape);

            // Allocate GPU memory for all input tensors and intermediate results
            var gpuTensors = new MemoryBuffer1D<float, Stride1D.Dense>[tensors.Length];
            MemoryBuffer1D<float, Stride1D.Dense>? gpuAccumulator = null;
            MemoryBuffer1D<float, Stride1D.Dense>? gpuTemp = null;

            try
            {
                // Upload all tensors to GPU
                for (int t = 0; t < tensors.Length; t++)
                {
                    gpuTensors[t] = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
                    gpuTensors[t].View.BaseView.CopyFromCPU(tensors[t].AsSpan());
                }

                // Allocate accumulator and temp buffer for ping-pong pattern
                gpuAccumulator = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
                gpuTemp = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);

                // Start with first tensor as accumulator
                gpuTensors[0].View.BaseView.CopyTo(gpuAccumulator.View.BaseView);

                // Perform reduction: accumulator = accumulator + tensors[i] for each tensor
                lock (_gpuLock)
                {
                    for (int t = 1; t < tensors.Length; t++)
                    {
                        // Add current tensor to accumulator, store in temp
                        (_tensorAddKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                            (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                            length,
                            gpuAccumulator.View,
                            gpuTensors[t].View,
                            gpuTemp.View);

                        // Swap accumulator and temp for next iteration
                        (gpuAccumulator, gpuTemp) = (gpuTemp, gpuAccumulator);
                    }
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Download final result (now in gpuAccumulator after all swaps)
                gpuAccumulator.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                // Return all GPU memory to pool
                if (_memoryPoolFloat != null)
                {
                    for (int t = 0; t < tensors.Length; t++)
                    {
                        if (gpuTensors[t] != null)
                            _memoryPoolFloat.Return(gpuTensors[t]);
                    }
                    if (gpuAccumulator != null)
                        _memoryPoolFloat.Return(gpuAccumulator);
                    if (gpuTemp != null)
                        _memoryPoolFloat.Return(gpuTemp);
                }
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU tensor add many failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorAddMany(tensors);
        }
    }

    private Tensor<double> TensorAddManyGpuDouble(Tensor<double>[] tensors)
    {
        // Validate all shapes match
        var referenceShape = tensors[0].Shape;
        for (int t = 1; t < tensors.Length; t++)
        {
            ValidateTensorShapes(tensors[0], tensors[t]);
        }

        try
        {
            int length = tensors[0].Length;
            var result = new Tensor<double>(referenceShape);

            // Allocate GPU memory for all input tensors and intermediate results
            var gpuTensors = new MemoryBuffer1D<double, Stride1D.Dense>[tensors.Length];
            MemoryBuffer1D<double, Stride1D.Dense>? gpuAccumulator = null;
            MemoryBuffer1D<double, Stride1D.Dense>? gpuTemp = null;

            try
            {
                // Upload all tensors to GPU
                for (int t = 0; t < tensors.Length; t++)
                {
                    gpuTensors[t] = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
                    gpuTensors[t].View.BaseView.CopyFromCPU(tensors[t].AsSpan());
                }

                // Allocate accumulator and temp buffer for ping-pong pattern
                gpuAccumulator = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
                gpuTemp = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);

                // Start with first tensor as accumulator
                gpuTensors[0].View.BaseView.CopyTo(gpuAccumulator.View.BaseView);

                // Perform reduction: accumulator = accumulator + tensors[i] for each tensor
                lock (_gpuLock)
                {
                    for (int t = 1; t < tensors.Length; t++)
                    {
                        // Add current tensor to accumulator, store in temp
                        (_tensorAddKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                            (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                            length,
                            gpuAccumulator.View,
                            gpuTensors[t].View,
                            gpuTemp.View);

                        // Swap accumulator and temp for next iteration
                        (gpuAccumulator, gpuTemp) = (gpuTemp, gpuAccumulator);
                    }
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Download final result (now in gpuAccumulator after all swaps)
                gpuAccumulator.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                // Return all GPU memory to pool
                if (_memoryPoolDouble != null)
                {
                    for (int t = 0; t < tensors.Length; t++)
                    {
                        if (gpuTensors[t] != null)
                            _memoryPoolDouble.Return(gpuTensors[t]);
                    }
                    if (gpuAccumulator != null)
                        _memoryPoolDouble.Return(gpuAccumulator);
                    if (gpuTemp != null)
                        _memoryPoolDouble.Return(gpuTemp);
                }
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU tensor add many (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorAddMany(tensors);
        }
    }

    /// <inheritdoc/>
    /// <remarks>
    /// GPU-optimized implementation using reduction pattern:
    /// 1. Upload all tensors to GPU memory once
    /// 2. Perform pairwise multiplications keeping intermediate results on GPU
    /// 3. Download final result once
    /// This minimizes CPU<->GPU transfers compared to calling TensorMultiply repeatedly.
    /// </remarks>
    public Tensor<T> TensorMultiplyMany<T>(params Tensor<T>[] tensors)
    {
        if (tensors == null) throw new ArgumentNullException(nameof(tensors));
        if (tensors.Length < 2)
            throw new ArgumentException("TensorMultiplyMany requires at least 2 tensors.", nameof(tensors));

        // For small tensors or few tensors, CPU may be faster due to transfer overhead
        if (tensors[0].Length < _thresholds.VectorMultiply || tensors.Length < 3)
        {
            return _cpuFallback.TensorMultiplyMany(tensors);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var floatTensors = tensors.Cast<Tensor<float>>().ToArray();
                return (Tensor<T>)(object)TensorMultiplyManyGpu(floatTensors);
            }
            if (typeof(T) == typeof(double))
            {
                var doubleTensors = tensors.Cast<Tensor<double>>().ToArray();
                return (Tensor<T>)(object)TensorMultiplyManyGpuDouble(doubleTensors);
            }
        }

        return _cpuFallback.TensorMultiplyMany(tensors);
    }

    private Tensor<float> TensorMultiplyManyGpu(Tensor<float>[] tensors)
    {
        // Validate all shapes match
        var referenceShape = tensors[0].Shape;
        for (int t = 1; t < tensors.Length; t++)
        {
            ValidateTensorShapes(tensors[0], tensors[t]);
        }

        try
        {
            int length = tensors[0].Length;
            var result = new Tensor<float>(referenceShape);

            // Allocate GPU memory for all input tensors and intermediate results
            var gpuTensors = new MemoryBuffer1D<float, Stride1D.Dense>[tensors.Length];
            MemoryBuffer1D<float, Stride1D.Dense>? gpuAccumulator = null;
            MemoryBuffer1D<float, Stride1D.Dense>? gpuTemp = null;

            try
            {
                // Upload all tensors to GPU
                for (int t = 0; t < tensors.Length; t++)
                {
                    gpuTensors[t] = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
                    gpuTensors[t].View.BaseView.CopyFromCPU(tensors[t].AsSpan());
                }

                // Allocate accumulator and temp buffer for ping-pong pattern
                gpuAccumulator = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
                gpuTemp = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);

                // Start with first tensor as accumulator
                gpuTensors[0].View.BaseView.CopyTo(gpuAccumulator.View.BaseView);

                // Perform reduction: accumulator = accumulator * tensors[i] for each tensor
                lock (_gpuLock)
                {
                    for (int t = 1; t < tensors.Length; t++)
                    {
                        // Multiply current tensor with accumulator, store in temp
                        (_tensorMultiplyKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                            (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                            length,
                            gpuAccumulator.View,
                            gpuTensors[t].View,
                            gpuTemp.View);

                        // Swap accumulator and temp for next iteration
                        (gpuAccumulator, gpuTemp) = (gpuTemp, gpuAccumulator);
                    }
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Download final result (now in gpuAccumulator after all swaps)
                gpuAccumulator.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                // Return all GPU memory to pool
                if (_memoryPoolFloat != null)
                {
                    for (int t = 0; t < tensors.Length; t++)
                    {
                        if (gpuTensors[t] != null)
                            _memoryPoolFloat.Return(gpuTensors[t]);
                    }
                    if (gpuAccumulator != null)
                        _memoryPoolFloat.Return(gpuAccumulator);
                    if (gpuTemp != null)
                        _memoryPoolFloat.Return(gpuTemp);
                }
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU tensor multiply many failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorMultiplyMany(tensors);
        }
    }

    private Tensor<double> TensorMultiplyManyGpuDouble(Tensor<double>[] tensors)
    {
        // Validate all shapes match
        var referenceShape = tensors[0].Shape;
        for (int t = 1; t < tensors.Length; t++)
        {
            ValidateTensorShapes(tensors[0], tensors[t]);
        }

        try
        {
            int length = tensors[0].Length;
            var result = new Tensor<double>(referenceShape);

            // Allocate GPU memory for all input tensors and intermediate results
            var gpuTensors = new MemoryBuffer1D<double, Stride1D.Dense>[tensors.Length];
            MemoryBuffer1D<double, Stride1D.Dense>? gpuAccumulator = null;
            MemoryBuffer1D<double, Stride1D.Dense>? gpuTemp = null;

            try
            {
                // Upload all tensors to GPU
                for (int t = 0; t < tensors.Length; t++)
                {
                    gpuTensors[t] = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
                    gpuTensors[t].View.BaseView.CopyFromCPU(tensors[t].AsSpan());
                }

                // Allocate accumulator and temp buffer for ping-pong pattern
                gpuAccumulator = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
                gpuTemp = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);

                // Start with first tensor as accumulator
                gpuTensors[0].View.BaseView.CopyTo(gpuAccumulator.View.BaseView);

                // Perform reduction: accumulator = accumulator * tensors[i] for each tensor
                lock (_gpuLock)
                {
                    for (int t = 1; t < tensors.Length; t++)
                    {
                        // Multiply current tensor with accumulator, store in temp
                        (_tensorMultiplyKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                            (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                            length,
                            gpuAccumulator.View,
                            gpuTensors[t].View,
                            gpuTemp.View);

                        // Swap accumulator and temp for next iteration
                        (gpuAccumulator, gpuTemp) = (gpuTemp, gpuAccumulator);
                    }
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Download final result (now in gpuAccumulator after all swaps)
                gpuAccumulator.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                // Return all GPU memory to pool
                if (_memoryPoolDouble != null)
                {
                    for (int t = 0; t < tensors.Length; t++)
                    {
                        if (gpuTensors[t] != null)
                            _memoryPoolDouble.Return(gpuTensors[t]);
                    }
                    if (gpuAccumulator != null)
                        _memoryPoolDouble.Return(gpuAccumulator);
                    if (gpuTemp != null)
                        _memoryPoolDouble.Return(gpuTemp);
                }
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU tensor multiply many (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorMultiplyMany(tensors);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorSubtract<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a.Length < _thresholds.VectorSubtract)
        {
            return _cpuFallback.TensorSubtract(a, b);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorSubtractGpu((Tensor<float>)(object)a, (Tensor<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorSubtractGpuDouble((Tensor<double>)(object)a, (Tensor<double>)(object)b);
        }

        return _cpuFallback.TensorSubtract(a, b);
    }

    private Tensor<float> TensorSubtractGpu(Tensor<float> a, Tensor<float> b)
    {
        ValidateTensorShapes(a, b);

        try
        {
            var result = new Tensor<float>(a.Shape);
            var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
            var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
            var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                (_tensorSubtractKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_tensorSubtractKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuA);
                _memoryPoolFloat.Return(gpuB);
                _memoryPoolFloat.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU tensor subtract failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorSubtract(a, b);
        }
    }

    private Tensor<double> TensorSubtractGpuDouble(Tensor<double> a, Tensor<double> b)
    {
        ValidateTensorShapes(a, b);

        try
        {
            var result = new Tensor<double>(a.Shape);
            var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
            var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
            var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                (_tensorSubtractKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_tensorSubtractKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuA);
                _memoryPoolDouble.Return(gpuB);
                _memoryPoolDouble.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU tensor subtract (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorSubtract(a, b);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorMultiply<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a.Length < _thresholds.VectorMultiply)
        {
            return _cpuFallback.TensorMultiply(a, b);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorMultiplyGpu((Tensor<float>)(object)a, (Tensor<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorMultiplyGpuDouble((Tensor<double>)(object)a, (Tensor<double>)(object)b);
        }

        return _cpuFallback.TensorMultiply(a, b);
    }

    private Tensor<float> TensorMultiplyGpu(Tensor<float> a, Tensor<float> b)
    {
        ValidateTensorShapes(a, b);

        try
        {
            var result = new Tensor<float>(a.Shape);
            var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
            var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
            var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                (_tensorMultiplyKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_tensorMultiplyKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuA);
                _memoryPoolFloat.Return(gpuB);
                _memoryPoolFloat.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU tensor multiply failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorMultiply(a, b);
        }
    }

    private Tensor<double> TensorMultiplyGpuDouble(Tensor<double> a, Tensor<double> b)
    {
        ValidateTensorShapes(a, b);

        try
        {
            var result = new Tensor<double>(a.Shape);
            var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
            var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
            var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                (_tensorMultiplyKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_tensorMultiplyKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuA);
                _memoryPoolDouble.Return(gpuB);
                _memoryPoolDouble.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU tensor multiply (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorMultiply(a, b);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorMultiplyScalar<T>(Tensor<T> tensor, T scalar)
    {
        if (tensor.Length < _thresholds.VectorMultiply)
        {
            return _cpuFallback.TensorMultiplyScalar(tensor, scalar);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorMultiplyScalarGpu((Tensor<float>)(object)tensor, (float)(object)scalar!);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorMultiplyScalarGpuDouble((Tensor<double>)(object)tensor, (double)(object)scalar!);
        }

        return _cpuFallback.TensorMultiplyScalar(tensor, scalar);
    }

    private Tensor<float> TensorMultiplyScalarGpu(Tensor<float> tensor, float scalar)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuTensor = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuTensor.View.BaseView.CopyFromCPU(tensor.AsSpan());

                (_tensorMultiplyScalarKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, tensor.Length, gpuTensor.View, scalar, gpuResult.View);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_tensorMultiplyScalarKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, tensor.Length, gpuTensor.View, scalar, gpuResult.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuTensor);
                _memoryPoolFloat.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU tensor scalar multiply failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorMultiplyScalar(tensor, scalar);
        }
    }

    private Tensor<double> TensorMultiplyScalarGpuDouble(Tensor<double> tensor, double scalar)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuTensor = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuTensor.View.BaseView.CopyFromCPU(tensor.AsSpan());

                (_tensorMultiplyScalarKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, tensor.Length, gpuTensor.View, scalar, gpuResult.View);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_tensorMultiplyScalarKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, tensor.Length, gpuTensor.View, scalar, gpuResult.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuTensor);
                _memoryPoolDouble.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU tensor scalar multiply (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorMultiplyScalar(tensor, scalar);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorDivide<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a.Length < _thresholds.VectorDivide)
        {
            return _cpuFallback.TensorDivide(a, b);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorDivideGpu((Tensor<float>)(object)a, (Tensor<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorDivideGpuDouble((Tensor<double>)(object)a, (Tensor<double>)(object)b);
        }

        return _cpuFallback.TensorDivide(a, b);
    }

    private Tensor<float> TensorDivideGpu(Tensor<float> a, Tensor<float> b)
    {
        ValidateTensorShapes(a, b);

        try
        {
            var result = new Tensor<float>(a.Shape);
            var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
            var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
            var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                (_tensorDivideKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_tensorDivideKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuA);
                _memoryPoolFloat.Return(gpuB);
                _memoryPoolFloat.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU tensor divide failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorDivide(a, b);
        }
    }

    private Tensor<double> TensorDivideGpuDouble(Tensor<double> a, Tensor<double> b)
    {
        ValidateTensorShapes(a, b);

        try
        {
            var result = new Tensor<double>(a.Shape);
            var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
            var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
            var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                (_tensorDivideKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_tensorDivideKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, a.Length, gpuA.View, gpuB.View, gpuResult.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuA);
                _memoryPoolDouble.Return(gpuB);
                _memoryPoolDouble.Return(gpuResult);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU tensor divide (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorDivide(a, b);
        }
    }

    #region Tensor Comparison Operations

    /// <inheritdoc/>
    /// <remarks>
    /// Comparison operations use CPU fallback as they're typically used for masking
    /// which is done once at setup time, not in hot paths.
    /// For very large tensors (>100K elements), parallel CPU execution is used.
    /// </remarks>
    public Tensor<T> TensorEquals<T>(Tensor<T> tensor, T value)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            // GPU optimization: parallel comparison with scalar
            if (typeof(T) == typeof(float))
            {
                var t = (Tensor<float>)(object)tensor;
                var valueObj = (object?)value; float v = valueObj is float fv ? fv : Convert.ToSingle(value);
                var result = new float[t.Length];
                var tData = t.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, t.Length, i =>
                {
                    result[i] = tData[i] == v ? 1.0f : 0.0f;
                });
                return (Tensor<T>)(object)new Tensor<float>(tensor.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var t = (Tensor<double>)(object)tensor;
                var valueObj = (object?)value; double v = valueObj is double dv ? dv : Convert.ToDouble(value);
                var result = new double[t.Length];
                var tData = t.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, t.Length, i =>
                {
                    result[i] = tData[i] == v ? 1.0 : 0.0;
                });
                return (Tensor<T>)(object)new Tensor<double>(tensor.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.TensorEquals(tensor, value);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorEquals<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var ta = (Tensor<float>)(object)a;
                var tb = (Tensor<float>)(object)b;
                var result = new float[ta.Length];
                var aData = ta.AsSpan().ToArray();
                var bData = tb.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, ta.Length, i =>
                {
                    result[i] = aData[i] == bData[i] ? 1.0f : 0.0f;
                });
                return (Tensor<T>)(object)new Tensor<float>(a.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var ta = (Tensor<double>)(object)a;
                var tb = (Tensor<double>)(object)b;
                var result = new double[ta.Length];
                var aData = ta.AsSpan().ToArray();
                var bData = tb.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, ta.Length, i =>
                {
                    result[i] = aData[i] == bData[i] ? 1.0 : 0.0;
                });
                return (Tensor<T>)(object)new Tensor<double>(a.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.TensorEquals(a, b);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorNotEquals<T>(Tensor<T> tensor, T value)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var t = (Tensor<float>)(object)tensor;
                var valueObj = (object?)value; float v = valueObj is float fv ? fv : Convert.ToSingle(value);
                var result = new float[t.Length];
                var tData = t.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, t.Length, i =>
                {
                    result[i] = tData[i] != v ? 1.0f : 0.0f;
                });
                return (Tensor<T>)(object)new Tensor<float>(tensor.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var t = (Tensor<double>)(object)tensor;
                var valueObj = (object?)value; double v = valueObj is double dv ? dv : Convert.ToDouble(value);
                var result = new double[t.Length];
                var tData = t.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, t.Length, i =>
                {
                    result[i] = tData[i] != v ? 1.0 : 0.0;
                });
                return (Tensor<T>)(object)new Tensor<double>(tensor.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.TensorNotEquals(tensor, value);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorNotEquals<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var ta = (Tensor<float>)(object)a;
                var tb = (Tensor<float>)(object)b;
                var result = new float[ta.Length];
                var aData = ta.AsSpan().ToArray();
                var bData = tb.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, ta.Length, i =>
                {
                    result[i] = aData[i] != bData[i] ? 1.0f : 0.0f;
                });
                return (Tensor<T>)(object)new Tensor<float>(a.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var ta = (Tensor<double>)(object)a;
                var tb = (Tensor<double>)(object)b;
                var result = new double[ta.Length];
                var aData = ta.AsSpan().ToArray();
                var bData = tb.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, ta.Length, i =>
                {
                    result[i] = aData[i] != bData[i] ? 1.0 : 0.0;
                });
                return (Tensor<T>)(object)new Tensor<double>(a.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.TensorNotEquals(a, b);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorGreaterThan<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var ta = (Tensor<float>)(object)a;
                var tb = (Tensor<float>)(object)b;
                var result = new float[ta.Length];
                var aData = ta.AsSpan().ToArray();
                var bData = tb.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, ta.Length, i =>
                {
                    result[i] = aData[i] > bData[i] ? 1.0f : 0.0f;
                });
                return (Tensor<T>)(object)new Tensor<float>(a.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var ta = (Tensor<double>)(object)a;
                var tb = (Tensor<double>)(object)b;
                var result = new double[ta.Length];
                var aData = ta.AsSpan().ToArray();
                var bData = tb.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, ta.Length, i =>
                {
                    result[i] = aData[i] > bData[i] ? 1.0 : 0.0;
                });
                return (Tensor<T>)(object)new Tensor<double>(a.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.TensorGreaterThan(a, b);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorGreaterThan<T>(Tensor<T> tensor, T value)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var t = (Tensor<float>)(object)tensor;
                var valueObj = (object?)value; float v = valueObj is float fv ? fv : Convert.ToSingle(value);
                var result = new float[t.Length];
                var tData = t.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, t.Length, i =>
                {
                    result[i] = tData[i] > v ? 1.0f : 0.0f;
                });
                return (Tensor<T>)(object)new Tensor<float>(tensor.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var t = (Tensor<double>)(object)tensor;
                var valueObj = (object?)value; double v = valueObj is double dv ? dv : Convert.ToDouble(value);
                var result = new double[t.Length];
                var tData = t.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, t.Length, i =>
                {
                    result[i] = tData[i] > v ? 1.0 : 0.0;
                });
                return (Tensor<T>)(object)new Tensor<double>(tensor.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.TensorGreaterThan(tensor, value);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorLessThan<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var ta = (Tensor<float>)(object)a;
                var tb = (Tensor<float>)(object)b;
                var result = new float[ta.Length];
                var aData = ta.AsSpan().ToArray();
                var bData = tb.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, ta.Length, i =>
                {
                    result[i] = aData[i] < bData[i] ? 1.0f : 0.0f;
                });
                return (Tensor<T>)(object)new Tensor<float>(a.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var ta = (Tensor<double>)(object)a;
                var tb = (Tensor<double>)(object)b;
                var result = new double[ta.Length];
                var aData = ta.AsSpan().ToArray();
                var bData = tb.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, ta.Length, i =>
                {
                    result[i] = aData[i] < bData[i] ? 1.0 : 0.0;
                });
                return (Tensor<T>)(object)new Tensor<double>(a.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.TensorLessThan(a, b);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorLessThan<T>(Tensor<T> tensor, T value)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var t = (Tensor<float>)(object)tensor;
                var valueObj = (object?)value; float v = valueObj is float fv ? fv : Convert.ToSingle(value);
                var result = new float[t.Length];
                var tData = t.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, t.Length, i =>
                {
                    result[i] = tData[i] < v ? 1.0f : 0.0f;
                });
                return (Tensor<T>)(object)new Tensor<float>(tensor.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var t = (Tensor<double>)(object)tensor;
                var valueObj = (object?)value; double v = valueObj is double dv ? dv : Convert.ToDouble(value);
                var result = new double[t.Length];
                var tData = t.AsSpan().ToArray();
                System.Threading.Tasks.Parallel.For(0, t.Length, i =>
                {
                    result[i] = tData[i] < v ? 1.0 : 0.0;
                });
                return (Tensor<T>)(object)new Tensor<double>(tensor.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.TensorLessThan(tensor, value);
    }

    #endregion

    #region Tensor Element-wise Math Operations

    /// <inheritdoc/>
    public Tensor<T> TensorLog<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        // Adaptive execution threshold
        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorLog(tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorLogGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorLogGpuDouble((Tensor<double>)(object)tensor);
        }

        return _cpuFallback.TensorLog(tensor);
    }

    private Tensor<float> TensorLogGpu(Tensor<float> tensor)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_logKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorLog(tensor);
        }
    }

    private Tensor<double> TensorLogGpuDouble(Tensor<double> tensor)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_logKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorLog(tensor);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorExp<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorExp(tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorExpGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorExpGpuDouble((Tensor<double>)(object)tensor);
        }

        return _cpuFallback.TensorExp(tensor);
    }

    private Tensor<float> TensorExpGpu(Tensor<float> tensor)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_expKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorExp(tensor);
        }
    }

    private Tensor<double> TensorExpGpuDouble(Tensor<double> tensor)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_expKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorExp(tensor);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorSqrt<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorSqrt(tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorSqrtGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorSqrtGpuDouble((Tensor<double>)(object)tensor);
        }

        return _cpuFallback.TensorSqrt(tensor);
    }

    private Tensor<float> TensorSqrtGpu(Tensor<float> tensor)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_sqrtKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorSqrt(tensor);
        }
    }

    private Tensor<double> TensorSqrtGpuDouble(Tensor<double> tensor)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_sqrtKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorSqrt(tensor);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorAbs<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorAbs(tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorAbsGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorAbsGpuDouble((Tensor<double>)(object)tensor);
        }

        return _cpuFallback.TensorAbs(tensor);
    }

    private Tensor<float> TensorAbsGpu(Tensor<float> tensor)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_absKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorAbs(tensor);
        }
    }

    private Tensor<double> TensorAbsGpuDouble(Tensor<double> tensor)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_absKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorAbs(tensor);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorNegate<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        // Negate is multiply by -1, use existing scalar multiply kernel
        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorNegate(tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorNegateGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorNegateGpuDouble((Tensor<double>)(object)tensor);
        }

        return _cpuFallback.TensorNegate(tensor);
    }

    private Tensor<float> TensorNegateGpu(Tensor<float> tensor)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    // Use dedicated negate kernel
                    (_negateKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorNegate(tensor);
        }
    }

    private Tensor<double> TensorNegateGpuDouble(Tensor<double> tensor)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_negateKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorNegate(tensor);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorPower<T>(Tensor<T> tensor, T exponent)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        // TensorPower with scalar exponent - fall back to CPU for now
        // GPU implementation would require a dedicated kernel with scalar parameter
        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorPower(tensor, exponent);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var exponentObj = (object?)exponent; float exp = exponentObj is float fexp ? fexp : Convert.ToSingle(exponent);
                return (Tensor<T>)(object)TensorPowerGpu((Tensor<float>)(object)tensor, exp);
            }
            if (typeof(T) == typeof(double))
            {
                var exponentObj = (object?)exponent; double exp = exponentObj is double dexp ? dexp : Convert.ToDouble(exponent);
                return (Tensor<T>)(object)TensorPowerGpuDouble((Tensor<double>)(object)tensor, exp);
            }
        }

        return _cpuFallback.TensorPower(tensor, exponent);
    }

    private Tensor<float> TensorPowerGpu(Tensor<float> tensor, float exponent)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    // Use power kernel with scalar exponent
                    (_powerScalarKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, exponent, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorPower(tensor, exponent);
        }
    }

    private Tensor<double> TensorPowerGpuDouble(Tensor<double> tensor, double exponent)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_powerScalarKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, exponent, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorPower(tensor, exponent);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorPower<T>(Tensor<T> bases, Tensor<T> exponents)
    {
        // Element-wise power - fall back to CPU as this requires element-wise kernel
        return _cpuFallback.TensorPower(bases, exponents);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorFloor<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorFloor(tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorFloorGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorFloorGpuDouble((Tensor<double>)(object)tensor);
        }

        return _cpuFallback.TensorFloor(tensor);
    }

    private Tensor<float> TensorFloorGpu(Tensor<float> tensor)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_floorKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorFloor(tensor);
        }
    }

    private Tensor<double> TensorFloorGpuDouble(Tensor<double> tensor)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_floorKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorFloor(tensor);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorCeiling<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorCeiling(tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorCeilingGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorCeilingGpuDouble((Tensor<double>)(object)tensor);
        }

        return _cpuFallback.TensorCeiling(tensor);
    }

    private Tensor<float> TensorCeilingGpu(Tensor<float> tensor)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_ceilingKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorCeiling(tensor);
        }
    }

    private Tensor<double> TensorCeilingGpuDouble(Tensor<double> tensor)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_ceilingKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorCeiling(tensor);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorFrac<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorFrac(tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorFracGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorFracGpuDouble((Tensor<double>)(object)tensor);
        }

        return _cpuFallback.TensorFrac(tensor);
    }

    private Tensor<float> TensorFracGpu(Tensor<float> tensor)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_fracKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorFrac(tensor);
        }
    }

    private Tensor<double> TensorFracGpuDouble(Tensor<double> tensor)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_fracKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorFrac(tensor);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorSin<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorSin(tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorSinGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorSinGpuDouble((Tensor<double>)(object)tensor);
        }

        return _cpuFallback.TensorSin(tensor);
    }

    private Tensor<float> TensorSinGpu(Tensor<float> tensor)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_sinKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorSin(tensor);
        }
    }

    private Tensor<double> TensorSinGpuDouble(Tensor<double> tensor)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_sinKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorSin(tensor);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorCos<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorCos(tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorCosGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorCosGpuDouble((Tensor<double>)(object)tensor);
        }

        return _cpuFallback.TensorCos(tensor);
    }

    private Tensor<float> TensorCosGpu(Tensor<float> tensor)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_cosKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorCos(tensor);
        }
    }

    private Tensor<double> TensorCosGpuDouble(Tensor<double> tensor)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_cosKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorCos(tensor);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorTrilinearInterpolate<T>(Tensor<T> grid, Tensor<T> positions)
    {
        if (grid == null) throw new ArgumentNullException(nameof(grid));
        if (positions == null) throw new ArgumentNullException(nameof(positions));

        // Grid should be [D, H, W, C], positions should be [N, 3]
        if (grid.Rank != 4) throw new ArgumentException("Grid must be 4D [D, H, W, C]", nameof(grid));
        if (positions.Rank != 2 || positions.Shape[1] != 3) throw new ArgumentException("Positions must be [N, 3]", nameof(positions));

        int numPositions = positions.Shape[0];
        int channels = grid.Shape[3];
        int outputLength = numPositions * channels;

        if (outputLength < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorTrilinearInterpolate(grid, positions);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorTrilinearInterpolateGpu(
                    (Tensor<float>)(object)grid, (Tensor<float>)(object)positions);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorTrilinearInterpolateGpuDouble(
                    (Tensor<double>)(object)grid, (Tensor<double>)(object)positions);
        }

        return _cpuFallback.TensorTrilinearInterpolate(grid, positions);
    }

    private Tensor<float> TensorTrilinearInterpolateGpu(Tensor<float> grid, Tensor<float> positions)
    {
        try
        {
            int depth = grid.Shape[0];
            int height = grid.Shape[1];
            int width = grid.Shape[2];
            int channels = grid.Shape[3];
            int numPositions = positions.Shape[0];

            var result = new Tensor<float>(new[] { numPositions, channels });
            var gpuGrid = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(grid.Length);
            var gpuPositions = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(positions.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(result.Length);

            try
            {
                gpuGrid.View.BaseView.CopyFromCPU(grid.AsSpan());
                gpuPositions.View.BaseView.CopyFromCPU(positions.AsSpan());

                lock (_gpuLock)
                {
                    (_trilinearInterpolateKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        result.Length, gpuGrid.View, gpuPositions.View, gpuOutput.View,
                        depth, height, width, channels);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGrid);
                _memoryPoolFloat.Return(gpuPositions);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorTrilinearInterpolate(grid, positions);
        }
    }

    private Tensor<double> TensorTrilinearInterpolateGpuDouble(Tensor<double> grid, Tensor<double> positions)
    {
        try
        {
            int depth = grid.Shape[0];
            int height = grid.Shape[1];
            int width = grid.Shape[2];
            int channels = grid.Shape[3];
            int numPositions = positions.Shape[0];

            var result = new Tensor<double>(new[] { numPositions, channels });
            var gpuGrid = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(grid.Length);
            var gpuPositions = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(positions.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(result.Length);

            try
            {
                gpuGrid.View.BaseView.CopyFromCPU(grid.AsSpan());
                gpuPositions.View.BaseView.CopyFromCPU(positions.AsSpan());

                lock (_gpuLock)
                {
                    (_trilinearInterpolateKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        result.Length, gpuGrid.View, gpuPositions.View, gpuOutput.View,
                        depth, height, width, channels);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGrid);
                _memoryPoolDouble.Return(gpuPositions);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorTrilinearInterpolate(grid, positions);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorTrilinearInterpolateBackward<T>(Tensor<T> gradOutput, Tensor<T> grid, Tensor<T> positions)
    {
        if (gradOutput == null) throw new ArgumentNullException(nameof(gradOutput));
        if (grid == null) throw new ArgumentNullException(nameof(grid));
        if (positions == null) throw new ArgumentNullException(nameof(positions));

        // Grid should be [D, H, W, C], positions should be [N, 3], gradOutput should be [N, C]
        if (grid.Rank != 4) throw new ArgumentException("Grid must be 4D [D, H, W, C]", nameof(grid));
        if (positions.Rank != 2 || positions.Shape[1] != 3) throw new ArgumentException("Positions must be [N, 3]", nameof(positions));

        int numPositions = positions.Shape[0];
        int channels = grid.Shape[3];

        if (gradOutput.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorTrilinearInterpolateBackward(gradOutput, grid, positions);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorTrilinearInterpolateBackwardGpu(
                    (Tensor<float>)(object)gradOutput, (Tensor<float>)(object)grid, (Tensor<float>)(object)positions);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorTrilinearInterpolateBackwardGpuDouble(
                    (Tensor<double>)(object)gradOutput, (Tensor<double>)(object)grid, (Tensor<double>)(object)positions);
        }

        return _cpuFallback.TensorTrilinearInterpolateBackward(gradOutput, grid, positions);
    }

    private Tensor<float> TensorTrilinearInterpolateBackwardGpu(Tensor<float> gradOutput, Tensor<float> grid, Tensor<float> positions)
    {
        try
        {
            int depth = grid.Shape[0];
            int height = grid.Shape[1];
            int width = grid.Shape[2];
            int channels = grid.Shape[3];
            int numPositions = positions.Shape[0];

            var gradGrid = new Tensor<float>(grid.Shape);
            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuPositions = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(positions.Length);
            var gpuGradGrid = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradGrid.Length);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuPositions.View.BaseView.CopyFromCPU(positions.AsSpan());

                // Zero-initialize the gradient grid
                gpuGradGrid.View.BaseView.MemSetToZero();

                lock (_gpuLock)
                {
                    (_trilinearInterpolateBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        gradOutput.Length, gpuGradOutput.View, gpuPositions.View, gpuGradGrid.View,
                        depth, height, width, channels);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradGrid.View.BaseView.CopyToCPU(gradGrid.AsWritableSpan());
                return gradGrid;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuPositions);
                _memoryPoolFloat.Return(gpuGradGrid);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorTrilinearInterpolateBackward(gradOutput, grid, positions);
        }
    }

    private Tensor<double> TensorTrilinearInterpolateBackwardGpuDouble(Tensor<double> gradOutput, Tensor<double> grid, Tensor<double> positions)
    {
        try
        {
            int depth = grid.Shape[0];
            int height = grid.Shape[1];
            int width = grid.Shape[2];
            int channels = grid.Shape[3];
            int numPositions = positions.Shape[0];

            var gradGrid = new Tensor<double>(grid.Shape);
            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuPositions = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(positions.Length);
            var gpuGradGrid = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradGrid.Length);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuPositions.View.BaseView.CopyFromCPU(positions.AsSpan());

                // Zero-initialize the gradient grid
                gpuGradGrid.View.BaseView.MemSetToZero();

                lock (_gpuLock)
                {
                    (_trilinearInterpolateBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        gradOutput.Length, gpuGradOutput.View, gpuPositions.View, gpuGradGrid.View,
                        depth, height, width, channels);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradGrid.View.BaseView.CopyToCPU(gradGrid.AsWritableSpan());
                return gradGrid;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuPositions);
                _memoryPoolDouble.Return(gpuGradGrid);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorTrilinearInterpolateBackward(gradOutput, grid, positions);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorPow<T>(Tensor<T> tensor, T exponent)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorPow(tensor, exponent);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var floatTensor = (Tensor<float>)(object)tensor;
                var floatExponent = Convert.ToSingle(exponent);
                return (Tensor<T>)(object)TensorPowGpu(floatTensor, floatExponent);
            }
            if (typeof(T) == typeof(double))
            {
                var doubleTensor = (Tensor<double>)(object)tensor;
                var doubleExponent = Convert.ToDouble(exponent);
                return (Tensor<T>)(object)TensorPowGpuDouble(doubleTensor, doubleExponent);
            }
        }

        return _cpuFallback.TensorPow(tensor, exponent);
    }

    private Tensor<float> TensorPowGpu(Tensor<float> tensor, float exponent)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_powerKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, exponent, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorPow(tensor, exponent);
        }
    }

    private Tensor<double> TensorPowGpuDouble(Tensor<double> tensor, double exponent)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_powerKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, exponent, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorPow(tensor, exponent);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorMax<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));

        if (a.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorMax(a, b);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorMaxGpu((Tensor<float>)(object)a, (Tensor<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorMaxGpuDouble((Tensor<double>)(object)a, (Tensor<double>)(object)b);
        }

        return _cpuFallback.TensorMax(a, b);
    }

    private Tensor<float> TensorMaxGpu(Tensor<float> a, Tensor<float> b)
    {
        ValidateTensorShapes(a, b);

        try
        {
            var result = new Tensor<float>(a.Shape);
            var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
            var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                lock (_gpuLock)
                {
                    (_maxKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        a.Length, gpuA.View, gpuB.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuA);
                _memoryPoolFloat.Return(gpuB);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorMax(a, b);
        }
    }

    private Tensor<double> TensorMaxGpuDouble(Tensor<double> a, Tensor<double> b)
    {
        ValidateTensorShapes(a, b);

        try
        {
            var result = new Tensor<double>(a.Shape);
            var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
            var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                lock (_gpuLock)
                {
                    (_maxKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        a.Length, gpuA.View, gpuB.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuA);
                _memoryPoolDouble.Return(gpuB);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorMax(a, b);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorMax<T>(Tensor<T> tensor, T value)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        // For scalar max, create a tensor filled with the value and use element-wise max
        // This is a common pattern - GPU kernels typically work on tensors
        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorMax(tensor, value);
        }

        // Create broadcast tensor and use element-wise max
        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var floatTensor = (Tensor<float>)(object)tensor;
                var floatValue = Convert.ToSingle(value);
                return (Tensor<T>)(object)TensorMaxScalarGpu(floatTensor, floatValue);
            }
            if (typeof(T) == typeof(double))
            {
                var doubleTensor = (Tensor<double>)(object)tensor;
                var doubleValue = Convert.ToDouble(value);
                return (Tensor<T>)(object)TensorMaxScalarGpuDouble(doubleTensor, doubleValue);
            }
        }

        return _cpuFallback.TensorMax(tensor, value);
    }

    private Tensor<float> TensorMaxScalarGpu(Tensor<float> tensor, float value)
    {
        // Create a tensor filled with the scalar value for broadcast max
        var broadcastTensor = new Tensor<float>(tensor.Shape);
        var span = broadcastTensor.AsWritableSpan();
        for (int i = 0; i < span.Length; i++) span[i] = value;

        return TensorMaxGpu(tensor, broadcastTensor);
    }

    private Tensor<double> TensorMaxScalarGpuDouble(Tensor<double> tensor, double value)
    {
        var broadcastTensor = new Tensor<double>(tensor.Shape);
        var span = broadcastTensor.AsWritableSpan();
        for (int i = 0; i < span.Length; i++) span[i] = value;

        return TensorMaxGpuDouble(tensor, broadcastTensor);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorMin<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));

        if (a.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorMin(a, b);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorMinGpu((Tensor<float>)(object)a, (Tensor<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorMinGpuDouble((Tensor<double>)(object)a, (Tensor<double>)(object)b);
        }

        return _cpuFallback.TensorMin(a, b);
    }

    private Tensor<float> TensorMinGpu(Tensor<float> a, Tensor<float> b)
    {
        ValidateTensorShapes(a, b);

        try
        {
            var result = new Tensor<float>(a.Shape);
            var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
            var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                lock (_gpuLock)
                {
                    (_minKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        a.Length, gpuA.View, gpuB.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuA);
                _memoryPoolFloat.Return(gpuB);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorMin(a, b);
        }
    }

    private Tensor<double> TensorMinGpuDouble(Tensor<double> a, Tensor<double> b)
    {
        ValidateTensorShapes(a, b);

        try
        {
            var result = new Tensor<double>(a.Shape);
            var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);
            var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(b.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(a.Length);

            try
            {
                gpuA.View.BaseView.CopyFromCPU(a.AsSpan());
                gpuB.View.BaseView.CopyFromCPU(b.AsSpan());

                lock (_gpuLock)
                {
                    (_minKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        a.Length, gpuA.View, gpuB.View, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuA);
                _memoryPoolDouble.Return(gpuB);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorMin(a, b);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorMin<T>(Tensor<T> tensor, T value)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorMin(tensor, value);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var floatTensor = (Tensor<float>)(object)tensor;
                var floatValue = Convert.ToSingle(value);
                return (Tensor<T>)(object)TensorMinScalarGpu(floatTensor, floatValue);
            }
            if (typeof(T) == typeof(double))
            {
                var doubleTensor = (Tensor<double>)(object)tensor;
                var doubleValue = Convert.ToDouble(value);
                return (Tensor<T>)(object)TensorMinScalarGpuDouble(doubleTensor, doubleValue);
            }
        }

        return _cpuFallback.TensorMin(tensor, value);
    }

    private Tensor<float> TensorMinScalarGpu(Tensor<float> tensor, float value)
    {
        var broadcastTensor = new Tensor<float>(tensor.Shape);
        var span = broadcastTensor.AsWritableSpan();
        for (int i = 0; i < span.Length; i++) span[i] = value;

        return TensorMinGpu(tensor, broadcastTensor);
    }

    private Tensor<double> TensorMinScalarGpuDouble(Tensor<double> tensor, double value)
    {
        var broadcastTensor = new Tensor<double>(tensor.Shape);
        var span = broadcastTensor.AsWritableSpan();
        for (int i = 0; i < span.Length; i++) span[i] = value;

        return TensorMinGpuDouble(tensor, broadcastTensor);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorClamp<T>(Tensor<T> tensor, T min, T max)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorClamp(tensor, min, max);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var floatTensor = (Tensor<float>)(object)tensor;
                var floatMin = Convert.ToSingle(min);
                var floatMax = Convert.ToSingle(max);
                return (Tensor<T>)(object)TensorClampGpu(floatTensor, floatMin, floatMax);
            }
            if (typeof(T) == typeof(double))
            {
                var doubleTensor = (Tensor<double>)(object)tensor;
                var doubleMin = Convert.ToDouble(min);
                var doubleMax = Convert.ToDouble(max);
                return (Tensor<T>)(object)TensorClampGpuDouble(doubleTensor, doubleMin, doubleMax);
            }
        }

        return _cpuFallback.TensorClamp(tensor, min, max);
    }

    private Tensor<float> TensorClampGpu(Tensor<float> tensor, float min, float max)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_clampKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, min, max, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorClamp(tensor, min, max);
        }
    }

    private Tensor<double> TensorClampGpuDouble(Tensor<double> tensor, double min, double max)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_clampKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, min, max, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorClamp(tensor, min, max);
        }
    }

    /// <inheritdoc/>
    public T TensorSum<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        // Use adaptive threshold - GPU reduction benefits from large tensors
        if (tensor.Length < _thresholds.VectorAdd * 4)
        {
            return _cpuFallback.TensorSum(tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (T)(object)TensorSumGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (T)(object)TensorSumGpuDouble((Tensor<double>)(object)tensor);
        }

        return _cpuFallback.TensorSum(tensor);
    }

    private float TensorSumGpu(Tensor<float> tensor)
    {
        try
        {
            int length = tensor.Length;
            int numBlocks = (length + ReductionBlockSize - 1) / ReductionBlockSize;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
            var gpuPartialSums = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    // First pass: compute partial sums for each block
                    (_partialSumKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numBlocks, gpuInput.View, gpuPartialSums.View, length);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Copy partial sums back and finish reduction on CPU
                // (for very large tensors, could do multi-level GPU reduction)
                var partialSums = new float[numBlocks];
                gpuPartialSums.View.BaseView.CopyToCPU(partialSums);

                float total = 0;
                for (int i = 0; i < numBlocks; i++)
                    total += partialSums[i];

                return total;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuPartialSums);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorSum(tensor);
        }
    }

    private double TensorSumGpuDouble(Tensor<double> tensor)
    {
        try
        {
            int length = tensor.Length;
            int numBlocks = (length + ReductionBlockSize - 1) / ReductionBlockSize;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
            var gpuPartialSums = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_partialSumKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numBlocks, gpuInput.View, gpuPartialSums.View, length);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var partialSums = new double[numBlocks];
                gpuPartialSums.View.BaseView.CopyToCPU(partialSums);

                double total = 0;
                for (int i = 0; i < numBlocks; i++)
                    total += partialSums[i];

                return total;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuPartialSums);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorSum(tensor);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> ReduceSum<T>(Tensor<T> tensor, int[]? axes = null, bool keepDims = false)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        // Full reduction (sum all elements) - use TensorSum
        if (axes == null || axes.Length == 0)
        {
            T sum = TensorSum(tensor);
            if (keepDims)
            {
                var shape = new int[tensor.Rank];
                for (int i = 0; i < tensor.Rank; i++) shape[i] = 1;
                var result = new Tensor<T>(shape);
                result.SetFlat(0, sum);
                return result;
            }
            return new Tensor<T>([1], new Vector<T>([sum]));
        }

        // Threshold check - small tensors use CPU
        if (tensor.Length < _thresholds.VectorAdd * 2)
        {
            return _cpuFallback.ReduceSum(tensor, axes, keepDims);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)ReduceSumGpu((Tensor<float>)(object)tensor, axes, keepDims);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)ReduceSumGpuDouble((Tensor<double>)(object)tensor, axes, keepDims);
        }

        return _cpuFallback.ReduceSum(tensor, axes, keepDims);
    }

    private Tensor<float> ReduceSumGpu(Tensor<float> tensor, int[] axes, bool keepDims)
    {
        try
        {
            // Normalize axes (handle negative indices)
            var normalizedAxes = axes.Select(a => a < 0 ? a + tensor.Rank : a).OrderBy(a => a).ToArray();

            // Validate axes are within bounds
            if (normalizedAxes.Any(a => a < 0 || a >= tensor.Rank))
            {
                return _cpuFallback.ReduceSum(tensor, axes, keepDims);
            }

            // Compute outer, reduce, and inner sizes
            // For axes to reduce, we reshape logically to [outerSize, reduceSize, innerSize]
            int outerSize = 1;
            int reduceSize = 1;
            int innerSize = 1;

            for (int i = 0; i < tensor.Rank; i++)
            {
                if (normalizedAxes.Contains(i))
                {
                    reduceSize *= tensor.Shape[i];
                }
                else if (i < normalizedAxes[0])
                {
                    outerSize *= tensor.Shape[i];
                }
                else
                {
                    innerSize *= tensor.Shape[i];
                }
            }

            int outputSize = outerSize * innerSize;

            // Calculate output shape
            var outputShapeList = new List<int>();
            for (int i = 0; i < tensor.Rank; i++)
            {
                if (normalizedAxes.Contains(i))
                {
                    if (keepDims) outputShapeList.Add(1);
                }
                else
                {
                    outputShapeList.Add(tensor.Shape[i]);
                }
            }
            var outputShape = outputShapeList.Count > 0 ? outputShapeList.ToArray() : new[] { 1 };

            // Need to transpose tensor so reduced axes are contiguous
            // For simplicity, if axes are already contiguous and in the middle, use direct kernel
            // Otherwise, fall back to CPU (complex transpose patterns)
            bool axesContiguous = true;
            for (int i = 1; i < normalizedAxes.Length; i++)
            {
                if (normalizedAxes[i] != normalizedAxes[i - 1] + 1)
                {
                    axesContiguous = false;
                    break;
                }
            }

            if (!axesContiguous || normalizedAxes.Length > 1 && normalizedAxes[0] != 0 && normalizedAxes[normalizedAxes.Length - 1] != tensor.Rank - 1)
            {
                // Complex reduction pattern - transpose needed, use CPU
                return _cpuFallback.ReduceSum(tensor, axes, keepDims);
            }

            var result = new Tensor<float>(outputShape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_reduceSumAxisKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuInput.View, gpuOutput.View, outerSize, reduceSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.ReduceSum(tensor, axes, keepDims);
        }
    }

    private Tensor<double> ReduceSumGpuDouble(Tensor<double> tensor, int[] axes, bool keepDims)
    {
        try
        {
            var normalizedAxes = axes.Select(a => a < 0 ? a + tensor.Rank : a).OrderBy(a => a).ToArray();

            // Validate axes are within bounds
            if (normalizedAxes.Any(a => a < 0 || a >= tensor.Rank))
            {
                return _cpuFallback.ReduceSum(tensor, axes, keepDims);
            }

            int outerSize = 1;
            int reduceSize = 1;
            int innerSize = 1;

            for (int i = 0; i < tensor.Rank; i++)
            {
                if (normalizedAxes.Contains(i))
                {
                    reduceSize *= tensor.Shape[i];
                }
                else if (i < normalizedAxes[0])
                {
                    outerSize *= tensor.Shape[i];
                }
                else
                {
                    innerSize *= tensor.Shape[i];
                }
            }

            int outputSize = outerSize * innerSize;

            var outputShapeList = new List<int>();
            for (int i = 0; i < tensor.Rank; i++)
            {
                if (normalizedAxes.Contains(i))
                {
                    if (keepDims) outputShapeList.Add(1);
                }
                else
                {
                    outputShapeList.Add(tensor.Shape[i]);
                }
            }
            var outputShape = outputShapeList.Count > 0 ? outputShapeList.ToArray() : new[] { 1 };

            bool axesContiguous = true;
            for (int i = 1; i < normalizedAxes.Length; i++)
            {
                if (normalizedAxes[i] != normalizedAxes[i - 1] + 1)
                {
                    axesContiguous = false;
                    break;
                }
            }

            if (!axesContiguous || normalizedAxes.Length > 1 && normalizedAxes[0] != 0 && normalizedAxes[normalizedAxes.Length - 1] != tensor.Rank - 1)
            {
                return _cpuFallback.ReduceSum(tensor, axes, keepDims);
            }

            var result = new Tensor<double>(outputShape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_reduceSumAxisKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuInput.View, gpuOutput.View, outerSize, reduceSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.ReduceSum(tensor, axes, keepDims);
        }
    }

    /// <inheritdoc/>
    public T TensorMaxValue<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));
        if (tensor.Length == 0) throw new ArgumentException("Cannot compute max of empty tensor.", nameof(tensor));

        // Use adaptive threshold - GPU reduction benefits from large tensors
        if (tensor.Length < _thresholds.VectorAdd * 4)
        {
            return _cpuFallback.TensorMaxValue(tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (T)(object)TensorMaxValueGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (T)(object)TensorMaxValueGpuDouble((Tensor<double>)(object)tensor);
        }

        return _cpuFallback.TensorMaxValue(tensor);
    }

    private float TensorMaxValueGpu(Tensor<float> tensor)
    {
        try
        {
            int length = tensor.Length;
            int numBlocks = (length + ReductionBlockSize - 1) / ReductionBlockSize;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
            var gpuPartialMaxes = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_partialMaxKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numBlocks, gpuInput.View, gpuPartialMaxes.View, length);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var partialMaxes = new float[numBlocks];
                gpuPartialMaxes.View.BaseView.CopyToCPU(partialMaxes);

                float maxVal = partialMaxes[0];
                for (int i = 1; i < numBlocks; i++)
                {
                    if (partialMaxes[i] > maxVal)
                        maxVal = partialMaxes[i];
                }

                return maxVal;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuPartialMaxes);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorMaxValue(tensor);
        }
    }

    private double TensorMaxValueGpuDouble(Tensor<double> tensor)
    {
        try
        {
            int length = tensor.Length;
            int numBlocks = (length + ReductionBlockSize - 1) / ReductionBlockSize;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
            var gpuPartialMaxes = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_partialMaxKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numBlocks, gpuInput.View, gpuPartialMaxes.View, length);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var partialMaxes = new double[numBlocks];
                gpuPartialMaxes.View.BaseView.CopyToCPU(partialMaxes);

                double maxVal = partialMaxes[0];
                for (int i = 1; i < numBlocks; i++)
                {
                    if (partialMaxes[i] > maxVal)
                        maxVal = partialMaxes[i];
                }

                return maxVal;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuPartialMaxes);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorMaxValue(tensor);
        }
    }

    /// <inheritdoc/>
    public T TensorMinValue<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));
        if (tensor.Length == 0) throw new ArgumentException("Cannot compute min of empty tensor.", nameof(tensor));

        if (tensor.Length < _thresholds.VectorAdd * 4)
        {
            return _cpuFallback.TensorMinValue(tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (T)(object)TensorMinValueGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (T)(object)TensorMinValueGpuDouble((Tensor<double>)(object)tensor);
        }

        return _cpuFallback.TensorMinValue(tensor);
    }

    private float TensorMinValueGpu(Tensor<float> tensor)
    {
        try
        {
            int length = tensor.Length;
            int numBlocks = (length + ReductionBlockSize - 1) / ReductionBlockSize;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
            var gpuPartialMins = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_partialMinKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numBlocks, gpuInput.View, gpuPartialMins.View, length);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var partialMins = new float[numBlocks];
                gpuPartialMins.View.BaseView.CopyToCPU(partialMins);

                float minVal = partialMins[0];
                for (int i = 1; i < numBlocks; i++)
                {
                    if (partialMins[i] < minVal)
                        minVal = partialMins[i];
                }

                return minVal;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuPartialMins);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorMinValue(tensor);
        }
    }

    private double TensorMinValueGpuDouble(Tensor<double> tensor)
    {
        try
        {
            int length = tensor.Length;
            int numBlocks = (length + ReductionBlockSize - 1) / ReductionBlockSize;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
            var gpuPartialMins = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_partialMinKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numBlocks, gpuInput.View, gpuPartialMins.View, length);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var partialMins = new double[numBlocks];
                gpuPartialMins.View.BaseView.CopyToCPU(partialMins);

                double minVal = partialMins[0];
                for (int i = 1; i < numBlocks; i++)
                {
                    if (partialMins[i] < minVal)
                        minVal = partialMins[i];
                }

                return minVal;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuPartialMins);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorMinValue(tensor);
        }
    }

    /// <inheritdoc/>
    public T TensorMean<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));
        if (tensor.Length == 0) throw new ArgumentException("Cannot compute mean of empty tensor.", nameof(tensor));

        // Mean is sum / count - use TensorSum which has GPU acceleration
        var numOps = MathHelper.GetNumericOperations<T>();
        T sum = TensorSum(tensor);
        return numOps.Divide(sum, numOps.FromDouble(tensor.Length));
    }

    #endregion

    /// <summary>
    /// Helper method to validate that two tensors have matching shapes.
    /// </summary>
    private void ValidateTensorShapes<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));

        if (a.Shape.Length != b.Shape.Length)
        {
            throw new ArgumentException(
                $"Tensor ranks must match. Got {a.Rank} and {b.Rank}.");
        }

        for (int i = 0; i < a.Shape.Length; i++)
        {
            if (a.Shape[i] != b.Shape[i])
            {
                throw new ArgumentException(
                    $"Tensor shapes must match. Got [{string.Join(", ", a.Shape)}] and [{string.Join(", ", b.Shape)}].");
            }
        }
    }

    /// <inheritdoc/>
    public Tensor<T> MaxPool2D<T>(Tensor<T> input, int poolSize, int stride = 0, int padding = 0)
    {
        // Adaptive execution: use pooling threshold (Phase B: US-GPU-004)
        if (input.Length < _thresholds.Pooling)
        {
            return _cpuFallback.MaxPool2D(input, poolSize, stride, padding);
        }

        // Check GPU health and type support (Phase B: US-GPU-006)
        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)MaxPool2DGpu((Tensor<float>)(object)input, poolSize, stride, padding);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)MaxPool2DGpuDouble((Tensor<double>)(object)input, poolSize, stride, padding);
        }

        return _cpuFallback.MaxPool2D(input, poolSize, stride, padding);
    }

    private Tensor<float> MaxPool2DGpu(Tensor<float> input, int poolSize, int stride, int padding)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (input.Rank != 4)
        {
            throw new ArgumentException($"MaxPool2D requires a 4D tensor. Got rank {input.Rank}.");
        }

        if (stride == 0) stride = poolSize;

        int batch = input.Shape[0];
        int channels = input.Shape[1];
        int height = input.Shape[2];
        int width = input.Shape[3];

        int outputHeight = (height + 2 * padding - poolSize) / stride + 1;
        int outputWidth = (width + 2 * padding - poolSize) / stride + 1;

        try
        {
            var result = new Tensor<float>(new[] { batch, channels, outputHeight, outputWidth });
            int outputSize = batch * channels * outputHeight * outputWidth;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_maxPool2DKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, outputSize, gpuInput.View, gpuOutput.View,
                        batch, channels, height, width, outputHeight, outputWidth, poolSize, stride, padding);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU max pool 2D failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MaxPool2D(input, poolSize, stride, padding);
        }
    }

    private Tensor<double> MaxPool2DGpuDouble(Tensor<double> input, int poolSize, int stride, int padding)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (input.Rank != 4)
        {
            throw new ArgumentException($"MaxPool2D requires a 4D tensor. Got rank {input.Rank}.");
        }

        if (stride == 0) stride = poolSize;

        int batch = input.Shape[0];
        int channels = input.Shape[1];
        int height = input.Shape[2];
        int width = input.Shape[3];

        int outputHeight = (height + 2 * padding - poolSize) / stride + 1;
        int outputWidth = (width + 2 * padding - poolSize) / stride + 1;

        try
        {
            var result = new Tensor<double>(new[] { batch, channels, outputHeight, outputWidth });
            int outputSize = batch * channels * outputHeight * outputWidth;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_maxPool2DKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, outputSize, gpuInput.View, gpuOutput.View,
                        batch, channels, height, width, outputHeight, outputWidth, poolSize, stride, padding);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU max pool 2D (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MaxPool2D(input, poolSize, stride, padding);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> AvgPool2D<T>(Tensor<T> input, int poolSize, int stride = 0, int padding = 0)
    {
        if (input.Length < _thresholds.Pooling)
        {
            return _cpuFallback.AvgPool2D(input, poolSize, stride, padding);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)AvgPool2DGpu((Tensor<float>)(object)input, poolSize, stride, padding);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)AvgPool2DGpuDouble((Tensor<double>)(object)input, poolSize, stride, padding);
        }

        return _cpuFallback.AvgPool2D(input, poolSize, stride, padding);
    }

    private Tensor<float> AvgPool2DGpu(Tensor<float> input, int poolSize, int stride, int padding)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (input.Rank != 4)
        {
            throw new ArgumentException($"AvgPool2D requires a 4D tensor. Got rank {input.Rank}.");
        }

        if (stride == 0) stride = poolSize;

        int batch = input.Shape[0];
        int channels = input.Shape[1];
        int height = input.Shape[2];
        int width = input.Shape[3];

        int outputHeight = (height + 2 * padding - poolSize) / stride + 1;
        int outputWidth = (width + 2 * padding - poolSize) / stride + 1;

        try
        {
            var result = new Tensor<float>(new[] { batch, channels, outputHeight, outputWidth });
            int outputSize = batch * channels * outputHeight * outputWidth;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_avgPool2DKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, outputSize, gpuInput.View, gpuOutput.View,
                        batch, channels, height, width, outputHeight, outputWidth, poolSize, stride, padding);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU avg pool 2D failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.AvgPool2D(input, poolSize, stride, padding);
        }
    }

    private Tensor<double> AvgPool2DGpuDouble(Tensor<double> input, int poolSize, int stride, int padding)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (input.Rank != 4)
        {
            throw new ArgumentException($"AvgPool2D requires a 4D tensor. Got rank {input.Rank}.");
        }

        if (stride == 0) stride = poolSize;

        int batch = input.Shape[0];
        int channels = input.Shape[1];
        int height = input.Shape[2];
        int width = input.Shape[3];

        int outputHeight = (height + 2 * padding - poolSize) / stride + 1;
        int outputWidth = (width + 2 * padding - poolSize) / stride + 1;

        try
        {
            var result = new Tensor<double>(new[] { batch, channels, outputHeight, outputWidth });
            int outputSize = batch * channels * outputHeight * outputWidth;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    (_avgPool2DKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))((_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream, outputSize, gpuInput.View, gpuOutput.View,
                        batch, channels, height, width, outputHeight, outputWidth, poolSize, stride, padding);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU avg pool 2D (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.AvgPool2D(input, poolSize, stride, padding);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> Conv2D<T>(Tensor<T> input, Tensor<T> kernel, int stride = 1, int padding = 0, int dilation = 1)
    {
        // Adaptive execution: use convolution threshold (Phase B: US-GPU-004)
        if (input.Length < _thresholds.Convolution)
        {
            return _cpuFallback.Conv2D(input, kernel, stride, padding, dilation);
        }

        // Check GPU health and type support (Phase B: US-GPU-006)
        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)Conv2DGpu((Tensor<float>)(object)input, (Tensor<float>)(object)kernel, stride, padding, dilation);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)Conv2DGpuDouble((Tensor<double>)(object)input, (Tensor<double>)(object)kernel, stride, padding, dilation);
        }

        return _cpuFallback.Conv2D(input, kernel, stride, padding, dilation);
    }

    private Tensor<float> Conv2DGpu(Tensor<float> input, Tensor<float> kernel, int stride, int padding, int dilation)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (kernel == null) throw new ArgumentNullException(nameof(kernel));
        if (input.Rank != 4 || kernel.Rank != 4)
        {
            throw new ArgumentException($"Conv2D requires 4D tensors. Got input rank {input.Rank}, kernel rank {kernel.Rank}.");
        }

        int batch = input.Shape[0];
        int inChannels = input.Shape[1];
        int height = input.Shape[2];
        int width = input.Shape[3];

        int outChannels = kernel.Shape[0];
        int kernelHeight = kernel.Shape[2];
        int kernelWidth = kernel.Shape[3];

        int effectiveKernelHeight = dilation * (kernelHeight - 1) + 1;
        int effectiveKernelWidth = dilation * (kernelWidth - 1) + 1;

        int outputHeight = (height + 2 * padding - effectiveKernelHeight) / stride + 1;
        int outputWidth = (width + 2 * padding - effectiveKernelWidth) / stride + 1;

        try
        {
            var result = new Tensor<float>(new[] { batch, outChannels, outputHeight, outputWidth });
            int outputSize = batch * outChannels * outputHeight * outputWidth;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuKernel = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernel.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuKernel.View.BaseView.CopyFromCPU(kernel.AsSpan());

                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    var parameters = new Conv2DParams(batch, inChannels, height, width, outChannels,
                        outputHeight, outputWidth, kernelHeight, kernelWidth, stride, padding, dilation);
                    (_conv2DKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuInput.View, gpuKernel.View, gpuOutput.View, parameters);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuKernel);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Conv2D failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Conv2D(input, kernel, stride, padding, dilation);
        }
    }

    private Tensor<double> Conv2DGpuDouble(Tensor<double> input, Tensor<double> kernel, int stride, int padding, int dilation)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (kernel == null) throw new ArgumentNullException(nameof(kernel));
        if (input.Rank != 4 || kernel.Rank != 4)
        {
            throw new ArgumentException($"Conv2D requires 4D tensors. Got input rank {input.Rank}, kernel rank {kernel.Rank}.");
        }

        int batch = input.Shape[0];
        int inChannels = input.Shape[1];
        int height = input.Shape[2];
        int width = input.Shape[3];

        int outChannels = kernel.Shape[0];
        int kernelHeight = kernel.Shape[2];
        int kernelWidth = kernel.Shape[3];

        int effectiveKernelHeight = dilation * (kernelHeight - 1) + 1;
        int effectiveKernelWidth = dilation * (kernelWidth - 1) + 1;

        int outputHeight = (height + 2 * padding - effectiveKernelHeight) / stride + 1;
        int outputWidth = (width + 2 * padding - effectiveKernelWidth) / stride + 1;

        try
        {
            var result = new Tensor<double>(new[] { batch, outChannels, outputHeight, outputWidth });
            int outputSize = batch * outChannels * outputHeight * outputWidth;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuKernel = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernel.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuKernel.View.BaseView.CopyFromCPU(kernel.AsSpan());

                // Thread-safe kernel execution (Phase B: US-GPU-019)
                lock (_gpuLock)
                {
                    var parameters = new Conv2DParams(batch, inChannels, height, width, outChannels,
                        outputHeight, outputWidth, kernelHeight, kernelWidth, stride, padding, dilation);
                    (_conv2DKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuInput.View, gpuKernel.View, gpuOutput.View, parameters);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuKernel);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Conv2D (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Conv2D(input, kernel, stride, padding, dilation);
        }
    }

    #endregion

    /// <summary>
    /// Disposes GPU resources.
    /// </summary>

    #region GPU Health Monitoring and Recovery (Phase B: US-GPU-020)

    /// <summary>
    /// Records a GPU failure and determines if recovery should be attempted.
    /// </summary>
    /// <param name="exception">The exception that caused the failure.</param>
    /// <returns>True if the GPU is now marked unhealthy.</returns>
    private bool RecordGpuFailure(Exception exception)
    {
        lock (_recoveryLock)
        {
            if (_gpuPermanentlyDisabled)
                return true;

            _consecutiveFailures++;
            _gpuHealthy = false;
            Interlocked.Exchange(ref _lastFailureTimeTicks, DateTime.UtcNow.Ticks);

            Console.WriteLine($"[GpuEngine] GPU failure #{_consecutiveFailures}: {exception.Message}");

            // If we've exceeded maximum recovery attempts, permanently disable GPU
            if (_consecutiveFailures >= MaxRecoveryAttempts)
            {
                _gpuPermanentlyDisabled = true;
                Console.WriteLine($"[GpuEngine] GPU permanently disabled after {_consecutiveFailures} failures.");
                return true;
            }

            // Temporarily mark unhealthy but allow recovery attempts
            Console.WriteLine($"[GpuEngine] GPU temporarily disabled. Recovery attempt {_consecutiveFailures}/{MaxRecoveryAttempts} will be tried after backoff period.");
            return true;
        }
    }

    /// <summary>
    /// Attempts to recover GPU health after a failure.
    /// </summary>
    /// <returns>True if GPU recovery succeeded.</returns>
    private bool AttemptGpuRecovery()
    {
        lock (_recoveryLock)
        {
            // If GPU is permanently disabled, don't attempt recovery
            if (_gpuPermanentlyDisabled)
                return false;

            if (_gpuHealthy)
                return true;

            // Check if we're in backoff period
            var lastFailureTicks = Interlocked.Read(ref _lastFailureTimeTicks);
            var timeSinceFailure = DateTime.UtcNow - new DateTime(lastFailureTicks);
            if (timeSinceFailure < RecoveryBackoffPeriod)
            {
                // Still in backoff period - don't attempt recovery yet
                return false;
            }

            // Check if accelerator is still responsive
            if (_accelerator == null)
            {
                Console.WriteLine("[GpuEngine] GPU accelerator is null - cannot recover.");
                _gpuHealthy = false;
                return false;
            }

            try
            {
                // Test if GPU is responsive with a simple operation
                lock (_gpuLock)
                {
                    // Try to synchronize - if this works, GPU is healthy again
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Recovery successful!
                _consecutiveFailures = 0;
                Interlocked.Exchange(ref _lastFailureTimeTicks, DateTime.MinValue.Ticks);
                Console.WriteLine("[GpuEngine] GPU recovery successful! GPU operations re-enabled.");
                return true;
            }
            catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
            {
                Console.WriteLine($"[GpuEngine] GPU recovery failed: {ex.Message}");
                RecordGpuFailure(ex);
                return false;
            }
        }
    }

    /// <summary>
    /// Gets diagnostic information about GPU health status.
    /// </summary>
    /// <returns>A string containing GPU health diagnostics.</returns>
    public string GetGpuHealthDiagnostics()
    {
        var diagnostics = new System.Text.StringBuilder();
        diagnostics.AppendLine("GPU Health Diagnostics:");
        diagnostics.AppendLine($"  SupportsGpu: {SupportsGpu}");
        diagnostics.AppendLine($"  Healthy: {_gpuHealthy}");
        diagnostics.AppendLine($"  Permanently Disabled: {_gpuPermanentlyDisabled}");
        diagnostics.AppendLine($"  Consecutive Failures: {_consecutiveFailures}/{MaxRecoveryAttempts}");

        var lastFailureTicks = Interlocked.Read(ref _lastFailureTimeTicks);
        DateTime? lastFailureTimeUtc = null;
        if (lastFailureTicks != DateTime.MinValue.Ticks)
        {
            lastFailureTimeUtc = new DateTime(lastFailureTicks, DateTimeKind.Utc);
            diagnostics.AppendLine($"  Last Failure: {lastFailureTimeUtc:yyyy-MM-dd HH:mm:ss} UTC");
        }
        else
        {
            diagnostics.AppendLine("  Last Failure: Never");
        }

        if (lastFailureTimeUtc.HasValue)
        {
            var timeSinceFailure = DateTime.UtcNow - lastFailureTimeUtc.Value;
            diagnostics.AppendLine($"  Time Since Failure: {timeSinceFailure.TotalSeconds:F1}s");

            if (_gpuPermanentlyDisabled)
            {
                diagnostics.AppendLine("  Recovery Available: No (permanently disabled)");
            }
            else if (timeSinceFailure < RecoveryBackoffPeriod)
            {
                var timeUntilRecovery = RecoveryBackoffPeriod - timeSinceFailure;
                diagnostics.AppendLine($"  Recovery Available In: {timeUntilRecovery.TotalSeconds:F1}s");
            }
            else
            {
                diagnostics.AppendLine("  Recovery Available: Yes");
            }
        }

        if (_accelerator == null)
        {
            diagnostics.AppendLine("  Accelerator: Not Available (no accelerator initialized)");
            diagnostics.AppendLine("  Memory: N/A");
            return diagnostics.ToString();
        }

        diagnostics.AppendLine($"  Accelerator: {_accelerator.Name}");
        diagnostics.AppendLine($"  Memory: {_accelerator.MemorySize / (1024.0 * 1024.0 * 1024.0):F2} GB");

        return diagnostics.ToString();
    }

    /// <summary>
    /// Manually triggers a GPU health check and recovery attempt if needed.
    /// </summary>
    /// <returns>True if GPU is healthy after the check.</returns>
    public bool CheckAndRecoverGpuHealth()
    {
        if (_gpuHealthy)
            return true;

        // Attempt recovery
        return AttemptGpuRecovery();
    }

    #endregion

    #region Trigonometric Span Overloads

    /// <inheritdoc/>
    public void Sin(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinOperatorFloat>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            SinGpuFloat(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinOperatorFloat>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Sin(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinOperatorDouble>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            SinGpuDouble(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinOperatorDouble>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Cos(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<CosOperatorFloat>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            CosGpuFloat(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<CosOperatorFloat>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Cos(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<CosOperatorDouble>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            CosGpuDouble(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<CosOperatorDouble>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Tan(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanOperatorFloat>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            TanGpuFloat(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanOperatorFloat>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Tan(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanOperatorDouble>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            TanGpuDouble(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanOperatorDouble>(x, destination);
        }
    }

    /// <inheritdoc/>
    public Vector<T> Asin<T>(Vector<T> vector)
    {
        if (vector.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.Asin(vector);
        }

        if (typeof(T) == typeof(float))
        {
            var floatVec = (Vector<float>)(object)vector;
            var result = new Vector<float>(floatVec.Length);
            AsinGpuFloat(floatVec.AsSpan(), result.AsWritableSpan());
            return (Vector<T>)(object)result;
        }
        if (typeof(T) == typeof(double))
        {
            var doubleVec = (Vector<double>)(object)vector;
            var result = new Vector<double>(doubleVec.Length);
            AsinGpuDouble(doubleVec.AsSpan(), result.AsWritableSpan());
            return (Vector<T>)(object)result;
        }

        return _cpuFallback.Asin(vector);
    }

    /// <inheritdoc/>
    public void Asin(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AsinOperatorFloat>(x, destination);
            return;
        }
        AsinGpuFloat(x, destination);
    }

    private void AsinGpuFloat(ReadOnlySpan<float> x, Span<float> destination)
    {
        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);
        var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(x);

            lock (_gpuLock)
            {
                (_asinKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    x.Length, gpuInput.View, gpuOutput.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Asin (float) failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AsinOperatorFloat>(x, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public void Asin(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AsinOperatorDouble>(x, destination);
            return;
        }
        AsinGpuDouble(x, destination);
    }

    private void AsinGpuDouble(ReadOnlySpan<double> x, Span<double> destination)
    {
        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);
        var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(x);

            lock (_gpuLock)
            {
                (_asinKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    x.Length, gpuInput.View, gpuOutput.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Asin (double) failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AsinOperatorDouble>(x, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public Vector<T> Acos<T>(Vector<T> vector)
    {
        if (vector.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.Acos(vector);
        }

        if (typeof(T) == typeof(float))
        {
            var floatVec = (Vector<float>)(object)vector;
            var result = new Vector<float>(floatVec.Length);
            AcosGpuFloat(floatVec.AsSpan(), result.AsWritableSpan());
            return (Vector<T>)(object)result;
        }
        if (typeof(T) == typeof(double))
        {
            var doubleVec = (Vector<double>)(object)vector;
            var result = new Vector<double>(doubleVec.Length);
            AcosGpuDouble(doubleVec.AsSpan(), result.AsWritableSpan());
            return (Vector<T>)(object)result;
        }

        return _cpuFallback.Acos(vector);
    }

    /// <inheritdoc/>
    public void Acos(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AcosOperatorFloat>(x, destination);
            return;
        }
        AcosGpuFloat(x, destination);
    }

    private void AcosGpuFloat(ReadOnlySpan<float> x, Span<float> destination)
    {
        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);
        var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(x);

            lock (_gpuLock)
            {
                (_acosKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    x.Length, gpuInput.View, gpuOutput.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Acos (float) failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AcosOperatorFloat>(x, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public void Acos(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AcosOperatorDouble>(x, destination);
            return;
        }
        AcosGpuDouble(x, destination);
    }

    private void AcosGpuDouble(ReadOnlySpan<double> x, Span<double> destination)
    {
        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);
        var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(x);

            lock (_gpuLock)
            {
                (_acosKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    x.Length, gpuInput.View, gpuOutput.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Acos (double) failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AcosOperatorDouble>(x, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public Vector<T> Atan<T>(Vector<T> vector)
    {
        if (vector.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.Atan(vector);
        }

        if (typeof(T) == typeof(float))
        {
            var floatVec = (Vector<float>)(object)vector;
            var result = new Vector<float>(floatVec.Length);
            AtanGpuFloat(floatVec.AsSpan(), result.AsWritableSpan());
            return (Vector<T>)(object)result;
        }
        if (typeof(T) == typeof(double))
        {
            var doubleVec = (Vector<double>)(object)vector;
            var result = new Vector<double>(doubleVec.Length);
            AtanGpuDouble(doubleVec.AsSpan(), result.AsWritableSpan());
            return (Vector<T>)(object)result;
        }

        return _cpuFallback.Atan(vector);
    }

    /// <inheritdoc/>
    public void Atan(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AtanOperatorFloat>(x, destination);
            return;
        }
        AtanGpuFloat(x, destination);
    }

    private void AtanGpuFloat(ReadOnlySpan<float> x, Span<float> destination)
    {
        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);
        var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(x);

            lock (_gpuLock)
            {
                (_atanKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    x.Length, gpuInput.View, gpuOutput.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Atan (float) failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AtanOperatorFloat>(x, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public void Atan(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AtanOperatorDouble>(x, destination);
            return;
        }
        AtanGpuDouble(x, destination);
    }

    private void AtanGpuDouble(ReadOnlySpan<double> x, Span<double> destination)
    {
        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);
        var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(x);

            lock (_gpuLock)
            {
                (_atanKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    x.Length, gpuInput.View, gpuOutput.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Atan (double) failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AtanOperatorDouble>(x, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public void Sqrt(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<SqrtOperatorFloat>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            SqrtGpuFloat(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<SqrtOperatorFloat>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Sqrt(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<SqrtOperatorDouble>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            SqrtGpuDouble(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<SqrtOperatorDouble>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Abs(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AbsOperatorFloat>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            AbsGpuFloat(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AbsOperatorFloat>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Abs(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AbsOperatorDouble>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            AbsGpuDouble(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AbsOperatorDouble>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Sinh(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinhOperatorFloat>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            SinhGpuFloat(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinhOperatorFloat>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Sinh(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinhOperatorDouble>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            SinhGpuDouble(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<SinhOperatorDouble>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Cosh(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<CoshOperatorFloat>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            CoshGpuFloat(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<CoshOperatorFloat>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Cosh(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<CoshOperatorDouble>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            CoshGpuDouble(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<CoshOperatorDouble>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Tanh(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanhOperatorFloat>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            TanhGpuFloat(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanhOperatorFloat>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Tanh(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanhOperatorDouble>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            TanhGpuDouble(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<TanhOperatorDouble>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Asinh(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AsinhOperatorFloat>(x, destination);
            return;
        }
        AsinhGpuFloat(x, destination);
    }

    private void AsinhGpuFloat(ReadOnlySpan<float> x, Span<float> destination)
    {
        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);
        var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(x);

            lock (_gpuLock)
            {
                (_asinhKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    x.Length, gpuInput.View, gpuOutput.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Asinh (float) failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AsinhOperatorFloat>(x, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public void Asinh(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AsinhOperatorDouble>(x, destination);
            return;
        }
        AsinhGpuDouble(x, destination);
    }

    private void AsinhGpuDouble(ReadOnlySpan<double> x, Span<double> destination)
    {
        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);
        var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(x);

            lock (_gpuLock)
            {
                (_asinhKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    x.Length, gpuInput.View, gpuOutput.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Asinh (double) failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AsinhOperatorDouble>(x, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public void Acosh(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AcoshOperatorFloat>(x, destination);
            return;
        }
        AcoshGpuFloat(x, destination);
    }

    private void AcoshGpuFloat(ReadOnlySpan<float> x, Span<float> destination)
    {
        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);
        var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(x);

            lock (_gpuLock)
            {
                (_acoshKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    x.Length, gpuInput.View, gpuOutput.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Acosh (float) failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AcoshOperatorFloat>(x, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public void Acosh(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AcoshOperatorDouble>(x, destination);
            return;
        }
        AcoshGpuDouble(x, destination);
    }

    private void AcoshGpuDouble(ReadOnlySpan<double> x, Span<double> destination)
    {
        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);
        var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(x);

            lock (_gpuLock)
            {
                (_acoshKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    x.Length, gpuInput.View, gpuOutput.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Acosh (double) failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AcoshOperatorDouble>(x, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public void Atanh(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AtanhOperatorFloat>(x, destination);
            return;
        }
        AtanhGpuFloat(x, destination);
    }

    private void AtanhGpuFloat(ReadOnlySpan<float> x, Span<float> destination)
    {
        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);
        var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(x);

            lock (_gpuLock)
            {
                (_atanhKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    x.Length, gpuInput.View, gpuOutput.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Atanh (float) failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AtanhOperatorFloat>(x, destination);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public void Atanh(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt || !SupportsGpu || !_gpuHealthy)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<AtanhOperatorDouble>(x, destination);
            return;
        }
        AtanhGpuDouble(x, destination);
    }

    private void AtanhGpuDouble(ReadOnlySpan<double> x, Span<double> destination)
    {
        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);
        var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(x.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(x);

            lock (_gpuLock)
            {
                (_atanhKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    x.Length, gpuInput.View, gpuOutput.View);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(destination);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Atanh (double) failed: {ex.Message}. Falling back to CPU.");
            TensorPrimitivesCore.InvokeSpanIntoSpan<AtanhOperatorDouble>(x, destination);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public void Exp(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<ExpOperatorFloat>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            ExpGpuFloat(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<ExpOperatorFloat>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Exp(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<ExpOperatorDouble>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            ExpGpuDouble(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<ExpOperatorDouble>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Log(ReadOnlySpan<float> x, Span<float> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<LogOperatorFloat>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            LogGpuFloat(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<LogOperatorFloat>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void Log(ReadOnlySpan<double> x, Span<double> destination)
    {
        if (x.Length < _thresholds.VectorSqrt)
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<LogOperatorDouble>(x, destination);
            return;
        }

        if (SupportsGpu && _gpuHealthy)
        {
            LogGpuDouble(x, destination);
        }
        else
        {
            TensorPrimitivesCore.InvokeSpanIntoSpan<LogOperatorDouble>(x, destination);
        }
    }

    /// <inheritdoc/>
    public void ExpM1(ReadOnlySpan<float> x, Span<float> destination)
    {
        // For now, use CPU fallback. Future GPU implementation can use custom kernel.
        TensorPrimitivesCore.InvokeSpanIntoSpan<ExpM1OperatorFloat>(x, destination);
    }

    /// <inheritdoc/>
    public void ExpM1(ReadOnlySpan<double> x, Span<double> destination)
    {
        // For now, use CPU fallback. Future GPU implementation can use custom kernel.
        TensorPrimitivesCore.InvokeSpanIntoSpan<ExpM1OperatorDouble>(x, destination);
    }

    /// <inheritdoc/>
    public void Log1P(ReadOnlySpan<float> x, Span<float> destination)
    {
        // For now, use CPU fallback. Future GPU implementation can use custom kernel.
        TensorPrimitivesCore.InvokeSpanIntoSpan<Log1POperatorFloat>(x, destination);
    }

    /// <inheritdoc/>
    public void Log1P(ReadOnlySpan<double> x, Span<double> destination)
    {
        // For now, use CPU fallback. Future GPU implementation can use custom kernel.
        TensorPrimitivesCore.InvokeSpanIntoSpan<Log1POperatorDouble>(x, destination);
    }

    /// <inheritdoc/>
    public void Reciprocal(ReadOnlySpan<float> x, Span<float> destination)
    {
        TensorPrimitivesCore.InvokeSpanIntoSpan<ReciprocalOperatorFloat>(x, destination);
    }

    /// <inheritdoc/>
    public void Reciprocal(ReadOnlySpan<double> x, Span<double> destination)
    {
        TensorPrimitivesCore.InvokeSpanIntoSpan<ReciprocalOperatorDouble>(x, destination);
    }

    /// <inheritdoc/>
    public void Cbrt(ReadOnlySpan<float> x, Span<float> destination)
    {
        TensorPrimitivesCore.InvokeSpanIntoSpan<CbrtOperatorFloat>(x, destination);
    }

    /// <inheritdoc/>
    public void Cbrt(ReadOnlySpan<double> x, Span<double> destination)
    {
        TensorPrimitivesCore.InvokeSpanIntoSpan<CbrtOperatorDouble>(x, destination);
    }

    /// <inheritdoc/>
    public void Log2(ReadOnlySpan<float> x, Span<float> destination)
    {
        TensorPrimitivesCore.InvokeSpanIntoSpan<Log2OperatorFloat>(x, destination);
    }

    /// <inheritdoc/>
    public void Log2(ReadOnlySpan<double> x, Span<double> destination)
    {
        TensorPrimitivesCore.InvokeSpanIntoSpan<Log2OperatorDouble>(x, destination);
    }

    /// <inheritdoc/>
    public void Log10(ReadOnlySpan<float> x, Span<float> destination)
    {
        TensorPrimitivesCore.InvokeSpanIntoSpan<Log10OperatorFloat>(x, destination);
    }

    /// <inheritdoc/>
    public void Log10(ReadOnlySpan<double> x, Span<double> destination)
    {
        TensorPrimitivesCore.InvokeSpanIntoSpan<Log10OperatorDouble>(x, destination);
    }

    #endregion

    #region Extended Tensor Operations

    /// <inheritdoc/>
    public Tensor<T> TensorTranspose<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));
        if (tensor.Rank != 2)
            throw new ArgumentException($"TensorTranspose requires a 2D tensor. Got rank {tensor.Rank}.");

        // GPU transpose for supported types and large enough tensors
        // Use lower threshold than MatMul since transpose is simpler but benefits from GPU parallelism
        if (tensor.Length >= _thresholds.MatrixMultiply / 2 && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorTransposeGpuFloat((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorTransposeGpuDouble((Tensor<double>)(object)tensor);
        }
        return _cpuFallback.TensorTranspose(tensor);
    }

    private Tensor<float> TensorTransposeGpuFloat(Tensor<float> tensor)
    {
        int rows = tensor.Shape[0];
        int cols = tensor.Shape[1];

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
        var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(tensor.ToArray());

            lock (_gpuLock)
            {
                (_tensorTransposeKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    new Index2D(rows, cols), gpuInput.View.BaseView, gpuOutput.View.BaseView, rows, cols);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            var resultData = new float[tensor.Length];
            gpuOutput.View.BaseView.CopyToCPU(resultData);
            return new Tensor<float>([cols, rows], new Vector<float>(resultData));
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.TensorTranspose(tensor);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuOutput);
        }
    }

    private Tensor<double> TensorTransposeGpuDouble(Tensor<double> tensor)
    {
        int rows = tensor.Shape[0];
        int cols = tensor.Shape[1];

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
        var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(tensor.ToArray());

            lock (_gpuLock)
            {
                (_tensorTransposeKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    new Index2D(rows, cols), gpuInput.View.BaseView, gpuOutput.View.BaseView, rows, cols);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            var resultData = new double[tensor.Length];
            gpuOutput.View.BaseView.CopyToCPU(resultData);
            return new Tensor<double>([cols, rows], new Vector<double>(resultData));
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.TensorTranspose(tensor);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorMatMul<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));
        if (a.Rank != 2 || b.Rank != 2)
            throw new ArgumentException($"TensorMatMul requires 2D tensors. Got ranks {a.Rank} and {b.Rank}.");

        int m = a.Shape[0];
        int n = a.Shape[1];
        int p = b.Shape[1];

        if (n != b.Shape[0])
            throw new ArgumentException($"Matrix dimensions incompatible: [{m},{n}] x [{b.Shape[0]},{p}]");

        // GPU matrix multiplication for supported types and large enough operations
        int totalOps = m * n * p;
        if (totalOps >= _thresholds.MatrixMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorMatMulGpuFloat((Tensor<float>)(object)a, (Tensor<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorMatMulGpuDouble((Tensor<double>)(object)a, (Tensor<double>)(object)b);
        }
        return _cpuFallback.TensorMatMul(a, b);
    }

    private Tensor<float> TensorMatMulGpuFloat(Tensor<float> a, Tensor<float> b)
    {
        int m = a.Shape[0];
        int k = a.Shape[1];
        int n = b.Shape[1];

        var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(m * k);
        var gpuB = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(k * n);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(m * n);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.ToArray());
            gpuB.View.BaseView.CopyFromCPU(b.ToArray());

            // Create 2D views for GEMM
            var viewA = gpuA.View.As2DView<Stride2D.DenseY>(new Index2D(m, k), new Stride2D.DenseY(k));
            var viewB = gpuB.View.As2DView<Stride2D.DenseY>(new Index2D(k, n), new Stride2D.DenseY(n));
            var viewResult = gpuResult.View.As2DView<Stride2D.DenseY>(new Index2D(m, n), new Stride2D.DenseY(n));

            lock (_gpuLock)
            {
                // Use existing matrix multiply kernel (already optimized)
                (_matrixMultiplyKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    new Index2D(m, n), viewA, viewB, viewResult, k);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            var resultData = new float[m * n];
            gpuResult.View.BaseView.CopyToCPU(resultData);
            return new Tensor<float>([m, n], new Vector<float>(resultData));
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.TensorMatMul(a, b);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuA);
            _memoryPoolFloat.Return(gpuB);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    private Tensor<double> TensorMatMulGpuDouble(Tensor<double> a, Tensor<double> b)
    {
        int m = a.Shape[0];
        int k = a.Shape[1];
        int n = b.Shape[1];

        var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(m * k);
        var gpuB = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(k * n);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(m * n);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.ToArray());
            gpuB.View.BaseView.CopyFromCPU(b.ToArray());

            var viewA = gpuA.View.As2DView<Stride2D.DenseY>(new Index2D(m, k), new Stride2D.DenseY(k));
            var viewB = gpuB.View.As2DView<Stride2D.DenseY>(new Index2D(k, n), new Stride2D.DenseY(n));
            var viewResult = gpuResult.View.As2DView<Stride2D.DenseY>(new Index2D(m, n), new Stride2D.DenseY(n));

            lock (_gpuLock)
            {
                (_matrixMultiplyKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    new Index2D(m, n), viewA, viewB, viewResult, k);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            var resultData = new double[m * n];
            gpuResult.View.BaseView.CopyToCPU(resultData);
            return new Tensor<double>([m, n], new Vector<double>(resultData));
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.TensorMatMul(a, b);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuA);
            _memoryPoolDouble.Return(gpuB);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    internal Tensor<float> TensorMatMulCachedWeights(Tensor<float> a, Tensor<float> b, GpuTensor<float> gpuWeights)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));
        if (gpuWeights == null) throw new ArgumentNullException(nameof(gpuWeights));
        if (a.Rank != 2 || b.Rank != 2)
            throw new ArgumentException($"TensorMatMul requires 2D tensors. Got ranks {a.Rank} and {b.Rank}.");

        int m = a.Shape[0];
        int k = a.Shape[1];
        int n = b.Shape[1];

        if (k != b.Shape[0])
            throw new ArgumentException($"Matrix dimensions incompatible: [{m},{k}] x [{b.Shape[0]},{n}]");

        if (!SupportsGpu || !_gpuHealthy || gpuWeights.IsDisposed || gpuWeights.Length != b.Length)
            return _cpuFallback.TensorMatMul(a, b);

        int totalOps = m * k * n;
        if (totalOps < _thresholds.MatrixMultiply)
            return _cpuFallback.TensorMatMul(a, b);

        var gpuA = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(m * k);
        var gpuResult = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(m * n);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());

            var viewA = gpuA.View.As2DView<Stride2D.DenseY>(new Index2D(m, k), new Stride2D.DenseY(k));
            var viewB = gpuWeights.View.As2DView<Stride2D.DenseY>(new Index2D(k, n), new Stride2D.DenseY(n));
            var viewResult = gpuResult.View.As2DView<Stride2D.DenseY>(new Index2D(m, n), new Stride2D.DenseY(n));

            lock (_gpuLock)
            {
                (_matrixMultiplyKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    new Index2D(m, n), viewA, viewB, viewResult, k);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            var result = new Tensor<float>([m, n]);
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.TensorMatMul(a, b);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuA);
            _memoryPoolFloat.Return(gpuResult);
        }
    }

    internal Tensor<double> TensorMatMulCachedWeights(Tensor<double> a, Tensor<double> b, GpuTensor<double> gpuWeights)
    {
        if (a == null) throw new ArgumentNullException(nameof(a));
        if (b == null) throw new ArgumentNullException(nameof(b));
        if (gpuWeights == null) throw new ArgumentNullException(nameof(gpuWeights));
        if (a.Rank != 2 || b.Rank != 2)
            throw new ArgumentException($"TensorMatMul requires 2D tensors. Got ranks {a.Rank} and {b.Rank}.");

        int m = a.Shape[0];
        int k = a.Shape[1];
        int n = b.Shape[1];

        if (k != b.Shape[0])
            throw new ArgumentException($"Matrix dimensions incompatible: [{m},{k}] x [{b.Shape[0]},{n}]");

        if (!SupportsGpu || !_gpuHealthy || gpuWeights.IsDisposed || gpuWeights.Length != b.Length)
            return _cpuFallback.TensorMatMul(a, b);

        int totalOps = m * k * n;
        if (totalOps < _thresholds.MatrixMultiply)
            return _cpuFallback.TensorMatMul(a, b);

        var gpuA = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(m * k);
        var gpuResult = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(m * n);

        try
        {
            gpuA.View.BaseView.CopyFromCPU(a.AsSpan());

            var viewA = gpuA.View.As2DView<Stride2D.DenseY>(new Index2D(m, k), new Stride2D.DenseY(k));
            var viewB = gpuWeights.View.As2DView<Stride2D.DenseY>(new Index2D(k, n), new Stride2D.DenseY(n));
            var viewResult = gpuResult.View.As2DView<Stride2D.DenseY>(new Index2D(m, n), new Stride2D.DenseY(n));

            lock (_gpuLock)
            {
                (_matrixMultiplyKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    new Index2D(m, n), viewA, viewB, viewResult, k);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            var result = new Tensor<double>([m, n]);
            gpuResult.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.TensorMatMul(a, b);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuA);
            _memoryPoolDouble.Return(gpuResult);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> Conv2D<T>(Tensor<T> input, Tensor<T> kernel, int[] stride, int[] padding, int[] dilation)
    {
        // GPU Conv2D with asymmetric parameters
        // For now use CPU, can extend existing Conv2D GPU kernel
        return _cpuFallback.Conv2D(input, kernel, stride, padding, dilation);
    }

    /// <inheritdoc/>
    public Tensor<T> Conv2DBackwardInput<T>(Tensor<T> gradOutput, Tensor<T> kernel, int[] inputShape, int[] stride, int[] padding, int[] dilation)
    {
        if (gradOutput.Length < _thresholds.VectorAdd)
            return _cpuFallback.Conv2DBackwardInput(gradOutput, kernel, inputShape, stride, padding, dilation);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)Conv2DBackwardInputGpu(
                    (Tensor<float>)(object)gradOutput, (Tensor<float>)(object)kernel, inputShape, stride, padding, dilation);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)Conv2DBackwardInputGpuDouble(
                    (Tensor<double>)(object)gradOutput, (Tensor<double>)(object)kernel, inputShape, stride, padding, dilation);
        }
        return _cpuFallback.Conv2DBackwardInput(gradOutput, kernel, inputShape, stride, padding, dilation);
    }

    private Tensor<float> Conv2DBackwardInputGpu(Tensor<float> gradOutput, Tensor<float> kernel, int[] inputShape, int[] stride, int[] padding, int[] dilation)
    {
        try
        {
            int batch = inputShape[0], inChannels = inputShape[1], height = inputShape[2], width = inputShape[3];
            int outChannels = kernel.Shape[0], kh = kernel.Shape[2], kw = kernel.Shape[3];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];

            var p = new Conv2DParams(batch, inChannels, height, width, outChannels, outH, outW, kh, kw, stride[0], padding[0], dilation[0]);
            var gradInput = new Tensor<float>(inputShape);
            int inputLength = batch * inChannels * height * width;

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuKernel = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernel.Length);
            var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(inputLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuKernel.View.BaseView.CopyFromCPU(kernel.AsSpan());

                lock (_gpuLock)
                {
                    (_conv2DBackwardInputKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        inputLength, gpuGradOutput.View, gpuKernel.View, gpuGradInput.View, p);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(gradInput.AsWritableSpan());
                return gradInput;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuKernel);
                _memoryPoolFloat.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU Conv2DBackwardInput failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Conv2DBackwardInput(gradOutput, kernel, inputShape, stride, padding, dilation);
        }
    }

    private Tensor<double> Conv2DBackwardInputGpuDouble(Tensor<double> gradOutput, Tensor<double> kernel, int[] inputShape, int[] stride, int[] padding, int[] dilation)
    {
        try
        {
            int batch = inputShape[0], inChannels = inputShape[1], height = inputShape[2], width = inputShape[3];
            int outChannels = kernel.Shape[0], kh = kernel.Shape[2], kw = kernel.Shape[3];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];

            var p = new Conv2DParams(batch, inChannels, height, width, outChannels, outH, outW, kh, kw, stride[0], padding[0], dilation[0]);
            var gradInput = new Tensor<double>(inputShape);
            int inputLength = batch * inChannels * height * width;

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuKernel = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernel.Length);
            var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(inputLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuKernel.View.BaseView.CopyFromCPU(kernel.AsSpan());

                lock (_gpuLock)
                {
                    (_conv2DBackwardInputKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        inputLength, gpuGradOutput.View, gpuKernel.View, gpuGradInput.View, p);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(gradInput.AsWritableSpan());
                return gradInput;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuKernel);
                _memoryPoolDouble.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU Conv2DBackwardInput (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Conv2DBackwardInput(gradOutput, kernel, inputShape, stride, padding, dilation);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> Conv2DBackwardKernel<T>(Tensor<T> gradOutput, Tensor<T> input, int[] kernelShape, int[] stride, int[] padding, int[] dilation)
    {
        if (gradOutput.Length < _thresholds.VectorAdd)
            return _cpuFallback.Conv2DBackwardKernel(gradOutput, input, kernelShape, stride, padding, dilation);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)Conv2DBackwardKernelGpu(
                    (Tensor<float>)(object)gradOutput, (Tensor<float>)(object)input, kernelShape, stride, padding, dilation);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)Conv2DBackwardKernelGpuDouble(
                    (Tensor<double>)(object)gradOutput, (Tensor<double>)(object)input, kernelShape, stride, padding, dilation);
        }
        return _cpuFallback.Conv2DBackwardKernel(gradOutput, input, kernelShape, stride, padding, dilation);
    }

    private Tensor<float> Conv2DBackwardKernelGpu(Tensor<float> gradOutput, Tensor<float> input, int[] kernelShape, int[] stride, int[] padding, int[] dilation)
    {
        try
        {
            int outChannels = kernelShape[0], inChannels = kernelShape[1], kh = kernelShape[2], kw = kernelShape[3];
            int batch = input.Shape[0], height = input.Shape[2], width = input.Shape[3];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];

            var p = new Conv2DParams(batch, inChannels, height, width, outChannels, outH, outW, kh, kw, stride[0], padding[0], dilation[0]);
            var gradKernel = new Tensor<float>(kernelShape);
            int kernelLength = outChannels * inChannels * kh * kw;

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuGradKernel = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernelLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_conv2DBackwardKernelKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        kernelLength, gpuGradOutput.View, gpuInput.View, gpuGradKernel.View, p);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradKernel.View.BaseView.CopyToCPU(gradKernel.AsWritableSpan());
                return gradKernel;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuGradKernel);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU Conv2DBackwardKernel failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Conv2DBackwardKernel(gradOutput, input, kernelShape, stride, padding, dilation);
        }
    }

    private Tensor<double> Conv2DBackwardKernelGpuDouble(Tensor<double> gradOutput, Tensor<double> input, int[] kernelShape, int[] stride, int[] padding, int[] dilation)
    {
        try
        {
            int outChannels = kernelShape[0], inChannels = kernelShape[1], kh = kernelShape[2], kw = kernelShape[3];
            int batch = input.Shape[0], height = input.Shape[2], width = input.Shape[3];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];

            var p = new Conv2DParams(batch, inChannels, height, width, outChannels, outH, outW, kh, kw, stride[0], padding[0], dilation[0]);
            var gradKernel = new Tensor<double>(kernelShape);
            int kernelLength = outChannels * inChannels * kh * kw;

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuGradKernel = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernelLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_conv2DBackwardKernelKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        kernelLength, gpuGradOutput.View, gpuInput.View, gpuGradKernel.View, p);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradKernel.View.BaseView.CopyToCPU(gradKernel.AsWritableSpan());
                return gradKernel;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuGradKernel);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU Conv2DBackwardKernel (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Conv2DBackwardKernel(gradOutput, input, kernelShape, stride, padding, dilation);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> MaxPool2DWithIndices<T>(Tensor<T> input, int[] poolSize, int[] stride, out int[,,,,] maxIndices)
    {
        if (input.Length < _thresholds.VectorAdd)
            return _cpuFallback.MaxPool2DWithIndices(input, poolSize, stride, out maxIndices);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)MaxPool2DWithIndicesGpu(
                    (Tensor<float>)(object)input, poolSize, stride, out maxIndices);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)MaxPool2DWithIndicesGpuDouble(
                    (Tensor<double>)(object)input, poolSize, stride, out maxIndices);
        }
        return _cpuFallback.MaxPool2DWithIndices(input, poolSize, stride, out maxIndices);
    }

    private Tensor<float> MaxPool2DWithIndicesGpu(Tensor<float> input, int[] poolSize, int[] stride, out int[,,,,] maxIndices)
    {
        try
        {
            var shape = input.Shape;
            int batch = shape[0], channels = shape[1], inH = shape[2], inW = shape[3];
            int poolH = poolSize[0], poolW = poolSize[1];
            int strideVal = stride[0];
            int outH = (inH - poolH) / strideVal + 1;
            int outW = (inW - poolW) / strideVal + 1;

            var outputShape = new int[] { batch, channels, outH, outW };
            var output = new Tensor<float>(outputShape);
            int outputLength = batch * channels * outH * outW;

            // Initialize 5D maxIndices array (batch, channels, 1, outH, outW)
            maxIndices = new int[batch, channels, 1, outH, outW];

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputLength);
            var gpuMaxIndices = (_memoryPoolInt ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputLength);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_maxPool2DWithIndicesKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputLength, gpuInput.View, gpuOutput.View, gpuMaxIndices.View,
                        batch, channels, inH, inW, outH, outW, poolH, poolW, strideVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(output.AsWritableSpan());

                // Copy flat indices to 5D array
                var flatIndices = new int[outputLength];
                gpuMaxIndices.View.BaseView.CopyToCPU(flatIndices);
                int idx = 0;
                for (int b = 0; b < batch; b++)
                    for (int c = 0; c < channels; c++)
                        for (int oh = 0; oh < outH; oh++)
                            for (int ow = 0; ow < outW; ow++)
                                maxIndices[b, c, 0, oh, ow] = flatIndices[idx++];

                return output;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
                _memoryPoolInt.Return(gpuMaxIndices);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU MaxPool2DWithIndices failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MaxPool2DWithIndices(input, poolSize, stride, out maxIndices);
        }
    }

    private Tensor<double> MaxPool2DWithIndicesGpuDouble(Tensor<double> input, int[] poolSize, int[] stride, out int[,,,,] maxIndices)
    {
        try
        {
            var shape = input.Shape;
            int batch = shape[0], channels = shape[1], inH = shape[2], inW = shape[3];
            int poolH = poolSize[0], poolW = poolSize[1];
            int strideVal = stride[0];
            int outH = (inH - poolH) / strideVal + 1;
            int outW = (inW - poolW) / strideVal + 1;

            var outputShape = new int[] { batch, channels, outH, outW };
            var output = new Tensor<double>(outputShape);
            int outputLength = batch * channels * outH * outW;

            // Initialize 5D maxIndices array (batch, channels, 1, outH, outW)
            maxIndices = new int[batch, channels, 1, outH, outW];

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputLength);
            var gpuMaxIndices = (_memoryPoolInt ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputLength);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_maxPool2DWithIndicesKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputLength, gpuInput.View, gpuOutput.View, gpuMaxIndices.View,
                        batch, channels, inH, inW, outH, outW, poolH, poolW, strideVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(output.AsWritableSpan());

                // Copy flat indices to 5D array
                var flatIndices = new int[outputLength];
                gpuMaxIndices.View.BaseView.CopyToCPU(flatIndices);
                int idx = 0;
                for (int b = 0; b < batch; b++)
                    for (int c = 0; c < channels; c++)
                        for (int oh = 0; oh < outH; oh++)
                            for (int ow = 0; ow < outW; ow++)
                                maxIndices[b, c, 0, oh, ow] = flatIndices[idx++];

                return output;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
                _memoryPoolInt.Return(gpuMaxIndices);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU MaxPool2DWithIndices (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MaxPool2DWithIndices(input, poolSize, stride, out maxIndices);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> MaxPool2DBackward<T>(Tensor<T> gradOutput, int[,,,,] maxIndices, int[] inputShape, int[] poolSize, int[] stride)
    {
        if (gradOutput.Length < _thresholds.VectorAdd)
            return _cpuFallback.MaxPool2DBackward(gradOutput, maxIndices, inputShape, poolSize, stride);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)MaxPool2DBackwardGpu(
                    (Tensor<float>)(object)gradOutput, maxIndices, inputShape, poolSize, stride);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)MaxPool2DBackwardGpuDouble(
                    (Tensor<double>)(object)gradOutput, maxIndices, inputShape, poolSize, stride);
        }
        return _cpuFallback.MaxPool2DBackward(gradOutput, maxIndices, inputShape, poolSize, stride);
    }

    private Tensor<float> MaxPool2DBackwardGpu(Tensor<float> gradOutput, int[,,,,] maxIndices, int[] inputShape, int[] poolSize, int[] stride)
    {
        try
        {
            int batch = inputShape[0], channels = inputShape[1], inH = inputShape[2], inW = inputShape[3];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];

            var gradInput = new Tensor<float>(inputShape);
            int inputLength = batch * channels * inH * inW;
            int outputLength = gradOutput.Length;

            // Flatten maxIndices to 1D array for GPU
            var flatMaxIndices = new int[outputLength];
            int idx = 0;
            for (int b = 0; b < batch; b++)
                for (int c = 0; c < channels; c++)
                    for (int oh = 0; oh < outH; oh++)
                        for (int ow = 0; ow < outW; ow++)
                            flatMaxIndices[idx++] = maxIndices[b, c, 0, oh, ow];

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputLength);
            var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(inputLength);
            var gpuMaxIndices = (_memoryPoolInt ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuMaxIndices.View.BaseView.CopyFromCPU(flatMaxIndices);
                // Initialize gradInput to zero
                var zeros = new float[inputLength];
                gpuGradInput.View.BaseView.CopyFromCPU(zeros);

                lock (_gpuLock)
                {
                    (_maxPool2DBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputLength, gpuGradOutput.View, gpuMaxIndices.View, gpuGradInput.View,
                        batch, channels, inH, inW, outH, outW);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(gradInput.AsWritableSpan());
                return gradInput;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuGradInput);
                _memoryPoolInt.Return(gpuMaxIndices);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU MaxPool2DBackward failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MaxPool2DBackward(gradOutput, maxIndices, inputShape, poolSize, stride);
        }
    }

    private Tensor<double> MaxPool2DBackwardGpuDouble(Tensor<double> gradOutput, int[,,,,] maxIndices, int[] inputShape, int[] poolSize, int[] stride)
    {
        try
        {
            int batch = inputShape[0], channels = inputShape[1], inH = inputShape[2], inW = inputShape[3];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];

            var gradInput = new Tensor<double>(inputShape);
            int inputLength = batch * channels * inH * inW;
            int outputLength = gradOutput.Length;

            // Flatten maxIndices to 1D array for GPU
            var flatMaxIndices = new int[outputLength];
            int idx = 0;
            for (int b = 0; b < batch; b++)
                for (int c = 0; c < channels; c++)
                    for (int oh = 0; oh < outH; oh++)
                        for (int ow = 0; ow < outW; ow++)
                            flatMaxIndices[idx++] = maxIndices[b, c, 0, oh, ow];

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputLength);
            var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(inputLength);
            var gpuMaxIndices = (_memoryPoolInt ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuMaxIndices.View.BaseView.CopyFromCPU(flatMaxIndices);
                // Initialize gradInput to zero
                var zeros = new double[inputLength];
                gpuGradInput.View.BaseView.CopyFromCPU(zeros);

                lock (_gpuLock)
                {
                    (_maxPool2DBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputLength, gpuGradOutput.View, gpuMaxIndices.View, gpuGradInput.View,
                        batch, channels, inH, inW, outH, outW);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(gradInput.AsWritableSpan());
                return gradInput;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuGradInput);
                _memoryPoolInt.Return(gpuMaxIndices);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU MaxPool2DBackward (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MaxPool2DBackward(gradOutput, maxIndices, inputShape, poolSize, stride);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> AvgPool2D<T>(Tensor<T> input, int[] poolSize, int[] stride)
    {
        // For non-square pooling, fall back to CPU implementation
        // GPU only supports square pooling via the scalar overload
        if (poolSize[0] != poolSize[1] || stride[0] != stride[1])
        {
            return _cpuFallback.AvgPool2D(input, poolSize, stride);
        }

        // Use existing GPU AvgPool2D with square parameters
        return AvgPool2D(input, poolSize[0], stride[0], 0);
    }

    /// <inheritdoc/>
    public Tensor<T> AvgPool2DBackward<T>(Tensor<T> gradOutput, int[] inputShape, int[] poolSize, int[] stride)
    {
        if (gradOutput.Length < _thresholds.VectorAdd)
            return _cpuFallback.AvgPool2DBackward(gradOutput, inputShape, poolSize, stride);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)AvgPool2DBackwardGpu(
                    (Tensor<float>)(object)gradOutput, inputShape, poolSize, stride);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)AvgPool2DBackwardGpuDouble(
                    (Tensor<double>)(object)gradOutput, inputShape, poolSize, stride);
        }
        return _cpuFallback.AvgPool2DBackward(gradOutput, inputShape, poolSize, stride);
    }

    private Tensor<float> AvgPool2DBackwardGpu(Tensor<float> gradOutput, int[] inputShape, int[] poolSize, int[] stride)
    {
        try
        {
            int batch = inputShape[0], channels = inputShape[1], inH = inputShape[2], inW = inputShape[3];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];
            int poolH = poolSize[0], poolW = poolSize[1];
            int strideVal = stride[0];

            var gradInput = new Tensor<float>(inputShape);
            int inputLength = batch * channels * inH * inW;

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(inputLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());

                lock (_gpuLock)
                {
                    (_avgPool2DBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        inputLength, gpuGradOutput.View, gpuGradInput.View,
                        batch, channels, inH, inW, outH, outW, poolH, poolW, strideVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(gradInput.AsWritableSpan());
                return gradInput;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU AvgPool2DBackward failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.AvgPool2DBackward(gradOutput, inputShape, poolSize, stride);
        }
    }

    private Tensor<double> AvgPool2DBackwardGpuDouble(Tensor<double> gradOutput, int[] inputShape, int[] poolSize, int[] stride)
    {
        try
        {
            int batch = inputShape[0], channels = inputShape[1], inH = inputShape[2], inW = inputShape[3];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];
            int poolH = poolSize[0], poolW = poolSize[1];
            int strideVal = stride[0];

            var gradInput = new Tensor<double>(inputShape);
            int inputLength = batch * channels * inH * inW;

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(inputLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());

                lock (_gpuLock)
                {
                    (_avgPool2DBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        inputLength, gpuGradOutput.View, gpuGradInput.View,
                        batch, channels, inH, inW, outH, outW, poolH, poolW, strideVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(gradInput.AsWritableSpan());
                return gradInput;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU AvgPool2DBackward (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.AvgPool2DBackward(gradOutput, inputShape, poolSize, stride);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> DepthwiseConv2D<T>(Tensor<T> input, Tensor<T> kernel, int[] stride, int[] padding)
    {
        if (input.Length < _thresholds.VectorAdd)
            return _cpuFallback.DepthwiseConv2D(input, kernel, stride, padding);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)DepthwiseConv2DGpu(
                    (Tensor<float>)(object)input, (Tensor<float>)(object)kernel, stride, padding);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)DepthwiseConv2DGpuDouble(
                    (Tensor<double>)(object)input, (Tensor<double>)(object)kernel, stride, padding);
        }
        return _cpuFallback.DepthwiseConv2D(input, kernel, stride, padding);
    }

    private Tensor<float> DepthwiseConv2DGpu(Tensor<float> input, Tensor<float> kernel, int[] stride, int[] padding)
    {
        try
        {
            var shape = input.Shape;
            int batch = shape[0], channels = shape[1], inH = shape[2], inW = shape[3];
            int kH = kernel.Shape[1], kW = kernel.Shape[2];
            int strideVal = stride[0], paddingVal = padding[0];
            int outH = (inH + 2 * paddingVal - kH) / strideVal + 1;
            int outW = (inW + 2 * paddingVal - kW) / strideVal + 1;

            var output = new Tensor<float>([batch, channels, outH, outW]);
            int outputLength = batch * channels * outH * outW;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuKernel = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernel.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputLength);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuKernel.View.BaseView.CopyFromCPU(kernel.AsSpan());

                lock (_gpuLock)
                {
                    (_depthwiseConv2DKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputLength, gpuInput.View, gpuKernel.View, gpuOutput.View,
                        batch, channels, inH, inW, outH, outW, kH, kW, strideVal, paddingVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(output.AsWritableSpan());
                return output;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuKernel);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU DepthwiseConv2D failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.DepthwiseConv2D(input, kernel, stride, padding);
        }
    }

    private Tensor<double> DepthwiseConv2DGpuDouble(Tensor<double> input, Tensor<double> kernel, int[] stride, int[] padding)
    {
        try
        {
            var shape = input.Shape;
            int batch = shape[0], channels = shape[1], inH = shape[2], inW = shape[3];
            int kH = kernel.Shape[1], kW = kernel.Shape[2];
            int strideVal = stride[0], paddingVal = padding[0];
            int outH = (inH + 2 * paddingVal - kH) / strideVal + 1;
            int outW = (inW + 2 * paddingVal - kW) / strideVal + 1;

            var output = new Tensor<double>([batch, channels, outH, outW]);
            int outputLength = batch * channels * outH * outW;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuKernel = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernel.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputLength);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuKernel.View.BaseView.CopyFromCPU(kernel.AsSpan());

                lock (_gpuLock)
                {
                    (_depthwiseConv2DKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputLength, gpuInput.View, gpuKernel.View, gpuOutput.View,
                        batch, channels, inH, inW, outH, outW, kH, kW, strideVal, paddingVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(output.AsWritableSpan());
                return output;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuKernel);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU DepthwiseConv2D (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.DepthwiseConv2D(input, kernel, stride, padding);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> DepthwiseConv2DBackwardInput<T>(Tensor<T> gradOutput, Tensor<T> kernel, int[] inputShape, int[] stride, int[] padding)
    {
        if (gradOutput.Length < _thresholds.VectorAdd)
            return _cpuFallback.DepthwiseConv2DBackwardInput(gradOutput, kernel, inputShape, stride, padding);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)DepthwiseConv2DBackwardInputGpu(
                    (Tensor<float>)(object)gradOutput, (Tensor<float>)(object)kernel, inputShape, stride, padding);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)DepthwiseConv2DBackwardInputGpuDouble(
                    (Tensor<double>)(object)gradOutput, (Tensor<double>)(object)kernel, inputShape, stride, padding);
        }
        return _cpuFallback.DepthwiseConv2DBackwardInput(gradOutput, kernel, inputShape, stride, padding);
    }

    private Tensor<float> DepthwiseConv2DBackwardInputGpu(Tensor<float> gradOutput, Tensor<float> kernel, int[] inputShape, int[] stride, int[] padding)
    {
        try
        {
            int batch = inputShape[0], channels = inputShape[1], inH = inputShape[2], inW = inputShape[3];
            int kH = kernel.Shape[1], kW = kernel.Shape[2];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];
            int strideVal = stride[0], paddingVal = padding[0];

            var gradInput = new Tensor<float>(inputShape);
            int inputLength = batch * channels * inH * inW;

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuKernel = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernel.Length);
            var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(inputLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuKernel.View.BaseView.CopyFromCPU(kernel.AsSpan());

                lock (_gpuLock)
                {
                    (_depthwiseConv2DBackwardInputKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        inputLength, gpuGradOutput.View, gpuKernel.View, gpuGradInput.View,
                        batch, channels, inH, inW, outH, outW, kH, kW, strideVal, paddingVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(gradInput.AsWritableSpan());
                return gradInput;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuKernel);
                _memoryPoolFloat.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU DepthwiseConv2DBackwardInput failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.DepthwiseConv2DBackwardInput(gradOutput, kernel, inputShape, stride, padding);
        }
    }

    private Tensor<double> DepthwiseConv2DBackwardInputGpuDouble(Tensor<double> gradOutput, Tensor<double> kernel, int[] inputShape, int[] stride, int[] padding)
    {
        try
        {
            int batch = inputShape[0], channels = inputShape[1], inH = inputShape[2], inW = inputShape[3];
            int kH = kernel.Shape[1], kW = kernel.Shape[2];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];
            int strideVal = stride[0], paddingVal = padding[0];

            var gradInput = new Tensor<double>(inputShape);
            int inputLength = batch * channels * inH * inW;

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuKernel = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernel.Length);
            var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(inputLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuKernel.View.BaseView.CopyFromCPU(kernel.AsSpan());

                lock (_gpuLock)
                {
                    (_depthwiseConv2DBackwardInputKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        inputLength, gpuGradOutput.View, gpuKernel.View, gpuGradInput.View,
                        batch, channels, inH, inW, outH, outW, kH, kW, strideVal, paddingVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(gradInput.AsWritableSpan());
                return gradInput;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuKernel);
                _memoryPoolDouble.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU DepthwiseConv2DBackwardInput (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.DepthwiseConv2DBackwardInput(gradOutput, kernel, inputShape, stride, padding);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> DepthwiseConv2DBackwardKernel<T>(Tensor<T> gradOutput, Tensor<T> input, int[] kernelShape, int[] stride, int[] padding)
    {
        if (gradOutput.Length < _thresholds.VectorAdd)
            return _cpuFallback.DepthwiseConv2DBackwardKernel(gradOutput, input, kernelShape, stride, padding);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)DepthwiseConv2DBackwardKernelGpu(
                    (Tensor<float>)(object)gradOutput, (Tensor<float>)(object)input, kernelShape, stride, padding);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)DepthwiseConv2DBackwardKernelGpuDouble(
                    (Tensor<double>)(object)gradOutput, (Tensor<double>)(object)input, kernelShape, stride, padding);
        }
        return _cpuFallback.DepthwiseConv2DBackwardKernel(gradOutput, input, kernelShape, stride, padding);
    }

    private Tensor<float> DepthwiseConv2DBackwardKernelGpu(Tensor<float> gradOutput, Tensor<float> input, int[] kernelShape, int[] stride, int[] padding)
    {
        try
        {
            var inputShape = input.Shape;
            int batch = inputShape[0], channels = inputShape[1], inH = inputShape[2], inW = inputShape[3];
            int kH = kernelShape[1], kW = kernelShape[2];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];
            int strideVal = stride[0], paddingVal = padding[0];

            var gradKernel = new Tensor<float>(kernelShape);
            int kernelLength = channels * kH * kW;

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuGradKernel = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernelLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_depthwiseConv2DBackwardKernelKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        kernelLength, gpuGradOutput.View, gpuInput.View, gpuGradKernel.View,
                        batch, channels, inH, inW, outH, outW, kH, kW, strideVal, paddingVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradKernel.View.BaseView.CopyToCPU(gradKernel.AsWritableSpan());
                return gradKernel;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuGradKernel);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU DepthwiseConv2DBackwardKernel failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.DepthwiseConv2DBackwardKernel(gradOutput, input, kernelShape, stride, padding);
        }
    }

    private Tensor<double> DepthwiseConv2DBackwardKernelGpuDouble(Tensor<double> gradOutput, Tensor<double> input, int[] kernelShape, int[] stride, int[] padding)
    {
        try
        {
            var inputShape = input.Shape;
            int batch = inputShape[0], channels = inputShape[1], inH = inputShape[2], inW = inputShape[3];
            int kH = kernelShape[1], kW = kernelShape[2];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];
            int strideVal = stride[0], paddingVal = padding[0];

            var gradKernel = new Tensor<double>(kernelShape);
            int kernelLength = channels * kH * kW;

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuGradKernel = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernelLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_depthwiseConv2DBackwardKernelKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        kernelLength, gpuGradOutput.View, gpuInput.View, gpuGradKernel.View,
                        batch, channels, inH, inW, outH, outW, kH, kW, strideVal, paddingVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradKernel.View.BaseView.CopyToCPU(gradKernel.AsWritableSpan());
                return gradKernel;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuGradKernel);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU DepthwiseConv2DBackwardKernel (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.DepthwiseConv2DBackwardKernel(gradOutput, input, kernelShape, stride, padding);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> ConvTranspose2D<T>(Tensor<T> input, Tensor<T> kernel, int[] stride, int[] padding, int[] outputPadding)
    {
        if (input.Length < _thresholds.VectorAdd)
            return _cpuFallback.ConvTranspose2D(input, kernel, stride, padding, outputPadding);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)ConvTranspose2DGpu(
                    (Tensor<float>)(object)input, (Tensor<float>)(object)kernel, stride, padding, outputPadding);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)ConvTranspose2DGpuDouble(
                    (Tensor<double>)(object)input, (Tensor<double>)(object)kernel, stride, padding, outputPadding);
        }
        return _cpuFallback.ConvTranspose2D(input, kernel, stride, padding, outputPadding);
    }

    private Tensor<float> ConvTranspose2DGpu(Tensor<float> input, Tensor<float> kernel, int[] stride, int[] padding, int[] outputPadding)
    {
        try
        {
            var shape = input.Shape;
            int batch = shape[0], channels = shape[1], inH = shape[2], inW = shape[3];
            var kshape = kernel.Shape;
            int outChannels = kshape[1], kH = kshape[2], kW = kshape[3];
            int strideVal = stride[0], paddingVal = padding[0];
            int outH = (inH - 1) * strideVal - 2 * paddingVal + kH + outputPadding[0];
            int outW = (inW - 1) * strideVal - 2 * paddingVal + kW + outputPadding[1];

            var output = new Tensor<float>([batch, outChannels, outH, outW]);
            int outputLength = batch * outChannels * outH * outW;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuKernel = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernel.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputLength);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuKernel.View.BaseView.CopyFromCPU(kernel.AsSpan());

                lock (_gpuLock)
                {
                    (_convTranspose2DKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputLength, gpuInput.View, gpuKernel.View, gpuOutput.View,
                        batch, channels, inH, inW, outH, outW, outChannels, kH, kW, strideVal, paddingVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(output.AsWritableSpan());
                return output;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuKernel);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ConvTranspose2D failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ConvTranspose2D(input, kernel, stride, padding, outputPadding);
        }
    }

    private Tensor<double> ConvTranspose2DGpuDouble(Tensor<double> input, Tensor<double> kernel, int[] stride, int[] padding, int[] outputPadding)
    {
        try
        {
            var shape = input.Shape;
            int batch = shape[0], channels = shape[1], inH = shape[2], inW = shape[3];
            var kshape = kernel.Shape;
            int outChannels = kshape[1], kH = kshape[2], kW = kshape[3];
            int strideVal = stride[0], paddingVal = padding[0];
            int outH = (inH - 1) * strideVal - 2 * paddingVal + kH + outputPadding[0];
            int outW = (inW - 1) * strideVal - 2 * paddingVal + kW + outputPadding[1];

            var output = new Tensor<double>([batch, outChannels, outH, outW]);
            int outputLength = batch * outChannels * outH * outW;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuKernel = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernel.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputLength);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuKernel.View.BaseView.CopyFromCPU(kernel.AsSpan());

                lock (_gpuLock)
                {
                    (_convTranspose2DKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputLength, gpuInput.View, gpuKernel.View, gpuOutput.View,
                        batch, channels, inH, inW, outH, outW, outChannels, kH, kW, strideVal, paddingVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(output.AsWritableSpan());
                return output;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuKernel);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ConvTranspose2D (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ConvTranspose2D(input, kernel, stride, padding, outputPadding);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> ConvTranspose2DBackwardInput<T>(Tensor<T> gradOutput, Tensor<T> kernel, int[] inputShape, int[] stride, int[] padding)
    {
        if (gradOutput.Length < _thresholds.VectorAdd)
            return _cpuFallback.ConvTranspose2DBackwardInput(gradOutput, kernel, inputShape, stride, padding);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)ConvTranspose2DBackwardInputGpu(
                    (Tensor<float>)(object)gradOutput, (Tensor<float>)(object)kernel, inputShape, stride, padding);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)ConvTranspose2DBackwardInputGpuDouble(
                    (Tensor<double>)(object)gradOutput, (Tensor<double>)(object)kernel, inputShape, stride, padding);
        }
        return _cpuFallback.ConvTranspose2DBackwardInput(gradOutput, kernel, inputShape, stride, padding);
    }

    private Tensor<float> ConvTranspose2DBackwardInputGpu(Tensor<float> gradOutput, Tensor<float> kernel, int[] inputShape, int[] stride, int[] padding)
    {
        try
        {
            int batch = inputShape[0], channels = inputShape[1], inH = inputShape[2], inW = inputShape[3];
            var kshape = kernel.Shape;
            int outChannels = kshape[1], kH = kshape[2], kW = kshape[3];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];
            int strideVal = stride[0];

            var gradInput = new Tensor<float>(inputShape);
            int inputLength = batch * channels * inH * inW;

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuKernel = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernel.Length);
            var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(inputLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuKernel.View.BaseView.CopyFromCPU(kernel.AsSpan());

                lock (_gpuLock)
                {
                    (_convTranspose2DBackwardInputKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        inputLength, gpuGradOutput.View, gpuKernel.View, gpuGradInput.View,
                        batch, channels, inH, inW, outH, outW, outChannels, kH, kW, strideVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(gradInput.AsWritableSpan());
                return gradInput;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuKernel);
                _memoryPoolFloat.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ConvTranspose2DBackwardInput failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ConvTranspose2DBackwardInput(gradOutput, kernel, inputShape, stride, padding);
        }
    }

    private Tensor<double> ConvTranspose2DBackwardInputGpuDouble(Tensor<double> gradOutput, Tensor<double> kernel, int[] inputShape, int[] stride, int[] padding)
    {
        try
        {
            int batch = inputShape[0], channels = inputShape[1], inH = inputShape[2], inW = inputShape[3];
            var kshape = kernel.Shape;
            int outChannels = kshape[1], kH = kshape[2], kW = kshape[3];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];
            int strideVal = stride[0];

            var gradInput = new Tensor<double>(inputShape);
            int inputLength = batch * channels * inH * inW;

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuKernel = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernel.Length);
            var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(inputLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuKernel.View.BaseView.CopyFromCPU(kernel.AsSpan());

                lock (_gpuLock)
                {
                    (_convTranspose2DBackwardInputKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        inputLength, gpuGradOutput.View, gpuKernel.View, gpuGradInput.View,
                        batch, channels, inH, inW, outH, outW, outChannels, kH, kW, strideVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(gradInput.AsWritableSpan());
                return gradInput;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuKernel);
                _memoryPoolDouble.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ConvTranspose2DBackwardInput (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ConvTranspose2DBackwardInput(gradOutput, kernel, inputShape, stride, padding);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> ConvTranspose2DBackwardKernel<T>(Tensor<T> gradOutput, Tensor<T> input, int[] kernelShape, int[] stride, int[] padding)
    {
        if (gradOutput.Length < _thresholds.VectorAdd)
            return _cpuFallback.ConvTranspose2DBackwardKernel(gradOutput, input, kernelShape, stride, padding);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)ConvTranspose2DBackwardKernelGpu(
                    (Tensor<float>)(object)gradOutput, (Tensor<float>)(object)input, kernelShape, stride, padding);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)ConvTranspose2DBackwardKernelGpuDouble(
                    (Tensor<double>)(object)gradOutput, (Tensor<double>)(object)input, kernelShape, stride, padding);
        }
        return _cpuFallback.ConvTranspose2DBackwardKernel(gradOutput, input, kernelShape, stride, padding);
    }

    private Tensor<float> ConvTranspose2DBackwardKernelGpu(Tensor<float> gradOutput, Tensor<float> input, int[] kernelShape, int[] stride, int[] padding)
    {
        try
        {
            var inputShape = input.Shape;
            int batch = inputShape[0], channels = inputShape[1], inH = inputShape[2], inW = inputShape[3];
            int outChannels = kernelShape[1], kH = kernelShape[2], kW = kernelShape[3];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];
            int strideVal = stride[0];

            var gradKernel = new Tensor<float>(kernelShape);
            int kernelLength = channels * outChannels * kH * kW;

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuGradKernel = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernelLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_convTranspose2DBackwardKernelKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        kernelLength, gpuGradOutput.View, gpuInput.View, gpuGradKernel.View,
                        batch, channels, inH, inW, outH, outW, outChannels, kH, kW, strideVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradKernel.View.BaseView.CopyToCPU(gradKernel.AsWritableSpan());
                return gradKernel;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuGradKernel);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ConvTranspose2DBackwardKernel failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ConvTranspose2DBackwardKernel(gradOutput, input, kernelShape, stride, padding);
        }
    }

    private Tensor<double> ConvTranspose2DBackwardKernelGpuDouble(Tensor<double> gradOutput, Tensor<double> input, int[] kernelShape, int[] stride, int[] padding)
    {
        try
        {
            var inputShape = input.Shape;
            int batch = inputShape[0], channels = inputShape[1], inH = inputShape[2], inW = inputShape[3];
            int outChannels = kernelShape[1], kH = kernelShape[2], kW = kernelShape[3];
            int outH = gradOutput.Shape[2], outW = gradOutput.Shape[3];
            int strideVal = stride[0];

            var gradKernel = new Tensor<double>(kernelShape);
            int kernelLength = channels * outChannels * kH * kW;

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuGradKernel = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernelLength);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_convTranspose2DBackwardKernelKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        kernelLength, gpuGradOutput.View, gpuInput.View, gpuGradKernel.View,
                        batch, channels, inH, inW, outH, outW, outChannels, kH, kW, strideVal);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradKernel.View.BaseView.CopyToCPU(gradKernel.AsWritableSpan());
                return gradKernel;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuGradKernel);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ConvTranspose2DBackwardKernel (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ConvTranspose2DBackwardKernel(gradOutput, input, kernelShape, stride, padding);
        }
    }

    #endregion

    #region 3D Convolution and Pooling Operations

    /// <inheritdoc/>
    public Tensor<T> Conv3D<T>(Tensor<T> input, Tensor<T> kernel, int stride = 1, int padding = 0, int dilation = 1)
    {
        return Conv3D(input, kernel, [stride, stride, stride], [padding, padding, padding], [dilation, dilation, dilation]);
    }

    /// <inheritdoc/>
    public Tensor<T> Conv3D<T>(Tensor<T> input, Tensor<T> kernel, int[] stride, int[] padding, int[] dilation)
    {
        // Validate array parameter lengths
        if (stride == null || stride.Length != 3)
            throw new ArgumentException("stride array must have exactly 3 elements (D, H, W).", nameof(stride));
        if (padding == null || padding.Length != 3)
            throw new ArgumentException("padding array must have exactly 3 elements (D, H, W).", nameof(padding));
        if (dilation == null || dilation.Length != 3)
            throw new ArgumentException("dilation array must have exactly 3 elements (D, H, W).", nameof(dilation));

        // Adaptive execution: use convolution threshold
        if (input.Length < _thresholds.Convolution)
        {
            return _cpuFallback.Conv3D(input, kernel, stride, padding, dilation);
        }

        // Check GPU health and type support
        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)Conv3DGpu((Tensor<float>)(object)input, (Tensor<float>)(object)kernel, stride, padding, dilation);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)Conv3DGpuDouble((Tensor<double>)(object)input, (Tensor<double>)(object)kernel, stride, padding, dilation);
        }

        return _cpuFallback.Conv3D(input, kernel, stride, padding, dilation);
    }

    private Tensor<float> Conv3DGpu(Tensor<float> input, Tensor<float> kernel, int[] stride, int[] padding, int[] dilation)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (kernel == null) throw new ArgumentNullException(nameof(kernel));
        if (input.Rank != 5 || kernel.Rank != 5)
        {
            throw new ArgumentException($"Conv3D requires 5D tensors. Got input rank {input.Rank}, kernel rank {kernel.Rank}.");
        }

        int batch = input.Shape[0];
        int inChannels = input.Shape[1];
        int depth = input.Shape[2];
        int height = input.Shape[3];
        int width = input.Shape[4];

        int outChannels = kernel.Shape[0];
        int kernelDepth = kernel.Shape[2];
        int kernelHeight = kernel.Shape[3];
        int kernelWidth = kernel.Shape[4];

        int effectiveKernelDepth = dilation[0] * (kernelDepth - 1) + 1;
        int effectiveKernelHeight = dilation[1] * (kernelHeight - 1) + 1;
        int effectiveKernelWidth = dilation[2] * (kernelWidth - 1) + 1;

        int outputDepth = (depth + 2 * padding[0] - effectiveKernelDepth) / stride[0] + 1;
        int outputHeight = (height + 2 * padding[1] - effectiveKernelHeight) / stride[1] + 1;
        int outputWidth = (width + 2 * padding[2] - effectiveKernelWidth) / stride[2] + 1;

        // Check for potential overflow using long arithmetic
        long outputSizeLong = (long)batch * outChannels * outputDepth * outputHeight * outputWidth;
        if (outputSizeLong > int.MaxValue)
        {
            throw new ArgumentException($"Output tensor size ({outputSizeLong}) exceeds maximum supported size ({int.MaxValue}). Consider reducing batch size or output dimensions.");
        }
        int outputSize = (int)outputSizeLong;

        try
        {
            var result = new Tensor<float>(new[] { batch, outChannels, outputDepth, outputHeight, outputWidth });

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuKernel = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernel.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuKernel.View.BaseView.CopyFromCPU(kernel.AsSpan());

                // Thread-safe kernel execution
                lock (_gpuLock)
                {
                    var parameters = new Conv3DParams(batch, inChannels, depth, height, width, outChannels,
                        outputDepth, outputHeight, outputWidth, kernelDepth, kernelHeight, kernelWidth,
                        stride[0], stride[1], stride[2], padding[0], padding[1], padding[2],
                        dilation[0], dilation[1], dilation[2]);
                    (_conv3DKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuInput.View, gpuKernel.View, gpuOutput.View, parameters);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuKernel);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Conv3D failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Conv3D(input, kernel, stride, padding, dilation);
        }
    }

    private Tensor<double> Conv3DGpuDouble(Tensor<double> input, Tensor<double> kernel, int[] stride, int[] padding, int[] dilation)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (kernel == null) throw new ArgumentNullException(nameof(kernel));
        if (input.Rank != 5 || kernel.Rank != 5)
        {
            throw new ArgumentException($"Conv3D requires 5D tensors. Got input rank {input.Rank}, kernel rank {kernel.Rank}.");
        }

        int batch = input.Shape[0];
        int inChannels = input.Shape[1];
        int depth = input.Shape[2];
        int height = input.Shape[3];
        int width = input.Shape[4];

        int outChannels = kernel.Shape[0];
        int kernelDepth = kernel.Shape[2];
        int kernelHeight = kernel.Shape[3];
        int kernelWidth = kernel.Shape[4];

        int effectiveKernelDepth = dilation[0] * (kernelDepth - 1) + 1;
        int effectiveKernelHeight = dilation[1] * (kernelHeight - 1) + 1;
        int effectiveKernelWidth = dilation[2] * (kernelWidth - 1) + 1;

        int outputDepth = (depth + 2 * padding[0] - effectiveKernelDepth) / stride[0] + 1;
        int outputHeight = (height + 2 * padding[1] - effectiveKernelHeight) / stride[1] + 1;
        int outputWidth = (width + 2 * padding[2] - effectiveKernelWidth) / stride[2] + 1;

        // Check for potential overflow using long arithmetic
        long outputSizeLong = (long)batch * outChannels * outputDepth * outputHeight * outputWidth;
        if (outputSizeLong > int.MaxValue)
        {
            throw new ArgumentException($"Output tensor size ({outputSizeLong}) exceeds maximum supported size ({int.MaxValue}). Consider reducing batch size or output dimensions.");
        }
        int outputSize = (int)outputSizeLong;

        try
        {
            var result = new Tensor<double>(new[] { batch, outChannels, outputDepth, outputHeight, outputWidth });

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuKernel = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(kernel.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuKernel.View.BaseView.CopyFromCPU(kernel.AsSpan());

                lock (_gpuLock)
                {
                    var parameters = new Conv3DParams(batch, inChannels, depth, height, width, outChannels,
                        outputDepth, outputHeight, outputWidth, kernelDepth, kernelHeight, kernelWidth,
                        stride[0], stride[1], stride[2], padding[0], padding[1], padding[2],
                        dilation[0], dilation[1], dilation[2]);
                    (_conv3DKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuInput.View, gpuKernel.View, gpuOutput.View, parameters);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuKernel);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Conv3D double failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Conv3D(input, kernel, stride, padding, dilation);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> Conv3DBackwardInput<T>(Tensor<T> gradOutput, Tensor<T> kernel, int[] inputShape, int[] stride, int[] padding, int[] dilation)
    {
        // Conv3D backward GPU kernels not yet implemented - use CPU fallback
        return _cpuFallback.Conv3DBackwardInput(gradOutput, kernel, inputShape, stride, padding, dilation);
    }

    /// <inheritdoc/>
    public Tensor<T> Conv3DBackwardKernel<T>(Tensor<T> gradOutput, Tensor<T> input, int[] kernelShape, int[] stride, int[] padding, int[] dilation)
    {
        // Conv3D backward GPU kernels not yet implemented - use CPU fallback
        return _cpuFallback.Conv3DBackwardKernel(gradOutput, input, kernelShape, stride, padding, dilation);
    }

    /// <inheritdoc/>
    public Tensor<T> MaxPool3D<T>(Tensor<T> input, int poolSize, int stride = 0, int padding = 0)
    {
        if (stride == 0) stride = poolSize;
        return MaxPool3D(input, [poolSize, poolSize, poolSize], [stride, stride, stride], [padding, padding, padding]);
    }

    /// <inheritdoc/>
    public Tensor<T> MaxPool3D<T>(Tensor<T> input, int[] poolSize, int[] stride, int[] padding)
    {
        // Validate array parameter lengths
        if (poolSize == null || poolSize.Length != 3)
            throw new ArgumentException("poolSize array must have exactly 3 elements (D, H, W).", nameof(poolSize));
        if (stride == null || stride.Length != 3)
            throw new ArgumentException("stride array must have exactly 3 elements (D, H, W).", nameof(stride));
        if (padding == null || padding.Length != 3)
            throw new ArgumentException("padding array must have exactly 3 elements (D, H, W).", nameof(padding));

        // Adaptive execution
        if (input.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.MaxPool3D(input, poolSize, stride, padding);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)MaxPool3DGpu((Tensor<float>)(object)input, poolSize, stride, padding);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)MaxPool3DGpuDouble((Tensor<double>)(object)input, poolSize, stride, padding);
        }

        return _cpuFallback.MaxPool3D(input, poolSize, stride, padding);
    }

    private Tensor<float> MaxPool3DGpu(Tensor<float> input, int[] poolSize, int[] stride, int[] padding)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (input.Rank != 5) throw new ArgumentException($"MaxPool3D requires 5D tensor. Got rank {input.Rank}.");

        int batch = input.Shape[0];
        int channels = input.Shape[1];
        int depth = input.Shape[2];
        int height = input.Shape[3];
        int width = input.Shape[4];

        int outputDepth = (depth + 2 * padding[0] - poolSize[0]) / stride[0] + 1;
        int outputHeight = (height + 2 * padding[1] - poolSize[1]) / stride[1] + 1;
        int outputWidth = (width + 2 * padding[2] - poolSize[2]) / stride[2] + 1;

        // Check for potential overflow using long arithmetic
        long outputSizeLong = (long)batch * channels * outputDepth * outputHeight * outputWidth;
        if (outputSizeLong > int.MaxValue)
        {
            throw new ArgumentException($"Output tensor size ({outputSizeLong}) exceeds maximum supported size ({int.MaxValue}).");
        }

        try
        {
            var result = new Tensor<float>(new[] { batch, channels, outputDepth, outputHeight, outputWidth });
            int outputSize = batch * channels * outputDepth * outputHeight * outputWidth;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    var parameters = new Pool3DParams(batch, channels, depth, height, width,
                        outputDepth, outputHeight, outputWidth,
                        poolSize[0], poolSize[1], poolSize[2],
                        stride[0], stride[1], stride[2],
                        padding[0], padding[1], padding[2]);
                    (_maxPool3DKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuInput.View, gpuOutput.View, parameters);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU MaxPool3D failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MaxPool3D(input, poolSize, stride, padding);
        }
    }

    private Tensor<double> MaxPool3DGpuDouble(Tensor<double> input, int[] poolSize, int[] stride, int[] padding)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (input.Rank != 5) throw new ArgumentException($"MaxPool3D requires 5D tensor. Got rank {input.Rank}.");

        int batch = input.Shape[0];
        int channels = input.Shape[1];
        int depth = input.Shape[2];
        int height = input.Shape[3];
        int width = input.Shape[4];

        int outputDepth = (depth + 2 * padding[0] - poolSize[0]) / stride[0] + 1;
        int outputHeight = (height + 2 * padding[1] - poolSize[1]) / stride[1] + 1;
        int outputWidth = (width + 2 * padding[2] - poolSize[2]) / stride[2] + 1;

        try
        {
            var result = new Tensor<double>(new[] { batch, channels, outputDepth, outputHeight, outputWidth });
            int outputSize = batch * channels * outputDepth * outputHeight * outputWidth;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    var parameters = new Pool3DParams(batch, channels, depth, height, width,
                        outputDepth, outputHeight, outputWidth,
                        poolSize[0], poolSize[1], poolSize[2],
                        stride[0], stride[1], stride[2],
                        padding[0], padding[1], padding[2]);
                    (_maxPool3DKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuInput.View, gpuOutput.View, parameters);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU MaxPool3D double failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.MaxPool3D(input, poolSize, stride, padding);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> MaxPool3DWithIndices<T>(Tensor<T> input, int[] poolSize, int[] stride, out int[,,,,,] maxIndices)
    {
        // MaxPool3DWithIndices requires tracking indices - use CPU implementation
        return _cpuFallback.MaxPool3DWithIndices(input, poolSize, stride, out maxIndices);
    }

    /// <inheritdoc/>
    public Tensor<T> MaxPool3DBackward<T>(Tensor<T> gradOutput, int[,,,,,] maxIndices, int[] inputShape, int[] poolSize, int[] stride)
    {
        // MaxPool3DBackward uses indices from forward pass - use CPU implementation
        return _cpuFallback.MaxPool3DBackward(gradOutput, maxIndices, inputShape, poolSize, stride);
    }

    /// <inheritdoc/>
    public Tensor<T> AvgPool3D<T>(Tensor<T> input, int poolSize, int stride = 0, int padding = 0)
    {
        if (stride == 0) stride = poolSize;
        return AvgPool3D(input, [poolSize, poolSize, poolSize], [stride, stride, stride], [padding, padding, padding]);
    }

    /// <inheritdoc/>
    public Tensor<T> AvgPool3D<T>(Tensor<T> input, int[] poolSize, int[] stride, int[] padding)
    {
        // Validate array parameter lengths
        if (poolSize == null || poolSize.Length != 3)
            throw new ArgumentException("poolSize array must have exactly 3 elements (D, H, W).", nameof(poolSize));
        if (stride == null || stride.Length != 3)
            throw new ArgumentException("stride array must have exactly 3 elements (D, H, W).", nameof(stride));
        if (padding == null || padding.Length != 3)
            throw new ArgumentException("padding array must have exactly 3 elements (D, H, W).", nameof(padding));

        // Adaptive execution
        if (input.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.AvgPool3D(input, poolSize, stride, padding);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)AvgPool3DGpu((Tensor<float>)(object)input, poolSize, stride, padding);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)AvgPool3DGpuDouble((Tensor<double>)(object)input, poolSize, stride, padding);
        }

        return _cpuFallback.AvgPool3D(input, poolSize, stride, padding);
    }

    private Tensor<float> AvgPool3DGpu(Tensor<float> input, int[] poolSize, int[] stride, int[] padding)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (input.Rank != 5) throw new ArgumentException($"AvgPool3D requires 5D tensor. Got rank {input.Rank}.");

        int batch = input.Shape[0];
        int channels = input.Shape[1];
        int depth = input.Shape[2];
        int height = input.Shape[3];
        int width = input.Shape[4];

        int outputDepth = (depth + 2 * padding[0] - poolSize[0]) / stride[0] + 1;
        int outputHeight = (height + 2 * padding[1] - poolSize[1]) / stride[1] + 1;
        int outputWidth = (width + 2 * padding[2] - poolSize[2]) / stride[2] + 1;

        // Check for potential overflow using long arithmetic
        long outputSizeLong = (long)batch * channels * outputDepth * outputHeight * outputWidth;
        if (outputSizeLong > int.MaxValue)
        {
            throw new ArgumentException($"Output tensor size ({outputSizeLong}) exceeds maximum supported size ({int.MaxValue}).");
        }
        int outputSize = (int)outputSizeLong;

        try
        {
            var result = new Tensor<float>(new[] { batch, channels, outputDepth, outputHeight, outputWidth });

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    var parameters = new Pool3DParams(batch, channels, depth, height, width,
                        outputDepth, outputHeight, outputWidth,
                        poolSize[0], poolSize[1], poolSize[2],
                        stride[0], stride[1], stride[2],
                        padding[0], padding[1], padding[2]);
                    (_avgPool3DKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuInput.View, gpuOutput.View, parameters);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU AvgPool3D failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.AvgPool3D(input, poolSize, stride, padding);
        }
    }

    private Tensor<double> AvgPool3DGpuDouble(Tensor<double> input, int[] poolSize, int[] stride, int[] padding)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (input.Rank != 5) throw new ArgumentException($"AvgPool3D requires 5D tensor. Got rank {input.Rank}.");

        int batch = input.Shape[0];
        int channels = input.Shape[1];
        int depth = input.Shape[2];
        int height = input.Shape[3];
        int width = input.Shape[4];

        int outputDepth = (depth + 2 * padding[0] - poolSize[0]) / stride[0] + 1;
        int outputHeight = (height + 2 * padding[1] - poolSize[1]) / stride[1] + 1;
        int outputWidth = (width + 2 * padding[2] - poolSize[2]) / stride[2] + 1;

        try
        {
            var result = new Tensor<double>(new[] { batch, channels, outputDepth, outputHeight, outputWidth });
            int outputSize = batch * channels * outputDepth * outputHeight * outputWidth;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    var parameters = new Pool3DParams(batch, channels, depth, height, width,
                        outputDepth, outputHeight, outputWidth,
                        poolSize[0], poolSize[1], poolSize[2],
                        stride[0], stride[1], stride[2],
                        padding[0], padding[1], padding[2]);
                    (_avgPool3DKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuInput.View, gpuOutput.View, parameters);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU AvgPool3D double failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.AvgPool3D(input, poolSize, stride, padding);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> AvgPool3DBackward<T>(Tensor<T> gradOutput, int[] inputShape, int[] poolSize, int[] stride, int[] padding)
    {
        // AvgPool3DBackward GPU kernels not yet implemented - use CPU fallback
        return _cpuFallback.AvgPool3DBackward(gradOutput, inputShape, poolSize, stride, padding);
    }

    /// <inheritdoc/>
    public Tensor<T> Upsample3D<T>(Tensor<T> input, int scaleD, int scaleH, int scaleW)
    {
        // Upsample3D GPU kernels not yet implemented - use CPU fallback
        return _cpuFallback.Upsample3D(input, scaleD, scaleH, scaleW);
    }

    /// <inheritdoc/>
    public Tensor<T> Upsample3DBackward<T>(Tensor<T> gradOutput, int[] inputShape, int scaleD, int scaleH, int scaleW)
    {
        // Upsample3DBackward GPU kernels not yet implemented - use CPU fallback
        return _cpuFallback.Upsample3DBackward(gradOutput, inputShape, scaleD, scaleH, scaleW);
    }

    /// <inheritdoc/>
    public Tensor<T> ConvTranspose3D<T>(Tensor<T> input, Tensor<T> kernel, int[] stride, int[] padding, int[] outputPadding)
    {
        // ConvTranspose3D GPU kernels not yet implemented - use CPU fallback
        return _cpuFallback.ConvTranspose3D(input, kernel, stride, padding, outputPadding);
    }

    /// <inheritdoc/>
    public Tensor<T> ConvTranspose3DBackwardInput<T>(Tensor<T> gradOutput, Tensor<T> kernel, int[] inputShape, int[] stride, int[] padding)
    {
        // ConvTranspose3DBackwardInput GPU kernels not yet implemented - use CPU fallback
        return _cpuFallback.ConvTranspose3DBackwardInput(gradOutput, kernel, inputShape, stride, padding);
    }

    /// <inheritdoc/>
    public Tensor<T> ConvTranspose3DBackwardKernel<T>(Tensor<T> gradOutput, Tensor<T> input, int[] kernelShape, int[] stride, int[] padding)
    {
        // ConvTranspose3DBackwardKernel GPU kernels not yet implemented - use CPU fallback
        return _cpuFallback.ConvTranspose3DBackwardKernel(gradOutput, input, kernelShape, stride, padding);
    }

    #endregion

    #region Normalization and Activation Operations (Extended)

    /// <inheritdoc/>
    public Tensor<T> Softmax<T>(Tensor<T> input, int axis = -1)
    {
        // Normalize axis
        int rank = input.Rank;
        if (axis < 0) axis = rank + axis;

        // Threshold check - small tensors use CPU
        if (input.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.Softmax(input, axis);
        }

        // GPU acceleration for supported types
        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)SoftmaxGpu((Tensor<float>)(object)input, axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)SoftmaxGpuDouble((Tensor<double>)(object)input, axis);
        }

        return _cpuFallback.Softmax(input, axis);
    }

    private Tensor<float> SoftmaxGpu(Tensor<float> input, int axis)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            // Compute outerSize, axisSize, innerSize for strided memory access
            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<float>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_tensorSoftmaxKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuInput.View, gpuOutput.View, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU softmax failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Softmax(input, axis);
        }
    }

    private Tensor<double> SoftmaxGpuDouble(Tensor<double> input, int axis)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<double>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_tensorSoftmaxKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuInput.View, gpuOutput.View, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU softmax (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Softmax(input, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> SoftmaxBackward<T>(Tensor<T> gradOutput, Tensor<T> output, int axis = -1)
    {
        if (gradOutput == null) throw new ArgumentNullException(nameof(gradOutput));
        if (output == null) throw new ArgumentNullException(nameof(output));

        var shape = gradOutput.Shape;
        int rank = shape.Length;
        if (axis < 0) axis = rank + axis;

        // Calculate outer, axis, inner sizes for generalized axis handling
        int outerSize = 1;
        for (int i = 0; i < axis; i++) outerSize *= shape[i];
        int axisSize = shape[axis];
        int innerSize = 1;
        for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

        int numElements = outerSize * innerSize;

        if (numElements < _thresholds.VectorAdd || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.SoftmaxBackward(gradOutput, output, axis);
        }

        if (typeof(T) == typeof(float))
            return (Tensor<T>)(object)SoftmaxBackwardGpuFloat((Tensor<float>)(object)gradOutput, (Tensor<float>)(object)output, outerSize, axisSize, innerSize);
        if (typeof(T) == typeof(double))
            return (Tensor<T>)(object)SoftmaxBackwardGpuDouble((Tensor<double>)(object)gradOutput, (Tensor<double>)(object)output, outerSize, axisSize, innerSize);

        return _cpuFallback.SoftmaxBackward(gradOutput, output, axis);
    }

    private Tensor<float> SoftmaxBackwardGpuFloat(Tensor<float> gradOutput, Tensor<float> output, int outerSize, int axisSize, int innerSize)
    {
        int totalSize = gradOutput.Length;
        var result = new Tensor<float>(gradOutput.Shape);
        int numWorkItems = outerSize * innerSize;

        var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
        var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
        var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);

        try
        {
            gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
            gpuOutput.View.BaseView.CopyFromCPU(output.AsSpan());

            lock (_gpuLock)
            {
                (_softmaxBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    numWorkItems, gpuGradOutput.View, gpuOutput.View, gpuGradInput.View, outerSize, axisSize, innerSize);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU SoftmaxBackward (float) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.SoftmaxBackward(gradOutput, output, -1);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuGradOutput);
            _memoryPoolFloat.Return(gpuOutput);
            _memoryPoolFloat.Return(gpuGradInput);
        }
    }

    private Tensor<double> SoftmaxBackwardGpuDouble(Tensor<double> gradOutput, Tensor<double> output, int outerSize, int axisSize, int innerSize)
    {
        int totalSize = gradOutput.Length;
        var result = new Tensor<double>(gradOutput.Shape);
        int numWorkItems = outerSize * innerSize;

        var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
        var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
        var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);

        try
        {
            gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
            gpuOutput.View.BaseView.CopyFromCPU(output.AsSpan());

            lock (_gpuLock)
            {
                (_softmaxBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    numWorkItems, gpuGradOutput.View, gpuOutput.View, gpuGradInput.View, outerSize, axisSize, innerSize);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU SoftmaxBackward (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.SoftmaxBackward(gradOutput, output, -1);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuGradOutput);
            _memoryPoolDouble.Return(gpuOutput);
            _memoryPoolDouble.Return(gpuGradInput);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> GumbelSoftmax<T>(Tensor<T> input, double temperature = 1.0, bool hard = false, int axis = -1)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (temperature <= 0)
            throw new ArgumentOutOfRangeException(nameof(temperature), temperature, "Temperature must be positive.");
        if (double.IsNaN(temperature) || double.IsInfinity(temperature))
            throw new ArgumentOutOfRangeException(nameof(temperature), temperature, "Temperature must be a finite number.");

        int rank = input.Rank;
        if (axis < 0) axis = rank + axis;

        // Small tensors use CPU
        if (input.Length < _thresholds.VectorAdd || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.GumbelSoftmax(input, temperature, hard, axis);
        }

        if (typeof(T) == typeof(float))
            return (Tensor<T>)(object)GumbelSoftmaxGpuFloat((Tensor<float>)(object)input, (float)temperature, hard, axis);
        if (typeof(T) == typeof(double))
            return (Tensor<T>)(object)GumbelSoftmaxGpuDouble((Tensor<double>)(object)input, temperature, hard, axis);

        return _cpuFallback.GumbelSoftmax(input, temperature, hard, axis);
    }

    private Tensor<float> GumbelSoftmaxGpuFloat(Tensor<float> input, float temperature, bool hard, int axis)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<float>(shape);
            int numWorkItems = outerSize * innerSize;

            // Generate Gumbel noise on CPU (random number generation not well-suited for GPU)
            var gumbelNoise = new float[input.Length];
            var random = RandomHelper.ThreadSafeRandom;
            const float eps = 1e-10f;
            for (int i = 0; i < gumbelNoise.Length; i++)
            {
                var u = (float)random.NextDouble();
                u = Math.Max(u, eps);
                u = Math.Min(u, 1 - eps);
                gumbelNoise[i] = -(float)Math.Log(-Math.Log(u));
            }

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuNoise = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuNoise.View.BaseView.CopyFromCPU(gumbelNoise);

                lock (_gpuLock)
                {
                    (_gumbelSoftmaxKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuInput.View, gpuNoise.View, gpuOutput.View, temperature, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());

                if (hard)
                {
                    // Apply hard one-hot on CPU (argmax + one-hot creation)
                    var resultData = result.AsWritableSpan();
                    for (int outer = 0; outer < outerSize; outer++)
                    {
                        for (int inner = 0; inner < innerSize; inner++)
                        {
                            // Find argmax
                            int maxIdx = 0;
                            float maxVal = resultData[(outer * axisSize) * innerSize + inner];
                            for (int i = 1; i < axisSize; i++)
                            {
                                int flatIdx = (outer * axisSize + i) * innerSize + inner;
                                if (resultData[flatIdx] > maxVal)
                                {
                                    maxVal = resultData[flatIdx];
                                    maxIdx = i;
                                }
                            }

                            // Create one-hot
                            for (int i = 0; i < axisSize; i++)
                            {
                                int flatIdx = (outer * axisSize + i) * innerSize + inner;
                                resultData[flatIdx] = i == maxIdx ? 1.0f : 0.0f;
                            }
                        }
                    }
                }

                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuNoise);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU GumbelSoftmax (float) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.GumbelSoftmax(input, temperature, hard, axis);
        }
    }

    private Tensor<double> GumbelSoftmaxGpuDouble(Tensor<double> input, double temperature, bool hard, int axis)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<double>(shape);
            int numWorkItems = outerSize * innerSize;

            var gumbelNoise = new double[input.Length];
            var random = RandomHelper.ThreadSafeRandom;
            const double eps = 1e-10;
            for (int i = 0; i < gumbelNoise.Length; i++)
            {
                var u = random.NextDouble();
                u = Math.Max(u, eps);
                u = Math.Min(u, 1 - eps);
                gumbelNoise[i] = -Math.Log(-Math.Log(u));
            }

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuNoise = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuNoise.View.BaseView.CopyFromCPU(gumbelNoise);

                lock (_gpuLock)
                {
                    (_gumbelSoftmaxKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuInput.View, gpuNoise.View, gpuOutput.View, temperature, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());

                if (hard)
                {
                    var resultData = result.AsWritableSpan();
                    for (int outer = 0; outer < outerSize; outer++)
                    {
                        for (int inner = 0; inner < innerSize; inner++)
                        {
                            int maxIdx = 0;
                            double maxVal = resultData[(outer * axisSize) * innerSize + inner];
                            for (int i = 1; i < axisSize; i++)
                            {
                                int flatIdx = (outer * axisSize + i) * innerSize + inner;
                                if (resultData[flatIdx] > maxVal)
                                {
                                    maxVal = resultData[flatIdx];
                                    maxIdx = i;
                                }
                            }

                            for (int i = 0; i < axisSize; i++)
                            {
                                int flatIdx = (outer * axisSize + i) * innerSize + inner;
                                resultData[flatIdx] = i == maxIdx ? 1.0 : 0.0;
                            }
                        }
                    }
                }

                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuNoise);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU GumbelSoftmax (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.GumbelSoftmax(input, temperature, hard, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> GumbelSoftmaxBackward<T>(Tensor<T> gradOutput, Tensor<T> output, double temperature, int axis = -1)
    {
        if (gradOutput == null) throw new ArgumentNullException(nameof(gradOutput));
        if (output == null) throw new ArgumentNullException(nameof(output));
        if (temperature <= 0)
            throw new ArgumentOutOfRangeException(nameof(temperature), temperature, "Temperature must be positive.");

        int rank = output.Rank;
        if (axis < 0) axis = rank + axis;

        if (output.Length < _thresholds.VectorAdd || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.GumbelSoftmaxBackward(gradOutput, output, temperature, axis);
        }

        if (typeof(T) == typeof(float))
            return (Tensor<T>)(object)GumbelSoftmaxBackwardGpuFloat((Tensor<float>)(object)gradOutput, (Tensor<float>)(object)output, (float)temperature, axis);
        if (typeof(T) == typeof(double))
            return (Tensor<T>)(object)GumbelSoftmaxBackwardGpuDouble((Tensor<double>)(object)gradOutput, (Tensor<double>)(object)output, temperature, axis);

        return _cpuFallback.GumbelSoftmaxBackward(gradOutput, output, temperature, axis);
    }

    private Tensor<float> GumbelSoftmaxBackwardGpuFloat(Tensor<float> gradOutput, Tensor<float> output, float temperature, int axis)
    {
        try
        {
            var shape = output.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<float>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuOutput.View.BaseView.CopyFromCPU(output.AsSpan());

                lock (_gpuLock)
                {
                    (_gumbelSoftmaxBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuGradOutput.View, gpuOutput.View, gpuGradInput.View, temperature, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuOutput);
                _memoryPoolFloat.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU GumbelSoftmaxBackward (float) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.GumbelSoftmaxBackward(gradOutput, output, temperature, axis);
        }
    }

    private Tensor<double> GumbelSoftmaxBackwardGpuDouble(Tensor<double> gradOutput, Tensor<double> output, double temperature, int axis)
    {
        try
        {
            var shape = output.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<double>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuOutput.View.BaseView.CopyFromCPU(output.AsSpan());

                lock (_gpuLock)
                {
                    (_gumbelSoftmaxBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuGradOutput.View, gpuOutput.View, gpuGradInput.View, temperature, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuOutput);
                _memoryPoolDouble.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU GumbelSoftmaxBackward (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.GumbelSoftmaxBackward(gradOutput, output, temperature, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TaylorSoftmax<T>(Tensor<T> input, int order = 2, int axis = -1)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (order < 1)
            throw new ArgumentOutOfRangeException(nameof(order), order, "Order must be at least 1.");

        int rank = input.Rank;
        if (axis < 0) axis = rank + axis;

        if (input.Length < _thresholds.VectorAdd || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.TaylorSoftmax(input, order, axis);
        }

        if (typeof(T) == typeof(float))
            return (Tensor<T>)(object)TaylorSoftmaxGpuFloat((Tensor<float>)(object)input, order, axis);
        if (typeof(T) == typeof(double))
            return (Tensor<T>)(object)TaylorSoftmaxGpuDouble((Tensor<double>)(object)input, order, axis);

        return _cpuFallback.TaylorSoftmax(input, order, axis);
    }

    private Tensor<float> TaylorSoftmaxGpuFloat(Tensor<float> input, int order, int axis)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<float>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_taylorSoftmaxKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuInput.View, gpuOutput.View, order, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU TaylorSoftmax (float) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TaylorSoftmax(input, order, axis);
        }
    }

    private Tensor<double> TaylorSoftmaxGpuDouble(Tensor<double> input, int order, int axis)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<double>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_taylorSoftmaxKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuInput.View, gpuOutput.View, order, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU TaylorSoftmax (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TaylorSoftmax(input, order, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TaylorSoftmaxBackward<T>(Tensor<T> gradOutput, Tensor<T> input, Tensor<T> output, int order, int axis = -1)
    {
        if (gradOutput == null) throw new ArgumentNullException(nameof(gradOutput));
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (output == null) throw new ArgumentNullException(nameof(output));

        int rank = output.Rank;
        if (axis < 0) axis = rank + axis;

        if (output.Length < _thresholds.VectorAdd || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.TaylorSoftmaxBackward(gradOutput, input, output, order, axis);
        }

        if (typeof(T) == typeof(float))
            return (Tensor<T>)(object)TaylorSoftmaxBackwardGpuFloat((Tensor<float>)(object)gradOutput, (Tensor<float>)(object)input, (Tensor<float>)(object)output, order, axis);
        if (typeof(T) == typeof(double))
            return (Tensor<T>)(object)TaylorSoftmaxBackwardGpuDouble((Tensor<double>)(object)gradOutput, (Tensor<double>)(object)input, (Tensor<double>)(object)output, order, axis);

        return _cpuFallback.TaylorSoftmaxBackward(gradOutput, input, output, order, axis);
    }

    private Tensor<float> TaylorSoftmaxBackwardGpuFloat(Tensor<float> gradOutput, Tensor<float> input, Tensor<float> output, int order, int axis)
    {
        try
        {
            var shape = output.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<float>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuOutput.View.BaseView.CopyFromCPU(output.AsSpan());

                lock (_gpuLock)
                {
                    (_taylorSoftmaxBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuGradOutput.View, gpuInput.View, gpuOutput.View, gpuGradInput.View, order, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
                _memoryPoolFloat.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU TaylorSoftmaxBackward (float) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TaylorSoftmaxBackward(gradOutput, input, output, order, axis);
        }
    }

    private Tensor<double> TaylorSoftmaxBackwardGpuDouble(Tensor<double> gradOutput, Tensor<double> input, Tensor<double> output, int order, int axis)
    {
        try
        {
            var shape = output.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<double>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuOutput.View.BaseView.CopyFromCPU(output.AsSpan());

                lock (_gpuLock)
                {
                    (_taylorSoftmaxBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuGradOutput.View, gpuInput.View, gpuOutput.View, gpuGradInput.View, order, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
                _memoryPoolDouble.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU TaylorSoftmaxBackward (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TaylorSoftmaxBackward(gradOutput, input, output, order, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> Sparsemax<T>(Tensor<T> input, int axis = -1)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));

        int rank = input.Rank;
        if (axis < 0) axis = rank + axis;

        if (input.Length < _thresholds.VectorAdd || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.Sparsemax(input, axis);
        }

        if (typeof(T) == typeof(float))
            return (Tensor<T>)(object)SparsemaxGpuFloat((Tensor<float>)(object)input, axis);
        if (typeof(T) == typeof(double))
            return (Tensor<T>)(object)SparsemaxGpuDouble((Tensor<double>)(object)input, axis);

        return _cpuFallback.Sparsemax(input, axis);
    }

    private Tensor<float> SparsemaxGpuFloat(Tensor<float> input, int axis)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<float>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_sparsemaxKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuInput.View, gpuOutput.View, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Sparsemax (float) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Sparsemax(input, axis);
        }
    }

    private Tensor<double> SparsemaxGpuDouble(Tensor<double> input, int axis)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<double>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_sparsemaxKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuInput.View, gpuOutput.View, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Sparsemax (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Sparsemax(input, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> SparsemaxBackward<T>(Tensor<T> gradOutput, Tensor<T> output, int axis = -1)
    {
        if (gradOutput == null) throw new ArgumentNullException(nameof(gradOutput));
        if (output == null) throw new ArgumentNullException(nameof(output));

        int rank = output.Rank;
        if (axis < 0) axis = rank + axis;

        if (output.Length < _thresholds.VectorAdd || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.SparsemaxBackward(gradOutput, output, axis);
        }

        if (typeof(T) == typeof(float))
            return (Tensor<T>)(object)SparsemaxBackwardGpuFloat((Tensor<float>)(object)gradOutput, (Tensor<float>)(object)output, axis);
        if (typeof(T) == typeof(double))
            return (Tensor<T>)(object)SparsemaxBackwardGpuDouble((Tensor<double>)(object)gradOutput, (Tensor<double>)(object)output, axis);

        return _cpuFallback.SparsemaxBackward(gradOutput, output, axis);
    }

    private Tensor<float> SparsemaxBackwardGpuFloat(Tensor<float> gradOutput, Tensor<float> output, int axis)
    {
        try
        {
            var shape = output.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<float>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuOutput.View.BaseView.CopyFromCPU(output.AsSpan());

                lock (_gpuLock)
                {
                    (_sparsemaxBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuGradOutput.View, gpuOutput.View, gpuGradInput.View, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuOutput);
                _memoryPoolFloat.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU SparsemaxBackward (float) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.SparsemaxBackward(gradOutput, output, axis);
        }
    }

    private Tensor<double> SparsemaxBackwardGpuDouble(Tensor<double> gradOutput, Tensor<double> output, int axis)
    {
        try
        {
            var shape = output.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<double>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuOutput.View.BaseView.CopyFromCPU(output.AsSpan());

                lock (_gpuLock)
                {
                    (_sparsemaxBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuGradOutput.View, gpuOutput.View, gpuGradInput.View, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuOutput);
                _memoryPoolDouble.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU SparsemaxBackward (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.SparsemaxBackward(gradOutput, output, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> SphericalSoftmax<T>(Tensor<T> input, int axis = -1)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));

        int rank = input.Rank;
        if (axis < 0) axis = rank + axis;

        if (input.Length < _thresholds.VectorAdd || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.SphericalSoftmax(input, axis);
        }

        if (typeof(T) == typeof(float))
            return (Tensor<T>)(object)SphericalSoftmaxGpuFloat((Tensor<float>)(object)input, axis);
        if (typeof(T) == typeof(double))
            return (Tensor<T>)(object)SphericalSoftmaxGpuDouble((Tensor<double>)(object)input, axis);

        return _cpuFallback.SphericalSoftmax(input, axis);
    }

    private Tensor<float> SphericalSoftmaxGpuFloat(Tensor<float> input, int axis)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<float>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_sphericalSoftmaxKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuInput.View, gpuOutput.View, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU SphericalSoftmax (float) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.SphericalSoftmax(input, axis);
        }
    }

    private Tensor<double> SphericalSoftmaxGpuDouble(Tensor<double> input, int axis)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<double>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_sphericalSoftmaxKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuInput.View, gpuOutput.View, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU SphericalSoftmax (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.SphericalSoftmax(input, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> SphericalSoftmaxBackward<T>(Tensor<T> gradOutput, Tensor<T> input, Tensor<T> output, int axis = -1)
    {
        if (gradOutput == null) throw new ArgumentNullException(nameof(gradOutput));
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (output == null) throw new ArgumentNullException(nameof(output));

        int rank = output.Rank;
        if (axis < 0) axis = rank + axis;

        if (output.Length < _thresholds.VectorAdd || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.SphericalSoftmaxBackward(gradOutput, input, output, axis);
        }

        if (typeof(T) == typeof(float))
            return (Tensor<T>)(object)SphericalSoftmaxBackwardGpuFloat((Tensor<float>)(object)gradOutput, (Tensor<float>)(object)input, (Tensor<float>)(object)output, axis);
        if (typeof(T) == typeof(double))
            return (Tensor<T>)(object)SphericalSoftmaxBackwardGpuDouble((Tensor<double>)(object)gradOutput, (Tensor<double>)(object)input, (Tensor<double>)(object)output, axis);

        return _cpuFallback.SphericalSoftmaxBackward(gradOutput, input, output, axis);
    }

    private Tensor<float> SphericalSoftmaxBackwardGpuFloat(Tensor<float> gradOutput, Tensor<float> input, Tensor<float> output, int axis)
    {
        try
        {
            var shape = output.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<float>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuOutput.View.BaseView.CopyFromCPU(output.AsSpan());

                lock (_gpuLock)
                {
                    (_sphericalSoftmaxBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuGradOutput.View, gpuInput.View, gpuOutput.View, gpuGradInput.View, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
                _memoryPoolFloat.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU SphericalSoftmaxBackward (float) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.SphericalSoftmaxBackward(gradOutput, input, output, axis);
        }
    }

    private Tensor<double> SphericalSoftmaxBackwardGpuDouble(Tensor<double> gradOutput, Tensor<double> input, Tensor<double> output, int axis)
    {
        try
        {
            var shape = output.Shape;
            int rank = shape.Length;

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var result = new Tensor<double>(shape);
            int numWorkItems = outerSize * innerSize;

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);
            var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(output.Length);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuOutput.View.BaseView.CopyFromCPU(output.AsSpan());

                lock (_gpuLock)
                {
                    (_sphericalSoftmaxBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numWorkItems, gpuGradOutput.View, gpuInput.View, gpuOutput.View, gpuGradInput.View, outerSize, axisSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
                _memoryPoolDouble.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU SphericalSoftmaxBackward (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.SphericalSoftmaxBackward(gradOutput, input, output, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> BatchNorm<T>(Tensor<T> input, Tensor<T> gamma, Tensor<T> beta, double epsilon, out Tensor<T> mean, out Tensor<T> variance)
    {
        // Compute statistics on CPU, then apply normalization on GPU if beneficial
        if (input.Length < _thresholds.VectorAdd || input.Rank != 2)
        {
            return _cpuFallback.BatchNorm(input, gamma, beta, epsilon, out mean, out variance);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var result = BatchNormGpu((Tensor<float>)(object)input, (Tensor<float>)(object)gamma,
                    (Tensor<float>)(object)beta, (float)epsilon, out var meanF, out var varF);
                mean = (Tensor<T>)(object)meanF;
                variance = (Tensor<T>)(object)varF;
                return (Tensor<T>)(object)result;
            }
            if (typeof(T) == typeof(double))
            {
                var result = BatchNormGpuDouble((Tensor<double>)(object)input, (Tensor<double>)(object)gamma,
                    (Tensor<double>)(object)beta, epsilon, out var meanD, out var varD);
                mean = (Tensor<T>)(object)meanD;
                variance = (Tensor<T>)(object)varD;
                return (Tensor<T>)(object)result;
            }
        }

        return _cpuFallback.BatchNorm(input, gamma, beta, epsilon, out mean, out variance);
    }

    private Tensor<float> BatchNormGpu(Tensor<float> input, Tensor<float> gamma, Tensor<float> beta, float epsilon, out Tensor<float> mean, out Tensor<float> variance)
    {
        int batch = input.Shape[0];
        int features = input.Shape[1];

        // Compute mean and variance on CPU (reduction operations)
        var meanData = new float[features];
        var varData = new float[features];
        var inputData = input.AsSpan().ToArray();

        for (int f = 0; f < features; f++)
        {
            float sum = 0;
            for (int b = 0; b < batch; b++)
                sum += inputData[b * features + f];
            meanData[f] = sum / batch;
        }

        for (int f = 0; f < features; f++)
        {
            float sumSq = 0;
            for (int b = 0; b < batch; b++)
            {
                float diff = inputData[b * features + f] - meanData[f];
                sumSq += diff * diff;
            }
            varData[f] = sumSq / batch;
        }

        mean = new Tensor<float>([features], new Vector<float>(meanData));
        variance = new Tensor<float>([features], new Vector<float>(varData));

        try
        {
            var result = new Tensor<float>(input.Shape);

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuGamma = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(features);
            var gpuBeta = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(features);
            var gpuMean = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(features);
            var gpuVar = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(features);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuGamma.View.BaseView.CopyFromCPU(gamma.AsSpan());
                gpuBeta.View.BaseView.CopyFromCPU(beta.AsSpan());
                gpuMean.View.BaseView.CopyFromCPU(meanData);
                gpuVar.View.BaseView.CopyFromCPU(varData);

                lock (_gpuLock)
                {
                    (_batchNormKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        input.Length, gpuInput.View, gpuOutput.View, gpuGamma.View, gpuBeta.View,
                        gpuMean.View, gpuVar.View, epsilon, batch, features);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
                _memoryPoolFloat.Return(gpuGamma);
                _memoryPoolFloat.Return(gpuBeta);
                _memoryPoolFloat.Return(gpuMean);
                _memoryPoolFloat.Return(gpuVar);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU batch norm failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.BatchNorm(input, gamma, beta, epsilon, out mean, out variance);
        }
    }

    private Tensor<double> BatchNormGpuDouble(Tensor<double> input, Tensor<double> gamma, Tensor<double> beta, double epsilon, out Tensor<double> mean, out Tensor<double> variance)
    {
        int batch = input.Shape[0];
        int features = input.Shape[1];

        var meanData = new double[features];
        var varData = new double[features];
        var inputData = input.AsSpan().ToArray();

        for (int f = 0; f < features; f++)
        {
            double sum = 0;
            for (int b = 0; b < batch; b++)
                sum += inputData[b * features + f];
            meanData[f] = sum / batch;
        }

        for (int f = 0; f < features; f++)
        {
            double sumSq = 0;
            for (int b = 0; b < batch; b++)
            {
                double diff = inputData[b * features + f] - meanData[f];
                sumSq += diff * diff;
            }
            varData[f] = sumSq / batch;
        }

        mean = new Tensor<double>([features], new Vector<double>(meanData));
        variance = new Tensor<double>([features], new Vector<double>(varData));

        try
        {
            var result = new Tensor<double>(input.Shape);

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuGamma = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(features);
            var gpuBeta = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(features);
            var gpuMean = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(features);
            var gpuVar = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(features);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuGamma.View.BaseView.CopyFromCPU(gamma.AsSpan());
                gpuBeta.View.BaseView.CopyFromCPU(beta.AsSpan());
                gpuMean.View.BaseView.CopyFromCPU(meanData);
                gpuVar.View.BaseView.CopyFromCPU(varData);

                lock (_gpuLock)
                {
                    (_batchNormKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        input.Length, gpuInput.View, gpuOutput.View, gpuGamma.View, gpuBeta.View,
                        gpuMean.View, gpuVar.View, epsilon, batch, features);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
                _memoryPoolDouble.Return(gpuGamma);
                _memoryPoolDouble.Return(gpuBeta);
                _memoryPoolDouble.Return(gpuMean);
                _memoryPoolDouble.Return(gpuVar);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU batch norm (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.BatchNorm(input, gamma, beta, epsilon, out mean, out variance);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> BatchNormBackward<T>(Tensor<T> gradOutput, Tensor<T> input, Tensor<T> gamma, Tensor<T> mean, Tensor<T> variance, double epsilon, out Tensor<T> gradGamma, out Tensor<T> gradBeta)
    {
        if (gradOutput.Length < _thresholds.VectorAdd || gradOutput.Rank != 2)
            return _cpuFallback.BatchNormBackward(gradOutput, input, gamma, mean, variance, epsilon, out gradGamma, out gradBeta);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var result = BatchNormBackwardGpu(
                    (Tensor<float>)(object)gradOutput, (Tensor<float>)(object)input,
                    (Tensor<float>)(object)gamma, (Tensor<float>)(object)mean,
                    (Tensor<float>)(object)variance, (float)epsilon,
                    out var gradGammaF, out var gradBetaF);
                gradGamma = (Tensor<T>)(object)gradGammaF;
                gradBeta = (Tensor<T>)(object)gradBetaF;
                return (Tensor<T>)(object)result;
            }
            if (typeof(T) == typeof(double))
            {
                var result = BatchNormBackwardGpuDouble(
                    (Tensor<double>)(object)gradOutput, (Tensor<double>)(object)input,
                    (Tensor<double>)(object)gamma, (Tensor<double>)(object)mean,
                    (Tensor<double>)(object)variance, epsilon,
                    out var gradGammaD, out var gradBetaD);
                gradGamma = (Tensor<T>)(object)gradGammaD;
                gradBeta = (Tensor<T>)(object)gradBetaD;
                return (Tensor<T>)(object)result;
            }
        }
        return _cpuFallback.BatchNormBackward(gradOutput, input, gamma, mean, variance, epsilon, out gradGamma, out gradBeta);
    }

    private Tensor<float> BatchNormBackwardGpu(Tensor<float> gradOutput, Tensor<float> input, Tensor<float> gamma, Tensor<float> mean, Tensor<float> variance, float epsilon, out Tensor<float> gradGamma, out Tensor<float> gradBeta)
    {
        try
        {
            var shape = input.Shape;
            int batchSize = shape[0], featureSize = shape[1];
            int totalSize = batchSize * featureSize;

            var gradInput = new Tensor<float>(shape);
            gradGamma = new Tensor<float>([featureSize]);
            gradBeta = new Tensor<float>([featureSize]);

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
            var gpuGamma = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);
            var gpuMean = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);
            var gpuVariance = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);
            var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
            var gpuGradGamma = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);
            var gpuGradBeta = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuGamma.View.BaseView.CopyFromCPU(gamma.AsSpan());
                gpuMean.View.BaseView.CopyFromCPU(mean.AsSpan());
                gpuVariance.View.BaseView.CopyFromCPU(variance.AsSpan());
                // Initialize gradGamma and gradBeta to zero
                gpuGradGamma.View.BaseView.CopyFromCPU(new float[featureSize]);
                gpuGradBeta.View.BaseView.CopyFromCPU(new float[featureSize]);

                lock (_gpuLock)
                {
                    (_batchNormBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalSize, gpuGradOutput.View, gpuInput.View, gpuGamma.View, gpuMean.View, gpuVariance.View,
                        gpuGradInput.View, gpuGradGamma.View, gpuGradBeta.View, epsilon, batchSize, featureSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(gradInput.AsWritableSpan());
                gpuGradGamma.View.BaseView.CopyToCPU(gradGamma.AsWritableSpan());
                gpuGradBeta.View.BaseView.CopyToCPU(gradBeta.AsWritableSpan());
                return gradInput;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuGamma);
                _memoryPoolFloat.Return(gpuMean);
                _memoryPoolFloat.Return(gpuVariance);
                _memoryPoolFloat.Return(gpuGradInput);
                _memoryPoolFloat.Return(gpuGradGamma);
                _memoryPoolFloat.Return(gpuGradBeta);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU BatchNormBackward failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.BatchNormBackward(gradOutput, input, gamma, mean, variance, epsilon, out gradGamma, out gradBeta);
        }
    }

    private Tensor<double> BatchNormBackwardGpuDouble(Tensor<double> gradOutput, Tensor<double> input, Tensor<double> gamma, Tensor<double> mean, Tensor<double> variance, double epsilon, out Tensor<double> gradGamma, out Tensor<double> gradBeta)
    {
        try
        {
            var shape = input.Shape;
            int batchSize = shape[0], featureSize = shape[1];
            int totalSize = batchSize * featureSize;

            var gradInput = new Tensor<double>(shape);
            gradGamma = new Tensor<double>([featureSize]);
            gradBeta = new Tensor<double>([featureSize]);

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
            var gpuGamma = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);
            var gpuMean = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);
            var gpuVariance = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);
            var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
            var gpuGradGamma = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);
            var gpuGradBeta = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuGamma.View.BaseView.CopyFromCPU(gamma.AsSpan());
                gpuMean.View.BaseView.CopyFromCPU(mean.AsSpan());
                gpuVariance.View.BaseView.CopyFromCPU(variance.AsSpan());
                gpuGradGamma.View.BaseView.CopyFromCPU(new double[featureSize]);
                gpuGradBeta.View.BaseView.CopyFromCPU(new double[featureSize]);

                lock (_gpuLock)
                {
                    (_batchNormBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalSize, gpuGradOutput.View, gpuInput.View, gpuGamma.View, gpuMean.View, gpuVariance.View,
                        gpuGradInput.View, gpuGradGamma.View, gpuGradBeta.View, epsilon, batchSize, featureSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(gradInput.AsWritableSpan());
                gpuGradGamma.View.BaseView.CopyToCPU(gradGamma.AsWritableSpan());
                gpuGradBeta.View.BaseView.CopyToCPU(gradBeta.AsWritableSpan());
                return gradInput;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuGamma);
                _memoryPoolDouble.Return(gpuMean);
                _memoryPoolDouble.Return(gpuVariance);
                _memoryPoolDouble.Return(gpuGradInput);
                _memoryPoolDouble.Return(gpuGradGamma);
                _memoryPoolDouble.Return(gpuGradBeta);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU BatchNormBackward (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.BatchNormBackward(gradOutput, input, gamma, mean, variance, epsilon, out gradGamma, out gradBeta);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> LayerNorm<T>(Tensor<T> input, Tensor<T> gamma, Tensor<T> beta, double epsilon, out Tensor<T> mean, out Tensor<T> variance)
    {
        if (input.Length < _thresholds.VectorAdd || input.Rank != 2)
        {
            return _cpuFallback.LayerNorm(input, gamma, beta, epsilon, out mean, out variance);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var result = LayerNormGpu((Tensor<float>)(object)input, (Tensor<float>)(object)gamma,
                    (Tensor<float>)(object)beta, (float)epsilon, out var meanF, out var varF);
                mean = (Tensor<T>)(object)meanF;
                variance = (Tensor<T>)(object)varF;
                return (Tensor<T>)(object)result;
            }
            if (typeof(T) == typeof(double))
            {
                var result = LayerNormGpuDouble((Tensor<double>)(object)input, (Tensor<double>)(object)gamma,
                    (Tensor<double>)(object)beta, epsilon, out var meanD, out var varD);
                mean = (Tensor<T>)(object)meanD;
                variance = (Tensor<T>)(object)varD;
                return (Tensor<T>)(object)result;
            }
        }

        return _cpuFallback.LayerNorm(input, gamma, beta, epsilon, out mean, out variance);
    }

    private Tensor<float> LayerNormGpu(Tensor<float> input, Tensor<float> gamma, Tensor<float> beta, float epsilon, out Tensor<float> mean, out Tensor<float> variance)
    {
        int batch = input.Shape[0];
        int features = input.Shape[1];

        // Compute mean and variance per sample on CPU
        var meanData = new float[batch];
        var varData = new float[batch];
        var inputData = input.AsSpan().ToArray();

        for (int b = 0; b < batch; b++)
        {
            float sum = 0;
            for (int f = 0; f < features; f++)
                sum += inputData[b * features + f];
            meanData[b] = sum / features;
        }

        for (int b = 0; b < batch; b++)
        {
            float sumSq = 0;
            for (int f = 0; f < features; f++)
            {
                float diff = inputData[b * features + f] - meanData[b];
                sumSq += diff * diff;
            }
            varData[b] = sumSq / features;
        }

        mean = new Tensor<float>([batch], new Vector<float>(meanData));
        variance = new Tensor<float>([batch], new Vector<float>(varData));

        try
        {
            var result = new Tensor<float>(input.Shape);

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuGamma = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(features);
            var gpuBeta = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(features);
            var gpuMean = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(batch);
            var gpuVar = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(batch);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuGamma.View.BaseView.CopyFromCPU(gamma.AsSpan());
                gpuBeta.View.BaseView.CopyFromCPU(beta.AsSpan());
                gpuMean.View.BaseView.CopyFromCPU(meanData);
                gpuVar.View.BaseView.CopyFromCPU(varData);

                lock (_gpuLock)
                {
                    (_layerNormKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        input.Length, gpuInput.View, gpuOutput.View, gpuGamma.View, gpuBeta.View,
                        gpuMean.View, gpuVar.View, epsilon, batch, features);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
                _memoryPoolFloat.Return(gpuGamma);
                _memoryPoolFloat.Return(gpuBeta);
                _memoryPoolFloat.Return(gpuMean);
                _memoryPoolFloat.Return(gpuVar);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU layer norm failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.LayerNorm(input, gamma, beta, epsilon, out mean, out variance);
        }
    }

    private Tensor<double> LayerNormGpuDouble(Tensor<double> input, Tensor<double> gamma, Tensor<double> beta, double epsilon, out Tensor<double> mean, out Tensor<double> variance)
    {
        int batch = input.Shape[0];
        int features = input.Shape[1];

        var meanData = new double[batch];
        var varData = new double[batch];
        var inputData = input.AsSpan().ToArray();

        for (int b = 0; b < batch; b++)
        {
            double sum = 0;
            for (int f = 0; f < features; f++)
                sum += inputData[b * features + f];
            meanData[b] = sum / features;
        }

        for (int b = 0; b < batch; b++)
        {
            double sumSq = 0;
            for (int f = 0; f < features; f++)
            {
                double diff = inputData[b * features + f] - meanData[b];
                sumSq += diff * diff;
            }
            varData[b] = sumSq / features;
        }

        mean = new Tensor<double>([batch], new Vector<double>(meanData));
        variance = new Tensor<double>([batch], new Vector<double>(varData));

        try
        {
            var result = new Tensor<double>(input.Shape);

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuGamma = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(features);
            var gpuBeta = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(features);
            var gpuMean = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(batch);
            var gpuVar = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(batch);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuGamma.View.BaseView.CopyFromCPU(gamma.AsSpan());
                gpuBeta.View.BaseView.CopyFromCPU(beta.AsSpan());
                gpuMean.View.BaseView.CopyFromCPU(meanData);
                gpuVar.View.BaseView.CopyFromCPU(varData);

                lock (_gpuLock)
                {
                    (_layerNormKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        input.Length, gpuInput.View, gpuOutput.View, gpuGamma.View, gpuBeta.View,
                        gpuMean.View, gpuVar.View, epsilon, batch, features);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
                _memoryPoolDouble.Return(gpuGamma);
                _memoryPoolDouble.Return(gpuBeta);
                _memoryPoolDouble.Return(gpuMean);
                _memoryPoolDouble.Return(gpuVar);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU layer norm (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.LayerNorm(input, gamma, beta, epsilon, out mean, out variance);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> LayerNormBackward<T>(Tensor<T> gradOutput, Tensor<T> input, Tensor<T> gamma, Tensor<T> mean, Tensor<T> variance, double epsilon, out Tensor<T> gradGamma, out Tensor<T> gradBeta)
    {
        if (gradOutput.Length < _thresholds.VectorAdd || gradOutput.Rank != 2)
            return _cpuFallback.LayerNormBackward(gradOutput, input, gamma, mean, variance, epsilon, out gradGamma, out gradBeta);

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var result = LayerNormBackwardGpu(
                    (Tensor<float>)(object)gradOutput, (Tensor<float>)(object)input,
                    (Tensor<float>)(object)gamma, (Tensor<float>)(object)mean,
                    (Tensor<float>)(object)variance, (float)epsilon,
                    out var gradGammaF, out var gradBetaF);
                gradGamma = (Tensor<T>)(object)gradGammaF;
                gradBeta = (Tensor<T>)(object)gradBetaF;
                return (Tensor<T>)(object)result;
            }
            if (typeof(T) == typeof(double))
            {
                var result = LayerNormBackwardGpuDouble(
                    (Tensor<double>)(object)gradOutput, (Tensor<double>)(object)input,
                    (Tensor<double>)(object)gamma, (Tensor<double>)(object)mean,
                    (Tensor<double>)(object)variance, epsilon,
                    out var gradGammaD, out var gradBetaD);
                gradGamma = (Tensor<T>)(object)gradGammaD;
                gradBeta = (Tensor<T>)(object)gradBetaD;
                return (Tensor<T>)(object)result;
            }
        }
        return _cpuFallback.LayerNormBackward(gradOutput, input, gamma, mean, variance, epsilon, out gradGamma, out gradBeta);
    }

    private Tensor<float> LayerNormBackwardGpu(Tensor<float> gradOutput, Tensor<float> input, Tensor<float> gamma, Tensor<float> mean, Tensor<float> variance, float epsilon, out Tensor<float> gradGamma, out Tensor<float> gradBeta)
    {
        try
        {
            var shape = input.Shape;
            int batchSize = shape[0], featureSize = shape[1];
            int totalSize = batchSize * featureSize;

            var gradInput = new Tensor<float>(shape);
            gradGamma = new Tensor<float>([featureSize]);
            gradBeta = new Tensor<float>([featureSize]);

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
            var gpuGamma = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);
            var gpuMean = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(batchSize);
            var gpuVariance = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(batchSize);
            var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
            var gpuGradGamma = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);
            var gpuGradBeta = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuGamma.View.BaseView.CopyFromCPU(gamma.AsSpan());
                gpuMean.View.BaseView.CopyFromCPU(mean.AsSpan());
                gpuVariance.View.BaseView.CopyFromCPU(variance.AsSpan());
                gpuGradGamma.View.BaseView.CopyFromCPU(new float[featureSize]);
                gpuGradBeta.View.BaseView.CopyFromCPU(new float[featureSize]);

                lock (_gpuLock)
                {
                    (_layerNormBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalSize, gpuGradOutput.View, gpuInput.View, gpuGamma.View, gpuMean.View, gpuVariance.View,
                        gpuGradInput.View, gpuGradGamma.View, gpuGradBeta.View, epsilon, batchSize, featureSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(gradInput.AsWritableSpan());
                gpuGradGamma.View.BaseView.CopyToCPU(gradGamma.AsWritableSpan());
                gpuGradBeta.View.BaseView.CopyToCPU(gradBeta.AsWritableSpan());
                return gradInput;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuGamma);
                _memoryPoolFloat.Return(gpuMean);
                _memoryPoolFloat.Return(gpuVariance);
                _memoryPoolFloat.Return(gpuGradInput);
                _memoryPoolFloat.Return(gpuGradGamma);
                _memoryPoolFloat.Return(gpuGradBeta);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU LayerNormBackward failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.LayerNormBackward(gradOutput, input, gamma, mean, variance, epsilon, out gradGamma, out gradBeta);
        }
    }

    private Tensor<double> LayerNormBackwardGpuDouble(Tensor<double> gradOutput, Tensor<double> input, Tensor<double> gamma, Tensor<double> mean, Tensor<double> variance, double epsilon, out Tensor<double> gradGamma, out Tensor<double> gradBeta)
    {
        try
        {
            var shape = input.Shape;
            int batchSize = shape[0], featureSize = shape[1];
            int totalSize = batchSize * featureSize;

            var gradInput = new Tensor<double>(shape);
            gradGamma = new Tensor<double>([featureSize]);
            gradBeta = new Tensor<double>([featureSize]);

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
            var gpuGamma = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);
            var gpuMean = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(batchSize);
            var gpuVariance = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(batchSize);
            var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalSize);
            var gpuGradGamma = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);
            var gpuGradBeta = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(featureSize);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuGamma.View.BaseView.CopyFromCPU(gamma.AsSpan());
                gpuMean.View.BaseView.CopyFromCPU(mean.AsSpan());
                gpuVariance.View.BaseView.CopyFromCPU(variance.AsSpan());
                gpuGradGamma.View.BaseView.CopyFromCPU(new double[featureSize]);
                gpuGradBeta.View.BaseView.CopyFromCPU(new double[featureSize]);

                lock (_gpuLock)
                {
                    (_layerNormBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalSize, gpuGradOutput.View, gpuInput.View, gpuGamma.View, gpuMean.View, gpuVariance.View,
                        gpuGradInput.View, gpuGradGamma.View, gpuGradBeta.View, epsilon, batchSize, featureSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(gradInput.AsWritableSpan());
                gpuGradGamma.View.BaseView.CopyToCPU(gradGamma.AsWritableSpan());
                gpuGradBeta.View.BaseView.CopyToCPU(gradBeta.AsWritableSpan());
                return gradInput;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuGamma);
                _memoryPoolDouble.Return(gpuMean);
                _memoryPoolDouble.Return(gpuVariance);
                _memoryPoolDouble.Return(gpuGradInput);
                _memoryPoolDouble.Return(gpuGradGamma);
                _memoryPoolDouble.Return(gpuGradBeta);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU LayerNormBackward (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.LayerNormBackward(gradOutput, input, gamma, mean, variance, epsilon, out gradGamma, out gradBeta);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> GroupNorm<T>(Tensor<T> input, int numGroups, Tensor<T> gamma, Tensor<T> beta, double epsilon, out Tensor<T> mean, out Tensor<T> variance)
    {
        // GroupNorm has different memory access patterns than LayerNorm due to channel grouping
        // For now, delegate to CPU. GPU kernel can be added for high-throughput scenarios.
        return _cpuFallback.GroupNorm(input, numGroups, gamma, beta, epsilon, out mean, out variance);
    }

    /// <inheritdoc/>
    public Tensor<T> GroupNormBackward<T>(Tensor<T> gradOutput, Tensor<T> input, int numGroups, Tensor<T> gamma, Tensor<T> mean, Tensor<T> variance, double epsilon, out Tensor<T> gradGamma, out Tensor<T> gradBeta)
    {
        // Delegate to CPU fallback for now
        return _cpuFallback.GroupNormBackward(gradOutput, input, numGroups, gamma, mean, variance, epsilon, out gradGamma, out gradBeta);
    }

    #endregion

    #region Tensor Reduction Operations

    /// <inheritdoc/>
    public Tensor<T> ReduceMax<T>(Tensor<T> input, int[] axes, bool keepDims, out int[] maxIndices)
    {
        // For single-axis reductions on 2D+ tensors, we can use GPU
        if (axes.Length == 1 && input.Rank >= 2 && input.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            int axis = axes[0];
            if (axis < 0) axis = input.Rank + axis;

            if (typeof(T) == typeof(float))
            {
                var result = ReduceMaxGpu((Tensor<float>)(object)input, axis, keepDims, out maxIndices);
                return (Tensor<T>)(object)result;
            }
            if (typeof(T) == typeof(double))
            {
                var result = ReduceMaxGpuDouble((Tensor<double>)(object)input, axis, keepDims, out maxIndices);
                return (Tensor<T>)(object)result;
            }
        }
        return _cpuFallback.ReduceMax(input, axes, keepDims, out maxIndices);
    }

    private Tensor<float> ReduceMaxGpu(Tensor<float> input, int axis, bool keepDims, out int[] maxIndices)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            // Calculate outer, reduce, and inner sizes
            int outerSize = 1, reduceSize = shape[axis], innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            int outputSize = outerSize * innerSize;
            var outputShape = keepDims
                ? shape.Select((s, i) => i == axis ? 1 : s).ToArray()
                : shape.Where((_, i) => i != axis).ToArray();

            var output = new Tensor<float>(outputShape);
            maxIndices = new int[outputSize];

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);
            var gpuIndices = (_memoryPoolInt ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_reduceMaxKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuInput.View, gpuOutput.View, gpuIndices.View, outerSize, reduceSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(output.AsWritableSpan());
                gpuIndices.View.BaseView.CopyToCPU(maxIndices);
                return output;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
                _memoryPoolInt.Return(gpuIndices);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ReduceMax failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ReduceMax(input, [axis], keepDims, out maxIndices);
        }
    }

    private Tensor<double> ReduceMaxGpuDouble(Tensor<double> input, int axis, bool keepDims, out int[] maxIndices)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, reduceSize = shape[axis], innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            int outputSize = outerSize * innerSize;
            var outputShape = keepDims
                ? shape.Select((s, i) => i == axis ? 1 : s).ToArray()
                : shape.Where((_, i) => i != axis).ToArray();

            var output = new Tensor<double>(outputShape);
            maxIndices = new int[outputSize];

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);
            var gpuIndices = (_memoryPoolInt ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_reduceMaxKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuInput.View, gpuOutput.View, gpuIndices.View, outerSize, reduceSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(output.AsWritableSpan());
                gpuIndices.View.BaseView.CopyToCPU(maxIndices);
                return output;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
                _memoryPoolInt.Return(gpuIndices);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ReduceMax (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ReduceMax(input, [axis], keepDims, out maxIndices);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> ReduceMaxBackward<T>(Tensor<T> gradOutput, int[] maxIndices, int[] inputShape)
    {
        // ReduceMaxBackward is complex due to arbitrary shapes - use CPU for now
        // GPU implementation would require knowing the original reduction axis
        return _cpuFallback.ReduceMaxBackward(gradOutput, maxIndices, inputShape);
    }

    /// <inheritdoc/>
    public Tensor<T> ReduceMean<T>(Tensor<T> input, int[] axes, bool keepDims)
    {
        // For single-axis reductions on 2D+ tensors, we can use GPU
        if (axes.Length == 1 && input.Rank >= 2 && input.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            int axis = axes[0];
            if (axis < 0) axis = input.Rank + axis;

            if (typeof(T) == typeof(float))
            {
                var result = ReduceMeanGpu((Tensor<float>)(object)input, axis, keepDims);
                return (Tensor<T>)(object)result;
            }
            if (typeof(T) == typeof(double))
            {
                var result = ReduceMeanGpuDouble((Tensor<double>)(object)input, axis, keepDims);
                return (Tensor<T>)(object)result;
            }
        }
        return _cpuFallback.ReduceMean(input, axes, keepDims);
    }

    private Tensor<float> ReduceMeanGpu(Tensor<float> input, int axis, bool keepDims)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, reduceSize = shape[axis], innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            int outputSize = outerSize * innerSize;
            var outputShape = keepDims
                ? shape.Select((s, i) => i == axis ? 1 : s).ToArray()
                : shape.Where((_, i) => i != axis).ToArray();

            var output = new Tensor<float>(outputShape);

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_reduceMeanKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuInput.View, gpuOutput.View, outerSize, reduceSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(output.AsWritableSpan());
                return output;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ReduceMean failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ReduceMean(input, [axis], keepDims);
        }
    }

    private Tensor<double> ReduceMeanGpuDouble(Tensor<double> input, int axis, bool keepDims)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, reduceSize = shape[axis], innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            int outputSize = outerSize * innerSize;
            var outputShape = keepDims
                ? shape.Select((s, i) => i == axis ? 1 : s).ToArray()
                : shape.Where((_, i) => i != axis).ToArray();

            var output = new Tensor<double>(outputShape);

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                lock (_gpuLock)
                {
                    (_reduceMeanKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuInput.View, gpuOutput.View, outerSize, reduceSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(output.AsWritableSpan());
                return output;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ReduceMean (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ReduceMean(input, [axis], keepDims);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> ReduceMeanBackward<T>(Tensor<T> gradOutput, int[] inputShape, int[] axes)
    {
        // For single-axis reductions, we can use GPU
        if (axes.Length == 1 && inputShape.Length >= 2 && gradOutput.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            int axis = axes[0];
            if (axis < 0) axis = inputShape.Length + axis;

            if (typeof(T) == typeof(float))
            {
                var result = ReduceMeanBackwardGpu((Tensor<float>)(object)gradOutput, inputShape, axis);
                return (Tensor<T>)(object)result;
            }
            if (typeof(T) == typeof(double))
            {
                var result = ReduceMeanBackwardGpuDouble((Tensor<double>)(object)gradOutput, inputShape, axis);
                return (Tensor<T>)(object)result;
            }
        }
        return _cpuFallback.ReduceMeanBackward(gradOutput, inputShape, axes);
    }

    private Tensor<float> ReduceMeanBackwardGpu(Tensor<float> gradOutput, int[] inputShape, int axis)
    {
        try
        {
            int rank = inputShape.Length;

            int outerSize = 1, reduceSize = inputShape[axis], innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= inputShape[i];
            for (int i = axis + 1; i < rank; i++) innerSize *= inputShape[i];

            int outputSize = inputShape.Aggregate(1, (a, b) => a * b);
            var output = new Tensor<float>(inputShape);

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());

                lock (_gpuLock)
                {
                    (_reduceMeanBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuGradOutput.View, gpuGradInput.View, outerSize, reduceSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(output.AsWritableSpan());
                return output;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ReduceMeanBackward failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ReduceMeanBackward(gradOutput, inputShape, [axis]);
        }
    }

    private Tensor<double> ReduceMeanBackwardGpuDouble(Tensor<double> gradOutput, int[] inputShape, int axis)
    {
        try
        {
            int rank = inputShape.Length;

            int outerSize = 1, reduceSize = inputShape[axis], innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= inputShape[i];
            for (int i = axis + 1; i < rank; i++) innerSize *= inputShape[i];

            int outputSize = inputShape.Aggregate(1, (a, b) => a * b);
            var output = new Tensor<double>(inputShape);

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());

                lock (_gpuLock)
                {
                    (_reduceMeanBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        outputSize, gpuGradOutput.View, gpuGradInput.View, outerSize, reduceSize, innerSize);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuGradInput.View.BaseView.CopyToCPU(output.AsWritableSpan());
                return output;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ReduceMeanBackward (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ReduceMeanBackward(gradOutput, inputShape, [axis]);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> ReduceVariance<T>(Tensor<T> input, int[] axes, bool keepDims)
    {
        // For single-axis reductions on 2D+ tensors, we can use GPU
        if (axes.Length == 1 && input.Rank >= 2 && input.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            int axis = axes[0];
            if (axis < 0) axis = input.Rank + axis;

            if (typeof(T) == typeof(float))
            {
                var result = ReduceVarianceGpu((Tensor<float>)(object)input, axis, keepDims);
                return (Tensor<T>)(object)result;
            }
            if (typeof(T) == typeof(double))
            {
                var result = ReduceVarianceGpuDouble((Tensor<double>)(object)input, axis, keepDims);
                return (Tensor<T>)(object)result;
            }
        }
        return _cpuFallback.ReduceVariance(input, axes, keepDims);
    }

    private Tensor<float> ReduceVarianceGpu(Tensor<float> input, int axis, bool keepDims)
    {
        try
        {
            var mean = ReduceMeanGpu(input, axis, keepDims: true);
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, reduceSize = shape[axis], innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var outputShape = keepDims
                ? shape.Select((s, i) => i == axis ? 1 : s).ToArray()
                : shape.Where((_, i) => i != axis).ToArray();

            var output = new Tensor<float>(outputShape);
            var inputSpan = input.AsSpan();
            var meanSpan = mean.AsSpan();
            var outputSpan = output.AsWritableSpan();

            for (int outer = 0; outer < outerSize; outer++)
            {
                for (int inner = 0; inner < innerSize; inner++)
                {
                    int outIdx = outer * innerSize + inner;
                    float meanVal = meanSpan[outIdx];
                    float sum = 0;

                    for (int r = 0; r < reduceSize; r++)
                    {
                        int inIdx = (outer * reduceSize + r) * innerSize + inner;
                        float diff = inputSpan[inIdx] - meanVal;
                        sum += diff * diff;
                    }
                    outputSpan[outIdx] = sum / reduceSize;
                }
            }
            return output;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ReduceVariance failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ReduceVariance(input, [axis], keepDims);
        }
    }

    private Tensor<double> ReduceVarianceGpuDouble(Tensor<double> input, int axis, bool keepDims)
    {
        try
        {
            var mean = ReduceMeanGpuDouble(input, axis, keepDims: true);
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, reduceSize = shape[axis], innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var outputShape = keepDims
                ? shape.Select((s, i) => i == axis ? 1 : s).ToArray()
                : shape.Where((_, i) => i != axis).ToArray();

            var output = new Tensor<double>(outputShape);
            var inputSpan = input.AsSpan();
            var meanSpan = mean.AsSpan();
            var outputSpan = output.AsWritableSpan();

            for (int outer = 0; outer < outerSize; outer++)
            {
                for (int inner = 0; inner < innerSize; inner++)
                {
                    int outIdx = outer * innerSize + inner;
                    double meanVal = meanSpan[outIdx];
                    double sum = 0;

                    for (int r = 0; r < reduceSize; r++)
                    {
                        int inIdx = (outer * reduceSize + r) * innerSize + inner;
                        double diff = inputSpan[inIdx] - meanVal;
                        sum += diff * diff;
                    }
                    outputSpan[outIdx] = sum / reduceSize;
                }
            }
            return output;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ReduceVariance (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ReduceVariance(input, [axis], keepDims);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> ReduceVarianceBackward<T>(Tensor<T> gradOutput, Tensor<T> input, Tensor<T> mean, int[] axes)
    {
        if (axes.Length == 1 && input.Rank >= 2 && gradOutput.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            int axis = axes[0];
            if (axis < 0) axis = input.Rank + axis;

            if (typeof(T) == typeof(float))
            {
                var result = ReduceVarianceBackwardGpu((Tensor<float>)(object)gradOutput, (Tensor<float>)(object)input, (Tensor<float>)(object)mean, axis);
                return (Tensor<T>)(object)result;
            }
            if (typeof(T) == typeof(double))
            {
                var result = ReduceVarianceBackwardGpuDouble((Tensor<double>)(object)gradOutput, (Tensor<double>)(object)input, (Tensor<double>)(object)mean, axis);
                return (Tensor<T>)(object)result;
            }
        }
        return _cpuFallback.ReduceVarianceBackward(gradOutput, input, mean, axes);
    }

    private Tensor<float> ReduceVarianceBackwardGpu(Tensor<float> gradOutput, Tensor<float> input, Tensor<float> mean, int axis)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, reduceSize = shape[axis], innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var output = new Tensor<float>(shape);
            var inputSpan = input.AsSpan();
            var meanSpan = mean.AsSpan();
            var gradOutSpan = gradOutput.AsSpan();
            var outputSpan = output.AsWritableSpan();
            float scale = 2.0f / reduceSize;

            for (int outer = 0; outer < outerSize; outer++)
            {
                for (int inner = 0; inner < innerSize; inner++)
                {
                    int outIdx = outer * innerSize + inner;
                    float meanVal = meanSpan[outIdx];
                    float gradVal = gradOutSpan[outIdx];

                    for (int r = 0; r < reduceSize; r++)
                    {
                        int inIdx = (outer * reduceSize + r) * innerSize + inner;
                        outputSpan[inIdx] = gradVal * scale * (inputSpan[inIdx] - meanVal);
                    }
                }
            }
            return output;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ReduceVarianceBackward failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ReduceVarianceBackward(gradOutput, input, mean, [axis]);
        }
    }

    private Tensor<double> ReduceVarianceBackwardGpuDouble(Tensor<double> gradOutput, Tensor<double> input, Tensor<double> mean, int axis)
    {
        try
        {
            var shape = input.Shape;
            int rank = shape.Length;

            int outerSize = 1, reduceSize = shape[axis], innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            for (int i = axis + 1; i < rank; i++) innerSize *= shape[i];

            var output = new Tensor<double>(shape);
            var inputSpan = input.AsSpan();
            var meanSpan = mean.AsSpan();
            var gradOutSpan = gradOutput.AsSpan();
            var outputSpan = output.AsWritableSpan();
            double scale = 2.0 / reduceSize;

            for (int outer = 0; outer < outerSize; outer++)
            {
                for (int inner = 0; inner < innerSize; inner++)
                {
                    int outIdx = outer * innerSize + inner;
                    double meanVal = meanSpan[outIdx];
                    double gradVal = gradOutSpan[outIdx];

                    for (int r = 0; r < reduceSize; r++)
                    {
                        int inIdx = (outer * reduceSize + r) * innerSize + inner;
                        outputSpan[inIdx] = gradVal * scale * (inputSpan[inIdx] - meanVal);
                    }
                }
            }
            return output;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU ReduceVarianceBackward (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.ReduceVarianceBackward(gradOutput, input, mean, [axis]);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> ReduceLogVariance<T>(Tensor<T> input, int[] axes, bool keepDims, double epsilon = 1e-8)
    {
        // Use CPU fallback
        return _cpuFallback.ReduceLogVariance(input, axes, keepDims, epsilon);
    }

    /// <inheritdoc/>
    public Tensor<T> ReduceLogVarianceBackward<T>(Tensor<T> gradOutput, Tensor<T> input, Tensor<T> mean, Tensor<T> variance, int[] axes)
    {
        // Use CPU fallback
        return _cpuFallback.ReduceLogVarianceBackward(gradOutput, input, mean, variance, axes);
    }

    #endregion

    #region Spatial Operations

    /// <inheritdoc/>
    public Tensor<T> Upsample<T>(Tensor<T> input, int scaleH, int scaleW)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        var shape = input.Shape;
        if (shape.Length < 2)
            throw new ArgumentException("Upsample requires tensor with at least 2 dimensions for height and width.");

        // Industry-standard: last two dimensions are height and width
        int heightIdx = shape.Length - 2;
        int widthIdx = shape.Length - 1;
        int height = shape[heightIdx];
        int width = shape[widthIdx];

        // Flatten all leading dimensions into batch*channels for GPU kernel
        int flatBatch = 1;
        for (int i = 0; i < shape.Length - 2; i++)
        {
            flatBatch *= shape[i];
        }

        int newHeight = height * scaleH;
        int newWidth = width * scaleW;
        int outputSize = flatBatch * newHeight * newWidth;

        // Create output shape preserving all leading dimensions
        var outputShape = new int[shape.Length];
        for (int i = 0; i < shape.Length - 2; i++)
        {
            outputShape[i] = shape[i];
        }
        outputShape[heightIdx] = newHeight;
        outputShape[widthIdx] = newWidth;

        // GPU upsample for supported types and large enough tensors
        if (outputSize >= _thresholds.MatrixMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)UpsampleGpuFloatAnyRank((Tensor<float>)(object)input, scaleH, scaleW, outputShape);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)UpsampleGpuDoubleAnyRank((Tensor<double>)(object)input, scaleH, scaleW, outputShape);
        }
        return _cpuFallback.Upsample(input, scaleH, scaleW);
    }

    private Tensor<float> UpsampleGpuFloat(Tensor<float> input, int scaleH, int scaleW)
    {
        var shape = input.Shape;
        int batch = shape[0];
        int channels = shape[1];
        int height = shape[2];
        int width = shape[3];
        int newHeight = height * scaleH;
        int newWidth = width * scaleW;
        int outputSize = batch * channels * newHeight * newWidth;

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.ToArray());

            lock (_gpuLock)
            {
                (_upsampleKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    outputSize, gpuInput.View.BaseView, gpuOutput.View.BaseView,
                    batch, channels, height, width, scaleH, scaleW);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            var resultData = new float[outputSize];
            gpuOutput.View.BaseView.CopyToCPU(resultData);
            return new Tensor<float>([batch, channels, newHeight, newWidth], new Vector<float>(resultData));
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Upsample(input, scaleH, scaleW);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuOutput);
        }
    }

    private Tensor<double> UpsampleGpuDouble(Tensor<double> input, int scaleH, int scaleW)
    {
        var shape = input.Shape;
        int batch = shape[0];
        int channels = shape[1];
        int height = shape[2];
        int width = shape[3];
        int newHeight = height * scaleH;
        int newWidth = width * scaleW;
        int outputSize = batch * channels * newHeight * newWidth;

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.ToArray());

            lock (_gpuLock)
            {
                (_upsampleKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    outputSize, gpuInput.View.BaseView, gpuOutput.View.BaseView,
                    batch, channels, height, width, scaleH, scaleW);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            var resultData = new double[outputSize];
            gpuOutput.View.BaseView.CopyToCPU(resultData);
            return new Tensor<double>([batch, channels, newHeight, newWidth], new Vector<double>(resultData));
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Upsample(input, scaleH, scaleW);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuOutput);
        }
    }

    /// <summary>
    /// GPU-accelerated upsample for any-rank tensors (float).
    /// Flattens leading dimensions to use optimized 4D GPU kernel.
    /// </summary>
    private Tensor<float> UpsampleGpuFloatAnyRank(Tensor<float> input, int scaleH, int scaleW, int[] outputShape)
    {
        var shape = input.Shape;
        int heightIdx = shape.Length - 2;
        int height = shape[heightIdx];
        int width = shape[shape.Length - 1];

        // Flatten all leading dimensions into a single batch dimension
        int flatBatch = 1;
        for (int i = 0; i < shape.Length - 2; i++)
        {
            flatBatch *= shape[i];
        }

        int newHeight = height * scaleH;
        int newWidth = width * scaleW;
        int outputSize = flatBatch * newHeight * newWidth;

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.ToArray());

            lock (_gpuLock)
            {
                // Use GPU kernel with flatBatch as batch, 1 as channels (flattened into batch)
                (_upsampleKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    outputSize, gpuInput.View.BaseView, gpuOutput.View.BaseView,
                    flatBatch, 1, height, width, scaleH, scaleW);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            var resultData = new float[outputSize];
            gpuOutput.View.BaseView.CopyToCPU(resultData);
            return new Tensor<float>(outputShape, new Vector<float>(resultData));
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Upsample(input, scaleH, scaleW);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuOutput);
        }
    }

    /// <summary>
    /// GPU-accelerated upsample for any-rank tensors (double).
    /// Flattens leading dimensions to use optimized 4D GPU kernel.
    /// </summary>
    private Tensor<double> UpsampleGpuDoubleAnyRank(Tensor<double> input, int scaleH, int scaleW, int[] outputShape)
    {
        var shape = input.Shape;
        int heightIdx = shape.Length - 2;
        int height = shape[heightIdx];
        int width = shape[shape.Length - 1];

        // Flatten all leading dimensions into a single batch dimension
        int flatBatch = 1;
        for (int i = 0; i < shape.Length - 2; i++)
        {
            flatBatch *= shape[i];
        }

        int newHeight = height * scaleH;
        int newWidth = width * scaleW;
        int outputSize = flatBatch * newHeight * newWidth;

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.ToArray());

            lock (_gpuLock)
            {
                // Use GPU kernel with flatBatch as batch, 1 as channels (flattened into batch)
                (_upsampleKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    outputSize, gpuInput.View.BaseView, gpuOutput.View.BaseView,
                    flatBatch, 1, height, width, scaleH, scaleW);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            var resultData = new double[outputSize];
            gpuOutput.View.BaseView.CopyToCPU(resultData);
            return new Tensor<double>(outputShape, new Vector<double>(resultData));
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.Upsample(input, scaleH, scaleW);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> UpsampleBackward<T>(Tensor<T> gradOutput, int[] inputShape, int scaleH, int scaleW)
    {
        if (gradOutput == null) throw new ArgumentNullException(nameof(gradOutput));
        if (inputShape == null) throw new ArgumentNullException(nameof(inputShape));
        if (inputShape.Length < 2)
            throw new ArgumentException("UpsampleBackward requires inputShape with at least 2 dimensions for height and width.");

        // Industry-standard: last two dimensions are height and width
        int heightIdx = inputShape.Length - 2;
        int widthIdx = inputShape.Length - 1;
        int height = inputShape[heightIdx];
        int width = inputShape[widthIdx];

        // Flatten all leading dimensions into a single batch dimension
        int flatBatch = 1;
        int totalInput = 1;
        for (int i = 0; i < inputShape.Length; i++)
        {
            totalInput *= inputShape[i];
            if (i < inputShape.Length - 2)
            {
                flatBatch *= inputShape[i];
            }
        }

        if (totalInput < _thresholds.MatrixMultiply || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.UpsampleBackward(gradOutput, inputShape, scaleH, scaleW);
        }

        if (typeof(T) == typeof(float))
            return (Tensor<T>)(object)UpsampleBackwardGpuFloatAnyRank((Tensor<float>)(object)gradOutput, inputShape, scaleH, scaleW);
        if (typeof(T) == typeof(double))
            return (Tensor<T>)(object)UpsampleBackwardGpuDoubleAnyRank((Tensor<double>)(object)gradOutput, inputShape, scaleH, scaleW);

        return _cpuFallback.UpsampleBackward(gradOutput, inputShape, scaleH, scaleW);
    }

    private Tensor<float> UpsampleBackwardGpuFloat(Tensor<float> gradOutput, int[] inputShape, int scaleH, int scaleW)
    {
        int batch = inputShape[0];
        int channels = inputShape[1];
        int inH = inputShape[2];
        int inW = inputShape[3];
        int inputSize = batch * channels * inH * inW;

        var result = new Tensor<float>(inputShape);

        var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
        var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(inputSize);

        try
        {
            gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());

            lock (_gpuLock)
            {
                (_upsampleBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    inputSize, gpuGradOutput.View, gpuGradInput.View, batch, channels, inH, inW, scaleH, scaleW);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU UpsampleBackward (float) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.UpsampleBackward(gradOutput, inputShape, scaleH, scaleW);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuGradOutput);
            _memoryPoolFloat.Return(gpuGradInput);
        }
    }

    private Tensor<double> UpsampleBackwardGpuDouble(Tensor<double> gradOutput, int[] inputShape, int scaleH, int scaleW)
    {
        int batch = inputShape[0];
        int channels = inputShape[1];
        int inH = inputShape[2];
        int inW = inputShape[3];
        int inputSize = batch * channels * inH * inW;

        var result = new Tensor<double>(inputShape);

        var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
        var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(inputSize);

        try
        {
            gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());

            lock (_gpuLock)
            {
                (_upsampleBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    inputSize, gpuGradOutput.View, gpuGradInput.View, batch, channels, inH, inW, scaleH, scaleW);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU UpsampleBackward (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.UpsampleBackward(gradOutput, inputShape, scaleH, scaleW);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuGradOutput);
            _memoryPoolDouble.Return(gpuGradInput);
        }
    }

    /// <summary>
    /// GPU-accelerated upsample backward for any-rank tensors (float).
    /// Flattens leading dimensions to use optimized 4D GPU kernel.
    /// </summary>
    private Tensor<float> UpsampleBackwardGpuFloatAnyRank(Tensor<float> gradOutput, int[] inputShape, int scaleH, int scaleW)
    {
        int heightIdx = inputShape.Length - 2;
        int height = inputShape[heightIdx];
        int width = inputShape[inputShape.Length - 1];

        // Flatten all leading dimensions into a single batch dimension
        int flatBatch = 1;
        int totalInput = 1;
        for (int i = 0; i < inputShape.Length; i++)
        {
            totalInput *= inputShape[i];
            if (i < inputShape.Length - 2)
            {
                flatBatch *= inputShape[i];
            }
        }

        var result = new Tensor<float>(inputShape);

        var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
        var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalInput);

        try
        {
            gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());

            lock (_gpuLock)
            {
                // Use GPU kernel with flatBatch as batch, 1 as channels (flattened into batch)
                (_upsampleBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    totalInput, gpuGradOutput.View, gpuGradInput.View, flatBatch, 1, height, width, scaleH, scaleW);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU UpsampleBackward (float, any-rank) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.UpsampleBackward(gradOutput, inputShape, scaleH, scaleW);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuGradOutput);
            _memoryPoolFloat.Return(gpuGradInput);
        }
    }

    /// <summary>
    /// GPU-accelerated upsample backward for any-rank tensors (double).
    /// Flattens leading dimensions to use optimized 4D GPU kernel.
    /// </summary>
    private Tensor<double> UpsampleBackwardGpuDoubleAnyRank(Tensor<double> gradOutput, int[] inputShape, int scaleH, int scaleW)
    {
        int heightIdx = inputShape.Length - 2;
        int height = inputShape[heightIdx];
        int width = inputShape[inputShape.Length - 1];

        // Flatten all leading dimensions into a single batch dimension
        int flatBatch = 1;
        int totalInput = 1;
        for (int i = 0; i < inputShape.Length; i++)
        {
            totalInput *= inputShape[i];
            if (i < inputShape.Length - 2)
            {
                flatBatch *= inputShape[i];
            }
        }

        var result = new Tensor<double>(inputShape);

        var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
        var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalInput);

        try
        {
            gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());

            lock (_gpuLock)
            {
                // Use GPU kernel with flatBatch as batch, 1 as channels (flattened into batch)
                (_upsampleBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    totalInput, gpuGradOutput.View, gpuGradInput.View, flatBatch, 1, height, width, scaleH, scaleW);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU UpsampleBackward (double, any-rank) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.UpsampleBackward(gradOutput, inputShape, scaleH, scaleW);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuGradOutput);
            _memoryPoolDouble.Return(gpuGradInput);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> PixelShuffle<T>(Tensor<T> input, int upscaleFactor)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        var shape = input.Shape;
        if (shape.Length != 4)
            throw new ArgumentException("PixelShuffle expects 4D tensor [batch, channels, height, width]");

        int batch = shape[0];
        int channels = shape[1];
        int height = shape[2];
        int width = shape[3];
        int r = upscaleFactor;

        if (channels % (r * r) != 0)
            throw new ArgumentException($"Number of channels ({channels}) must be divisible by r^2 ({r * r})");

        int outputSize = batch * (channels / (r * r)) * (height * r) * (width * r);

        // GPU pixel shuffle for supported types and large enough tensors
        if (outputSize >= _thresholds.MatrixMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)PixelShuffleGpuFloat((Tensor<float>)(object)input, upscaleFactor);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)PixelShuffleGpuDouble((Tensor<double>)(object)input, upscaleFactor);
        }
        return _cpuFallback.PixelShuffle(input, upscaleFactor);
    }

    private Tensor<float> PixelShuffleGpuFloat(Tensor<float> input, int upscaleFactor)
    {
        var shape = input.Shape;
        int batch = shape[0];
        int channels = shape[1];
        int height = shape[2];
        int width = shape[3];
        int r = upscaleFactor;
        int newChannels = channels / (r * r);
        int newHeight = height * r;
        int newWidth = width * r;
        int outputSize = batch * newChannels * newHeight * newWidth;

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.ToArray());

            lock (_gpuLock)
            {
                (_pixelShuffleKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    outputSize, gpuInput.View.BaseView, gpuOutput.View.BaseView,
                    batch, channels, height, width, upscaleFactor);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            var resultData = new float[outputSize];
            gpuOutput.View.BaseView.CopyToCPU(resultData);
            return new Tensor<float>([batch, newChannels, newHeight, newWidth], new Vector<float>(resultData));
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.PixelShuffle(input, upscaleFactor);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuOutput);
        }
    }

    private Tensor<double> PixelShuffleGpuDouble(Tensor<double> input, int upscaleFactor)
    {
        var shape = input.Shape;
        int batch = shape[0];
        int channels = shape[1];
        int height = shape[2];
        int width = shape[3];
        int r = upscaleFactor;
        int newChannels = channels / (r * r);
        int newHeight = height * r;
        int newWidth = width * r;
        int outputSize = batch * newChannels * newHeight * newWidth;

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.ToArray());

            lock (_gpuLock)
            {
                (_pixelShuffleKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    outputSize, gpuInput.View.BaseView, gpuOutput.View.BaseView,
                    batch, channels, height, width, upscaleFactor);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            var resultData = new double[outputSize];
            gpuOutput.View.BaseView.CopyToCPU(resultData);
            return new Tensor<double>([batch, newChannels, newHeight, newWidth], new Vector<double>(resultData));
        }
        catch (Exception ex) when (ex.Message.Contains("device") || ex.Message.Contains("accelerator"))
        {
            RecordGpuFailure(ex);
            return _cpuFallback.PixelShuffle(input, upscaleFactor);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> PixelShuffleBackward<T>(Tensor<T> gradOutput, int[] inputShape, int upscaleFactor)
    {
        if (gradOutput == null) throw new ArgumentNullException(nameof(gradOutput));
        if (inputShape == null) throw new ArgumentNullException(nameof(inputShape));
        if (inputShape.Length != 4)
            throw new ArgumentException("PixelShuffleBackward expects 4D input shape [batch, channels, height, width]");

        int inputSize = inputShape[0] * inputShape[1] * inputShape[2] * inputShape[3];

        if (inputSize < _thresholds.MatrixMultiply || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.PixelShuffleBackward(gradOutput, inputShape, upscaleFactor);
        }

        if (typeof(T) == typeof(float))
            return (Tensor<T>)(object)PixelShuffleBackwardGpuFloat((Tensor<float>)(object)gradOutput, inputShape, upscaleFactor);
        if (typeof(T) == typeof(double))
            return (Tensor<T>)(object)PixelShuffleBackwardGpuDouble((Tensor<double>)(object)gradOutput, inputShape, upscaleFactor);

        return _cpuFallback.PixelShuffleBackward(gradOutput, inputShape, upscaleFactor);
    }

    private Tensor<float> PixelShuffleBackwardGpuFloat(Tensor<float> gradOutput, int[] inputShape, int upscaleFactor)
    {
        int batch = inputShape[0];
        int channels = inputShape[1];
        int height = inputShape[2];
        int width = inputShape[3];
        int inputSize = batch * channels * height * width;

        var result = new Tensor<float>(inputShape);

        var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
        var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(inputSize);

        try
        {
            gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());

            lock (_gpuLock)
            {
                (_pixelShuffleBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    inputSize, gpuGradOutput.View, gpuGradInput.View, batch, channels, height, width, upscaleFactor);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU PixelShuffleBackward (float) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.PixelShuffleBackward(gradOutput, inputShape, upscaleFactor);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuGradOutput);
            _memoryPoolFloat.Return(gpuGradInput);
        }
    }

    private Tensor<double> PixelShuffleBackwardGpuDouble(Tensor<double> gradOutput, int[] inputShape, int upscaleFactor)
    {
        int batch = inputShape[0];
        int channels = inputShape[1];
        int height = inputShape[2];
        int width = inputShape[3];
        int inputSize = batch * channels * height * width;

        var result = new Tensor<double>(inputShape);

        var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
        var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(inputSize);

        try
        {
            gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());

            lock (_gpuLock)
            {
                (_pixelShuffleBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    inputSize, gpuGradOutput.View, gpuGradInput.View, batch, channels, height, width, upscaleFactor);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuGradInput.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU PixelShuffleBackward (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.PixelShuffleBackward(gradOutput, inputShape, upscaleFactor);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuGradOutput);
            _memoryPoolDouble.Return(gpuGradInput);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> Crop<T>(Tensor<T> input, int top, int left, int height, int width)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        var shape = input.Shape;
        if (shape.Length != 4)
            throw new ArgumentException("Crop expects 4D tensor [batch, channels, height, width]");

        int batch = shape[0];
        int channels = shape[1];
        int outputSize = batch * channels * height * width;

        if (outputSize < _thresholds.MatrixMultiply || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.Crop(input, top, left, height, width);
        }

        if (typeof(T) == typeof(float))
            return (Tensor<T>)(object)CropGpuFloat((Tensor<float>)(object)input, top, left, height, width);
        if (typeof(T) == typeof(double))
            return (Tensor<T>)(object)CropGpuDouble((Tensor<double>)(object)input, top, left, height, width);

        return _cpuFallback.Crop(input, top, left, height, width);
    }

    private Tensor<float> CropGpuFloat(Tensor<float> input, int top, int left, int cropH, int cropW)
    {
        var shape = input.Shape;
        int batch = shape[0];
        int channels = shape[1];
        int inH = shape[2];
        int inW = shape[3];
        int outputSize = batch * channels * cropH * cropW;

        var result = new Tensor<float>([batch, channels, cropH, cropW]);

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

            lock (_gpuLock)
            {
                (_cropKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    outputSize, gpuInput.View, gpuOutput.View, batch, channels, inH, inW, top, left, cropH, cropW);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Crop (float) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Crop(input, top, left, cropH, cropW);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuOutput);
        }
    }

    private Tensor<double> CropGpuDouble(Tensor<double> input, int top, int left, int cropH, int cropW)
    {
        var shape = input.Shape;
        int batch = shape[0];
        int channels = shape[1];
        int inH = shape[2];
        int inW = shape[3];
        int outputSize = batch * channels * cropH * cropW;

        var result = new Tensor<double>([batch, channels, cropH, cropW]);

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

            lock (_gpuLock)
            {
                (_cropKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    outputSize, gpuInput.View, gpuOutput.View, batch, channels, inH, inW, top, left, cropH, cropW);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Crop (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Crop(input, top, left, cropH, cropW);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> CropBackward<T>(Tensor<T> gradOutput, int[] inputShape, int top, int left)
    {
        // CropBackward: zero-pad gradient back to original input shape
        if (gradOutput.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)CropBackwardGpu((Tensor<float>)(object)gradOutput, inputShape, top, left);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)CropBackwardGpuDouble((Tensor<double>)(object)gradOutput, inputShape, top, left);
        }
        return _cpuFallback.CropBackward(gradOutput, inputShape, top, left);
    }

    private Tensor<float> CropBackwardGpu(Tensor<float> gradOutput, int[] inputShape, int top, int left)
    {
        try
        {
            var gradInput = new Tensor<float>(inputShape);
            var gradInputSpan = gradInput.AsWritableSpan();
            var gradOutSpan = gradOutput.AsSpan();
            var gradOutShape = gradOutput.Shape;

            // For 4D tensors [batch, channels, height, width]
            if (inputShape.Length == 4 && gradOutShape.Length == 4)
            {
                int batch = gradOutShape[0], channels = gradOutShape[1];
                int outH = gradOutShape[2], outW = gradOutShape[3];
                int inH = inputShape[2], inW = inputShape[3];

                for (int b = 0; b < batch; b++)
                {
                    for (int c = 0; c < channels; c++)
                    {
                        for (int h = 0; h < outH; h++)
                        {
                            for (int w = 0; w < outW; w++)
                            {
                                int outIdx = ((b * channels + c) * outH + h) * outW + w;
                                int inIdx = ((b * channels + c) * inH + (h + top)) * inW + (w + left);
                                gradInputSpan[inIdx] = gradOutSpan[outIdx];
                            }
                        }
                    }
                }
            }
            else
            {
                return _cpuFallback.CropBackward(gradOutput, inputShape, top, left);
            }

            return gradInput;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU CropBackward failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.CropBackward(gradOutput, inputShape, top, left);
        }
    }

    private Tensor<double> CropBackwardGpuDouble(Tensor<double> gradOutput, int[] inputShape, int top, int left)
    {
        try
        {
            var gradInput = new Tensor<double>(inputShape);
            var gradInputSpan = gradInput.AsWritableSpan();
            var gradOutSpan = gradOutput.AsSpan();
            var gradOutShape = gradOutput.Shape;

            if (inputShape.Length == 4 && gradOutShape.Length == 4)
            {
                int batch = gradOutShape[0], channels = gradOutShape[1];
                int outH = gradOutShape[2], outW = gradOutShape[3];
                int inH = inputShape[2], inW = inputShape[3];

                for (int b = 0; b < batch; b++)
                {
                    for (int c = 0; c < channels; c++)
                    {
                        for (int h = 0; h < outH; h++)
                        {
                            for (int w = 0; w < outW; w++)
                            {
                                int outIdx = ((b * channels + c) * outH + h) * outW + w;
                                int inIdx = ((b * channels + c) * inH + (h + top)) * inW + (w + left);
                                gradInputSpan[inIdx] = gradOutSpan[outIdx];
                            }
                        }
                    }
                }
            }
            else
            {
                return _cpuFallback.CropBackward(gradOutput, inputShape, top, left);
            }

            return gradInput;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU CropBackward (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.CropBackward(gradOutput, inputShape, top, left);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> Pad<T>(Tensor<T> input, int padTop, int padBottom, int padLeft, int padRight, T padValue)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        var shape = input.Shape;
        if (shape.Length != 4)
            throw new ArgumentException("Pad expects 4D tensor [batch, channels, height, width]");

        int batch = shape[0];
        int channels = shape[1];
        int outH = shape[2] + padTop + padBottom;
        int outW = shape[3] + padLeft + padRight;
        int outputSize = batch * channels * outH * outW;

        if (outputSize < _thresholds.MatrixMultiply || !SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.Pad(input, padTop, padBottom, padLeft, padRight, padValue);
        }

        if (typeof(T) == typeof(float))
            return (Tensor<T>)(object)PadGpuFloat((Tensor<float>)(object)input, padTop, padBottom, padLeft, padRight, (float)(object)padValue!);
        if (typeof(T) == typeof(double))
            return (Tensor<T>)(object)PadGpuDouble((Tensor<double>)(object)input, padTop, padBottom, padLeft, padRight, (double)(object)padValue!);

        return _cpuFallback.Pad(input, padTop, padBottom, padLeft, padRight, padValue);
    }

    private Tensor<float> PadGpuFloat(Tensor<float> input, int padTop, int padBottom, int padLeft, int padRight, float padValue)
    {
        var shape = input.Shape;
        int batch = shape[0];
        int channels = shape[1];
        int inH = shape[2];
        int inW = shape[3];
        int outH = inH + padTop + padBottom;
        int outW = inW + padLeft + padRight;
        int outputSize = batch * channels * outH * outW;

        var result = new Tensor<float>([batch, channels, outH, outW]);

        var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

            lock (_gpuLock)
            {
                (_padKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    outputSize, gpuInput.View, gpuOutput.View, batch, channels, inH, inW, padTop, padBottom, padLeft, padRight, padValue);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Pad (float) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Pad(input, padTop, padBottom, padLeft, padRight, padValue);
        }
        finally
        {
            _memoryPoolFloat.Return(gpuInput);
            _memoryPoolFloat.Return(gpuOutput);
        }
    }

    private Tensor<double> PadGpuDouble(Tensor<double> input, int padTop, int padBottom, int padLeft, int padRight, double padValue)
    {
        var shape = input.Shape;
        int batch = shape[0];
        int channels = shape[1];
        int inH = shape[2];
        int inW = shape[3];
        int outH = inH + padTop + padBottom;
        int outW = inW + padLeft + padRight;
        int outputSize = batch * channels * outH * outW;

        var result = new Tensor<double>([batch, channels, outH, outW]);

        var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
        var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(outputSize);

        try
        {
            gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

            lock (_gpuLock)
            {
                (_padKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                    outputSize, gpuInput.View, gpuOutput.View, batch, channels, inH, inW, padTop, padBottom, padLeft, padRight, padValue);
                (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
            }

            gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            Console.WriteLine($"[GpuEngine] GPU Pad (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Pad(input, padTop, padBottom, padLeft, padRight, padValue);
        }
        finally
        {
            _memoryPoolDouble.Return(gpuInput);
            _memoryPoolDouble.Return(gpuOutput);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> PadBackward<T>(Tensor<T> gradOutput, int padTop, int padLeft, int[] inputShape)
    {
        // PadBackward is essentially a Crop operation
        // Use the GPU Crop implementation
        if (gradOutput == null) throw new ArgumentNullException(nameof(gradOutput));
        if (inputShape == null) throw new ArgumentNullException(nameof(inputShape));

        int cropH = inputShape[2];
        int cropW = inputShape[3];
        return Crop(gradOutput, padTop, padLeft, cropH, cropW);
    }

    /// <inheritdoc/>
    public Tensor<T> Concat<T>(IReadOnlyList<Tensor<T>> tensors, int axis)
    {
        if (tensors is null || tensors.Count == 0)
            throw new ArgumentException("Tensors list cannot be null or empty", nameof(tensors));

        // Calculate total output size
        int totalSize = 0;
        foreach (var t in tensors) totalSize += t.Length;

        // For large concatenations, use optimized path
        if (totalSize >= _thresholds.VectorAdd * 2 && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)ConcatGpu(tensors.Cast<Tensor<float>>().ToList(), axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)ConcatGpuDouble(tensors.Cast<Tensor<double>>().ToList(), axis);
        }
        return _cpuFallback.Concat(tensors, axis);
    }

    private Tensor<float> ConcatGpu(IReadOnlyList<Tensor<float>> tensors, int axis)
    {
        try
        {
            if (tensors.Count == 0) throw new ArgumentException("No tensors to concatenate");
            if (tensors.Count == 1) return tensors[0];

            var firstShape = tensors[0].Shape;
            int rank = firstShape.Length;
            if (axis < 0) axis = rank + axis;

            // Calculate output shape
            int[] outputShape = (int[])firstShape.Clone();
            int concatDim = 0;
            foreach (var t in tensors) concatDim += t.Shape[axis];
            outputShape[axis] = concatDim;

            var result = new Tensor<float>(outputShape);
            var dstSpan = result.AsWritableSpan();

            // Calculate strides for efficient copy
            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= outputShape[i];
            for (int i = axis + 1; i < rank; i++) innerSize *= outputShape[i];

            int dstOffset = 0;
            foreach (var tensor in tensors)
            {
                var srcSpan = tensor.AsSpan();
                int srcAxisSize = tensor.Shape[axis];
                int srcSliceSize = srcAxisSize * innerSize;
                int dstSliceSize = outputShape[axis] * innerSize;

                for (int outer = 0; outer < outerSize; outer++)
                {
                    int srcBase = outer * srcSliceSize;
                    int dstBase = outer * dstSliceSize + dstOffset * innerSize;
                    for (int i = 0; i < srcSliceSize; i++)
                    {
                        dstSpan[dstBase + i] = srcSpan[srcBase + i];
                    }
                }
                dstOffset += srcAxisSize;
            }

            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU Concat failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Concat(tensors.Cast<Tensor<float>>().ToList(), axis);
        }
    }

    private Tensor<double> ConcatGpuDouble(IReadOnlyList<Tensor<double>> tensors, int axis)
    {
        try
        {
            if (tensors.Count == 0) throw new ArgumentException("No tensors to concatenate");
            if (tensors.Count == 1) return tensors[0];

            var firstShape = tensors[0].Shape;
            int rank = firstShape.Length;
            if (axis < 0) axis = rank + axis;

            int[] outputShape = (int[])firstShape.Clone();
            int concatDim = 0;
            foreach (var t in tensors) concatDim += t.Shape[axis];
            outputShape[axis] = concatDim;

            var result = new Tensor<double>(outputShape);
            var dstSpan = result.AsWritableSpan();

            int outerSize = 1, innerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= outputShape[i];
            for (int i = axis + 1; i < rank; i++) innerSize *= outputShape[i];

            int dstOffset = 0;
            foreach (var tensor in tensors)
            {
                var srcSpan = tensor.AsSpan();
                int srcAxisSize = tensor.Shape[axis];
                int srcSliceSize = srcAxisSize * innerSize;
                int dstSliceSize = outputShape[axis] * innerSize;

                for (int outer = 0; outer < outerSize; outer++)
                {
                    int srcBase = outer * srcSliceSize;
                    int dstBase = outer * dstSliceSize + dstOffset * innerSize;
                    for (int i = 0; i < srcSliceSize; i++)
                    {
                        dstSpan[dstBase + i] = srcSpan[srcBase + i];
                    }
                }
                dstOffset += srcAxisSize;
            }

            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU Concat (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.Concat(tensors.Cast<Tensor<double>>().ToList(), axis);
        }
    }

    /// <inheritdoc/>
    public T TensorSumOfSquares<T>(Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        // Use adaptive threshold - GPU reduction benefits from large tensors
        if (tensor.Length < _thresholds.VectorAdd * 4)
        {
            return _cpuFallback.TensorSumOfSquares(tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (T)(object)TensorSumOfSquaresGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (T)(object)TensorSumOfSquaresGpuDouble((Tensor<double>)(object)tensor);
        }

        return _cpuFallback.TensorSumOfSquares(tensor);
    }

    private float TensorSumOfSquaresGpu(Tensor<float> tensor)
    {
        try
        {
            int length = tensor.Length;
            int numBlocks = (length + ReductionBlockSize - 1) / ReductionBlockSize;

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
            var gpuPartialSums = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_partialSumOfSquaresKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numBlocks, gpuInput.View, gpuPartialSums.View, length);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Copy partial sums back and finish reduction on CPU
                var partialSums = new float[numBlocks];
                gpuPartialSums.View.BaseView.CopyToCPU(partialSums);

                float total = 0;
                for (int i = 0; i < numBlocks; i++)
                    total += partialSums[i];

                return total;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuPartialSums);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorSumOfSquares(tensor);
        }
    }

    private double TensorSumOfSquaresGpuDouble(Tensor<double> tensor)
    {
        try
        {
            int length = tensor.Length;
            int numBlocks = (length + ReductionBlockSize - 1) / ReductionBlockSize;

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(length);
            var gpuPartialSums = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(numBlocks);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_partialSumOfSquaresKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        numBlocks, gpuInput.View, gpuPartialSums.View, length);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                // Copy partial sums back and finish reduction on CPU
                var partialSums = new double[numBlocks];
                gpuPartialSums.View.BaseView.CopyToCPU(partialSums);

                double total = 0;
                for (int i = 0; i < numBlocks; i++)
                    total += partialSums[i];

                return total;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuPartialSums);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorSumOfSquares(tensor);
        }
    }

    /// <inheritdoc/>
    public Tensor<TValue> TensorEmbeddingLookup<TValue, TIndex>(Tensor<TValue> embeddings, Tensor<TIndex> indices)
        where TIndex : unmanaged
    {
        if (embeddings == null) throw new ArgumentNullException(nameof(embeddings));
        if (indices == null) throw new ArgumentNullException(nameof(indices));

        int numIndices = indices.Length;
        int embeddingDim = embeddings.Shape[1];
        int totalElements = numIndices * embeddingDim;

        // Use adaptive threshold
        if (totalElements < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorEmbeddingLookup<TValue, TIndex>(embeddings, indices);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(TValue) == typeof(float))
                return (Tensor<TValue>)(object)TensorEmbeddingLookupGpu(
                    (Tensor<float>)(object)embeddings, indices);
            if (typeof(TValue) == typeof(double))
                return (Tensor<TValue>)(object)TensorEmbeddingLookupGpuDouble(
                    (Tensor<double>)(object)embeddings, indices);
        }

        return _cpuFallback.TensorEmbeddingLookup<TValue, TIndex>(embeddings, indices);
    }

    private Tensor<float> TensorEmbeddingLookupGpu<TIndex>(Tensor<float> embeddings, Tensor<TIndex> indices)
        where TIndex : unmanaged
    {
        try
        {
            int vocabSize = embeddings.Shape[0];
            int embeddingDim = embeddings.Shape[1];
            int numIndices = indices.Length;
            int totalOutputElements = numIndices * embeddingDim;

            // Convert indices to int
            var intIndices = new int[numIndices];
            var indicesData = indices.ToArray();
            for (int i = 0; i < numIndices; i++)
                intIndices[i] = Convert.ToInt32(indicesData[i]);

            var gpuEmbeddings = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(embeddings.Length);
            var gpuIndices = (_memoryPoolInt ?? throw new InvalidOperationException("GPU not initialized")).Rent(numIndices);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalOutputElements);

            try
            {
                gpuEmbeddings.View.BaseView.CopyFromCPU(embeddings.AsSpan());
                gpuIndices.View.BaseView.CopyFromCPU(intIndices);

                lock (_gpuLock)
                {
                    (_embeddingLookupKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalOutputElements, gpuEmbeddings.View, gpuIndices.View, gpuOutput.View, embeddingDim);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var outputData = new float[totalOutputElements];
                gpuOutput.View.BaseView.CopyToCPU(outputData);

                // Create output tensor with proper shape [numIndices, embeddingDim]
                var outputShape = new int[indices.Rank + 1];
                for (int i = 0; i < indices.Rank; i++)
                    outputShape[i] = indices.Shape[i];
                outputShape[indices.Rank] = embeddingDim;

                return new Tensor<float>(outputShape, new Vector<float>(outputData));
            }
            finally
            {
                _memoryPoolFloat.Return(gpuEmbeddings);
                _memoryPoolInt.Return(gpuIndices);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorEmbeddingLookup<float, TIndex>(embeddings, indices);
        }
    }

    private Tensor<double> TensorEmbeddingLookupGpuDouble<TIndex>(Tensor<double> embeddings, Tensor<TIndex> indices)
        where TIndex : unmanaged
    {
        try
        {
            int vocabSize = embeddings.Shape[0];
            int embeddingDim = embeddings.Shape[1];
            int numIndices = indices.Length;
            int totalOutputElements = numIndices * embeddingDim;

            // Convert indices to int
            var intIndices = new int[numIndices];
            var indicesData = indices.ToArray();
            for (int i = 0; i < numIndices; i++)
                intIndices[i] = Convert.ToInt32(indicesData[i]);

            var gpuEmbeddings = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(embeddings.Length);
            var gpuIndices = (_memoryPoolInt ?? throw new InvalidOperationException("GPU not initialized")).Rent(numIndices);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalOutputElements);

            try
            {
                gpuEmbeddings.View.BaseView.CopyFromCPU(embeddings.AsSpan());
                gpuIndices.View.BaseView.CopyFromCPU(intIndices);

                lock (_gpuLock)
                {
                    (_embeddingLookupKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalOutputElements, gpuEmbeddings.View, gpuIndices.View, gpuOutput.View, embeddingDim);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var outputData = new double[totalOutputElements];
                gpuOutput.View.BaseView.CopyToCPU(outputData);

                // Create output tensor with proper shape [numIndices, embeddingDim]
                var outputShape = new int[indices.Rank + 1];
                for (int i = 0; i < indices.Rank; i++)
                    outputShape[i] = indices.Shape[i];
                outputShape[indices.Rank] = embeddingDim;

                return new Tensor<double>(outputShape, new Vector<double>(outputData));
            }
            finally
            {
                _memoryPoolDouble.Return(gpuEmbeddings);
                _memoryPoolInt.Return(gpuIndices);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorEmbeddingLookup<double, TIndex>(embeddings, indices);
        }
    }

    /// <inheritdoc/>
    public Tensor<TValue> TensorEmbeddingLookupBackward<TValue, TIndex>(Tensor<TValue> gradOutput, Tensor<TIndex> indices, int vocabSize, int embeddingDim)
        where TIndex : unmanaged
    {
        if (gradOutput == null) throw new ArgumentNullException(nameof(gradOutput));
        if (indices == null) throw new ArgumentNullException(nameof(indices));

        int numIndices = indices.Length;
        int totalGradElements = numIndices * embeddingDim;

        // Use adaptive threshold
        if (totalGradElements < _thresholds.VectorAdd)
        {
            return _cpuFallback.TensorEmbeddingLookupBackward<TValue, TIndex>(gradOutput, indices, vocabSize, embeddingDim);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(TValue) == typeof(float))
                return (Tensor<TValue>)(object)TensorEmbeddingLookupBackwardGpu(
                    (Tensor<float>)(object)gradOutput, indices, vocabSize, embeddingDim);
            if (typeof(TValue) == typeof(double))
                return (Tensor<TValue>)(object)TensorEmbeddingLookupBackwardGpuDouble(
                    (Tensor<double>)(object)gradOutput, indices, vocabSize, embeddingDim);
        }

        return _cpuFallback.TensorEmbeddingLookupBackward<TValue, TIndex>(gradOutput, indices, vocabSize, embeddingDim);
    }

    private Tensor<float> TensorEmbeddingLookupBackwardGpu<TIndex>(Tensor<float> gradOutput, Tensor<TIndex> indices, int vocabSize, int embeddingDim)
        where TIndex : unmanaged
    {
        try
        {
            int numIndices = indices.Length;
            int totalGradElements = numIndices * embeddingDim;
            int totalEmbeddingElements = vocabSize * embeddingDim;

            // Convert indices to int
            var intIndices = new int[numIndices];
            var indicesData = indices.ToArray();
            for (int i = 0; i < numIndices; i++)
                intIndices[i] = Convert.ToInt32(indicesData[i]);

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalGradElements);
            var gpuIndices = (_memoryPoolInt ?? throw new InvalidOperationException("GPU not initialized")).Rent(numIndices);
            var gpuGradEmbeddings = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalEmbeddingElements);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuIndices.View.BaseView.CopyFromCPU(intIndices);

                // Initialize gradEmbeddings to zero
                gpuGradEmbeddings.View.BaseView.MemSetToZero();

                lock (_gpuLock)
                {
                    (_embeddingLookupBackwardKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalGradElements, gpuGradOutput.View, gpuIndices.View, gpuGradEmbeddings.View, embeddingDim, numIndices);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var gradEmbeddingsData = new float[totalEmbeddingElements];
                gpuGradEmbeddings.View.BaseView.CopyToCPU(gradEmbeddingsData);

                return new Tensor<float>(new[] { vocabSize, embeddingDim }, new Vector<float>(gradEmbeddingsData));
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolInt.Return(gpuIndices);
                _memoryPoolFloat.Return(gpuGradEmbeddings);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorEmbeddingLookupBackward<float, TIndex>(gradOutput, indices, vocabSize, embeddingDim);
        }
    }

    private Tensor<double> TensorEmbeddingLookupBackwardGpuDouble<TIndex>(Tensor<double> gradOutput, Tensor<TIndex> indices, int vocabSize, int embeddingDim)
        where TIndex : unmanaged
    {
        try
        {
            int numIndices = indices.Length;
            int totalGradElements = numIndices * embeddingDim;
            int totalEmbeddingElements = vocabSize * embeddingDim;

            // Convert indices to int
            var intIndices = new int[numIndices];
            var indicesData = indices.ToArray();
            for (int i = 0; i < numIndices; i++)
                intIndices[i] = Convert.ToInt32(indicesData[i]);

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalGradElements);
            var gpuIndices = (_memoryPoolInt ?? throw new InvalidOperationException("GPU not initialized")).Rent(numIndices);
            var gpuGradEmbeddings = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalEmbeddingElements);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuIndices.View.BaseView.CopyFromCPU(intIndices);

                // Initialize gradEmbeddings to zero
                gpuGradEmbeddings.View.BaseView.MemSetToZero();

                lock (_gpuLock)
                {
                    (_embeddingLookupBackwardKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalGradElements, gpuGradOutput.View, gpuIndices.View, gpuGradEmbeddings.View, embeddingDim, numIndices);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var gradEmbeddingsData = new double[totalEmbeddingElements];
                gpuGradEmbeddings.View.BaseView.CopyToCPU(gradEmbeddingsData);

                return new Tensor<double>(new[] { vocabSize, embeddingDim }, new Vector<double>(gradEmbeddingsData));
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolInt.Return(gpuIndices);
                _memoryPoolDouble.Return(gpuGradEmbeddings);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.TensorEmbeddingLookupBackward<double, TIndex>(gradOutput, indices, vocabSize, embeddingDim);
        }
    }

    #endregion

    #region IDisposable

    /// <inheritdoc/>
    public void Dispose()
    {
        if (_disposed) return;

        // Dispose memory pools (Phase B: US-GPU-002, US-GPU-005)
        _memoryPoolFloat?.Dispose();
        _memoryPoolDouble?.Dispose();
        _memoryPoolInt?.Dispose();
        _memoryPoolLong?.Dispose();

        _accelerator?.Dispose();
        _context?.Dispose();

        _disposed = true;
        GC.SuppressFinalize(this);
    }

    #endregion

    #region LocallyConnected Operations

    /// <inheritdoc/>
    public Tensor<T> LocallyConnectedConv2D<T>(Tensor<T> input, Tensor<T> weights, Tensor<T>? bias, int[] stride)
    {
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (weights == null) throw new ArgumentNullException(nameof(weights));
        if (stride == null || stride.Length != 2) throw new ArgumentException("stride must be a 2-element array", nameof(stride));

        // Input: [batch, inChannels, height, width]
        // Weights: [outputHeight, outputWidth, outChannels, inChannels, kernelHeight, kernelWidth]
        int batch = input.Shape[0];
        int outChannels = weights.Shape[2];
        int outputHeight = weights.Shape[0];
        int outputWidth = weights.Shape[1];
        int totalOutputElements = batch * outChannels * outputHeight * outputWidth;

        // Use adaptive threshold - GPU is beneficial for larger operations
        if (totalOutputElements < _thresholds.VectorAdd)
        {
            return _cpuFallback.LocallyConnectedConv2D(input, weights, bias, stride);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)LocallyConnectedConv2DGpu(
                    (Tensor<float>)(object)input,
                    (Tensor<float>)(object)weights,
                    bias != null ? (Tensor<float>)(object)bias : null,
                    stride);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)LocallyConnectedConv2DGpuDouble(
                    (Tensor<double>)(object)input,
                    (Tensor<double>)(object)weights,
                    bias != null ? (Tensor<double>)(object)bias : null,
                    stride);
        }

        return _cpuFallback.LocallyConnectedConv2D(input, weights, bias, stride);
    }

    private Tensor<float> LocallyConnectedConv2DGpu(Tensor<float> input, Tensor<float> weights, Tensor<float>? bias, int[] stride)
    {
        try
        {
            // Input: [batch, inChannels, height, width]
            // Weights: [outputHeight, outputWidth, outChannels, inChannels, kernelHeight, kernelWidth]
            // Bias: [outputHeight, outputWidth, outChannels] or null
            int batch = input.Shape[0];
            int inChannels = input.Shape[1];
            int inputHeight = input.Shape[2];
            int inputWidth = input.Shape[3];
            int outputHeight = weights.Shape[0];
            int outputWidth = weights.Shape[1];
            int outChannels = weights.Shape[2];
            int kernelHeight = weights.Shape[4];
            int kernelWidth = weights.Shape[5];

            int totalOutputElements = batch * outChannels * outputHeight * outputWidth;
            int hasBias = bias != null ? 1 : 0;

            var p = new LocallyConnectedConv2DParams(
                batch, inChannels, inputHeight, inputWidth,
                outChannels, outputHeight, outputWidth,
                kernelHeight, kernelWidth, stride[0], stride[1]);

            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuWeights = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(weights.Length);
            var gpuBias = hasBias == 1
                ? (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(bias!.Length)
                : (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(1); // Dummy allocation
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalOutputElements);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuWeights.View.BaseView.CopyFromCPU(weights.AsSpan());
                if (hasBias == 1)
                    gpuBias.View.BaseView.CopyFromCPU(bias!.AsSpan());

                lock (_gpuLock)
                {
                    (_locallyConnectedConv2DKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalOutputElements, gpuInput.View, gpuWeights.View, gpuBias.View, gpuOutput.View, p, hasBias);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var outputData = new float[totalOutputElements];
                gpuOutput.View.BaseView.CopyToCPU(outputData);

                return new Tensor<float>(new[] { batch, outChannels, outputHeight, outputWidth }, new Vector<float>(outputData));
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuWeights);
                _memoryPoolFloat.Return(gpuBias);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.LocallyConnectedConv2D(input, weights, bias, stride);
        }
    }

    private Tensor<double> LocallyConnectedConv2DGpuDouble(Tensor<double> input, Tensor<double> weights, Tensor<double>? bias, int[] stride)
    {
        try
        {
            int batch = input.Shape[0];
            int inChannels = input.Shape[1];
            int inputHeight = input.Shape[2];
            int inputWidth = input.Shape[3];
            int outputHeight = weights.Shape[0];
            int outputWidth = weights.Shape[1];
            int outChannels = weights.Shape[2];
            int kernelHeight = weights.Shape[4];
            int kernelWidth = weights.Shape[5];

            int totalOutputElements = batch * outChannels * outputHeight * outputWidth;
            int hasBias = bias != null ? 1 : 0;

            var p = new LocallyConnectedConv2DParams(
                batch, inChannels, inputHeight, inputWidth,
                outChannels, outputHeight, outputWidth,
                kernelHeight, kernelWidth, stride[0], stride[1]);

            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuWeights = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(weights.Length);
            var gpuBias = hasBias == 1
                ? (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(bias!.Length)
                : (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(1);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalOutputElements);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());
                gpuWeights.View.BaseView.CopyFromCPU(weights.AsSpan());
                if (hasBias == 1)
                    gpuBias.View.BaseView.CopyFromCPU(bias!.AsSpan());

                lock (_gpuLock)
                {
                    (_locallyConnectedConv2DKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalOutputElements, gpuInput.View, gpuWeights.View, gpuBias.View, gpuOutput.View, p, hasBias);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var outputData = new double[totalOutputElements];
                gpuOutput.View.BaseView.CopyToCPU(outputData);

                return new Tensor<double>(new[] { batch, outChannels, outputHeight, outputWidth }, new Vector<double>(outputData));
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuWeights);
                _memoryPoolDouble.Return(gpuBias);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.LocallyConnectedConv2D(input, weights, bias, stride);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> LocallyConnectedConv2DBackwardInput<T>(Tensor<T> gradOutput, Tensor<T> weights, int[] inputShape, int[] stride)
    {
        if (gradOutput == null) throw new ArgumentNullException(nameof(gradOutput));
        if (weights == null) throw new ArgumentNullException(nameof(weights));
        if (inputShape == null || inputShape.Length != 4) throw new ArgumentException("inputShape must be a 4-element array", nameof(inputShape));
        if (stride == null || stride.Length != 2) throw new ArgumentException("stride must be a 2-element array", nameof(stride));

        int totalInputElements = inputShape[0] * inputShape[1] * inputShape[2] * inputShape[3];

        if (totalInputElements < _thresholds.VectorAdd)
        {
            return _cpuFallback.LocallyConnectedConv2DBackwardInput(gradOutput, weights, inputShape, stride);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)LocallyConnectedConv2DBackwardInputGpu(
                    (Tensor<float>)(object)gradOutput, (Tensor<float>)(object)weights, inputShape, stride);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)LocallyConnectedConv2DBackwardInputGpuDouble(
                    (Tensor<double>)(object)gradOutput, (Tensor<double>)(object)weights, inputShape, stride);
        }

        return _cpuFallback.LocallyConnectedConv2DBackwardInput(gradOutput, weights, inputShape, stride);
    }

    private Tensor<float> LocallyConnectedConv2DBackwardInputGpu(Tensor<float> gradOutput, Tensor<float> weights, int[] inputShape, int[] stride)
    {
        try
        {
            // GradOutput: [batch, outChannels, outputHeight, outputWidth]
            // Weights: [outputHeight, outputWidth, outChannels, inChannels, kernelHeight, kernelWidth]
            // Output (gradInput): [batch, inChannels, inputHeight, inputWidth]
            int batch = gradOutput.Shape[0];
            int outChannels = gradOutput.Shape[1];
            int outputHeight = gradOutput.Shape[2];
            int outputWidth = gradOutput.Shape[3];
            int inChannels = inputShape[1];
            int inputHeight = inputShape[2];
            int inputWidth = inputShape[3];
            int kernelHeight = weights.Shape[4];
            int kernelWidth = weights.Shape[5];

            int totalInputElements = batch * inChannels * inputHeight * inputWidth;

            var p = new LocallyConnectedConv2DParams(
                batch, inChannels, inputHeight, inputWidth,
                outChannels, outputHeight, outputWidth,
                kernelHeight, kernelWidth, stride[0], stride[1]);

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuWeights = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(weights.Length);
            var gpuGradInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalInputElements);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuWeights.View.BaseView.CopyFromCPU(weights.AsSpan());

                // Initialize gradInput to zero
                var zeroData = new float[totalInputElements];
                gpuGradInput.View.BaseView.CopyFromCPU(zeroData);

                lock (_gpuLock)
                {
                    (_locallyConnectedConv2DBackwardInputKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalInputElements, gpuGradOutput.View, gpuWeights.View, gpuGradInput.View, p);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var outputData = new float[totalInputElements];
                gpuGradInput.View.BaseView.CopyToCPU(outputData);

                return new Tensor<float>(inputShape, new Vector<float>(outputData));
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuWeights);
                _memoryPoolFloat.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.LocallyConnectedConv2DBackwardInput(gradOutput, weights, inputShape, stride);
        }
    }

    private Tensor<double> LocallyConnectedConv2DBackwardInputGpuDouble(Tensor<double> gradOutput, Tensor<double> weights, int[] inputShape, int[] stride)
    {
        try
        {
            int batch = gradOutput.Shape[0];
            int outChannels = gradOutput.Shape[1];
            int outputHeight = gradOutput.Shape[2];
            int outputWidth = gradOutput.Shape[3];
            int inChannels = inputShape[1];
            int inputHeight = inputShape[2];
            int inputWidth = inputShape[3];
            int kernelHeight = weights.Shape[4];
            int kernelWidth = weights.Shape[5];

            int totalInputElements = batch * inChannels * inputHeight * inputWidth;

            var p = new LocallyConnectedConv2DParams(
                batch, inChannels, inputHeight, inputWidth,
                outChannels, outputHeight, outputWidth,
                kernelHeight, kernelWidth, stride[0], stride[1]);

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuWeights = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(weights.Length);
            var gpuGradInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalInputElements);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuWeights.View.BaseView.CopyFromCPU(weights.AsSpan());

                var zeroData = new double[totalInputElements];
                gpuGradInput.View.BaseView.CopyFromCPU(zeroData);

                lock (_gpuLock)
                {
                    (_locallyConnectedConv2DBackwardInputKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalInputElements, gpuGradOutput.View, gpuWeights.View, gpuGradInput.View, p);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var outputData = new double[totalInputElements];
                gpuGradInput.View.BaseView.CopyToCPU(outputData);

                return new Tensor<double>(inputShape, new Vector<double>(outputData));
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuWeights);
                _memoryPoolDouble.Return(gpuGradInput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.LocallyConnectedConv2DBackwardInput(gradOutput, weights, inputShape, stride);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> LocallyConnectedConv2DBackwardWeights<T>(Tensor<T> gradOutput, Tensor<T> input, int[] weightsShape, int[] stride)
    {
        if (gradOutput == null) throw new ArgumentNullException(nameof(gradOutput));
        if (input == null) throw new ArgumentNullException(nameof(input));
        if (weightsShape == null || weightsShape.Length != 6) throw new ArgumentException("weightsShape must be a 6-element array", nameof(weightsShape));
        if (stride == null || stride.Length != 2) throw new ArgumentException("stride must be a 2-element array", nameof(stride));

        int totalWeightElements = weightsShape[0] * weightsShape[1] * weightsShape[2] * weightsShape[3] * weightsShape[4] * weightsShape[5];

        if (totalWeightElements < _thresholds.VectorAdd)
        {
            return _cpuFallback.LocallyConnectedConv2DBackwardWeights(gradOutput, input, weightsShape, stride);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)LocallyConnectedConv2DBackwardWeightsGpu(
                    (Tensor<float>)(object)gradOutput, (Tensor<float>)(object)input, weightsShape, stride);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)LocallyConnectedConv2DBackwardWeightsGpuDouble(
                    (Tensor<double>)(object)gradOutput, (Tensor<double>)(object)input, weightsShape, stride);
        }

        return _cpuFallback.LocallyConnectedConv2DBackwardWeights(gradOutput, input, weightsShape, stride);
    }

    private Tensor<float> LocallyConnectedConv2DBackwardWeightsGpu(Tensor<float> gradOutput, Tensor<float> input, int[] weightsShape, int[] stride)
    {
        try
        {
            // GradOutput: [batch, outChannels, outputHeight, outputWidth]
            // Input: [batch, inChannels, inputHeight, inputWidth]
            // Output (gradWeights): [outputHeight, outputWidth, outChannels, inChannels, kernelHeight, kernelWidth]
            int batch = input.Shape[0];
            int inChannels = input.Shape[1];
            int inputHeight = input.Shape[2];
            int inputWidth = input.Shape[3];
            int outputHeight = weightsShape[0];
            int outputWidth = weightsShape[1];
            int outChannels = weightsShape[2];
            int kernelHeight = weightsShape[4];
            int kernelWidth = weightsShape[5];

            int totalWeightElements = outputHeight * outputWidth * outChannels * inChannels * kernelHeight * kernelWidth;

            var p = new LocallyConnectedConv2DParams(
                batch, inChannels, inputHeight, inputWidth,
                outChannels, outputHeight, outputWidth,
                kernelHeight, kernelWidth, stride[0], stride[1]);

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuGradWeights = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalWeightElements);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                // Initialize gradWeights to zero
                var zeroData = new float[totalWeightElements];
                gpuGradWeights.View.BaseView.CopyFromCPU(zeroData);

                lock (_gpuLock)
                {
                    (_locallyConnectedConv2DBackwardWeightsKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalWeightElements, gpuGradOutput.View, gpuInput.View, gpuGradWeights.View, p);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var outputData = new float[totalWeightElements];
                gpuGradWeights.View.BaseView.CopyToCPU(outputData);

                return new Tensor<float>(weightsShape, new Vector<float>(outputData));
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuGradWeights);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.LocallyConnectedConv2DBackwardWeights(gradOutput, input, weightsShape, stride);
        }
    }

    private Tensor<double> LocallyConnectedConv2DBackwardWeightsGpuDouble(Tensor<double> gradOutput, Tensor<double> input, int[] weightsShape, int[] stride)
    {
        try
        {
            int batch = input.Shape[0];
            int inChannels = input.Shape[1];
            int inputHeight = input.Shape[2];
            int inputWidth = input.Shape[3];
            int outputHeight = weightsShape[0];
            int outputWidth = weightsShape[1];
            int outChannels = weightsShape[2];
            int kernelHeight = weightsShape[4];
            int kernelWidth = weightsShape[5];

            int totalWeightElements = outputHeight * outputWidth * outChannels * inChannels * kernelHeight * kernelWidth;

            var p = new LocallyConnectedConv2DParams(
                batch, inChannels, inputHeight, inputWidth,
                outChannels, outputHeight, outputWidth,
                kernelHeight, kernelWidth, stride[0], stride[1]);

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(input.Length);
            var gpuGradWeights = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalWeightElements);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());
                gpuInput.View.BaseView.CopyFromCPU(input.AsSpan());

                var zeroData = new double[totalWeightElements];
                gpuGradWeights.View.BaseView.CopyFromCPU(zeroData);

                lock (_gpuLock)
                {
                    (_locallyConnectedConv2DBackwardWeightsKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalWeightElements, gpuGradOutput.View, gpuInput.View, gpuGradWeights.View, p);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var outputData = new double[totalWeightElements];
                gpuGradWeights.View.BaseView.CopyToCPU(outputData);

                return new Tensor<double>(weightsShape, new Vector<double>(outputData));
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuGradWeights);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.LocallyConnectedConv2DBackwardWeights(gradOutput, input, weightsShape, stride);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> LocallyConnectedConv2DBackwardBias<T>(Tensor<T> gradOutput)
    {
        if (gradOutput == null) throw new ArgumentNullException(nameof(gradOutput));

        // GradOutput: [batch, outChannels, outputHeight, outputWidth]
        // Output (gradBias): [outputHeight, outputWidth, outChannels]
        int outChannels = gradOutput.Shape[1];
        int outputHeight = gradOutput.Shape[2];
        int outputWidth = gradOutput.Shape[3];
        int totalBiasElements = outputHeight * outputWidth * outChannels;

        if (totalBiasElements < _thresholds.VectorAdd)
        {
            return _cpuFallback.LocallyConnectedConv2DBackwardBias(gradOutput);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)LocallyConnectedConv2DBackwardBiasGpu((Tensor<float>)(object)gradOutput);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)LocallyConnectedConv2DBackwardBiasGpuDouble((Tensor<double>)(object)gradOutput);
        }

        return _cpuFallback.LocallyConnectedConv2DBackwardBias(gradOutput);
    }

    private Tensor<float> LocallyConnectedConv2DBackwardBiasGpu(Tensor<float> gradOutput)
    {
        try
        {
            // GradOutput: [batch, outChannels, outputHeight, outputWidth]
            // Output (gradBias): [outputHeight, outputWidth, outChannels]
            int batch = gradOutput.Shape[0];
            int outChannels = gradOutput.Shape[1];
            int outputHeight = gradOutput.Shape[2];
            int outputWidth = gradOutput.Shape[3];

            int totalBiasElements = outputHeight * outputWidth * outChannels;

            // Note: Using dummy values for input dimensions since bias backward doesn't need them
            var p = new LocallyConnectedConv2DParams(
                batch, 1, 1, 1,
                outChannels, outputHeight, outputWidth,
                1, 1, 1, 1);

            var gpuGradOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuGradBias = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalBiasElements);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());

                // Initialize gradBias to zero
                var zeroData = new float[totalBiasElements];
                gpuGradBias.View.BaseView.CopyFromCPU(zeroData);

                lock (_gpuLock)
                {
                    (_locallyConnectedConv2DBackwardBiasKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalBiasElements, gpuGradOutput.View, gpuGradBias.View, p);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var outputData = new float[totalBiasElements];
                gpuGradBias.View.BaseView.CopyToCPU(outputData);

                return new Tensor<float>(new[] { outputHeight, outputWidth, outChannels }, new Vector<float>(outputData));
            }
            finally
            {
                _memoryPoolFloat.Return(gpuGradOutput);
                _memoryPoolFloat.Return(gpuGradBias);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.LocallyConnectedConv2DBackwardBias(gradOutput);
        }
    }

    private Tensor<double> LocallyConnectedConv2DBackwardBiasGpuDouble(Tensor<double> gradOutput)
    {
        try
        {
            int batch = gradOutput.Shape[0];
            int outChannels = gradOutput.Shape[1];
            int outputHeight = gradOutput.Shape[2];
            int outputWidth = gradOutput.Shape[3];

            int totalBiasElements = outputHeight * outputWidth * outChannels;

            var p = new LocallyConnectedConv2DParams(
                batch, 1, 1, 1,
                outChannels, outputHeight, outputWidth,
                1, 1, 1, 1);

            var gpuGradOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(gradOutput.Length);
            var gpuGradBias = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(totalBiasElements);

            try
            {
                gpuGradOutput.View.BaseView.CopyFromCPU(gradOutput.AsSpan());

                var zeroData = new double[totalBiasElements];
                gpuGradBias.View.BaseView.CopyFromCPU(zeroData);

                lock (_gpuLock)
                {
                    (_locallyConnectedConv2DBackwardBiasKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        totalBiasElements, gpuGradOutput.View, gpuGradBias.View, p);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                var outputData = new double[totalBiasElements];
                gpuGradBias.View.BaseView.CopyToCPU(outputData);

                return new Tensor<double>(new[] { outputHeight, outputWidth, outChannels }, new Vector<double>(outputData));
            }
            finally
            {
                _memoryPoolDouble.Return(gpuGradOutput);
                _memoryPoolDouble.Return(gpuGradBias);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.LocallyConnectedConv2DBackwardBias(gradOutput);
        }
    }

    #endregion

    #region Reshape

    /// <inheritdoc/>
    public Tensor<T> Reshape<T>(Tensor<T> tensor, int[] newShape)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));
        if (newShape == null) throw new ArgumentNullException(nameof(newShape));

        return tensor.Reshape(newShape);
    }

    #endregion

    #region RBF Kernel

    /// <inheritdoc/>
    public Tensor<T> RBFKernel<T>(Tensor<T> input, Tensor<T> centers, Tensor<T> epsilons)
    {
        // GPU kernel not yet implemented - use CPU fallback
        return _cpuFallback.RBFKernel(input, centers, epsilons);
    }

    /// <inheritdoc/>
    public (Tensor<T> gradInput, Tensor<T> gradCenters, Tensor<T> gradEpsilons) RBFKernelBackward<T>(
        Tensor<T> gradOutput, Tensor<T> input, Tensor<T> centers, Tensor<T> epsilons, Tensor<T> output)
    {
        // GPU kernel not yet implemented - use CPU fallback
        return _cpuFallback.RBFKernelBackward(gradOutput, input, centers, epsilons, output);
    }

    #endregion

    #region Tensor Shape Operations

    /// <inheritdoc/>
    public Tensor<T> TensorRepeatElements<T>(Tensor<T> tensor, int repeats, int axis = 0)
    {
        // For large tensors with significant repetition, parallel CPU can help
        int outputSize = tensor.Length * repeats;
        if (outputSize >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorRepeatElementsGpu((Tensor<float>)(object)tensor, repeats, axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorRepeatElementsGpuDouble((Tensor<double>)(object)tensor, repeats, axis);
        }
        return _cpuFallback.TensorRepeatElements(tensor, repeats, axis);
    }

    private Tensor<float> TensorRepeatElementsGpu(Tensor<float> tensor, int repeats, int axis)
    {
        try
        {
            var shape = tensor.Shape.ToArray();
            var newShape = (int[])shape.Clone();
            newShape[axis] *= repeats;

            int resultLength = 1;
            foreach (var d in newShape) resultLength *= d;
            var srcSpan = tensor.AsSpan().ToArray();
            var resultArray = new float[resultLength];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize, o =>
            {
                for (int a = 0; a < axisSize; a++)
                {
                    int srcBase = (o * axisSize + a) * innerSize;
                    for (int r = 0; r < repeats; r++)
                    {
                        int dstBase = (o * axisSize * repeats + a * repeats + r) * innerSize;
                        for (int i = 0; i < innerSize; i++)
                        {
                            resultArray[dstBase + i] = srcSpan[srcBase + i];
                        }
                    }
                }
            });

            return new Tensor<float>(newShape, new Vector<float>(resultArray));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorRepeatElements(tensor, repeats, axis);
        }
    }

    private Tensor<double> TensorRepeatElementsGpuDouble(Tensor<double> tensor, int repeats, int axis)
    {
        try
        {
            var shape = tensor.Shape.ToArray();
            var newShape = (int[])shape.Clone();
            newShape[axis] *= repeats;

            int resultLength = 1;
            foreach (var d in newShape) resultLength *= d;
            var srcSpan = tensor.AsSpan().ToArray();
            var resultArray = new double[resultLength];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize, o =>
            {
                for (int a = 0; a < axisSize; a++)
                {
                    int srcBase = (o * axisSize + a) * innerSize;
                    for (int r = 0; r < repeats; r++)
                    {
                        int dstBase = (o * axisSize * repeats + a * repeats + r) * innerSize;
                        for (int i = 0; i < innerSize; i++)
                        {
                            resultArray[dstBase + i] = srcSpan[srcBase + i];
                        }
                    }
                }
            });

            return new Tensor<double>(newShape, new Vector<double>(resultArray));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorRepeatElements(tensor, repeats, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorTile<T>(Tensor<T> tensor, int[] multiples)
    {
        int outputSize = tensor.Length;
        foreach (var m in multiples) outputSize *= m;

        if (outputSize >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorTileGpu((Tensor<float>)(object)tensor, multiples);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorTileGpuDouble((Tensor<double>)(object)tensor, multiples);
        }
        return _cpuFallback.TensorTile(tensor, multiples);
    }

    private Tensor<float> TensorTileGpu(Tensor<float> tensor, int[] multiples)
    {
        try
        {
            var shape = tensor.Shape;
            var newShape = new int[shape.Length];
            for (int i = 0; i < shape.Length; i++)
                newShape[i] = shape[i] * (i < multiples.Length ? multiples[i] : 1);

            var srcData = tensor.AsSpan().ToArray();
            var resultArray = new float[tensor.Length * multiples.Aggregate(1, (a, b) => a * b)];
            int srcLength = tensor.Length;

            // For simple cases, use parallel tiling
            System.Threading.Tasks.Parallel.For(0, resultArray.Length, dstIdx =>
            {
                // Calculate source index by wrapping each dimension
                int srcIdx = 0;
                int stride = 1;
                int dstTemp = dstIdx;
                for (int d = shape.Length - 1; d >= 0; d--)
                {
                    int dstDimIdx = dstTemp % newShape[d];
                    int srcDimIdx = dstDimIdx % shape[d];
                    srcIdx += srcDimIdx * stride;
                    stride *= shape[d];
                    dstTemp /= newShape[d];
                }
                resultArray[dstIdx] = srcData[srcIdx];
            });

            return new Tensor<float>(newShape, new Vector<float>(resultArray));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorTile(tensor, multiples);
        }
    }

    private Tensor<double> TensorTileGpuDouble(Tensor<double> tensor, int[] multiples)
    {
        try
        {
            var shape = tensor.Shape;
            var newShape = new int[shape.Length];
            for (int i = 0; i < shape.Length; i++)
                newShape[i] = shape[i] * (i < multiples.Length ? multiples[i] : 1);

            var srcData = tensor.AsSpan().ToArray();
            int totalLength = 1;
            foreach (var n in newShape) totalLength *= n;
            var resultArray = new double[totalLength];
            int srcLength = tensor.Length;

            System.Threading.Tasks.Parallel.For(0, resultArray.Length, dstIdx =>
            {
                int srcIdx = 0;
                int stride = 1;
                int dstTemp = dstIdx;
                for (int d = shape.Length - 1; d >= 0; d--)
                {
                    int dstDimIdx = dstTemp % newShape[d];
                    int srcDimIdx = dstDimIdx % shape[d];
                    srcIdx += srcDimIdx * stride;
                    stride *= shape[d];
                    dstTemp /= newShape[d];
                }
                resultArray[dstIdx] = srcData[srcIdx];
            });

            return new Tensor<double>(newShape, new Vector<double>(resultArray));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorTile(tensor, multiples);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorSlice<T>(Tensor<T> tensor, int[] start, int[] length)
    {
        // For large tensors, optimized copy can be beneficial
        int outputSize = 1;
        for (int i = 0; i < length.Length; i++) outputSize *= length[i];

        if (outputSize >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorSliceGpu((Tensor<float>)(object)tensor, start, length);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorSliceGpuDouble((Tensor<double>)(object)tensor, start, length);
        }
        return _cpuFallback.TensorSlice(tensor, start, length);
    }

    private Tensor<float> TensorSliceGpu(Tensor<float> tensor, int[] start, int[] length)
    {
        try
        {
            var result = new Tensor<float>(length);
            var srcSpan = tensor.AsSpan();
            var dstSpan = result.AsWritableSpan();
            var shape = tensor.Shape;

            // Optimized for common 4D case [batch, channels, height, width]
            if (shape.Length == 4 && length.Length == 4)
            {
                int srcC = shape[1], srcH = shape[2], srcW = shape[3];
                int dstB = length[0], dstC = length[1], dstH = length[2], dstW = length[3];
                int offB = start[0], offC = start[1], offH = start[2], offW = start[3];

                int dstIdx = 0;
                for (int b = 0; b < dstB; b++)
                {
                    for (int c = 0; c < dstC; c++)
                    {
                        for (int h = 0; h < dstH; h++)
                        {
                            int srcBase = (((b + offB) * srcC + (c + offC)) * srcH + (h + offH)) * srcW + offW;
                            for (int w = 0; w < dstW; w++)
                            {
                                dstSpan[dstIdx++] = srcSpan[srcBase + w];
                            }
                        }
                    }
                }
            }
            else
            {
                return _cpuFallback.TensorSlice(tensor, start, length);
            }
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU TensorSlice failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorSlice(tensor, start, length);
        }
    }

    private Tensor<double> TensorSliceGpuDouble(Tensor<double> tensor, int[] start, int[] length)
    {
        try
        {
            var result = new Tensor<double>(length);
            var srcSpan = tensor.AsSpan();
            var dstSpan = result.AsWritableSpan();
            var shape = tensor.Shape;

            if (shape.Length == 4 && length.Length == 4)
            {
                int srcC = shape[1], srcH = shape[2], srcW = shape[3];
                int dstB = length[0], dstC = length[1], dstH = length[2], dstW = length[3];
                int offB = start[0], offC = start[1], offH = start[2], offW = start[3];

                int dstIdx = 0;
                for (int b = 0; b < dstB; b++)
                {
                    for (int c = 0; c < dstC; c++)
                    {
                        for (int h = 0; h < dstH; h++)
                        {
                            int srcBase = (((b + offB) * srcC + (c + offC)) * srcH + (h + offH)) * srcW + offW;
                            for (int w = 0; w < dstW; w++)
                            {
                                dstSpan[dstIdx++] = srcSpan[srcBase + w];
                            }
                        }
                    }
                }
            }
            else
            {
                return _cpuFallback.TensorSlice(tensor, start, length);
            }
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU TensorSlice (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorSlice(tensor, start, length);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorSetSlice<T>(Tensor<T> destination, Tensor<T> source, int[] start)
    {
        if (source.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorSetSliceGpu((Tensor<float>)(object)destination, (Tensor<float>)(object)source, start);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorSetSliceGpuDouble((Tensor<double>)(object)destination, (Tensor<double>)(object)source, start);
        }
        return _cpuFallback.TensorSetSlice(destination, source, start);
    }

    private Tensor<float> TensorSetSliceGpu(Tensor<float> destination, Tensor<float> source, int[] start)
    {
        try
        {
            var result = new Tensor<float>(destination.Shape);
            destination.AsSpan().CopyTo(result.AsWritableSpan());

            var srcSpan = source.AsSpan();
            var dstSpan = result.AsWritableSpan();
            var dstShape = destination.Shape;
            var srcShape = source.Shape;

            if (dstShape.Length == 4 && srcShape.Length == 4)
            {
                int dstC = dstShape[1], dstH = dstShape[2], dstW = dstShape[3];
                int srcB = srcShape[0], srcC = srcShape[1], srcH = srcShape[2], srcW = srcShape[3];
                int offB = start[0], offC = start[1], offH = start[2], offW = start[3];

                int srcIdx = 0;
                for (int b = 0; b < srcB; b++)
                {
                    for (int c = 0; c < srcC; c++)
                    {
                        for (int h = 0; h < srcH; h++)
                        {
                            int dstBase = (((b + offB) * dstC + (c + offC)) * dstH + (h + offH)) * dstW + offW;
                            for (int w = 0; w < srcW; w++)
                            {
                                dstSpan[dstBase + w] = srcSpan[srcIdx++];
                            }
                        }
                    }
                }
            }
            else
            {
                return _cpuFallback.TensorSetSlice(destination, source, start);
            }
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU TensorSetSlice failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorSetSlice(destination, source, start);
        }
    }

    private Tensor<double> TensorSetSliceGpuDouble(Tensor<double> destination, Tensor<double> source, int[] start)
    {
        try
        {
            var result = new Tensor<double>(destination.Shape);
            destination.AsSpan().CopyTo(result.AsWritableSpan());

            var srcSpan = source.AsSpan();
            var dstSpan = result.AsWritableSpan();
            var dstShape = destination.Shape;
            var srcShape = source.Shape;

            if (dstShape.Length == 4 && srcShape.Length == 4)
            {
                int dstC = dstShape[1], dstH = dstShape[2], dstW = dstShape[3];
                int srcB = srcShape[0], srcC = srcShape[1], srcH = srcShape[2], srcW = srcShape[3];
                int offB = start[0], offC = start[1], offH = start[2], offW = start[3];

                int srcIdx = 0;
                for (int b = 0; b < srcB; b++)
                {
                    for (int c = 0; c < srcC; c++)
                    {
                        for (int h = 0; h < srcH; h++)
                        {
                            int dstBase = (((b + offB) * dstC + (c + offC)) * dstH + (h + offH)) * dstW + offW;
                            for (int w = 0; w < srcW; w++)
                            {
                                dstSpan[dstBase + w] = srcSpan[srcIdx++];
                            }
                        }
                    }
                }
            }
            else
            {
                return _cpuFallback.TensorSetSlice(destination, source, start);
            }
            return result;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            Console.WriteLine($"[GpuEngine] GPU TensorSetSlice (double) failed: {ex.Message}. Falling back to CPU.");
            return _cpuFallback.TensorSetSlice(destination, source, start);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorWhere<T>(Tensor<T> condition, Tensor<T> x, Tensor<T> y)
    {
        // GPU kernel not yet implemented - use CPU fallback
        return _cpuFallback.TensorWhere(condition, x, y);
    }

    public Tensor<T> AffineGrid<T>(Tensor<T> theta, int outputHeight, int outputWidth)
    {
        int outputSize = theta.Shape[0] * outputHeight * outputWidth * 2;
        if (outputSize >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)AffineGridGpu((Tensor<float>)(object)theta, outputHeight, outputWidth);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)AffineGridGpuDouble((Tensor<double>)(object)theta, outputHeight, outputWidth);
        }
        return _cpuFallback.AffineGrid(theta, outputHeight, outputWidth);
    }

    private Tensor<float> AffineGridGpu(Tensor<float> theta, int outputHeight, int outputWidth)
    {
        try
        {
            int batchSize = theta.Shape[0];
            var gridArray = new float[batchSize * outputHeight * outputWidth * 2];
            var thetaData = theta.AsSpan().ToArray();

            // Generate normalized coordinates [-1, 1]
            System.Threading.Tasks.Parallel.For(0, batchSize, b =>
            {
                int thetaBase = b * 6;
                float a00 = thetaData[thetaBase + 0], a01 = thetaData[thetaBase + 1], a02 = thetaData[thetaBase + 2];
                float a10 = thetaData[thetaBase + 3], a11 = thetaData[thetaBase + 4], a12 = thetaData[thetaBase + 5];

                for (int h = 0; h < outputHeight; h++)
                {
                    float y = -1.0f + 2.0f * h / (outputHeight - 1);
                    for (int w = 0; w < outputWidth; w++)
                    {
                        float x = -1.0f + 2.0f * w / (outputWidth - 1);
                        int idx = ((b * outputHeight + h) * outputWidth + w) * 2;
                        gridArray[idx] = a00 * x + a01 * y + a02;
                        gridArray[idx + 1] = a10 * x + a11 * y + a12;
                    }
                }
            });

            return new Tensor<float>(new[] { batchSize, outputHeight, outputWidth, 2 }, new Vector<float>(gridArray));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.AffineGrid(theta, outputHeight, outputWidth);
        }
    }

    private Tensor<double> AffineGridGpuDouble(Tensor<double> theta, int outputHeight, int outputWidth)
    {
        try
        {
            int batchSize = theta.Shape[0];
            var gridArray = new double[batchSize * outputHeight * outputWidth * 2];
            var thetaData = theta.AsSpan().ToArray();

            System.Threading.Tasks.Parallel.For(0, batchSize, b =>
            {
                int thetaBase = b * 6;
                double a00 = thetaData[thetaBase + 0], a01 = thetaData[thetaBase + 1], a02 = thetaData[thetaBase + 2];
                double a10 = thetaData[thetaBase + 3], a11 = thetaData[thetaBase + 4], a12 = thetaData[thetaBase + 5];

                for (int h = 0; h < outputHeight; h++)
                {
                    double y = -1.0 + 2.0 * h / (outputHeight - 1);
                    for (int w = 0; w < outputWidth; w++)
                    {
                        double x = -1.0 + 2.0 * w / (outputWidth - 1);
                        int idx = ((b * outputHeight + h) * outputWidth + w) * 2;
                        gridArray[idx] = a00 * x + a01 * y + a02;
                        gridArray[idx + 1] = a10 * x + a11 * y + a12;
                    }
                }
            });

            return new Tensor<double>(new[] { batchSize, outputHeight, outputWidth, 2 }, new Vector<double>(gridArray));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.AffineGrid(theta, outputHeight, outputWidth);
        }
    }

    public Tensor<T> GridSample<T>(Tensor<T> input, Tensor<T> grid)
    {
        int outputSize = grid.Shape[0] * grid.Shape[1] * grid.Shape[2] * input.Shape[1];
        if (outputSize >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)GridSampleGpu((Tensor<float>)(object)input, (Tensor<float>)(object)grid);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)GridSampleGpuDouble((Tensor<double>)(object)input, (Tensor<double>)(object)grid);
        }
        return _cpuFallback.GridSample(input, grid);
    }

    private Tensor<float> GridSampleGpu(Tensor<float> input, Tensor<float> grid)
    {
        try
        {
            int batchSize = input.Shape[0];
            int channels = input.Shape[1];
            int inH = input.Shape[2];
            int inW = input.Shape[3];
            int outH = grid.Shape[1];
            int outW = grid.Shape[2];

            var outputArray = new float[batchSize * channels * outH * outW];
            var inputData = input.AsSpan().ToArray();
            var gridData = grid.AsSpan().ToArray();

            // Bilinear interpolation with parallel processing
            System.Threading.Tasks.Parallel.For(0, batchSize * channels, bc =>
            {
                int b = bc / channels;
                int c = bc % channels;
                int inputBase = (b * channels + c) * inH * inW;

                for (int h = 0; h < outH; h++)
                {
                    for (int w = 0; w < outW; w++)
                    {
                        int gridIdx = ((b * outH + h) * outW + w) * 2;
                        float gx = gridData[gridIdx];
                        float gy = gridData[gridIdx + 1];

                        // Unnormalize coordinates
                        float x = ((gx + 1) / 2) * (inW - 1);
                        float y = ((gy + 1) / 2) * (inH - 1);

                        // Bilinear interpolation
                        int x0 = (int)Math.Floor(x);
                        int y0 = (int)Math.Floor(y);
                        int x1 = x0 + 1;
                        int y1 = y0 + 1;

                        float xWeight = x - x0;
                        float yWeight = y - y0;

                        float val = 0;
                        if (x0 >= 0 && x0 < inW && y0 >= 0 && y0 < inH)
                            val += (1 - xWeight) * (1 - yWeight) * inputData[inputBase + y0 * inW + x0];
                        if (x1 >= 0 && x1 < inW && y0 >= 0 && y0 < inH)
                            val += xWeight * (1 - yWeight) * inputData[inputBase + y0 * inW + x1];
                        if (x0 >= 0 && x0 < inW && y1 >= 0 && y1 < inH)
                            val += (1 - xWeight) * yWeight * inputData[inputBase + y1 * inW + x0];
                        if (x1 >= 0 && x1 < inW && y1 >= 0 && y1 < inH)
                            val += xWeight * yWeight * inputData[inputBase + y1 * inW + x1];

                        int outIdx = ((b * channels + c) * outH + h) * outW + w;
                        outputArray[outIdx] = val;
                    }
                }
            });

            return new Tensor<float>(new[] { batchSize, channels, outH, outW }, new Vector<float>(outputArray));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.GridSample(input, grid);
        }
    }

    private Tensor<double> GridSampleGpuDouble(Tensor<double> input, Tensor<double> grid)
    {
        try
        {
            int batchSize = input.Shape[0];
            int channels = input.Shape[1];
            int inH = input.Shape[2];
            int inW = input.Shape[3];
            int outH = grid.Shape[1];
            int outW = grid.Shape[2];

            var outputArray = new double[batchSize * channels * outH * outW];
            var inputData = input.AsSpan().ToArray();
            var gridData = grid.AsSpan().ToArray();

            System.Threading.Tasks.Parallel.For(0, batchSize * channels, bc =>
            {
                int b = bc / channels;
                int c = bc % channels;
                int inputBase = (b * channels + c) * inH * inW;

                for (int h = 0; h < outH; h++)
                {
                    for (int w = 0; w < outW; w++)
                    {
                        int gridIdx = ((b * outH + h) * outW + w) * 2;
                        double gx = gridData[gridIdx];
                        double gy = gridData[gridIdx + 1];

                        double x = ((gx + 1) / 2) * (inW - 1);
                        double y = ((gy + 1) / 2) * (inH - 1);

                        int x0 = (int)Math.Floor(x);
                        int y0 = (int)Math.Floor(y);
                        int x1 = x0 + 1;
                        int y1 = y0 + 1;

                        double xWeight = x - x0;
                        double yWeight = y - y0;

                        double val = 0;
                        if (x0 >= 0 && x0 < inW && y0 >= 0 && y0 < inH)
                            val += (1 - xWeight) * (1 - yWeight) * inputData[inputBase + y0 * inW + x0];
                        if (x1 >= 0 && x1 < inW && y0 >= 0 && y0 < inH)
                            val += xWeight * (1 - yWeight) * inputData[inputBase + y0 * inW + x1];
                        if (x0 >= 0 && x0 < inW && y1 >= 0 && y1 < inH)
                            val += (1 - xWeight) * yWeight * inputData[inputBase + y1 * inW + x0];
                        if (x1 >= 0 && x1 < inW && y1 >= 0 && y1 < inH)
                            val += xWeight * yWeight * inputData[inputBase + y1 * inW + x1];

                        int outIdx = ((b * channels + c) * outH + h) * outW + w;
                        outputArray[outIdx] = val;
                    }
                }
            });

            return new Tensor<double>(new[] { batchSize, channels, outH, outW }, new Vector<double>(outputArray));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.GridSample(input, grid);
        }
    }

    public (Tensor<T> real, Tensor<T> imag) ComplexMatMul<T>(Tensor<T> aReal, Tensor<T> aImag, Tensor<T> bReal, Tensor<T> bImag)
    {
        // Complex matrix multiplication: (a + bi)(c + di) = (ac - bd) + (ad + bc)i
        int outputSize = aReal.Shape[0] * bReal.Shape[1];
        if (outputSize >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var (real, imag) = ComplexMatMulGpu(
                    (Tensor<float>)(object)aReal, (Tensor<float>)(object)aImag,
                    (Tensor<float>)(object)bReal, (Tensor<float>)(object)bImag);
                return ((Tensor<T>)(object)real, (Tensor<T>)(object)imag);
            }
            if (typeof(T) == typeof(double))
            {
                var (real, imag) = ComplexMatMulGpuDouble(
                    (Tensor<double>)(object)aReal, (Tensor<double>)(object)aImag,
                    (Tensor<double>)(object)bReal, (Tensor<double>)(object)bImag);
                return ((Tensor<T>)(object)real, (Tensor<T>)(object)imag);
            }
        }
        return _cpuFallback.ComplexMatMul(aReal, aImag, bReal, bImag);
    }

    private (Tensor<float> real, Tensor<float> imag) ComplexMatMulGpu(Tensor<float> aReal, Tensor<float> aImag, Tensor<float> bReal, Tensor<float> bImag)
    {
        try
        {
            int M = aReal.Shape[0], K = aReal.Shape[1], N = bReal.Shape[1];
            var resultReal = new float[M * N];
            var resultImag = new float[M * N];
            var arData = aReal.AsSpan().ToArray();
            var aiData = aImag.AsSpan().ToArray();
            var brData = bReal.AsSpan().ToArray();
            var biData = bImag.AsSpan().ToArray();

            System.Threading.Tasks.Parallel.For(0, M, i =>
            {
                for (int j = 0; j < N; j++)
                {
                    float sumReal = 0, sumImag = 0;
                    for (int k = 0; k < K; k++)
                    {
                        float ar = arData[i * K + k], ai = aiData[i * K + k];
                        float br = brData[k * N + j], bi = biData[k * N + j];
                        sumReal += ar * br - ai * bi;
                        sumImag += ar * bi + ai * br;
                    }
                    resultReal[i * N + j] = sumReal;
                    resultImag[i * N + j] = sumImag;
                }
            });

            return (new Tensor<float>(new[] { M, N }, new Vector<float>(resultReal)),
                    new Tensor<float>(new[] { M, N }, new Vector<float>(resultImag)));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.ComplexMatMul(aReal, aImag, bReal, bImag);
        }
    }

    private (Tensor<double> real, Tensor<double> imag) ComplexMatMulGpuDouble(Tensor<double> aReal, Tensor<double> aImag, Tensor<double> bReal, Tensor<double> bImag)
    {
        try
        {
            int M = aReal.Shape[0], K = aReal.Shape[1], N = bReal.Shape[1];
            var resultReal = new double[M * N];
            var resultImag = new double[M * N];
            var arData = aReal.AsSpan().ToArray();
            var aiData = aImag.AsSpan().ToArray();
            var brData = bReal.AsSpan().ToArray();
            var biData = bImag.AsSpan().ToArray();

            System.Threading.Tasks.Parallel.For(0, M, i =>
            {
                for (int j = 0; j < N; j++)
                {
                    double sumReal = 0, sumImag = 0;
                    for (int k = 0; k < K; k++)
                    {
                        double ar = arData[i * K + k], ai = aiData[i * K + k];
                        double br = brData[k * N + j], bi = biData[k * N + j];
                        sumReal += ar * br - ai * bi;
                        sumImag += ar * bi + ai * br;
                    }
                    resultReal[i * N + j] = sumReal;
                    resultImag[i * N + j] = sumImag;
                }
            });

            return (new Tensor<double>(new[] { M, N }, new Vector<double>(resultReal)),
                    new Tensor<double>(new[] { M, N }, new Vector<double>(resultImag)));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.ComplexMatMul(aReal, aImag, bReal, bImag);
        }
    }

    public Tensor<T> ComplexMagnitudeSquared<T>(Tensor<T> real, Tensor<T> imag)
    {
        // |z|^2 = real^2 + imag^2
        if (real.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var r = (Tensor<float>)(object)real;
                var i = (Tensor<float>)(object)imag;
                var rData = r.AsSpan().ToArray();
                var iData = i.AsSpan().ToArray();
                var result = new float[r.Length];
                System.Threading.Tasks.Parallel.For(0, r.Length, idx =>
                {
                    result[idx] = rData[idx] * rData[idx] + iData[idx] * iData[idx];
                });
                return (Tensor<T>)(object)new Tensor<float>(real.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var r = (Tensor<double>)(object)real;
                var i = (Tensor<double>)(object)imag;
                var rData = r.AsSpan().ToArray();
                var iData = i.AsSpan().ToArray();
                var result = new double[r.Length];
                System.Threading.Tasks.Parallel.For(0, r.Length, idx =>
                {
                    result[idx] = rData[idx] * rData[idx] + iData[idx] * iData[idx];
                });
                return (Tensor<T>)(object)new Tensor<double>(real.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.ComplexMagnitudeSquared(real, imag);
    }

    public (Tensor<T> real, Tensor<T> imag) ComplexNormalize<T>(Tensor<T> real, Tensor<T> imag)
    {
        // z / |z| = (real + i*imag) / sqrt(real^2 + imag^2)
        if (real.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var r = (Tensor<float>)(object)real;
                var i = (Tensor<float>)(object)imag;
                var rData = r.AsSpan().ToArray();
                var iData = i.AsSpan().ToArray();
                var resultReal = new float[r.Length];
                var resultImag = new float[r.Length];
                System.Threading.Tasks.Parallel.For(0, r.Length, idx =>
                {
                    float mag = (float)Math.Sqrt(rData[idx] * rData[idx] + iData[idx] * iData[idx]);
                    if (mag > 1e-10f)
                    {
                        resultReal[idx] = rData[idx] / mag;
                        resultImag[idx] = iData[idx] / mag;
                    }
                    else
                    {
                        resultReal[idx] = 0;
                        resultImag[idx] = 0;
                    }
                });
                return ((Tensor<T>)(object)new Tensor<float>(real.Shape, new Vector<float>(resultReal)),
                        (Tensor<T>)(object)new Tensor<float>(imag.Shape, new Vector<float>(resultImag)));
            }
            if (typeof(T) == typeof(double))
            {
                var r = (Tensor<double>)(object)real;
                var i = (Tensor<double>)(object)imag;
                var rData = r.AsSpan().ToArray();
                var iData = i.AsSpan().ToArray();
                var resultReal = new double[r.Length];
                var resultImag = new double[r.Length];
                System.Threading.Tasks.Parallel.For(0, r.Length, idx =>
                {
                    double mag = Math.Sqrt(rData[idx] * rData[idx] + iData[idx] * iData[idx]);
                    if (mag > 1e-15)
                    {
                        resultReal[idx] = rData[idx] / mag;
                        resultImag[idx] = iData[idx] / mag;
                    }
                    else
                    {
                        resultReal[idx] = 0;
                        resultImag[idx] = 0;
                    }
                });
                return ((Tensor<T>)(object)new Tensor<double>(real.Shape, new Vector<double>(resultReal)),
                        (Tensor<T>)(object)new Tensor<double>(imag.Shape, new Vector<double>(resultImag)));
            }
        }
        return _cpuFallback.ComplexNormalize(real, imag);
    }

    #endregion

    #region Loop Elimination Operations (CPU Fallback)

    /// <inheritdoc/>
    public void TensorCopy<T>(Tensor<T> source, Tensor<T> destination)
    {
        if (source.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                TensorCopyGpu((Tensor<float>)(object)source, (Tensor<float>)(object)destination);
                return;
            }
            if (typeof(T) == typeof(double))
            {
                TensorCopyGpuDouble((Tensor<double>)(object)source, (Tensor<double>)(object)destination);
                return;
            }
        }
        _cpuFallback.TensorCopy(source, destination);
    }

    private void TensorCopyGpu(Tensor<float> source, Tensor<float> destination)
    {
        try
        {
            source.AsSpan().CopyTo(destination.AsWritableSpan());
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            _cpuFallback.TensorCopy(source, destination);
        }
    }

    private void TensorCopyGpuDouble(Tensor<double> source, Tensor<double> destination)
    {
        try
        {
            source.AsSpan().CopyTo(destination.AsWritableSpan());
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            _cpuFallback.TensorCopy(source, destination);
        }
    }

    /// <inheritdoc/>
    public void TensorFill<T>(Tensor<T> tensor, T value)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var valObj = (object?)value; float v = valObj is float fv ? fv : Convert.ToSingle(value);
                TensorFillGpu((Tensor<float>)(object)tensor, v);
                return;
            }
            if (typeof(T) == typeof(double))
            {
                var valObj = (object?)value; double v = valObj is double dv ? dv : Convert.ToDouble(value);
                TensorFillGpuDouble((Tensor<double>)(object)tensor, v);
                return;
            }
        }
        _cpuFallback.TensorFill(tensor, value);
    }

    private void TensorFillGpu(Tensor<float> tensor, float value)
    {
        try
        {
            tensor.AsWritableSpan().Fill(value);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            _cpuFallback.TensorFill(tensor, value);
        }
    }

    private void TensorFillGpuDouble(Tensor<double> tensor, double value)
    {
        try
        {
            tensor.AsWritableSpan().Fill(value);
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            _cpuFallback.TensorFill(tensor, value);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorOuterProduct<T>(Tensor<T> a, Tensor<T> b)
    {
        int outputSize = a.Length * b.Length;
        if (outputSize >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorOuterProductGpu((Tensor<float>)(object)a, (Tensor<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorOuterProductGpuDouble((Tensor<double>)(object)a, (Tensor<double>)(object)b);
        }
        return _cpuFallback.TensorOuterProduct(a, b);
    }

    private Tensor<float> TensorOuterProductGpu(Tensor<float> a, Tensor<float> b)
    {
        try
        {
            var aData = a.AsSpan().ToArray();
            var bData = b.AsSpan().ToArray();
            var result = new float[a.Length * b.Length];

            System.Threading.Tasks.Parallel.For(0, a.Length, i =>
            {
                int rowBase = i * b.Length;
                float ai = aData[i];
                for (int j = 0; j < b.Length; j++)
                {
                    result[rowBase + j] = ai * bData[j];
                }
            });

            return new Tensor<float>(new[] { a.Length, b.Length }, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorOuterProduct(a, b);
        }
    }

    private Tensor<double> TensorOuterProductGpuDouble(Tensor<double> a, Tensor<double> b)
    {
        try
        {
            var aData = a.AsSpan().ToArray();
            var bData = b.AsSpan().ToArray();
            var result = new double[a.Length * b.Length];

            System.Threading.Tasks.Parallel.For(0, a.Length, i =>
            {
                int rowBase = i * b.Length;
                double ai = aData[i];
                for (int j = 0; j < b.Length; j++)
                {
                    result[rowBase + j] = ai * bData[j];
                }
            });

            return new Tensor<double>(new[] { a.Length, b.Length }, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorOuterProduct(a, b);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorBatchOuterProduct<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorBatchOuterProductGpu((Tensor<float>)(object)a, (Tensor<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorBatchOuterProductGpuDouble((Tensor<double>)(object)a, (Tensor<double>)(object)b);
        }
        return _cpuFallback.TensorBatchOuterProduct(a, b);
    }

    private Tensor<float> TensorBatchOuterProductGpu(Tensor<float> a, Tensor<float> b)
    {
        try
        {
            var aShape = a.Shape;
            var bShape = b.Shape;
            int batchSize = aShape[0];
            int m = aShape.Length > 1 ? aShape[1] : 1;
            int n = bShape.Length > 1 ? bShape[1] : 1;
            var aData = a.AsSpan().ToArray();
            var bData = b.AsSpan().ToArray();
            var result = new float[batchSize * m * n];

            System.Threading.Tasks.Parallel.For(0, batchSize, batch =>
            {
                for (int i = 0; i < m; i++)
                {
                    float ai = aData[batch * m + i];
                    int baseIdx = batch * m * n + i * n;
                    for (int j = 0; j < n; j++)
                    {
                        result[baseIdx + j] = ai * bData[batch * n + j];
                    }
                }
            });

            return new Tensor<float>(new[] { batchSize, m, n }, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorBatchOuterProduct(a, b);
        }
    }

    private Tensor<double> TensorBatchOuterProductGpuDouble(Tensor<double> a, Tensor<double> b)
    {
        try
        {
            var aShape = a.Shape;
            var bShape = b.Shape;
            int batchSize = aShape[0];
            int m = aShape.Length > 1 ? aShape[1] : 1;
            int n = bShape.Length > 1 ? bShape[1] : 1;
            var aData = a.AsSpan().ToArray();
            var bData = b.AsSpan().ToArray();
            var result = new double[batchSize * m * n];

            System.Threading.Tasks.Parallel.For(0, batchSize, batch =>
            {
                for (int i = 0; i < m; i++)
                {
                    double ai = aData[batch * m + i];
                    int baseIdx = batch * m * n + i * n;
                    for (int j = 0; j < n; j++)
                    {
                        result[baseIdx + j] = ai * bData[batch * n + j];
                    }
                }
            });

            return new Tensor<double>(new[] { batchSize, m, n }, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorBatchOuterProduct(a, b);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorPermute<T>(Tensor<T> tensor, int[] axes)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorPermuteGpu((Tensor<float>)(object)tensor, axes);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorPermuteGpuDouble((Tensor<double>)(object)tensor, axes);
        }
        return _cpuFallback.TensorPermute(tensor, axes);
    }

    private Tensor<float> TensorPermuteGpu(Tensor<float> tensor, int[] axes)
    {
        try
        {
            var shape = tensor.Shape;
            var data = tensor.AsSpan().ToArray();
            var newShape = axes.Select(a => shape[a]).ToArray();
            var result = new float[tensor.Length];

            int[] strides = new int[shape.Length];
            int[] newStrides = new int[shape.Length];
            strides[shape.Length - 1] = 1;
            newStrides[shape.Length - 1] = 1;
            for (int i = shape.Length - 2; i >= 0; i--)
            {
                strides[i] = strides[i + 1] * shape[i + 1];
                newStrides[i] = newStrides[i + 1] * newShape[i + 1];
            }

            System.Threading.Tasks.Parallel.For(0, tensor.Length, flatIdx =>
            {
                int[] indices = new int[shape.Length];
                int rem = flatIdx;
                for (int i = 0; i < shape.Length; i++)
                {
                    indices[i] = rem / strides[i];
                    rem %= strides[i];
                }

                int newIdx = 0;
                for (int i = 0; i < shape.Length; i++)
                {
                    newIdx += indices[axes[i]] * newStrides[i];
                }
                result[newIdx] = data[flatIdx];
            });

            return new Tensor<float>(newShape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorPermute(tensor, axes);
        }
    }

    private Tensor<double> TensorPermuteGpuDouble(Tensor<double> tensor, int[] axes)
    {
        try
        {
            var shape = tensor.Shape;
            var data = tensor.AsSpan().ToArray();
            var newShape = axes.Select(a => shape[a]).ToArray();
            var result = new double[tensor.Length];

            int[] strides = new int[shape.Length];
            int[] newStrides = new int[shape.Length];
            strides[shape.Length - 1] = 1;
            newStrides[shape.Length - 1] = 1;
            for (int i = shape.Length - 2; i >= 0; i--)
            {
                strides[i] = strides[i + 1] * shape[i + 1];
                newStrides[i] = newStrides[i + 1] * newShape[i + 1];
            }

            System.Threading.Tasks.Parallel.For(0, tensor.Length, flatIdx =>
            {
                int[] indices = new int[shape.Length];
                int rem = flatIdx;
                for (int i = 0; i < shape.Length; i++)
                {
                    indices[i] = rem / strides[i];
                    rem %= strides[i];
                }

                int newIdx = 0;
                for (int i = 0; i < shape.Length; i++)
                {
                    newIdx += indices[axes[i]] * newStrides[i];
                }
                result[newIdx] = data[flatIdx];
            });

            return new Tensor<double>(newShape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorPermute(tensor, axes);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorExpandDims<T>(Tensor<T> tensor, int axis)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorExpandDimsGpu((Tensor<float>)(object)tensor, axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorExpandDimsGpuDouble((Tensor<double>)(object)tensor, axis);
        }
        return _cpuFallback.TensorExpandDims(tensor, axis);
    }

    private Tensor<float> TensorExpandDimsGpu(Tensor<float> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + 1 + axis : axis;
            var newShape = new int[shape.Length + 1];
            for (int i = 0; i < axis; i++) newShape[i] = shape[i];
            newShape[axis] = 1;
            for (int i = axis; i < shape.Length; i++) newShape[i + 1] = shape[i];
            return new Tensor<float>(newShape, new Vector<float>(tensor.AsSpan().ToArray()));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorExpandDims(tensor, axis);
        }
    }

    private Tensor<double> TensorExpandDimsGpuDouble(Tensor<double> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + 1 + axis : axis;
            var newShape = new int[shape.Length + 1];
            for (int i = 0; i < axis; i++) newShape[i] = shape[i];
            newShape[axis] = 1;
            for (int i = axis; i < shape.Length; i++) newShape[i + 1] = shape[i];
            return new Tensor<double>(newShape, new Vector<double>(tensor.AsSpan().ToArray()));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorExpandDims(tensor, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorSqueeze<T>(Tensor<T> tensor, int axis = -1)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorSqueezeGpu((Tensor<float>)(object)tensor, axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorSqueezeGpuDouble((Tensor<double>)(object)tensor, axis);
        }
        return _cpuFallback.TensorSqueeze(tensor, axis);
    }

    private Tensor<float> TensorSqueezeGpu(Tensor<float> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            int[] newShape;
            if (axis == -1)
            {
                newShape = shape.Where(s => s != 1).ToArray();
            }
            else
            {
                axis = axis < 0 ? shape.Length + axis : axis;
                if (shape[axis] != 1) return tensor;
                newShape = shape.Where((_, i) => i != axis).ToArray();
            }
            if (newShape.Length == 0) newShape = new[] { 1 };
            return new Tensor<float>(newShape, new Vector<float>(tensor.AsSpan().ToArray()));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorSqueeze(tensor, axis);
        }
    }

    private Tensor<double> TensorSqueezeGpuDouble(Tensor<double> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            int[] newShape;
            if (axis == -1)
            {
                newShape = shape.Where(s => s != 1).ToArray();
            }
            else
            {
                axis = axis < 0 ? shape.Length + axis : axis;
                if (shape[axis] != 1) return tensor;
                newShape = shape.Where((_, i) => i != axis).ToArray();
            }
            if (newShape.Length == 0) newShape = new[] { 1 };
            return new Tensor<double>(newShape, new Vector<double>(tensor.AsSpan().ToArray()));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorSqueeze(tensor, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorScatterAdd<T>(Tensor<T> destination, Tensor<int> indices, Tensor<T> updates, int axis = 0)
    {
        if (destination.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorScatterAddGpu(
                    (Tensor<float>)(object)destination,
                    (indices),
                    (Tensor<float>)(object)updates, axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorScatterAddGpuDouble(
                    (Tensor<double>)(object)destination,
                    (indices),
                    (Tensor<double>)(object)updates, axis);
        }
        return _cpuFallback.TensorScatterAdd(destination, indices, updates, axis);
    }

    private Tensor<float> TensorScatterAddGpu(Tensor<float> destination, Tensor<int> indices, Tensor<float> updates, int axis)
    {
        try
        {
            var shape = destination.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var destData = destination.AsSpan().ToArray();
            var idxData = indices.AsSpan().ToArray();
            var updData = updates.AsSpan().ToArray();
            var result = destData.ToArray(); // Copy destination

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            // For thread safety with scatter add, use locking per destination index
            var locks = new object[result.Length];
            for (int i = 0; i < locks.Length; i++) locks[i] = new object();

            System.Threading.Tasks.Parallel.For(0, outerSize, o =>
            {
                for (int idx = 0; idx < indices.Length; idx++)
                {
                    int targetIdx = (int)idxData[idx];
                    if (targetIdx < 0) targetIdx += axisSize;
                    if (targetIdx >= 0 && targetIdx < axisSize)
                    {
                        for (int inner = 0; inner < innerSize; inner++)
                        {
                            int srcOffset = (o * indices.Length + idx) * innerSize + inner;
                            int dstOffset = (o * axisSize + targetIdx) * innerSize + inner;
                            if (srcOffset < updData.Length && dstOffset < result.Length)
                            {
                                lock (locks[dstOffset])
                                {
                                    result[dstOffset] += updData[srcOffset];
                                }
                            }
                        }
                    }
                }
            });

            return new Tensor<float>(destination.Shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorScatterAdd(destination, indices, updates, axis);
        }
    }

    private Tensor<double> TensorScatterAddGpuDouble(Tensor<double> destination, Tensor<int> indices, Tensor<double> updates, int axis)
    {
        try
        {
            var shape = destination.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var destData = destination.AsSpan().ToArray();
            var idxData = indices.AsSpan().ToArray();
            var updData = updates.AsSpan().ToArray();
            var result = destData.ToArray(); // Copy destination

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            var locks = new object[result.Length];
            for (int i = 0; i < locks.Length; i++) locks[i] = new object();

            System.Threading.Tasks.Parallel.For(0, outerSize, o =>
            {
                for (int idx = 0; idx < indices.Length; idx++)
                {
                    int targetIdx = (int)idxData[idx];
                    if (targetIdx < 0) targetIdx += axisSize;
                    if (targetIdx >= 0 && targetIdx < axisSize)
                    {
                        for (int inner = 0; inner < innerSize; inner++)
                        {
                            int srcOffset = (o * indices.Length + idx) * innerSize + inner;
                            int dstOffset = (o * axisSize + targetIdx) * innerSize + inner;
                            if (srcOffset < updData.Length && dstOffset < result.Length)
                            {
                                lock (locks[dstOffset])
                                {
                                    result[dstOffset] += updData[srcOffset];
                                }
                            }
                        }
                    }
                }
            });

            return new Tensor<double>(destination.Shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorScatterAdd(destination, indices, updates, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorGather<T>(Tensor<T> source, Tensor<int> indices, int axis = 0)
    {
        if (source.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorGatherGpu(
                    (Tensor<float>)(object)source,
                    (indices), axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorGatherGpuDouble(
                    (Tensor<double>)(object)source,
                    (indices), axis);
        }
        return _cpuFallback.TensorGather(source, indices, axis);
    }

    private Tensor<float> TensorGatherGpu(Tensor<float> source, Tensor<int> indices, int axis)
    {
        try
        {
            var shape = source.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var srcData = source.AsSpan().ToArray();
            var idxData = indices.AsSpan().ToArray();

            // Output shape: source.shape with axis dimension replaced by indices.shape
            var idxShape = indices.Shape;
            var newShape = new int[shape.Length - 1 + idxShape.Length];
            int ni = 0;
            for (int i = 0; i < axis; i++) newShape[ni++] = shape[i];
            for (int i = 0; i < idxShape.Length; i++) newShape[ni++] = idxShape[i];
            for (int i = axis + 1; i < shape.Length; i++) newShape[ni++] = shape[i];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            int resultLen = 1; foreach (var d in newShape) resultLen *= d;
            var result = new float[resultLen];

            System.Threading.Tasks.Parallel.For(0, outerSize, o =>
            {
                for (int idx = 0; idx < indices.Length; idx++)
                {
                    int srcIdx = (int)idxData[idx];
                    if (srcIdx < 0) srcIdx += axisSize;
                    if (srcIdx >= 0 && srcIdx < axisSize)
                    {
                        for (int inner = 0; inner < innerSize; inner++)
                        {
                            int srcOffset = (o * axisSize + srcIdx) * innerSize + inner;
                            int dstOffset = (o * indices.Length + idx) * innerSize + inner;
                            if (srcOffset < srcData.Length && dstOffset < result.Length)
                            {
                                result[dstOffset] = srcData[srcOffset];
                            }
                        }
                    }
                }
            });

            return new Tensor<float>(newShape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorGather(source, indices, axis);
        }
    }

    private Tensor<double> TensorGatherGpuDouble(Tensor<double> source, Tensor<int> indices, int axis)
    {
        try
        {
            var shape = source.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var srcData = source.AsSpan().ToArray();
            var idxData = indices.AsSpan().ToArray();

            var idxShape = indices.Shape;
            var newShape = new int[shape.Length - 1 + idxShape.Length];
            int ni = 0;
            for (int i = 0; i < axis; i++) newShape[ni++] = shape[i];
            for (int i = 0; i < idxShape.Length; i++) newShape[ni++] = idxShape[i];
            for (int i = axis + 1; i < shape.Length; i++) newShape[ni++] = shape[i];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            int resultLen = 1; foreach (var d in newShape) resultLen *= d;
            var result = new double[resultLen];

            System.Threading.Tasks.Parallel.For(0, outerSize, o =>
            {
                for (int idx = 0; idx < indices.Length; idx++)
                {
                    int srcIdx = (int)idxData[idx];
                    if (srcIdx < 0) srcIdx += axisSize;
                    if (srcIdx >= 0 && srcIdx < axisSize)
                    {
                        for (int inner = 0; inner < innerSize; inner++)
                        {
                            int srcOffset = (o * axisSize + srcIdx) * innerSize + inner;
                            int dstOffset = (o * indices.Length + idx) * innerSize + inner;
                            if (srcOffset < srcData.Length && dstOffset < result.Length)
                            {
                                result[dstOffset] = srcData[srcOffset];
                            }
                        }
                    }
                }
            });

            return new Tensor<double>(newShape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorGather(source, indices, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorCumSum<T>(Tensor<T> tensor, int axis)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorCumSumGpu((Tensor<float>)(object)tensor, axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorCumSumGpuDouble((Tensor<double>)(object)tensor, axis);
        }
        return _cpuFallback.TensorCumSum(tensor, axis);
    }

    private Tensor<float> TensorCumSumGpu(Tensor<float> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var result = new float[tensor.Length];
            var data = tensor.AsSpan().ToArray();

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int i = idx % innerSize;
                float cumSum = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + i;
                    cumSum += data[srcIdx];
                    result[srcIdx] = cumSum;
                }
            });

            return new Tensor<float>(shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorCumSum(tensor, axis);
        }
    }

    private Tensor<double> TensorCumSumGpuDouble(Tensor<double> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var result = new double[tensor.Length];
            var data = tensor.AsSpan().ToArray();

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int i = idx % innerSize;
                double cumSum = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + i;
                    cumSum += data[srcIdx];
                    result[srcIdx] = cumSum;
                }
            });

            return new Tensor<double>(shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorCumSum(tensor, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorLogSumExp<T>(Tensor<T> tensor, int axis, bool keepDims = false)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorLogSumExpGpu((Tensor<float>)(object)tensor, axis, keepDims);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorLogSumExpGpuDouble((Tensor<double>)(object)tensor, axis, keepDims);
        }
        return _cpuFallback.TensorLogSumExp(tensor, axis, keepDims);
    }

    private Tensor<float> TensorLogSumExpGpu(Tensor<float> tensor, int axis, bool keepDims)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            var resultSize = outerSize * innerSize;
            var result = new float[resultSize];

            System.Threading.Tasks.Parallel.For(0, resultSize, idx =>
            {
                int o = idx / innerSize;
                int i = idx % innerSize;

                // Find max for numerical stability
                float maxVal = float.MinValue;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + i;
                    if (data[srcIdx] > maxVal) maxVal = data[srcIdx];
                }

                // Compute log-sum-exp
                float sumExp = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + i;
                    sumExp += (float)Math.Exp(data[srcIdx] - maxVal);
                }
                result[idx] = maxVal + (float)Math.Log(sumExp);
            });

            var newShape = keepDims
                ? shape.Select((s, i) => i == axis ? 1 : s).ToArray()
                : shape.Where((_, i) => i != axis).ToArray();

            if (newShape.Length == 0) newShape = new[] { 1 };
            return new Tensor<float>(newShape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorLogSumExp(tensor, axis, keepDims);
        }
    }

    private Tensor<double> TensorLogSumExpGpuDouble(Tensor<double> tensor, int axis, bool keepDims)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            var resultSize = outerSize * innerSize;
            var result = new double[resultSize];

            System.Threading.Tasks.Parallel.For(0, resultSize, idx =>
            {
                int o = idx / innerSize;
                int i = idx % innerSize;

                double maxVal = double.MinValue;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + i;
                    if (data[srcIdx] > maxVal) maxVal = data[srcIdx];
                }

                double sumExp = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + i;
                    sumExp += Math.Exp(data[srcIdx] - maxVal);
                }
                result[idx] = maxVal + Math.Log(sumExp);
            });

            var newShape = keepDims
                ? shape.Select((s, i) => i == axis ? 1 : s).ToArray()
                : shape.Where((_, i) => i != axis).ToArray();

            if (newShape.Length == 0) newShape = new[] { 1 };
            return new Tensor<double>(newShape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorLogSumExp(tensor, axis, keepDims);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorRandomUniform<T>(int[] shape)
    {
        int totalSize = 1; foreach (var d in shape) totalSize *= d;
        if (totalSize >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorRandomUniformGpu(shape);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorRandomUniformGpuDouble(shape);
        }
        return _cpuFallback.TensorRandomUniform<T>(shape);
    }

    private Tensor<float> TensorRandomUniformGpu(int[] shape)
    {
        try
        {
            int totalSize = 1; foreach (var d in shape) totalSize *= d;
            var result = new float[totalSize];
            var baseSeed = RandomHelper.GenerateCryptographicSeed();

            // Generate random numbers in parallel batches
            int batchSize = Math.Max(1, totalSize / Environment.ProcessorCount);
            System.Threading.Tasks.Parallel.For(0, (totalSize + batchSize - 1) / batchSize, batchIdx =>
            {
                var localRandom = RandomHelper.CreateSeededRandom(unchecked(baseSeed + batchIdx));
                int start = batchIdx * batchSize;
                int end = Math.Min(start + batchSize, totalSize);
                for (int i = start; i < end; i++)
                {
                    result[i] = (float)localRandom.NextDouble();
                }
            });

            return new Tensor<float>(shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorRandomUniform<float>(shape);
        }
    }

    private Tensor<double> TensorRandomUniformGpuDouble(int[] shape)
    {
        try
        {
            int totalSize = 1; foreach (var d in shape) totalSize *= d;
            var result = new double[totalSize];
            var baseSeed = RandomHelper.GenerateCryptographicSeed();

            int batchSize = Math.Max(1, totalSize / Environment.ProcessorCount);
            System.Threading.Tasks.Parallel.For(0, (totalSize + batchSize - 1) / batchSize, batchIdx =>
            {
                var localRandom = RandomHelper.CreateSeededRandom(unchecked(baseSeed + batchIdx));
                int start = batchIdx * batchSize;
                int end = Math.Min(start + batchSize, totalSize);
                for (int i = start; i < end; i++)
                {
                    result[i] = localRandom.NextDouble();
                }
            });

            return new Tensor<double>(shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorRandomUniform<double>(shape);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorRandomNormal<T>(int[] shape, T mean, T stddev)
    {
        int totalSize = 1; foreach (var d in shape) totalSize *= d;
        if (totalSize >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var meanObj = (object?)mean; float m = meanObj is float fm ? fm : Convert.ToSingle(mean);
                var stdObj = (object?)stddev; float s = stdObj is float fs ? fs : Convert.ToSingle(stddev);
                return (Tensor<T>)(object)TensorRandomNormalGpu(shape, m, s);
            }
            if (typeof(T) == typeof(double))
            {
                var meanObj = (object?)mean; double m = meanObj is double dm ? dm : Convert.ToDouble(mean);
                var stdObj = (object?)stddev; double s = stdObj is double ds ? ds : Convert.ToDouble(stddev);
                return (Tensor<T>)(object)TensorRandomNormalGpuDouble(shape, m, s);
            }
        }
        return _cpuFallback.TensorRandomNormal(shape, mean, stddev);
    }

    private Tensor<float> TensorRandomNormalGpu(int[] shape, float mean, float stddev)
    {
        try
        {
            int totalSize = 1; foreach (var d in shape) totalSize *= d;
            var result = new float[totalSize];
            var baseSeed = RandomHelper.GenerateCryptographicSeed();

            int batchSize = Math.Max(1, totalSize / Environment.ProcessorCount);
            System.Threading.Tasks.Parallel.For(0, (totalSize + batchSize - 1) / batchSize, batchIdx =>
            {
                var localRandom = RandomHelper.CreateSeededRandom(unchecked(baseSeed + batchIdx));
                int start = batchIdx * batchSize;
                int end = Math.Min(start + batchSize, totalSize);
                for (int i = start; i < end; i++)
                {
                    // Box-Muller transform
                    double u1 = 1.0 - localRandom.NextDouble();
                    double u2 = localRandom.NextDouble();
                    double normal = Math.Sqrt(-2.0 * Math.Log(u1)) * Math.Cos(2.0 * Math.PI * u2);
                    result[i] = (float)(mean + stddev * normal);
                }
            });

            return new Tensor<float>(shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorRandomNormal(shape, mean, stddev);
        }
    }

    private Tensor<double> TensorRandomNormalGpuDouble(int[] shape, double mean, double stddev)
    {
        try
        {
            int totalSize = 1; foreach (var d in shape) totalSize *= d;
            var result = new double[totalSize];
            var baseSeed = RandomHelper.GenerateCryptographicSeed();

            int batchSize = Math.Max(1, totalSize / Environment.ProcessorCount);
            System.Threading.Tasks.Parallel.For(0, (totalSize + batchSize - 1) / batchSize, batchIdx =>
            {
                var localRandom = RandomHelper.CreateSeededRandom(unchecked(baseSeed + batchIdx));
                int start = batchIdx * batchSize;
                int end = Math.Min(start + batchSize, totalSize);
                for (int i = start; i < end; i++)
                {
                    // Box-Muller transform
                    double u1 = 1.0 - localRandom.NextDouble();
                    double u2 = localRandom.NextDouble();
                    double normal = Math.Sqrt(-2.0 * Math.Log(u1)) * Math.Cos(2.0 * Math.PI * u2);
                    result[i] = mean + stddev * normal;
                }
            });

            return new Tensor<double>(shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorRandomNormal(shape, mean, stddev);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorRandomUniformRange<T>(int[] shape, T min, T max, int? seed = null)
    {
        int totalSize = 1; foreach (var d in shape) totalSize *= d;
        if (totalSize >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var minObj = (object?)min; float minF = minObj is float fm ? fm : Convert.ToSingle(min);
                var maxObj = (object?)max; float maxF = maxObj is float fmx ? fmx : Convert.ToSingle(max);
                return (Tensor<T>)(object)TensorRandomUniformRangeGpu(shape, minF, maxF, seed);
            }
            if (typeof(T) == typeof(double))
            {
                var minObj = (object?)min; double minD = minObj is double dm ? dm : Convert.ToDouble(min);
                var maxObj = (object?)max; double maxD = maxObj is double dmx ? dmx : Convert.ToDouble(max);
                return (Tensor<T>)(object)TensorRandomUniformRangeGpuDouble(shape, minD, maxD, seed);
            }
        }
        return _cpuFallback.TensorRandomUniformRange(shape, min, max, seed);
    }

    private Tensor<float> TensorRandomUniformRangeGpu(int[] shape, float min, float max, int? seed)
    {
        try
        {
            int totalSize = 1; foreach (var d in shape) totalSize *= d;
            var result = new float[totalSize];
            float range = max - min;
            var baseSeed = seed ?? RandomHelper.GenerateCryptographicSeed();

            int batchSize = Math.Max(1, totalSize / Environment.ProcessorCount);
            System.Threading.Tasks.Parallel.For(0, (totalSize + batchSize - 1) / batchSize, batchIdx =>
            {
                var localRandom = RandomHelper.CreateSeededRandom(unchecked(baseSeed + batchIdx));
                int start = batchIdx * batchSize;
                int end = Math.Min(start + batchSize, totalSize);
                for (int i = start; i < end; i++)
                {
                    result[i] = (float)(localRandom.NextDouble() * range + min);
                }
            });

            return new Tensor<float>(shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorRandomUniformRange(shape, min, max, seed);
        }
    }

    private Tensor<double> TensorRandomUniformRangeGpuDouble(int[] shape, double min, double max, int? seed)
    {
        try
        {
            int totalSize = 1; foreach (var d in shape) totalSize *= d;
            var result = new double[totalSize];
            double range = max - min;
            var baseSeed = seed ?? RandomHelper.GenerateCryptographicSeed();

            int batchSize = Math.Max(1, totalSize / Environment.ProcessorCount);
            System.Threading.Tasks.Parallel.For(0, (totalSize + batchSize - 1) / batchSize, batchIdx =>
            {
                var localRandom = RandomHelper.CreateSeededRandom(unchecked(baseSeed + batchIdx));
                int start = batchIdx * batchSize;
                int end = Math.Min(start + batchSize, totalSize);
                for (int i = start; i < end; i++)
                {
                    result[i] = localRandom.NextDouble() * range + min;
                }
            });

            return new Tensor<double>(shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorRandomUniformRange(shape, min, max, seed);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorDropoutMask<T>(int[] shape, T dropoutRate, T scale, int? seed = null)
    {
        int totalSize = 1; foreach (var d in shape) totalSize *= d;
        if (totalSize >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var rateObj = (object?)dropoutRate; float rateF = rateObj is float fr ? fr : Convert.ToSingle(dropoutRate);
                var scaleObj = (object?)scale; float scaleF = scaleObj is float fs ? fs : Convert.ToSingle(scale);
                return (Tensor<T>)(object)TensorDropoutMaskGpu(shape, rateF, scaleF, seed);
            }
            if (typeof(T) == typeof(double))
            {
                var rateObj = (object?)dropoutRate; double rateD = rateObj is double dr ? dr : Convert.ToDouble(dropoutRate);
                var scaleObj = (object?)scale; double scaleD = scaleObj is double ds ? ds : Convert.ToDouble(scale);
                return (Tensor<T>)(object)TensorDropoutMaskGpuDouble(shape, rateD, scaleD, seed);
            }
        }
        return _cpuFallback.TensorDropoutMask(shape, dropoutRate, scale, seed);
    }

    private Tensor<float> TensorDropoutMaskGpu(int[] shape, float dropoutRate, float scale, int? seed)
    {
        try
        {
            int totalSize = 1; foreach (var d in shape) totalSize *= d;
            var result = new float[totalSize];
            var baseSeed = seed ?? RandomHelper.GenerateCryptographicSeed();

            int batchSize = Math.Max(1, totalSize / Environment.ProcessorCount);
            System.Threading.Tasks.Parallel.For(0, (totalSize + batchSize - 1) / batchSize, batchIdx =>
            {
                var localRandom = RandomHelper.CreateSeededRandom(unchecked(baseSeed + batchIdx));
                int start = batchIdx * batchSize;
                int end = Math.Min(start + batchSize, totalSize);
                for (int i = start; i < end; i++)
                {
                    result[i] = localRandom.NextDouble() < dropoutRate ? 0.0f : scale;
                }
            });

            return new Tensor<float>(shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorDropoutMask(shape, dropoutRate, scale, seed);
        }
    }

    private Tensor<double> TensorDropoutMaskGpuDouble(int[] shape, double dropoutRate, double scale, int? seed)
    {
        try
        {
            int totalSize = 1; foreach (var d in shape) totalSize *= d;
            var result = new double[totalSize];
            var baseSeed = seed ?? RandomHelper.GenerateCryptographicSeed();

            int batchSize = Math.Max(1, totalSize / Environment.ProcessorCount);
            System.Threading.Tasks.Parallel.For(0, (totalSize + batchSize - 1) / batchSize, batchIdx =>
            {
                var localRandom = RandomHelper.CreateSeededRandom(unchecked(baseSeed + batchIdx));
                int start = batchIdx * batchSize;
                int end = Math.Min(start + batchSize, totalSize);
                for (int i = start; i < end; i++)
                {
                    result[i] = localRandom.NextDouble() < dropoutRate ? 0.0 : scale;
                }
            });

            return new Tensor<double>(shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorDropoutMask(shape, dropoutRate, scale, seed);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> ScalarMinusTensor<T>(T scalar, Tensor<T> tensor)
    {
        if (tensor == null) throw new ArgumentNullException(nameof(tensor));

        if (tensor.Length < _thresholds.VectorAdd)
        {
            return _cpuFallback.ScalarMinusTensor(scalar, tensor);
        }

        if (SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var scalarObj = (object?)scalar; float s = scalarObj is float fs ? fs : Convert.ToSingle(scalar);
                return (Tensor<T>)(object)ScalarMinusTensorGpu(s, (Tensor<float>)(object)tensor);
            }
            if (typeof(T) == typeof(double))
            {
                var scalarObj = (object?)scalar; double s = scalarObj is double ds ? ds : Convert.ToDouble(scalar);
                return (Tensor<T>)(object)ScalarMinusTensorGpuDouble(s, (Tensor<double>)(object)tensor);
            }
        }

        return _cpuFallback.ScalarMinusTensor(scalar, tensor);
    }

    private Tensor<float> ScalarMinusTensorGpu(float scalar, Tensor<float> tensor)
    {
        try
        {
            var result = new Tensor<float>(tensor.Shape);
            var gpuInput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolFloat ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_scalarMinusTensorKernelFloat ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, scalar, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolFloat.Return(gpuInput);
                _memoryPoolFloat.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.ScalarMinusTensor(scalar, tensor);
        }
    }

    private Tensor<double> ScalarMinusTensorGpuDouble(double scalar, Tensor<double> tensor)
    {
        try
        {
            var result = new Tensor<double>(tensor.Shape);
            var gpuInput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);
            var gpuOutput = (_memoryPoolDouble ?? throw new InvalidOperationException("GPU not initialized")).Rent(tensor.Length);

            try
            {
                gpuInput.View.BaseView.CopyFromCPU(tensor.AsSpan());

                lock (_gpuLock)
                {
                    (_scalarMinusTensorKernelDouble ?? throw new InvalidOperationException("Kernel not initialized"))(
                        (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).DefaultStream,
                        tensor.Length, gpuInput.View, scalar, gpuOutput.View);
                    (_accelerator ?? throw new InvalidOperationException("GPU not initialized")).Synchronize();
                }

                gpuOutput.View.BaseView.CopyToCPU(result.AsWritableSpan());
                return result;
            }
            finally
            {
                _memoryPoolDouble.Return(gpuInput);
                _memoryPoolDouble.Return(gpuOutput);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or DllNotFoundException or PlatformNotSupportedException)
        {
            return _cpuFallback.ScalarMinusTensor(scalar, tensor);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorEye<T>(int size)
    {
        if (size * size >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorEyeGpu(size);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorEyeGpuDouble(size);
        }
        return _cpuFallback.TensorEye<T>(size);
    }

    private Tensor<float> TensorEyeGpu(int size)
    {
        try
        {
            var result = new float[size * size];
            System.Threading.Tasks.Parallel.For(0, size, i =>
            {
                result[i * size + i] = 1.0f;
            });
            return new Tensor<float>(new[] { size, size }, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorEye<float>(size);
        }
    }

    private Tensor<double> TensorEyeGpuDouble(int size)
    {
        try
        {
            var result = new double[size * size];
            System.Threading.Tasks.Parallel.For(0, size, i =>
            {
                result[i * size + i] = 1.0;
            });
            return new Tensor<double>(new[] { size, size }, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorEye<double>(size);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorDiag<T>(Tensor<T> diagonal)
    {
        if (diagonal.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorDiagGpu((Tensor<float>)(object)diagonal);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorDiagGpuDouble((Tensor<double>)(object)diagonal);
        }
        return _cpuFallback.TensorDiag(diagonal);
    }

    private Tensor<float> TensorDiagGpu(Tensor<float> diagonal)
    {
        try
        {
            int n = diagonal.Length;
            var data = diagonal.AsSpan().ToArray();
            var result = new float[n * n]; // zeros by default

            System.Threading.Tasks.Parallel.For(0, n, i =>
            {
                result[i * n + i] = data[i];
            });

            return new Tensor<float>(new[] { n, n }, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorDiag(diagonal);
        }
    }

    private Tensor<double> TensorDiagGpuDouble(Tensor<double> diagonal)
    {
        try
        {
            int n = diagonal.Length;
            var data = diagonal.AsSpan().ToArray();
            var result = new double[n * n];

            System.Threading.Tasks.Parallel.For(0, n, i =>
            {
                result[i * n + i] = data[i];
            });

            return new Tensor<double>(new[] { n, n }, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorDiag(diagonal);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorDiagonal<T>(Tensor<T> tensor)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorDiagonalGpu((Tensor<float>)(object)tensor);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorDiagonalGpuDouble((Tensor<double>)(object)tensor);
        }
        return _cpuFallback.TensorDiagonal(tensor);
    }

    private Tensor<float> TensorDiagonalGpu(Tensor<float> tensor)
    {
        try
        {
            var shape = tensor.Shape;
            if (shape.Length < 2) return _cpuFallback.TensorDiagonal(tensor);
            int rows = shape[shape.Length - 2];
            int cols = shape[shape.Length - 1];
            int diagLen = Math.Min(rows, cols);
            int batchSize = 1;
            for (int i = 0; i < shape.Length - 2; i++) batchSize *= shape[i];

            var data = tensor.AsSpan().ToArray();
            var result = new float[batchSize * diagLen];

            System.Threading.Tasks.Parallel.For(0, batchSize, b =>
            {
                int matrixBase = b * rows * cols;
                for (int d = 0; d < diagLen; d++)
                {
                    result[b * diagLen + d] = data[matrixBase + d * cols + d];
                }
            });

            var newShape = shape.Take(shape.Length - 2).Concat(new[] { diagLen }).ToArray();
            if (newShape.Length == 0) newShape = new[] { diagLen };
            return new Tensor<float>(newShape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorDiagonal(tensor);
        }
    }

    private Tensor<double> TensorDiagonalGpuDouble(Tensor<double> tensor)
    {
        try
        {
            var shape = tensor.Shape;
            if (shape.Length < 2) return _cpuFallback.TensorDiagonal(tensor);
            int rows = shape[shape.Length - 2];
            int cols = shape[shape.Length - 1];
            int diagLen = Math.Min(rows, cols);
            int batchSize = 1;
            for (int i = 0; i < shape.Length - 2; i++) batchSize *= shape[i];

            var data = tensor.AsSpan().ToArray();
            var result = new double[batchSize * diagLen];

            System.Threading.Tasks.Parallel.For(0, batchSize, b =>
            {
                int matrixBase = b * rows * cols;
                for (int d = 0; d < diagLen; d++)
                {
                    result[b * diagLen + d] = data[matrixBase + d * cols + d];
                }
            });

            var newShape = shape.Take(shape.Length - 2).Concat(new[] { diagLen }).ToArray();
            if (newShape.Length == 0) newShape = new[] { diagLen };
            return new Tensor<double>(newShape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorDiagonal(tensor);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorEinsum<T>(string subscripts, params Tensor<T>[] tensors)
    {
        if (tensors.Length > 0 && tensors[0].Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var floatTensors = tensors.Select(t => (Tensor<float>)(object)t).ToArray();
                return (Tensor<T>)(object)TensorEinsumGpu(subscripts, floatTensors);
            }
            if (typeof(T) == typeof(double))
            {
                var doubleTensors = tensors.Select(t => (Tensor<double>)(object)t).ToArray();
                return (Tensor<T>)(object)TensorEinsumGpuDouble(subscripts, doubleTensors);
            }
        }
        return _cpuFallback.TensorEinsum(subscripts, tensors);
    }

    private Tensor<float> TensorEinsumGpu(string subscripts, Tensor<float>[] tensors)
    {
        try
        {
            // Input validation
            if (string.IsNullOrWhiteSpace(subscripts))
            {
                return _cpuFallback.TensorEinsum(subscripts, tensors);
            }
            if (tensors is null || tensors.Length == 0)
            {
                throw new ArgumentException("Tensors array cannot be null or empty", nameof(tensors));
            }

            // Parse subscripts: "ij,jk->ik" format
            var parts = subscripts.Replace(" ", "").Split(new[] { "->" }, StringSplitOptions.None);
            var inputSubscripts = parts[0].Split(',');
            var outputSubscript = parts.Length > 1 ? parts[1] : "";

            if (tensors.Length == 1)
            {
                // Single tensor: trace, diagonal, transpose, or sum
                return EinsumSingleTensorGpu(inputSubscripts[0], outputSubscript, tensors[0]);
            }
            else if (tensors.Length == 2)
            {
                // Two tensors: matrix multiply, outer product, batch matmul, etc.
                return EinsumTwoTensorsGpu(inputSubscripts[0], inputSubscripts[1], outputSubscript, tensors[0], tensors[1]);
            }
            else
            {
                // Fall back to CPU for 3+ tensors
                return _cpuFallback.TensorEinsum(subscripts, tensors);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or FormatException or IndexOutOfRangeException)
        {
            return _cpuFallback.TensorEinsum(subscripts, tensors);
        }
    }

    private Tensor<float> EinsumSingleTensorGpu(string input, string output, Tensor<float> tensor)
    {
        var data = tensor.AsSpan().ToArray();
        var shape = tensor.Shape;

        // Common patterns for single tensor
        if (input == "ii" && output == "")
        {
            // Trace: sum of diagonal
            int n = shape[0];
            float trace = 0;
            for (int i = 0; i < n; i++) trace += data[i * n + i];
            return new Tensor<float>(new[] { 1 }, new Vector<float>(new[] { trace }));
        }
        else if (input == "ij" && output == "ji")
        {
            // Transpose
            int m = shape[0], n = shape[1];
            var result = new float[m * n];
            System.Threading.Tasks.Parallel.For(0, m, i =>
            {
                for (int j = 0; j < n; j++)
                    result[j * m + i] = data[i * n + j];
            });
            return new Tensor<float>(new[] { n, m }, new Vector<float>(result));
        }
        else if (input == "ij" && output == "")
        {
            // Sum all elements
            float sum = 0;
            for (int i = 0; i < data.Length; i++) sum += data[i];
            return new Tensor<float>(new[] { 1 }, new Vector<float>(new[] { sum }));
        }
        else if (input == "ij" && output == "i")
        {
            // Sum over j axis
            int m = shape[0], n = shape[1];
            var result = new float[m];
            System.Threading.Tasks.Parallel.For(0, m, i =>
            {
                float sum = 0;
                for (int j = 0; j < n; j++) sum += data[i * n + j];
                result[i] = sum;
            });
            return new Tensor<float>(new[] { m }, new Vector<float>(result));
        }
        else if (input == "ij" && output == "j")
        {
            // Sum over i axis
            int m = shape[0], n = shape[1];
            var result = new float[n];
            for (int j = 0; j < n; j++)
            {
                float sum = 0;
                for (int i = 0; i < m; i++) sum += data[i * n + j];
                result[j] = sum;
            }
            return new Tensor<float>(new[] { n }, new Vector<float>(result));
        }

        // Fall back to CPU for complex patterns
        return _cpuFallback.TensorEinsum($"{input}->{output}", new[] { tensor });
    }

    private Tensor<float> EinsumTwoTensorsGpu(string input1, string input2, string output, Tensor<float> a, Tensor<float> b)
    {
        var aData = a.AsSpan().ToArray();
        var bData = b.AsSpan().ToArray();
        var aShape = a.Shape;
        var bShape = b.Shape;

        // Common two-tensor patterns
        if (input1 == "ij" && input2 == "jk" && output == "ik")
        {
            // Matrix multiply: ij,jk->ik
            int m = aShape[0], k = aShape[1], n = bShape[1];
            var result = new float[m * n];
            System.Threading.Tasks.Parallel.For(0, m, i =>
            {
                for (int j = 0; j < n; j++)
                {
                    float sum = 0;
                    for (int kk = 0; kk < k; kk++)
                        sum += aData[i * k + kk] * bData[kk * n + j];
                    result[i * n + j] = sum;
                }
            });
            return new Tensor<float>(new[] { m, n }, new Vector<float>(result));
        }
        else if (input1 == "i" && input2 == "j" && output == "ij")
        {
            // Outer product: i,j->ij
            int m = aShape[0], n = bShape[0];
            var result = new float[m * n];
            System.Threading.Tasks.Parallel.For(0, m, i =>
            {
                for (int j = 0; j < n; j++)
                    result[i * n + j] = aData[i] * bData[j];
            });
            return new Tensor<float>(new[] { m, n }, new Vector<float>(result));
        }
        else if (input1 == "i" && input2 == "i" && output == "")
        {
            // Dot product: i,i->
            float dot = 0;
            for (int i = 0; i < aData.Length; i++) dot += aData[i] * bData[i];
            return new Tensor<float>(new[] { 1 }, new Vector<float>(new[] { dot }));
        }
        else if (input1 == "bij" && input2 == "bjk" && output == "bik")
        {
            // Batch matrix multiply: bij,bjk->bik
            int batch = aShape[0], m = aShape[1], k = aShape[2], n = bShape[2];
            var result = new float[batch * m * n];
            System.Threading.Tasks.Parallel.For(0, batch, bi =>
            {
                int aOffset = bi * m * k;
                int bOffset = bi * k * n;
                int cOffset = bi * m * n;
                for (int i = 0; i < m; i++)
                {
                    for (int j = 0; j < n; j++)
                    {
                        float sum = 0;
                        for (int kk = 0; kk < k; kk++)
                            sum += aData[aOffset + i * k + kk] * bData[bOffset + kk * n + j];
                        result[cOffset + i * n + j] = sum;
                    }
                }
            });
            return new Tensor<float>(new[] { batch, m, n }, new Vector<float>(result));
        }
        else if (input1 == "ij" && input2 == "ij" && output == "ij")
        {
            // Element-wise multiply: ij,ij->ij
            var result = new float[aData.Length];
            System.Threading.Tasks.Parallel.For(0, aData.Length, i =>
            {
                result[i] = aData[i] * bData[i];
            });
            return new Tensor<float>(aShape, new Vector<float>(result));
        }
        else if (input1 == "ij" && input2 == "ij" && output == "")
        {
            // Element-wise multiply then sum: ij,ij->
            float sum = 0;
            for (int i = 0; i < aData.Length; i++) sum += aData[i] * bData[i];
            return new Tensor<float>(new[] { 1 }, new Vector<float>(new[] { sum }));
        }

        // Fall back to CPU for complex patterns
        return _cpuFallback.TensorEinsum($"{input1},{input2}->{output}", new[] { a, b });
    }

    private Tensor<double> TensorEinsumGpuDouble(string subscripts, Tensor<double>[] tensors)
    {
        try
        {
            // Input validation
            if (string.IsNullOrWhiteSpace(subscripts))
            {
                return _cpuFallback.TensorEinsum(subscripts, tensors);
            }
            if (tensors is null || tensors.Length == 0)
            {
                throw new ArgumentException("Tensors array cannot be null or empty", nameof(tensors));
            }

            var parts = subscripts.Replace(" ", "").Split(new[] { "->" }, StringSplitOptions.None);
            var inputSubscripts = parts[0].Split(',');
            var outputSubscript = parts.Length > 1 ? parts[1] : "";

            if (tensors.Length == 1)
            {
                return EinsumSingleTensorGpuDouble(inputSubscripts[0], outputSubscript, tensors[0]);
            }
            else if (tensors.Length == 2)
            {
                return EinsumTwoTensorsGpuDouble(inputSubscripts[0], inputSubscripts[1], outputSubscript, tensors[0], tensors[1]);
            }
            else
            {
                return _cpuFallback.TensorEinsum(subscripts, tensors);
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or FormatException or IndexOutOfRangeException)
        {
            return _cpuFallback.TensorEinsum(subscripts, tensors);
        }
    }

    private Tensor<double> EinsumSingleTensorGpuDouble(string input, string output, Tensor<double> tensor)
    {
        var data = tensor.AsSpan().ToArray();
        var shape = tensor.Shape;

        if (input == "ii" && output == "")
        {
            int n = shape[0];
            double trace = 0;
            for (int i = 0; i < n; i++) trace += data[i * n + i];
            return new Tensor<double>(new[] { 1 }, new Vector<double>(new[] { trace }));
        }
        else if (input == "ij" && output == "ji")
        {
            int m = shape[0], n = shape[1];
            var result = new double[m * n];
            System.Threading.Tasks.Parallel.For(0, m, i =>
            {
                for (int j = 0; j < n; j++)
                    result[j * m + i] = data[i * n + j];
            });
            return new Tensor<double>(new[] { n, m }, new Vector<double>(result));
        }
        else if (input == "ij" && output == "")
        {
            double sum = 0;
            for (int i = 0; i < data.Length; i++) sum += data[i];
            return new Tensor<double>(new[] { 1 }, new Vector<double>(new[] { sum }));
        }
        else if (input == "ij" && output == "i")
        {
            int m = shape[0], n = shape[1];
            var result = new double[m];
            System.Threading.Tasks.Parallel.For(0, m, i =>
            {
                double sum = 0;
                for (int j = 0; j < n; j++) sum += data[i * n + j];
                result[i] = sum;
            });
            return new Tensor<double>(new[] { m }, new Vector<double>(result));
        }
        else if (input == "ij" && output == "j")
        {
            int m = shape[0], n = shape[1];
            var result = new double[n];
            for (int j = 0; j < n; j++)
            {
                double sum = 0;
                for (int i = 0; i < m; i++) sum += data[i * n + j];
                result[j] = sum;
            }
            return new Tensor<double>(new[] { n }, new Vector<double>(result));
        }

        return _cpuFallback.TensorEinsum($"{input}->{output}", new[] { tensor });
    }

    private Tensor<double> EinsumTwoTensorsGpuDouble(string input1, string input2, string output, Tensor<double> a, Tensor<double> b)
    {
        var aData = a.AsSpan().ToArray();
        var bData = b.AsSpan().ToArray();
        var aShape = a.Shape;
        var bShape = b.Shape;

        if (input1 == "ij" && input2 == "jk" && output == "ik")
        {
            int m = aShape[0], k = aShape[1], n = bShape[1];
            var result = new double[m * n];
            System.Threading.Tasks.Parallel.For(0, m, i =>
            {
                for (int j = 0; j < n; j++)
                {
                    double sum = 0;
                    for (int kk = 0; kk < k; kk++)
                        sum += aData[i * k + kk] * bData[kk * n + j];
                    result[i * n + j] = sum;
                }
            });
            return new Tensor<double>(new[] { m, n }, new Vector<double>(result));
        }
        else if (input1 == "i" && input2 == "j" && output == "ij")
        {
            int m = aShape[0], n = bShape[0];
            var result = new double[m * n];
            System.Threading.Tasks.Parallel.For(0, m, i =>
            {
                for (int j = 0; j < n; j++)
                    result[i * n + j] = aData[i] * bData[j];
            });
            return new Tensor<double>(new[] { m, n }, new Vector<double>(result));
        }
        else if (input1 == "i" && input2 == "i" && output == "")
        {
            double dot = 0;
            for (int i = 0; i < aData.Length; i++) dot += aData[i] * bData[i];
            return new Tensor<double>(new[] { 1 }, new Vector<double>(new[] { dot }));
        }
        else if (input1 == "bij" && input2 == "bjk" && output == "bik")
        {
            int batch = aShape[0], m = aShape[1], k = aShape[2], n = bShape[2];
            var result = new double[batch * m * n];
            System.Threading.Tasks.Parallel.For(0, batch, bi =>
            {
                int aOffset = bi * m * k;
                int bOffset = bi * k * n;
                int cOffset = bi * m * n;
                for (int i = 0; i < m; i++)
                {
                    for (int j = 0; j < n; j++)
                    {
                        double sum = 0;
                        for (int kk = 0; kk < k; kk++)
                            sum += aData[aOffset + i * k + kk] * bData[bOffset + kk * n + j];
                        result[cOffset + i * n + j] = sum;
                    }
                }
            });
            return new Tensor<double>(new[] { batch, m, n }, new Vector<double>(result));
        }
        else if (input1 == "ij" && input2 == "ij" && output == "ij")
        {
            var result = new double[aData.Length];
            System.Threading.Tasks.Parallel.For(0, aData.Length, i =>
            {
                result[i] = aData[i] * bData[i];
            });
            return new Tensor<double>(aShape, new Vector<double>(result));
        }
        else if (input1 == "ij" && input2 == "ij" && output == "")
        {
            double sum = 0;
            for (int i = 0; i < aData.Length; i++) sum += aData[i] * bData[i];
            return new Tensor<double>(new[] { 1 }, new Vector<double>(new[] { sum }));
        }

        return _cpuFallback.TensorEinsum($"{input1},{input2}->{output}", new[] { a, b });
    }

    /// <inheritdoc/>
    public Tensor<T> TensorAddScalar<T>(Tensor<T> tensor, T scalar)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var t = (Tensor<float>)(object)tensor;
                var valueObj = (object?)scalar; float s = valueObj is float fv ? fv : Convert.ToSingle(scalar);
                var data = t.AsSpan().ToArray();
                var result = new float[t.Length];
                System.Threading.Tasks.Parallel.For(0, t.Length, i => result[i] = data[i] + s);
                return (Tensor<T>)(object)new Tensor<float>(tensor.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var t = (Tensor<double>)(object)tensor;
                var valueObj = (object?)scalar; double s = valueObj is double dv ? dv : Convert.ToDouble(scalar);
                var data = t.AsSpan().ToArray();
                var result = new double[t.Length];
                System.Threading.Tasks.Parallel.For(0, t.Length, i => result[i] = data[i] + s);
                return (Tensor<T>)(object)new Tensor<double>(tensor.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.TensorAddScalar(tensor, scalar);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorSubtractScalar<T>(Tensor<T> tensor, T scalar)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var t = (Tensor<float>)(object)tensor;
                var valueObj = (object?)scalar; float s = valueObj is float fv ? fv : Convert.ToSingle(scalar);
                var data = t.AsSpan().ToArray();
                var result = new float[t.Length];
                System.Threading.Tasks.Parallel.For(0, t.Length, i => result[i] = data[i] - s);
                return (Tensor<T>)(object)new Tensor<float>(tensor.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var t = (Tensor<double>)(object)tensor;
                var valueObj = (object?)scalar; double s = valueObj is double dv ? dv : Convert.ToDouble(scalar);
                var data = t.AsSpan().ToArray();
                var result = new double[t.Length];
                System.Threading.Tasks.Parallel.For(0, t.Length, i => result[i] = data[i] - s);
                return (Tensor<T>)(object)new Tensor<double>(tensor.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.TensorSubtractScalar(tensor, scalar);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorDivideScalar<T>(Tensor<T> tensor, T scalar)
    {
        if (tensor.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var t = (Tensor<float>)(object)tensor;
                var valueObj = (object?)scalar; float s = valueObj is float fv ? fv : Convert.ToSingle(scalar);
                var data = t.AsSpan().ToArray();
                var result = new float[t.Length];
                System.Threading.Tasks.Parallel.For(0, t.Length, i => result[i] = data[i] / s);
                return (Tensor<T>)(object)new Tensor<float>(tensor.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var t = (Tensor<double>)(object)tensor;
                var valueObj = (object?)scalar; double s = valueObj is double dv ? dv : Convert.ToDouble(scalar);
                var data = t.AsSpan().ToArray();
                var result = new double[t.Length];
                System.Threading.Tasks.Parallel.For(0, t.Length, i => result[i] = data[i] / s);
                return (Tensor<T>)(object)new Tensor<double>(tensor.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.TensorDivideScalar(tensor, scalar);
    }

    /// <inheritdoc/>
    public Tensor<T> TanhDerivative<T>(Tensor<T> tanhOutput)
    {
        // tanh'(x) = 1 - tanh^2(x), given tanh output
        if (tanhOutput.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var t = (Tensor<float>)(object)tanhOutput;
                var data = t.AsSpan().ToArray();
                var result = new float[t.Length];
                System.Threading.Tasks.Parallel.For(0, t.Length, i =>
                {
                    result[i] = 1.0f - data[i] * data[i];
                });
                return (Tensor<T>)(object)new Tensor<float>(tanhOutput.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var t = (Tensor<double>)(object)tanhOutput;
                var data = t.AsSpan().ToArray();
                var result = new double[t.Length];
                System.Threading.Tasks.Parallel.For(0, t.Length, i =>
                {
                    result[i] = 1.0 - data[i] * data[i];
                });
                return (Tensor<T>)(object)new Tensor<double>(tanhOutput.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.TanhDerivative(tanhOutput);
    }

    /// <inheritdoc/>
    public Tensor<T> SigmoidDerivative<T>(Tensor<T> sigmoidOutput)
    {
        // sigmoid'(x) = sigmoid(x) * (1 - sigmoid(x)), given sigmoid output
        if (sigmoidOutput.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var t = (Tensor<float>)(object)sigmoidOutput;
                var data = t.AsSpan().ToArray();
                var result = new float[t.Length];
                System.Threading.Tasks.Parallel.For(0, t.Length, i =>
                {
                    result[i] = data[i] * (1.0f - data[i]);
                });
                return (Tensor<T>)(object)new Tensor<float>(sigmoidOutput.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var t = (Tensor<double>)(object)sigmoidOutput;
                var data = t.AsSpan().ToArray();
                var result = new double[t.Length];
                System.Threading.Tasks.Parallel.For(0, t.Length, i =>
                {
                    result[i] = data[i] * (1.0 - data[i]);
                });
                return (Tensor<T>)(object)new Tensor<double>(sigmoidOutput.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.SigmoidDerivative(sigmoidOutput);
    }

    /// <inheritdoc/>
    public Tensor<T> ReLUDerivative<T>(Tensor<T> input)
    {
        // ReLU'(x) = 1 if x > 0, else 0
        if (input.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var t = (Tensor<float>)(object)input;
                var data = t.AsSpan().ToArray();
                var result = new float[t.Length];
                System.Threading.Tasks.Parallel.For(0, t.Length, i =>
                {
                    result[i] = data[i] > 0 ? 1.0f : 0.0f;
                });
                return (Tensor<T>)(object)new Tensor<float>(input.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var t = (Tensor<double>)(object)input;
                var data = t.AsSpan().ToArray();
                var result = new double[t.Length];
                System.Threading.Tasks.Parallel.For(0, t.Length, i =>
                {
                    result[i] = data[i] > 0 ? 1.0 : 0.0;
                });
                return (Tensor<T>)(object)new Tensor<double>(input.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.ReLUDerivative(input);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorTriangularMask<T>(int size, bool upper = false, int diagonal = 0)
    {
        if (size * size >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorTriangularMaskGpu(size, upper, diagonal);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorTriangularMaskGpuDouble(size, upper, diagonal);
        }
        return _cpuFallback.TensorTriangularMask<T>(size, upper, diagonal);
    }

    private Tensor<float> TensorTriangularMaskGpu(int size, bool upper, int diagonal)
    {
        try
        {
            var result = new float[size * size];
            System.Threading.Tasks.Parallel.For(0, size, i =>
            {
                for (int j = 0; j < size; j++)
                {
                    bool include = upper
                        ? j >= i + diagonal
                        : j <= i + diagonal;
                    result[i * size + j] = include ? 1.0f : 0.0f;
                }
            });
            return new Tensor<float>(new[] { size, size }, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorTriangularMask<float>(size, upper, diagonal);
        }
    }

    private Tensor<double> TensorTriangularMaskGpuDouble(int size, bool upper, int diagonal)
    {
        try
        {
            var result = new double[size * size];
            System.Threading.Tasks.Parallel.For(0, size, i =>
            {
                for (int j = 0; j < size; j++)
                {
                    bool include = upper
                        ? j >= i + diagonal
                        : j <= i + diagonal;
                    result[i * size + j] = include ? 1.0 : 0.0;
                }
            });
            return new Tensor<double>(new[] { size, size }, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorTriangularMask<double>(size, upper, diagonal);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorSquash<T>(Tensor<T> tensor, int axis = -1)
    {
        if (tensor.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorSquashGpu((Tensor<float>)(object)tensor, axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorSquashGpuDouble((Tensor<double>)(object)tensor, axis);
        }
        return _cpuFallback.TensorSquash(tensor, axis);
    }

    private Tensor<float> TensorSquashGpu(Tensor<float> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();
            var result = new float[tensor.Length];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;

                float sumSq = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    sumSq += data[srcIdx] * data[srcIdx];
                }
                float norm = (float)Math.Sqrt(sumSq);
                float scale = sumSq / (1 + sumSq) / (norm + 1e-8f);

                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    result[srcIdx] = data[srcIdx] * scale;
                }
            });

            return new Tensor<float>(tensor.Shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorSquash(tensor, axis);
        }
    }

    private Tensor<double> TensorSquashGpuDouble(Tensor<double> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();
            var result = new double[tensor.Length];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;

                double sumSq = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    sumSq += data[srcIdx] * data[srcIdx];
                }
                double norm = Math.Sqrt(sumSq);
                double scale = sumSq / (1 + sumSq) / (norm + 1e-8);

                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    result[srcIdx] = data[srcIdx] * scale;
                }
            });

            return new Tensor<double>(tensor.Shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorSquash(tensor, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorSquashBackward<T>(Tensor<T> gradOutput, Tensor<T> input, Tensor<T> output, int axis = -1)
    {
        if (gradOutput.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorSquashBackwardGpu((Tensor<float>)(object)gradOutput, (Tensor<float>)(object)input, (Tensor<float>)(object)output, axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorSquashBackwardGpuDouble((Tensor<double>)(object)gradOutput, (Tensor<double>)(object)input, (Tensor<double>)(object)output, axis);
        }
        return _cpuFallback.TensorSquashBackward(gradOutput, input, output, axis);
    }

    private Tensor<float> TensorSquashBackwardGpu(Tensor<float> gradOutput, Tensor<float> input, Tensor<float> output, int axis)
    {
        try
        {
            var shape = input.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var gradData = gradOutput.AsSpan().ToArray();
            var inputData = input.AsSpan().ToArray();
            var outputData = output.AsSpan().ToArray();
            var result = new float[input.Length];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;

                float sumSqIn = 0, sumSqOut = 0, dotGradOut = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    sumSqIn += inputData[srcIdx] * inputData[srcIdx];
                    sumSqOut += outputData[srcIdx] * outputData[srcIdx];
                    dotGradOut += gradData[srcIdx] * outputData[srcIdx];
                }
                float normIn = (float)Math.Sqrt(sumSqIn) + 1e-8f;
                float normOut = (float)Math.Sqrt(sumSqOut) + 1e-8f;
                float factor = 1.0f / ((1 + sumSqIn) * (1 + sumSqIn));

                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    float grad = gradData[srcIdx];
                    float inp = inputData[srcIdx];
                    float outp = outputData[srcIdx];
                    result[srcIdx] = factor * (grad * (1 + sumSqIn) - 2 * inp * dotGradOut / normIn);
                }
            });

            return new Tensor<float>(input.Shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorSquashBackward(gradOutput, input, output, axis);
        }
    }

    private Tensor<double> TensorSquashBackwardGpuDouble(Tensor<double> gradOutput, Tensor<double> input, Tensor<double> output, int axis)
    {
        try
        {
            var shape = input.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var gradData = gradOutput.AsSpan().ToArray();
            var inputData = input.AsSpan().ToArray();
            var outputData = output.AsSpan().ToArray();
            var result = new double[input.Length];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;

                double sumSqIn = 0, sumSqOut = 0, dotGradOut = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    sumSqIn += inputData[srcIdx] * inputData[srcIdx];
                    sumSqOut += outputData[srcIdx] * outputData[srcIdx];
                    dotGradOut += gradData[srcIdx] * outputData[srcIdx];
                }
                double normIn = Math.Sqrt(sumSqIn) + 1e-8;
                double normOut = Math.Sqrt(sumSqOut) + 1e-8;
                double factor = 1.0 / ((1 + sumSqIn) * (1 + sumSqIn));

                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    double grad = gradData[srcIdx];
                    double inp = inputData[srcIdx];
                    double outp = outputData[srcIdx];
                    result[srcIdx] = factor * (grad * (1 + sumSqIn) - 2 * inp * dotGradOut / normIn);
                }
            });

            return new Tensor<double>(input.Shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorSquashBackward(gradOutput, input, output, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorNorm<T>(Tensor<T> tensor, int axis, bool keepDims = false)
    {
        if (tensor.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorNormGpu((Tensor<float>)(object)tensor, axis, keepDims);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorNormGpuDouble((Tensor<double>)(object)tensor, axis, keepDims);
        }
        return _cpuFallback.TensorNorm(tensor, axis, keepDims);
    }

    private Tensor<float> TensorNormGpu(Tensor<float> tensor, int axis, bool keepDims)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            var resultSize = outerSize * innerSize;
            var result = new float[resultSize];

            System.Threading.Tasks.Parallel.For(0, resultSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;
                float sumSq = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    sumSq += data[srcIdx] * data[srcIdx];
                }
                result[idx] = (float)Math.Sqrt(sumSq);
            });

            var newShape = keepDims
                ? shape.Select((s, i) => i == axis ? 1 : s).ToArray()
                : shape.Where((_, i) => i != axis).ToArray();
            if (newShape.Length == 0) newShape = new[] { 1 };

            return new Tensor<float>(newShape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorNorm(tensor, axis, keepDims);
        }
    }

    private Tensor<double> TensorNormGpuDouble(Tensor<double> tensor, int axis, bool keepDims)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            var resultSize = outerSize * innerSize;
            var result = new double[resultSize];

            System.Threading.Tasks.Parallel.For(0, resultSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;
                double sumSq = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    sumSq += data[srcIdx] * data[srcIdx];
                }
                result[idx] = Math.Sqrt(sumSq);
            });

            var newShape = keepDims
                ? shape.Select((s, i) => i == axis ? 1 : s).ToArray()
                : shape.Where((_, i) => i != axis).ToArray();
            if (newShape.Length == 0) newShape = new[] { 1 };

            return new Tensor<double>(newShape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorNorm(tensor, axis, keepDims);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorNormalize<T>(Tensor<T> tensor, int axis, T epsilon)
    {
        if (tensor.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var epsObj = (object?)epsilon; float eps = epsObj is float feps ? feps : Convert.ToSingle(epsilon);
                return (Tensor<T>)(object)TensorNormalizeGpu((Tensor<float>)(object)tensor, axis, eps);
            }
            if (typeof(T) == typeof(double))
            {
                var epsObj = (object?)epsilon; double eps = epsObj is double deps ? deps : Convert.ToDouble(epsilon);
                return (Tensor<T>)(object)TensorNormalizeGpuDouble((Tensor<double>)(object)tensor, axis, eps);
            }
        }
        return _cpuFallback.TensorNormalize(tensor, axis, epsilon);
    }

    private Tensor<float> TensorNormalizeGpu(Tensor<float> tensor, int axis, float epsilon)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();
            var result = new float[tensor.Length];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;

                // Calculate norm
                float sumSq = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    sumSq += data[srcIdx] * data[srcIdx];
                }
                float norm = (float)Math.Sqrt(sumSq) + epsilon;

                // Normalize
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    result[srcIdx] = data[srcIdx] / norm;
                }
            });

            return new Tensor<float>(shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorNormalize(tensor, axis, epsilon);
        }
    }

    private Tensor<double> TensorNormalizeGpuDouble(Tensor<double> tensor, int axis, double epsilon)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();
            var result = new double[tensor.Length];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;

                double sumSq = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    sumSq += data[srcIdx] * data[srcIdx];
                }
                double norm = Math.Sqrt(sumSq) + epsilon;

                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    result[srcIdx] = data[srcIdx] / norm;
                }
            });

            return new Tensor<double>(shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorNormalize(tensor, axis, epsilon);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorClip<T>(Tensor<T> tensor, T minValue, T maxValue)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var t = (Tensor<float>)(object)tensor;
                var minObj = (object?)minValue; float min = minObj is float fmin ? fmin : Convert.ToSingle(minValue);
                var maxObj = (object?)maxValue; float max = maxObj is float fmax ? fmax : Convert.ToSingle(maxValue);
                var data = t.AsSpan().ToArray();
                var result = new float[t.Length];
                System.Threading.Tasks.Parallel.For(0, t.Length, i => result[i] = Math.Max(min, Math.Min(max, data[i])));
                return (Tensor<T>)(object)new Tensor<float>(tensor.Shape, new Vector<float>(result));
            }
            if (typeof(T) == typeof(double))
            {
                var t = (Tensor<double>)(object)tensor;
                var minObj = (object?)minValue; double min = minObj is double dmin ? dmin : Convert.ToDouble(minValue);
                var maxObj = (object?)maxValue; double max = maxObj is double dmax ? dmax : Convert.ToDouble(maxValue);
                var data = t.AsSpan().ToArray();
                var result = new double[t.Length];
                System.Threading.Tasks.Parallel.For(0, t.Length, i => result[i] = Math.Max(min, Math.Min(max, data[i])));
                return (Tensor<T>)(object)new Tensor<double>(tensor.Shape, new Vector<double>(result));
            }
        }
        return _cpuFallback.TensorClip(tensor, minValue, maxValue);
    }

    /// <inheritdoc/>
    public Tensor<T> TensorConcatenate<T>(Tensor<T>[] tensors, int axis = 0)
    {
        if (tensors.Length > 0 && tensors[0].Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var floatTensors = tensors.Select(t => (Tensor<float>)(object)t).ToArray();
                return (Tensor<T>)(object)TensorConcatenateGpu(floatTensors, axis);
            }
            if (typeof(T) == typeof(double))
            {
                var doubleTensors = tensors.Select(t => (Tensor<double>)(object)t).ToArray();
                return (Tensor<T>)(object)TensorConcatenateGpuDouble(doubleTensors, axis);
            }
        }
        return _cpuFallback.TensorConcatenate(tensors, axis);
    }

    private Tensor<float> TensorConcatenateGpu(Tensor<float>[] tensors, int axis)
    {
        try
        {
            if (tensors.Length == 0) throw new ArgumentException("No tensors to concatenate");
            var shape = tensors[0].Shape.ToArray();
            axis = axis < 0 ? shape.Length + axis : axis;

            int totalAxisSize = tensors.Sum(t => t.Shape[axis]);
            var newShape = shape.ToArray();
            newShape[axis] = totalAxisSize;

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            int resultLen = 1; foreach (var d in newShape) resultLen *= d;
            var result = new float[resultLen];

            int axisOffset = 0;
            foreach (var tensor in tensors)
            {
                var data = tensor.AsSpan().ToArray();
                int axisSize = tensor.Shape[axis];

                System.Threading.Tasks.Parallel.For(0, outerSize, o =>
                {
                    for (int a = 0; a < axisSize; a++)
                    {
                        for (int inner = 0; inner < innerSize; inner++)
                        {
                            int srcIdx = (o * axisSize + a) * innerSize + inner;
                            int dstIdx = (o * totalAxisSize + axisOffset + a) * innerSize + inner;
                            result[dstIdx] = data[srcIdx];
                        }
                    }
                });
                axisOffset += axisSize;
            }

            return new Tensor<float>(newShape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorConcatenate(tensors, axis);
        }
    }

    private Tensor<double> TensorConcatenateGpuDouble(Tensor<double>[] tensors, int axis)
    {
        try
        {
            if (tensors.Length == 0) throw new ArgumentException("No tensors to concatenate");
            var shape = tensors[0].Shape.ToArray();
            axis = axis < 0 ? shape.Length + axis : axis;

            int totalAxisSize = tensors.Sum(t => t.Shape[axis]);
            var newShape = shape.ToArray();
            newShape[axis] = totalAxisSize;

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            int resultLen = 1; foreach (var d in newShape) resultLen *= d;
            var result = new double[resultLen];

            int axisOffset = 0;
            foreach (var tensor in tensors)
            {
                var data = tensor.AsSpan().ToArray();
                int axisSize = tensor.Shape[axis];

                System.Threading.Tasks.Parallel.For(0, outerSize, o =>
                {
                    for (int a = 0; a < axisSize; a++)
                    {
                        for (int inner = 0; inner < innerSize; inner++)
                        {
                            int srcIdx = (o * axisSize + a) * innerSize + inner;
                            int dstIdx = (o * totalAxisSize + axisOffset + a) * innerSize + inner;
                            result[dstIdx] = data[srcIdx];
                        }
                    }
                });
                axisOffset += axisSize;
            }

            return new Tensor<double>(newShape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorConcatenate(tensors, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T>[] TensorSplit<T>(Tensor<T> tensor, int numSplits, int axis = 0)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var result = TensorSplitGpu((Tensor<float>)(object)tensor, numSplits, axis);
                return result.Select(t => (Tensor<T>)(object)t).ToArray();
            }
            if (typeof(T) == typeof(double))
            {
                var result = TensorSplitGpuDouble((Tensor<double>)(object)tensor, numSplits, axis);
                return result.Select(t => (Tensor<T>)(object)t).ToArray();
            }
        }
        return _cpuFallback.TensorSplit(tensor, numSplits, axis);
    }

    private Tensor<float>[] TensorSplitGpu(Tensor<float> tensor, int numSplits, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();

            int splitSize = shape[axis] / numSplits;
            var results = new Tensor<float>[numSplits];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            for (int s = 0; s < numSplits; s++)
            {
                var newShape = shape.ToArray();
                newShape[axis] = splitSize;
                var result = new float[outerSize * splitSize * innerSize];
                int splitOffset = s * splitSize;

                System.Threading.Tasks.Parallel.For(0, outerSize, o =>
                {
                    for (int a = 0; a < splitSize; a++)
                    {
                        for (int inner = 0; inner < innerSize; inner++)
                        {
                            int srcIdx = (o * axisSize + splitOffset + a) * innerSize + inner;
                            int dstIdx = (o * splitSize + a) * innerSize + inner;
                            result[dstIdx] = data[srcIdx];
                        }
                    }
                });

                results[s] = new Tensor<float>(newShape, new Vector<float>(result));
            }
            return results;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorSplit(tensor, numSplits, axis);
        }
    }

    private Tensor<double>[] TensorSplitGpuDouble(Tensor<double> tensor, int numSplits, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();

            int splitSize = shape[axis] / numSplits;
            var results = new Tensor<double>[numSplits];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            for (int s = 0; s < numSplits; s++)
            {
                var newShape = shape.ToArray();
                newShape[axis] = splitSize;
                var result = new double[outerSize * splitSize * innerSize];
                int splitOffset = s * splitSize;

                System.Threading.Tasks.Parallel.For(0, outerSize, o =>
                {
                    for (int a = 0; a < splitSize; a++)
                    {
                        for (int inner = 0; inner < innerSize; inner++)
                        {
                            int srcIdx = (o * axisSize + splitOffset + a) * innerSize + inner;
                            int dstIdx = (o * splitSize + a) * innerSize + inner;
                            result[dstIdx] = data[srcIdx];
                        }
                    }
                });

                results[s] = new Tensor<double>(newShape, new Vector<double>(result));
            }
            return results;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorSplit(tensor, numSplits, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorOneHot<T>(Tensor<int> indices, int depth)
    {
        if (indices.Length * depth >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorOneHotGpu(indices, depth);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorOneHotGpuDouble(indices, depth);
        }
        return _cpuFallback.TensorOneHot<T>(indices, depth);
    }

    private Tensor<float> TensorOneHotGpu(Tensor<int> indices, int depth)
    {
        try
        {
            var idxData = indices.AsSpan().ToArray();
            var result = new float[indices.Length * depth];
            var newShape = indices.Shape.Concat(new[] { depth }).ToArray();

            System.Threading.Tasks.Parallel.For(0, indices.Length, i =>
            {
                int idx = idxData[i];
                if (idx >= 0 && idx < depth)
                {
                    result[i * depth + idx] = 1.0f;
                }
            });

            return new Tensor<float>(newShape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorOneHot<float>(indices, depth);
        }
    }

    private Tensor<double> TensorOneHotGpuDouble(Tensor<int> indices, int depth)
    {
        try
        {
            var idxData = indices.AsSpan().ToArray();
            var result = new double[indices.Length * depth];
            var newShape = indices.Shape.Concat(new[] { depth }).ToArray();

            System.Threading.Tasks.Parallel.For(0, indices.Length, i =>
            {
                int idx = idxData[i];
                if (idx >= 0 && idx < depth)
                {
                    result[i * depth + idx] = 1.0;
                }
            });

            return new Tensor<double>(newShape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorOneHot<double>(indices, depth);
        }
    }

    /// <inheritdoc/>
    public Tensor<int> TensorArgMax<T>(Tensor<T> tensor, int axis)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return TensorArgMaxGpu((Tensor<float>)(object)tensor, axis);
            if (typeof(T) == typeof(double))
                return TensorArgMaxGpuDouble((Tensor<double>)(object)tensor, axis);
        }
        return _cpuFallback.TensorArgMax(tensor, axis);
    }

    private Tensor<int> TensorArgMaxGpu(Tensor<float> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            // Validate non-empty tensor
            if (shape.Length == 0 || tensor.Length == 0)
            {
                return _cpuFallback.TensorArgMax(tensor, axis);
            }
            axis = axis < 0 ? shape.Length + axis : axis;
            // Validate axis is in bounds
            if (axis < 0 || axis >= shape.Length)
            {
                return _cpuFallback.TensorArgMax(tensor, axis);
            }
            var data = tensor.AsSpan().ToArray();

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            var resultSize = outerSize * innerSize;
            var result = new int[resultSize];

            System.Threading.Tasks.Parallel.For(0, resultSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;
                int maxIdx = 0;
                float maxVal = float.MinValue;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    if (data[srcIdx] > maxVal)
                    {
                        maxVal = data[srcIdx];
                        maxIdx = a;
                    }
                }
                result[idx] = maxIdx;
            });

            var newShape = shape.Where((_, i) => i != axis).ToArray();
            if (newShape.Length == 0) newShape = new[] { 1 };
            return new Tensor<int>(newShape, new Vector<int>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or IndexOutOfRangeException)
        {
            return _cpuFallback.TensorArgMax(tensor, axis);
        }
    }

    private Tensor<int> TensorArgMaxGpuDouble(Tensor<double> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            // Validate non-empty tensor
            if (shape.Length == 0 || tensor.Length == 0)
            {
                return _cpuFallback.TensorArgMax(tensor, axis);
            }
            axis = axis < 0 ? shape.Length + axis : axis;
            // Validate axis is in bounds
            if (axis < 0 || axis >= shape.Length)
            {
                return _cpuFallback.TensorArgMax(tensor, axis);
            }
            var data = tensor.AsSpan().ToArray();

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            var resultSize = outerSize * innerSize;
            var result = new int[resultSize];

            System.Threading.Tasks.Parallel.For(0, resultSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;
                int maxIdx = 0;
                double maxVal = double.MinValue;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    if (data[srcIdx] > maxVal)
                    {
                        maxVal = data[srcIdx];
                        maxIdx = a;
                    }
                }
                result[idx] = maxIdx;
            });

            var newShape = shape.Where((_, i) => i != axis).ToArray();
            if (newShape.Length == 0) newShape = new[] { 1 };
            return new Tensor<int>(newShape, new Vector<int>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or IndexOutOfRangeException)
        {
            return _cpuFallback.TensorArgMax(tensor, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<int> TensorArgMin<T>(Tensor<T> tensor, int axis)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return TensorArgMinGpu((Tensor<float>)(object)tensor, axis);
            if (typeof(T) == typeof(double))
                return TensorArgMinGpuDouble((Tensor<double>)(object)tensor, axis);
        }
        return _cpuFallback.TensorArgMin(tensor, axis);
    }

    private Tensor<int> TensorArgMinGpu(Tensor<float> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            // Validate non-empty tensor
            if (shape.Length == 0 || tensor.Length == 0)
            {
                return _cpuFallback.TensorArgMin(tensor, axis);
            }
            axis = axis < 0 ? shape.Length + axis : axis;
            // Validate axis is in bounds
            if (axis < 0 || axis >= shape.Length)
            {
                return _cpuFallback.TensorArgMin(tensor, axis);
            }
            var data = tensor.AsSpan().ToArray();

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            var resultSize = outerSize * innerSize;
            var result = new int[resultSize];

            System.Threading.Tasks.Parallel.For(0, resultSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;
                int minIdx = 0;
                float minVal = float.MaxValue;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    if (data[srcIdx] < minVal)
                    {
                        minVal = data[srcIdx];
                        minIdx = a;
                    }
                }
                result[idx] = minIdx;
            });

            var newShape = shape.Where((_, i) => i != axis).ToArray();
            if (newShape.Length == 0) newShape = new[] { 1 };
            return new Tensor<int>(newShape, new Vector<int>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or IndexOutOfRangeException)
        {
            return _cpuFallback.TensorArgMin(tensor, axis);
        }
    }

    private Tensor<int> TensorArgMinGpuDouble(Tensor<double> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            // Validate non-empty tensor
            if (shape.Length == 0 || tensor.Length == 0)
            {
                return _cpuFallback.TensorArgMin(tensor, axis);
            }
            axis = axis < 0 ? shape.Length + axis : axis;
            // Validate axis is in bounds
            if (axis < 0 || axis >= shape.Length)
            {
                return _cpuFallback.TensorArgMin(tensor, axis);
            }
            var data = tensor.AsSpan().ToArray();

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            var resultSize = outerSize * innerSize;
            var result = new int[resultSize];

            System.Threading.Tasks.Parallel.For(0, resultSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;
                int minIdx = 0;
                double minVal = double.MaxValue;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    if (data[srcIdx] < minVal)
                    {
                        minVal = data[srcIdx];
                        minIdx = a;
                    }
                }
                result[idx] = minIdx;
            });

            var newShape = shape.Where((_, i) => i != axis).ToArray();
            if (newShape.Length == 0) newShape = new[] { 1 };
            return new Tensor<int>(newShape, new Vector<int>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException or IndexOutOfRangeException)
        {
            return _cpuFallback.TensorArgMin(tensor, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorBinaryCrossEntropy<T>(Tensor<T> predictions, Tensor<T> targets, T epsilon)
    {
        if (predictions.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var epsObj = (object?)epsilon; float eps = epsObj is float feps ? feps : Convert.ToSingle(epsilon);
                return (Tensor<T>)(object)TensorBinaryCrossEntropyGpu(
                    (Tensor<float>)(object)predictions, (Tensor<float>)(object)targets, eps);
            }
            if (typeof(T) == typeof(double))
            {
                var epsObj = (object?)epsilon; double eps = epsObj is double deps ? deps : Convert.ToDouble(epsilon);
                return (Tensor<T>)(object)TensorBinaryCrossEntropyGpuDouble(
                    (Tensor<double>)(object)predictions, (Tensor<double>)(object)targets, eps);
            }
        }
        return _cpuFallback.TensorBinaryCrossEntropy(predictions, targets, epsilon);
    }

    private Tensor<float> TensorBinaryCrossEntropyGpu(Tensor<float> predictions, Tensor<float> targets, float epsilon)
    {
        try
        {
            var pData = predictions.AsSpan().ToArray();
            var tData = targets.AsSpan().ToArray();
            var result = new float[predictions.Length];

            System.Threading.Tasks.Parallel.For(0, predictions.Length, i =>
            {
                float p = Math.Max(epsilon, Math.Min(1 - epsilon, pData[i]));
                float t = tData[i];
                result[i] = -(t * (float)Math.Log(p) + (1 - t) * (float)Math.Log(1 - p));
            });

            return new Tensor<float>(predictions.Shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorBinaryCrossEntropy(predictions, targets, epsilon);
        }
    }

    private Tensor<double> TensorBinaryCrossEntropyGpuDouble(Tensor<double> predictions, Tensor<double> targets, double epsilon)
    {
        try
        {
            var pData = predictions.AsSpan().ToArray();
            var tData = targets.AsSpan().ToArray();
            var result = new double[predictions.Length];

            System.Threading.Tasks.Parallel.For(0, predictions.Length, i =>
            {
                double p = Math.Max(epsilon, Math.Min(1 - epsilon, pData[i]));
                double t = tData[i];
                result[i] = -(t * Math.Log(p) + (1 - t) * Math.Log(1 - p));
            });

            return new Tensor<double>(predictions.Shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorBinaryCrossEntropy(predictions, targets, epsilon);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorBinaryCrossEntropyBackward<T>(Tensor<T> predictions, Tensor<T> targets, T epsilon)
    {
        if (predictions.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var epsObj = (object?)epsilon; float eps = epsObj is float feps ? feps : Convert.ToSingle(epsilon);
                return (Tensor<T>)(object)TensorBinaryCrossEntropyBackwardGpu(
                    (Tensor<float>)(object)predictions, (Tensor<float>)(object)targets, eps);
            }
            if (typeof(T) == typeof(double))
            {
                var epsObj = (object?)epsilon; double eps = epsObj is double deps ? deps : Convert.ToDouble(epsilon);
                return (Tensor<T>)(object)TensorBinaryCrossEntropyBackwardGpuDouble(
                    (Tensor<double>)(object)predictions, (Tensor<double>)(object)targets, eps);
            }
        }
        return _cpuFallback.TensorBinaryCrossEntropyBackward(predictions, targets, epsilon);
    }

    private Tensor<float> TensorBinaryCrossEntropyBackwardGpu(Tensor<float> predictions, Tensor<float> targets, float epsilon)
    {
        try
        {
            var pData = predictions.AsSpan().ToArray();
            var tData = targets.AsSpan().ToArray();
            var result = new float[predictions.Length];

            // Gradient: (p - t) / (p * (1 - p))
            System.Threading.Tasks.Parallel.For(0, predictions.Length, i =>
            {
                float p = Math.Max(epsilon, Math.Min(1 - epsilon, pData[i]));
                float t = tData[i];
                result[i] = (p - t) / (p * (1 - p) + epsilon);
            });

            return new Tensor<float>(predictions.Shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorBinaryCrossEntropyBackward(predictions, targets, epsilon);
        }
    }

    private Tensor<double> TensorBinaryCrossEntropyBackwardGpuDouble(Tensor<double> predictions, Tensor<double> targets, double epsilon)
    {
        try
        {
            var pData = predictions.AsSpan().ToArray();
            var tData = targets.AsSpan().ToArray();
            var result = new double[predictions.Length];

            System.Threading.Tasks.Parallel.For(0, predictions.Length, i =>
            {
                double p = Math.Max(epsilon, Math.Min(1 - epsilon, pData[i]));
                double t = tData[i];
                result[i] = (p - t) / (p * (1 - p) + epsilon);
            });

            return new Tensor<double>(predictions.Shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorBinaryCrossEntropyBackward(predictions, targets, epsilon);
        }
    }

    /// <inheritdoc/>
    public (Tensor<T> X, Tensor<T> Y) TensorMeshgrid<T>(Tensor<T> x, Tensor<T> y)
    {
        int outputSize = x.Length * y.Length;
        if (outputSize >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var (X, Y) = TensorMeshgridGpu((Tensor<float>)(object)x, (Tensor<float>)(object)y);
                return ((Tensor<T>)(object)X, (Tensor<T>)(object)Y);
            }
            if (typeof(T) == typeof(double))
            {
                var (X, Y) = TensorMeshgridGpuDouble((Tensor<double>)(object)x, (Tensor<double>)(object)y);
                return ((Tensor<T>)(object)X, (Tensor<T>)(object)Y);
            }
        }
        return _cpuFallback.TensorMeshgrid(x, y);
    }

    private (Tensor<float> X, Tensor<float> Y) TensorMeshgridGpu(Tensor<float> x, Tensor<float> y)
    {
        try
        {
            int xLen = x.Length, yLen = y.Length;
            var xData = x.AsSpan().ToArray();
            var yData = y.AsSpan().ToArray();
            var resultX = new float[yLen * xLen];
            var resultY = new float[yLen * xLen];

            System.Threading.Tasks.Parallel.For(0, yLen, i =>
            {
                for (int j = 0; j < xLen; j++)
                {
                    int idx = i * xLen + j;
                    resultX[idx] = xData[j];
                    resultY[idx] = yData[i];
                }
            });

            return (new Tensor<float>(new[] { yLen, xLen }, new Vector<float>(resultX)),
                    new Tensor<float>(new[] { yLen, xLen }, new Vector<float>(resultY)));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorMeshgrid(x, y);
        }
    }

    private (Tensor<double> X, Tensor<double> Y) TensorMeshgridGpuDouble(Tensor<double> x, Tensor<double> y)
    {
        try
        {
            int xLen = x.Length, yLen = y.Length;
            var xData = x.AsSpan().ToArray();
            var yData = y.AsSpan().ToArray();
            var resultX = new double[yLen * xLen];
            var resultY = new double[yLen * xLen];

            System.Threading.Tasks.Parallel.For(0, yLen, i =>
            {
                for (int j = 0; j < xLen; j++)
                {
                    int idx = i * xLen + j;
                    resultX[idx] = xData[j];
                    resultY[idx] = yData[i];
                }
            });

            return (new Tensor<double>(new[] { yLen, xLen }, new Vector<double>(resultX)),
                    new Tensor<double>(new[] { yLen, xLen }, new Vector<double>(resultY)));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorMeshgrid(x, y);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorSliceAxis<T>(Tensor<T> tensor, int axis, int index)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorSliceAxisGpu((Tensor<float>)(object)tensor, axis, index);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorSliceAxisGpuDouble((Tensor<double>)(object)tensor, axis, index);
        }
        return _cpuFallback.TensorSliceAxis(tensor, axis, index);
    }

    private Tensor<float> TensorSliceAxisGpu(Tensor<float> tensor, int axis, int index)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            index = index < 0 ? shape[axis] + index : index;
            var data = tensor.AsSpan().ToArray();

            var newShape = shape.Where((_, i) => i != axis).ToArray();
            if (newShape.Length == 0) newShape = new[] { 1 };

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            var result = new float[outerSize * innerSize];

            System.Threading.Tasks.Parallel.For(0, outerSize, o =>
            {
                for (int inner = 0; inner < innerSize; inner++)
                {
                    int srcIdx = (o * axisSize + index) * innerSize + inner;
                    int dstIdx = o * innerSize + inner;
                    result[dstIdx] = data[srcIdx];
                }
            });

            return new Tensor<float>(newShape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorSliceAxis(tensor, axis, index);
        }
    }

    private Tensor<double> TensorSliceAxisGpuDouble(Tensor<double> tensor, int axis, int index)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            index = index < 0 ? shape[axis] + index : index;
            var data = tensor.AsSpan().ToArray();

            var newShape = shape.Where((_, i) => i != axis).ToArray();
            if (newShape.Length == 0) newShape = new[] { 1 };

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            var result = new double[outerSize * innerSize];

            System.Threading.Tasks.Parallel.For(0, outerSize, o =>
            {
                for (int inner = 0; inner < innerSize; inner++)
                {
                    int srcIdx = (o * axisSize + index) * innerSize + inner;
                    int dstIdx = o * innerSize + inner;
                    result[dstIdx] = data[srcIdx];
                }
            });

            return new Tensor<double>(newShape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorSliceAxis(tensor, axis, index);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorLinspace<T>(T start, T end, int count)
    {
        if (count >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var startObj = (object?)start; float s = startObj is float fs ? fs : Convert.ToSingle(start);
                var endObj = (object?)end; float e = endObj is float fe ? fe : Convert.ToSingle(end);
                return (Tensor<T>)(object)TensorLinspaceGpu(s, e, count);
            }
            if (typeof(T) == typeof(double))
            {
                var startObj = (object?)start; double s = startObj is double ds ? ds : Convert.ToDouble(start);
                var endObj = (object?)end; double e = endObj is double de ? de : Convert.ToDouble(end);
                return (Tensor<T>)(object)TensorLinspaceGpuDouble(s, e, count);
            }
        }
        return _cpuFallback.TensorLinspace(start, end, count);
    }

    private Tensor<float> TensorLinspaceGpu(float start, float end, int count)
    {
        try
        {
            var result = new float[count];
            float step = count > 1 ? (end - start) / (count - 1) : 0;
            System.Threading.Tasks.Parallel.For(0, count, i =>
            {
                result[i] = start + i * step;
            });
            return new Tensor<float>(new[] { count }, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorLinspace(start, end, count);
        }
    }

    private Tensor<double> TensorLinspaceGpuDouble(double start, double end, int count)
    {
        try
        {
            var result = new double[count];
            double step = count > 1 ? (end - start) / (count - 1) : 0;
            System.Threading.Tasks.Parallel.For(0, count, i =>
            {
                result[i] = start + i * step;
            });
            return new Tensor<double>(new[] { count }, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorLinspace(start, end, count);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorBatchMatMul<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a.Length >= _thresholds.MatrixMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorBatchMatMulGpu((Tensor<float>)(object)a, (Tensor<float>)(object)b);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorBatchMatMulGpuDouble((Tensor<double>)(object)a, (Tensor<double>)(object)b);
        }
        return _cpuFallback.TensorBatchMatMul(a, b);
    }

    private Tensor<float> TensorBatchMatMulGpu(Tensor<float> a, Tensor<float> b)
    {
        try
        {
            var aShape = a.Shape;
            var bShape = b.Shape;
            int batchSize = aShape[0];
            int m = aShape[1];
            int k = aShape[2];
            int n = bShape[2];
            var aData = a.AsSpan().ToArray();
            var bData = b.AsSpan().ToArray();
            var result = new float[batchSize * m * n];

            System.Threading.Tasks.Parallel.For(0, batchSize, batch =>
            {
                int aOffset = batch * m * k;
                int bOffset = batch * k * n;
                int cOffset = batch * m * n;
                for (int i = 0; i < m; i++)
                {
                    for (int j = 0; j < n; j++)
                    {
                        float sum = 0;
                        for (int kk = 0; kk < k; kk++)
                        {
                            sum += aData[aOffset + i * k + kk] * bData[bOffset + kk * n + j];
                        }
                        result[cOffset + i * n + j] = sum;
                    }
                }
            });

            return new Tensor<float>(new[] { batchSize, m, n }, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorBatchMatMul(a, b);
        }
    }

    private Tensor<double> TensorBatchMatMulGpuDouble(Tensor<double> a, Tensor<double> b)
    {
        try
        {
            var aShape = a.Shape;
            var bShape = b.Shape;
            int batchSize = aShape[0];
            int m = aShape[1];
            int k = aShape[2];
            int n = bShape[2];
            var aData = a.AsSpan().ToArray();
            var bData = b.AsSpan().ToArray();
            var result = new double[batchSize * m * n];

            System.Threading.Tasks.Parallel.For(0, batchSize, batch =>
            {
                int aOffset = batch * m * k;
                int bOffset = batch * k * n;
                int cOffset = batch * m * n;
                for (int i = 0; i < m; i++)
                {
                    for (int j = 0; j < n; j++)
                    {
                        double sum = 0;
                        for (int kk = 0; kk < k; kk++)
                        {
                            sum += aData[aOffset + i * k + kk] * bData[bOffset + kk * n + j];
                        }
                        result[cOffset + i * n + j] = sum;
                    }
                }
            });

            return new Tensor<double>(new[] { batchSize, m, n }, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorBatchMatMul(a, b);
        }
    }

    /// <inheritdoc/>
    public void TensorSetSliceAxis<T>(Tensor<T> destination, Tensor<T> source, int axis, int index)
    {
        if (source.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                TensorSetSliceAxisGpu((Tensor<float>)(object)destination, (Tensor<float>)(object)source, axis, index);
                return;
            }
            if (typeof(T) == typeof(double))
            {
                TensorSetSliceAxisGpuDouble((Tensor<double>)(object)destination, (Tensor<double>)(object)source, axis, index);
                return;
            }
        }
        _cpuFallback.TensorSetSliceAxis(destination, source, axis, index);
    }

    private void TensorSetSliceAxisGpu(Tensor<float> destination, Tensor<float> source, int axis, int index)
    {
        try
        {
            var shape = destination.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            index = index < 0 ? shape[axis] + index : index;
            var srcData = source.AsSpan().ToArray();
            var dstData = destination.AsSpan().ToArray();

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            var dstSpan = destination.AsWritableSpan();
            for (int o = 0; o < outerSize; o++)
            {
                for (int inner = 0; inner < innerSize; inner++)
                {
                    int srcIdx = o * innerSize + inner;
                    int dstIdx = (o * axisSize + index) * innerSize + inner;
                    dstSpan[dstIdx] = srcData[srcIdx];
                }
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            _cpuFallback.TensorSetSliceAxis(destination, source, axis, index);
        }
    }

    private void TensorSetSliceAxisGpuDouble(Tensor<double> destination, Tensor<double> source, int axis, int index)
    {
        try
        {
            var shape = destination.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            index = index < 0 ? shape[axis] + index : index;
            var srcData = source.AsSpan().ToArray();
            var dstData = destination.AsSpan().ToArray();

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            var dstSpan = destination.AsWritableSpan();
            for (int o = 0; o < outerSize; o++)
            {
                for (int inner = 0; inner < innerSize; inner++)
                {
                    int srcIdx = o * innerSize + inner;
                    int dstIdx = (o * axisSize + index) * innerSize + inner;
                    dstSpan[dstIdx] = srcData[srcIdx];
                }
            }
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            _cpuFallback.TensorSetSliceAxis(destination, source, axis, index);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorSoftmax<T>(Tensor<T> tensor, int axis)
    {
        if (tensor.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorSoftmaxGpuOpt((Tensor<float>)(object)tensor, axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorSoftmaxGpuOptDouble((Tensor<double>)(object)tensor, axis);
        }
        return _cpuFallback.TensorSoftmax(tensor, axis);
    }

    private Tensor<float> TensorSoftmaxGpuOpt(Tensor<float> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();
            var result = new float[tensor.Length];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;

                // Find max for stability
                float maxVal = float.MinValue;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    if (data[srcIdx] > maxVal) maxVal = data[srcIdx];
                }

                // Compute exp and sum
                float sumExp = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    float expVal = (float)Math.Exp(data[srcIdx] - maxVal);
                    result[srcIdx] = expVal;
                    sumExp += expVal;
                }

                // Normalize
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    result[srcIdx] /= sumExp;
                }
            });

            return new Tensor<float>(shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorSoftmax(tensor, axis);
        }
    }

    private Tensor<double> TensorSoftmaxGpuOptDouble(Tensor<double> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();
            var result = new double[tensor.Length];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;

                double maxVal = double.MinValue;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    if (data[srcIdx] > maxVal) maxVal = data[srcIdx];
                }

                double sumExp = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    double expVal = Math.Exp(data[srcIdx] - maxVal);
                    result[srcIdx] = expVal;
                    sumExp += expVal;
                }

                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    result[srcIdx] /= sumExp;
                }
            });

            return new Tensor<double>(shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorSoftmax(tensor, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorSoftmaxBackward<T>(Tensor<T> softmaxOutput, Tensor<T> outputGradient, int axis)
    {
        if (softmaxOutput.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorSoftmaxBackwardGpu((Tensor<float>)(object)softmaxOutput, (Tensor<float>)(object)outputGradient, axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorSoftmaxBackwardGpuDouble((Tensor<double>)(object)softmaxOutput, (Tensor<double>)(object)outputGradient, axis);
        }
        return _cpuFallback.TensorSoftmaxBackward(softmaxOutput, outputGradient, axis);
    }

    private Tensor<float> TensorSoftmaxBackwardGpu(Tensor<float> softmaxOutput, Tensor<float> outputGradient, int axis)
    {
        try
        {
            var shape = softmaxOutput.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var sData = softmaxOutput.AsSpan().ToArray();
            var gData = outputGradient.AsSpan().ToArray();
            var result = new float[softmaxOutput.Length];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;

                float dot = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    dot += sData[srcIdx] * gData[srcIdx];
                }

                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    result[srcIdx] = sData[srcIdx] * (gData[srcIdx] - dot);
                }
            });

            return new Tensor<float>(softmaxOutput.Shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorSoftmaxBackward(softmaxOutput, outputGradient, axis);
        }
    }

    private Tensor<double> TensorSoftmaxBackwardGpuDouble(Tensor<double> softmaxOutput, Tensor<double> outputGradient, int axis)
    {
        try
        {
            var shape = softmaxOutput.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var sData = softmaxOutput.AsSpan().ToArray();
            var gData = outputGradient.AsSpan().ToArray();
            var result = new double[softmaxOutput.Length];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;

                double dot = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    dot += sData[srcIdx] * gData[srcIdx];
                }

                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    result[srcIdx] = sData[srcIdx] * (gData[srcIdx] - dot);
                }
            });

            return new Tensor<double>(softmaxOutput.Shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorSoftmaxBackward(softmaxOutput, outputGradient, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorLogSoftmax<T>(Tensor<T> tensor, int axis)
    {
        if (tensor.Length >= _thresholds.VectorMultiply && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorLogSoftmaxGpu((Tensor<float>)(object)tensor, axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorLogSoftmaxGpuDouble((Tensor<double>)(object)tensor, axis);
        }
        return _cpuFallback.TensorLogSoftmax(tensor, axis);
    }

    private Tensor<float> TensorLogSoftmaxGpu(Tensor<float> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();
            var result = new float[tensor.Length];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;

                float maxVal = float.MinValue;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    if (data[srcIdx] > maxVal) maxVal = data[srcIdx];
                }

                float sumExp = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    sumExp += (float)Math.Exp(data[srcIdx] - maxVal);
                }

                float logSumExp = maxVal + (float)Math.Log(sumExp);
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    result[srcIdx] = data[srcIdx] - logSumExp;
                }
            });

            return new Tensor<float>(shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorLogSoftmax(tensor, axis);
        }
    }

    private Tensor<double> TensorLogSoftmaxGpuDouble(Tensor<double> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();
            var result = new double[tensor.Length];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;

                double maxVal = double.MinValue;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    if (data[srcIdx] > maxVal) maxVal = data[srcIdx];
                }

                double sumExp = 0;
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    sumExp += Math.Exp(data[srcIdx] - maxVal);
                }

                double logSumExp = maxVal + Math.Log(sumExp);
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    result[srcIdx] = data[srcIdx] - logSumExp;
                }
            });

            return new Tensor<double>(shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorLogSoftmax(tensor, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorTopK<T>(Tensor<T> tensor, int k, int axis, out Tensor<int> indices)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var (values, idx) = TensorTopKGpu((Tensor<float>)(object)tensor, k, axis);
                indices = idx;
                return (Tensor<T>)(object)values;
            }
            if (typeof(T) == typeof(double))
            {
                var (values, idx) = TensorTopKGpuDouble((Tensor<double>)(object)tensor, k, axis);
                indices = idx;
                return (Tensor<T>)(object)values;
            }
        }
        return _cpuFallback.TensorTopK(tensor, k, axis, out indices);
    }

    private (Tensor<float> values, Tensor<int> indices) TensorTopKGpu(Tensor<float> tensor, int k, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            k = Math.Min(k, axisSize);
            var newShape = shape.ToArray();
            newShape[axis] = k;

            int resultLen = 1; foreach (var d in newShape) resultLen *= d;
            var resultValues = new float[resultLen];
            var resultIndices = new int[resultLen];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;

                // Extract values along axis for this position
                var axisValues = new (float value, int index)[axisSize];
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    axisValues[a] = (data[srcIdx], a);
                }

                // Sort by value descending and take top k
                Array.Sort(axisValues, (x, y) => y.value.CompareTo(x.value));

                for (int ki = 0; ki < k; ki++)
                {
                    int dstIdx = (o * k + ki) * innerSize + inner;
                    resultValues[dstIdx] = axisValues[ki].value;
                    resultIndices[dstIdx] = axisValues[ki].index;
                }
            });

            return (new Tensor<float>(newShape, new Vector<float>(resultValues)),
                    new Tensor<int>(newShape, new Vector<int>(resultIndices)));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorTopK(tensor, k, axis, out var idx) is var values ? (values, idx) : default;
        }
    }

    private (Tensor<double> values, Tensor<int> indices) TensorTopKGpuDouble(Tensor<double> tensor, int k, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            k = Math.Min(k, axisSize);
            var newShape = shape.ToArray();
            newShape[axis] = k;

            int resultLen = 1; foreach (var d in newShape) resultLen *= d;
            var resultValues = new double[resultLen];
            var resultIndices = new int[resultLen];

            System.Threading.Tasks.Parallel.For(0, outerSize * innerSize, idx =>
            {
                int o = idx / innerSize;
                int inner = idx % innerSize;

                var axisValues = new (double value, int index)[axisSize];
                for (int a = 0; a < axisSize; a++)
                {
                    int srcIdx = (o * axisSize + a) * innerSize + inner;
                    axisValues[a] = (data[srcIdx], a);
                }

                Array.Sort(axisValues, (x, y) => y.value.CompareTo(x.value));

                for (int ki = 0; ki < k; ki++)
                {
                    int dstIdx = (o * k + ki) * innerSize + inner;
                    resultValues[dstIdx] = axisValues[ki].value;
                    resultIndices[dstIdx] = axisValues[ki].index;
                }
            });

            return (new Tensor<double>(newShape, new Vector<double>(resultValues)),
                    new Tensor<int>(newShape, new Vector<int>(resultIndices)));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorTopK(tensor, k, axis, out var idx) is var values ? (values, idx) : default;
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorScatter<T>(Tensor<T> destination, Tensor<int> indices, Tensor<T> source, int axis)
    {
        if (destination.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorScatterGpu((Tensor<float>)(object)destination, indices, (Tensor<float>)(object)source, axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorScatterGpuDouble((Tensor<double>)(object)destination, indices, (Tensor<double>)(object)source, axis);
        }
        return _cpuFallback.TensorScatter(destination, indices, source, axis);
    }

    private Tensor<float> TensorScatterGpu(Tensor<float> destination, Tensor<int> indices, Tensor<float> source, int axis)
    {
        try
        {
            var shape = destination.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var destData = destination.AsSpan().ToArray();
            var srcData = source.AsSpan().ToArray();
            var idxData = indices.AsSpan().ToArray();
            var result = destData.ToArray(); // Copy destination

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize, o =>
            {
                for (int idx = 0; idx < indices.Length; idx++)
                {
                    int targetIdx = idxData[idx];
                    if (targetIdx < 0) targetIdx += axisSize;
                    // Bounds check: ensure targetIdx is valid
                    if (targetIdx >= 0 && targetIdx < axisSize)
                    {
                        for (int inner = 0; inner < innerSize; inner++)
                        {
                            int srcOffset = (o * indices.Length + idx) * innerSize + inner;
                            int dstOffset = (o * axisSize + targetIdx) * innerSize + inner;
                            // Bounds check: ensure offsets are valid
                            if (srcOffset < srcData.Length && dstOffset < result.Length)
                            {
                                result[dstOffset] = srcData[srcOffset];
                            }
                        }
                    }
                }
            });

            return new Tensor<float>(destination.Shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorScatter(destination, indices, source, axis);
        }
    }

    private Tensor<double> TensorScatterGpuDouble(Tensor<double> destination, Tensor<int> indices, Tensor<double> source, int axis)
    {
        try
        {
            var shape = destination.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var destData = destination.AsSpan().ToArray();
            var srcData = source.AsSpan().ToArray();
            var idxData = indices.AsSpan().ToArray();
            var result = destData.ToArray(); // Copy destination

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            System.Threading.Tasks.Parallel.For(0, outerSize, o =>
            {
                for (int idx = 0; idx < indices.Length; idx++)
                {
                    int targetIdx = idxData[idx];
                    if (targetIdx < 0) targetIdx += axisSize;
                    // Bounds check: ensure targetIdx is valid
                    if (targetIdx >= 0 && targetIdx < axisSize)
                    {
                        for (int inner = 0; inner < innerSize; inner++)
                        {
                            int srcOffset = (o * indices.Length + idx) * innerSize + inner;
                            int dstOffset = (o * axisSize + targetIdx) * innerSize + inner;
                            // Bounds check: ensure offsets are valid
                            if (srcOffset < srcData.Length && dstOffset < result.Length)
                            {
                                result[dstOffset] = srcData[srcOffset];
                            }
                        }
                    }
                }
            });

            return new Tensor<double>(destination.Shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorScatter(destination, indices, source, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorIndexSelect<T>(Tensor<T> tensor, Tensor<int> indices, int axis)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorIndexSelectGpu((Tensor<float>)(object)tensor, indices, axis);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorIndexSelectGpuDouble((Tensor<double>)(object)tensor, indices, axis);
        }
        return _cpuFallback.TensorIndexSelect(tensor, indices, axis);
    }

    private Tensor<float> TensorIndexSelectGpu(Tensor<float> tensor, Tensor<int> indices, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();
            var idxData = indices.AsSpan().ToArray();

            var newShape = shape.ToArray();
            newShape[axis] = indices.Length;

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            int resultLen = 1; foreach (var d in newShape) resultLen *= d;
            var result = new float[resultLen];

            System.Threading.Tasks.Parallel.For(0, outerSize, o =>
            {
                for (int idx = 0; idx < indices.Length; idx++)
                {
                    int srcIdx = idxData[idx];
                    if (srcIdx < 0) srcIdx += axisSize;
                    // Bounds check: ensure srcIdx is valid
                    if (srcIdx >= 0 && srcIdx < axisSize)
                    {
                        for (int inner = 0; inner < innerSize; inner++)
                        {
                            int srcOffset = (o * axisSize + srcIdx) * innerSize + inner;
                            int dstOffset = (o * indices.Length + idx) * innerSize + inner;
                            // Bounds check: ensure offsets are valid
                            if (srcOffset < data.Length && dstOffset < result.Length)
                            {
                                result[dstOffset] = data[srcOffset];
                            }
                        }
                    }
                }
            });

            return new Tensor<float>(newShape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorIndexSelect(tensor, indices, axis);
        }
    }

    private Tensor<double> TensorIndexSelectGpuDouble(Tensor<double> tensor, Tensor<int> indices, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();
            var idxData = indices.AsSpan().ToArray();

            var newShape = shape.ToArray();
            newShape[axis] = indices.Length;

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            int resultLen = 1; foreach (var d in newShape) resultLen *= d;
            var result = new double[resultLen];

            System.Threading.Tasks.Parallel.For(0, outerSize, o =>
            {
                for (int idx = 0; idx < indices.Length; idx++)
                {
                    int srcIdx = idxData[idx];
                    if (srcIdx < 0) srcIdx += axisSize;
                    // Bounds check: ensure srcIdx is valid
                    if (srcIdx >= 0 && srcIdx < axisSize)
                    {
                        for (int inner = 0; inner < innerSize; inner++)
                        {
                            int srcOffset = (o * axisSize + srcIdx) * innerSize + inner;
                            int dstOffset = (o * indices.Length + idx) * innerSize + inner;
                            // Bounds check: ensure offsets are valid
                            if (srcOffset < data.Length && dstOffset < result.Length)
                            {
                                result[dstOffset] = data[srcOffset];
                            }
                        }
                    }
                }
            });

            return new Tensor<double>(newShape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorIndexSelect(tensor, indices, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorStack<T>(Tensor<T>[] tensors, int axis)
    {
        if (tensors is null || tensors.Length == 0)
            throw new ArgumentException("Tensors array cannot be null or empty", nameof(tensors));

        int totalSize = tensors.Length * tensors[0].Length;
        if (totalSize >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var floatTensors = tensors.Select(t => (Tensor<float>)(object)t).ToArray();
                return (Tensor<T>)(object)TensorStackGpu(floatTensors, axis);
            }
            if (typeof(T) == typeof(double))
            {
                var doubleTensors = tensors.Select(t => (Tensor<double>)(object)t).ToArray();
                return (Tensor<T>)(object)TensorStackGpuDouble(doubleTensors, axis);
            }
        }
        return _cpuFallback.TensorStack(tensors, axis);
    }

    private Tensor<float> TensorStackGpu(Tensor<float>[] tensors, int axis)
    {
        try
        {
            if (tensors.Length == 0) throw new ArgumentException("Cannot stack empty array");

            var firstShape = tensors[0].Shape;
            axis = axis < 0 ? firstShape.Length + 1 + axis : axis;

            var newShape = new List<int>(firstShape);
            newShape.Insert(axis, tensors.Length);

            var resultShape = newShape.ToArray();
            int resultLength = 1;
            foreach (var d in resultShape) resultLength *= d;
            var resultArray = new float[resultLength];

            // Calculate strides
            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= firstShape[i];
            int innerSize = 1;
            for (int i = axis; i < firstShape.Length; i++) innerSize *= firstShape[i];

            System.Threading.Tasks.Parallel.For(0, tensors.Length, t =>
            {
                var srcData = tensors[t].AsSpan().ToArray();
                for (int o = 0; o < outerSize; o++)
                {
                    int dstBase = o * tensors.Length * innerSize + t * innerSize;
                    int srcBase = o * innerSize;
                    for (int i = 0; i < innerSize; i++)
                    {
                        resultArray[dstBase + i] = srcData[srcBase + i];
                    }
                }
            });

            return new Tensor<float>(resultShape, new Vector<float>(resultArray));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorStack(tensors, axis);
        }
    }

    private Tensor<double> TensorStackGpuDouble(Tensor<double>[] tensors, int axis)
    {
        try
        {
            if (tensors.Length == 0) throw new ArgumentException("Cannot stack empty array");

            var firstShape = tensors[0].Shape;
            axis = axis < 0 ? firstShape.Length + 1 + axis : axis;

            var newShape = new List<int>(firstShape);
            newShape.Insert(axis, tensors.Length);

            var resultShape = newShape.ToArray();
            int resultLength = 1;
            foreach (var d in resultShape) resultLength *= d;
            var resultArray = new double[resultLength];

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= firstShape[i];
            int innerSize = 1;
            for (int i = axis; i < firstShape.Length; i++) innerSize *= firstShape[i];

            System.Threading.Tasks.Parallel.For(0, tensors.Length, t =>
            {
                var srcData = tensors[t].AsSpan().ToArray();
                for (int o = 0; o < outerSize; o++)
                {
                    int dstBase = o * tensors.Length * innerSize + t * innerSize;
                    int srcBase = o * innerSize;
                    for (int i = 0; i < innerSize; i++)
                    {
                        resultArray[dstBase + i] = srcData[srcBase + i];
                    }
                }
            });

            return new Tensor<double>(resultShape, new Vector<double>(resultArray));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorStack(tensors, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T>[] TensorUnstack<T>(Tensor<T> tensor, int axis)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var result = TensorUnstackGpu((Tensor<float>)(object)tensor, axis);
                return result.Select(t => (Tensor<T>)(object)t).ToArray();
            }
            if (typeof(T) == typeof(double))
            {
                var result = TensorUnstackGpuDouble((Tensor<double>)(object)tensor, axis);
                return result.Select(t => (Tensor<T>)(object)t).ToArray();
            }
        }
        return _cpuFallback.TensorUnstack(tensor, axis);
    }

    private Tensor<float>[] TensorUnstackGpu(Tensor<float> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();
            int numSlices = shape[axis];
            var results = new Tensor<float>[numSlices];

            var newShape = shape.Where((_, i) => i != axis).ToArray();
            if (newShape.Length == 0) newShape = new[] { 1 };

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            for (int s = 0; s < numSlices; s++)
            {
                var result = new float[outerSize * innerSize];

                System.Threading.Tasks.Parallel.For(0, outerSize, o =>
                {
                    for (int inner = 0; inner < innerSize; inner++)
                    {
                        int srcIdx = (o * axisSize + s) * innerSize + inner;
                        int dstIdx = o * innerSize + inner;
                        result[dstIdx] = data[srcIdx];
                    }
                });

                results[s] = new Tensor<float>(newShape, new Vector<float>(result));
            }
            return results;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorUnstack(tensor, axis);
        }
    }

    private Tensor<double>[] TensorUnstackGpuDouble(Tensor<double> tensor, int axis)
    {
        try
        {
            var shape = tensor.Shape;
            axis = axis < 0 ? shape.Length + axis : axis;
            var data = tensor.AsSpan().ToArray();
            int numSlices = shape[axis];
            var results = new Tensor<double>[numSlices];

            var newShape = shape.Where((_, i) => i != axis).ToArray();
            if (newShape.Length == 0) newShape = new[] { 1 };

            int outerSize = 1;
            for (int i = 0; i < axis; i++) outerSize *= shape[i];
            int axisSize = shape[axis];
            int innerSize = 1;
            for (int i = axis + 1; i < shape.Length; i++) innerSize *= shape[i];

            for (int s = 0; s < numSlices; s++)
            {
                var result = new double[outerSize * innerSize];

                System.Threading.Tasks.Parallel.For(0, outerSize, o =>
                {
                    for (int inner = 0; inner < innerSize; inner++)
                    {
                        int srcIdx = (o * axisSize + s) * innerSize + inner;
                        int dstIdx = o * innerSize + inner;
                        result[dstIdx] = data[srcIdx];
                    }
                });

                results[s] = new Tensor<double>(newShape, new Vector<double>(result));
            }
            return results;
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorUnstack(tensor, axis);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorMap<T>(Tensor<T> tensor, Func<T, T> func)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var typedFunc = (Func<float, float>)(object)func;
                return (Tensor<T>)(object)TensorMapGpu((Tensor<float>)(object)tensor, typedFunc);
            }
            if (typeof(T) == typeof(double))
            {
                var typedFunc = (Func<double, double>)(object)func;
                return (Tensor<T>)(object)TensorMapGpuDouble((Tensor<double>)(object)tensor, typedFunc);
            }
        }
        return _cpuFallback.TensorMap(tensor, func);
    }

    private Tensor<float> TensorMapGpu(Tensor<float> tensor, Func<float, float> func)
    {
        try
        {
            var data = tensor.AsSpan().ToArray();
            var result = new float[tensor.Length];

            // Parallel execution - func is assumed to be thread-safe (pure function)
            System.Threading.Tasks.Parallel.For(0, tensor.Length, i =>
            {
                result[i] = func(data[i]);
            });

            return new Tensor<float>(tensor.Shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorMap(tensor, func);
        }
    }

    private Tensor<double> TensorMapGpuDouble(Tensor<double> tensor, Func<double, double> func)
    {
        try
        {
            var data = tensor.AsSpan().ToArray();
            var result = new double[tensor.Length];

            System.Threading.Tasks.Parallel.For(0, tensor.Length, i =>
            {
                result[i] = func(data[i]);
            });

            return new Tensor<double>(tensor.Shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorMap(tensor, func);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorMaskedFill<T>(Tensor<T> tensor, Tensor<bool> mask, T value)
    {
        if (tensor.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                var valObj = (object?)value; float v = valObj is float fv ? fv : Convert.ToSingle(value);
                return (Tensor<T>)(object)TensorMaskedFillGpu((Tensor<float>)(object)tensor, mask, v);
            }
            if (typeof(T) == typeof(double))
            {
                var valObj = (object?)value; double v = valObj is double dv ? dv : Convert.ToDouble(value);
                return (Tensor<T>)(object)TensorMaskedFillGpuDouble((Tensor<double>)(object)tensor, mask, v);
            }
        }
        return _cpuFallback.TensorMaskedFill(tensor, mask, value);
    }

    private Tensor<float> TensorMaskedFillGpu(Tensor<float> tensor, Tensor<bool> mask, float value)
    {
        try
        {
            var data = tensor.AsSpan().ToArray();
            var maskData = mask.AsSpan().ToArray();
            var result = new float[tensor.Length];

            System.Threading.Tasks.Parallel.For(0, tensor.Length, i =>
            {
                result[i] = maskData[i] ? value : data[i];
            });

            return new Tensor<float>(tensor.Shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorMaskedFill(tensor, mask, value);
        }
    }

    private Tensor<double> TensorMaskedFillGpuDouble(Tensor<double> tensor, Tensor<bool> mask, double value)
    {
        try
        {
            var data = tensor.AsSpan().ToArray();
            var maskData = mask.AsSpan().ToArray();
            var result = new double[tensor.Length];

            System.Threading.Tasks.Parallel.For(0, tensor.Length, i =>
            {
                result[i] = maskData[i] ? value : data[i];
            });

            return new Tensor<double>(tensor.Shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorMaskedFill(tensor, mask, value);
        }
    }

    /// <inheritdoc/>
    public Tensor<T> TensorWhere<T>(Tensor<bool> condition, Tensor<T> x, Tensor<T> y)
    {
        if (x.Length >= _thresholds.VectorAdd && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
                return (Tensor<T>)(object)TensorWhereGpu(condition, (Tensor<float>)(object)x, (Tensor<float>)(object)y);
            if (typeof(T) == typeof(double))
                return (Tensor<T>)(object)TensorWhereGpuDouble(condition, (Tensor<double>)(object)x, (Tensor<double>)(object)y);
        }
        return _cpuFallback.TensorWhere(condition, x, y);
    }

    private Tensor<float> TensorWhereGpu(Tensor<bool> condition, Tensor<float> x, Tensor<float> y)
    {
        try
        {
            var condData = condition.AsSpan().ToArray();
            var xData = x.AsSpan().ToArray();
            var yData = y.AsSpan().ToArray();
            var result = new float[x.Length];

            System.Threading.Tasks.Parallel.For(0, x.Length, i =>
            {
                result[i] = condData[i] ? xData[i] : yData[i];
            });

            return new Tensor<float>(x.Shape, new Vector<float>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorWhere(condition, x, y);
        }
    }

    private Tensor<double> TensorWhereGpuDouble(Tensor<bool> condition, Tensor<double> x, Tensor<double> y)
    {
        try
        {
            var condData = condition.AsSpan().ToArray();
            var xData = x.AsSpan().ToArray();
            var yData = y.AsSpan().ToArray();
            var result = new double[x.Length];

            System.Threading.Tasks.Parallel.For(0, x.Length, i =>
            {
                result[i] = condData[i] ? xData[i] : yData[i];
            });

            return new Tensor<double>(x.Shape, new Vector<double>(result));
        }
        catch (Exception ex) when (ex is InvalidOperationException or ArgumentException or OutOfMemoryException)
        {
            return _cpuFallback.TensorWhere(condition, x, y);
        }
    }

    #endregion

    #region Neural Radiance Fields Operations

    /// <inheritdoc/>
    public Tensor<T> PositionalEncoding<T>(Tensor<T> positions, int numFrequencies)
    {
        if (!SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.PositionalEncoding(positions, numFrequencies);
        }

        // positions shape: [numPoints, inputDim] (typically inputDim=3 for xyz)
        int numPoints = positions.Shape[0];
        int inputDim = positions.Shape.Length > 1 ? positions.Shape[1] : 1;
        int outputDim = inputDim * (1 + 2 * numFrequencies);

        // For small tensors, use CPU (use VectorAdd threshold as baseline)
        if (numPoints * outputDim < _thresholds.VectorAdd)
        {
            return _cpuFallback.PositionalEncoding(positions, numFrequencies);
        }

        try
        {
            if (typeof(T) == typeof(float) && _positionalEncodingForwardKernelFloat != null)
            {
                return (Tensor<T>)(object)PositionalEncodingGpuFloat(
                    (Tensor<float>)(object)positions, numFrequencies, numPoints, inputDim, outputDim);
            }
            else if (typeof(T) == typeof(double) && _positionalEncodingForwardKernelDouble != null)
            {
                return (Tensor<T>)(object)PositionalEncodingGpuDouble(
                    (Tensor<double>)(object)positions, numFrequencies, numPoints, inputDim, outputDim);
            }
        }
        catch (Exception ex)
        {
            Console.WriteLine($"[GpuEngine] GPU PositionalEncoding failed: {ex.Message}. Falling back to CPU.");
        }

        return _cpuFallback.PositionalEncoding(positions, numFrequencies);
    }

    private Tensor<float> PositionalEncodingGpuFloat(Tensor<float> positions, int numFrequencies, int numPoints, int inputDim, int outputDim)
    {
        var outputShape = new int[] { numPoints, outputDim };
        int outputSize = numPoints * outputDim;

        lock (_gpuLock)
        {
            using var inputBuffer = _accelerator!.Allocate1D<float>(positions.Length);
            using var outputBuffer = _accelerator.Allocate1D<float>(outputSize);

            // Copy input data
            var inputData = new float[positions.Length];
            for (int i = 0; i < positions.Length; i++)
            {
                inputData[i] = positions[i];
            }
            inputBuffer.CopyFromCPU(inputData);

            var parameters = new PositionalEncodingParams(numPoints, inputDim, numFrequencies);

            _positionalEncodingForwardKernelFloat!(
                _accelerator.DefaultStream,
                outputSize,
                inputBuffer.View,
                outputBuffer.View,
                parameters);

            _accelerator.Synchronize();

            var outputData = outputBuffer.GetAsArray1D();
            return new Tensor<float>(outputShape, new Vector<float>(outputData));
        }
    }

    private Tensor<double> PositionalEncodingGpuDouble(Tensor<double> positions, int numFrequencies, int numPoints, int inputDim, int outputDim)
    {
        var outputShape = new int[] { numPoints, outputDim };
        int outputSize = numPoints * outputDim;

        lock (_gpuLock)
        {
            using var inputBuffer = _accelerator!.Allocate1D<double>(positions.Length);
            using var outputBuffer = _accelerator.Allocate1D<double>(outputSize);

            var inputData = new double[positions.Length];
            for (int i = 0; i < positions.Length; i++)
            {
                inputData[i] = positions[i];
            }
            inputBuffer.CopyFromCPU(inputData);

            var parameters = new PositionalEncodingParams(numPoints, inputDim, numFrequencies);

            _positionalEncodingForwardKernelDouble!(
                _accelerator.DefaultStream,
                outputSize,
                inputBuffer.View,
                outputBuffer.View,
                parameters);

            _accelerator.Synchronize();

            var outputData = outputBuffer.GetAsArray1D();
            return new Tensor<double>(outputShape, new Vector<double>(outputData));
        }
    }

    /// <inheritdoc/>
    public Tensor<T> PositionalEncodingBackward<T>(Tensor<T> positions, Tensor<T> encodedGradient, int numFrequencies)
    {
        if (!SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.PositionalEncodingBackward(positions, encodedGradient, numFrequencies);
        }

        int numPoints = positions.Shape[0];
        int inputDim = positions.Shape.Length > 1 ? positions.Shape[1] : 1;

        if (numPoints * inputDim < _thresholds.VectorAdd)
        {
            return _cpuFallback.PositionalEncodingBackward(positions, encodedGradient, numFrequencies);
        }

        try
        {
            if (typeof(T) == typeof(float) && _positionalEncodingBackwardKernelFloat != null)
            {
                return (Tensor<T>)(object)PositionalEncodingBackwardGpuFloat(
                    (Tensor<float>)(object)positions, (Tensor<float>)(object)encodedGradient, numFrequencies, numPoints, inputDim);
            }
            else if (typeof(T) == typeof(double) && _positionalEncodingBackwardKernelDouble != null)
            {
                return (Tensor<T>)(object)PositionalEncodingBackwardGpuDouble(
                    (Tensor<double>)(object)positions, (Tensor<double>)(object)encodedGradient, numFrequencies, numPoints, inputDim);
            }
        }
        catch (Exception ex)
        {
            Console.WriteLine($"[GpuEngine] GPU PositionalEncodingBackward failed: {ex.Message}. Falling back to CPU.");
        }

        return _cpuFallback.PositionalEncodingBackward(positions, encodedGradient, numFrequencies);
    }

    private Tensor<float> PositionalEncodingBackwardGpuFloat(Tensor<float> positions, Tensor<float> encodedGrad, int numFrequencies, int numPoints, int inputDim)
    {
        var outputShape = positions.Shape;
        int outputSize = numPoints * inputDim;

        lock (_gpuLock)
        {
            using var positionsBuffer = _accelerator!.Allocate1D<float>(positions.Length);
            using var gradBuffer = _accelerator.Allocate1D<float>(encodedGrad.Length);
            using var outputBuffer = _accelerator.Allocate1D<float>(outputSize);

            var posData = new float[positions.Length];
            for (int i = 0; i < positions.Length; i++) posData[i] = positions[i];
            positionsBuffer.CopyFromCPU(posData);

            var gradData = new float[encodedGrad.Length];
            for (int i = 0; i < encodedGrad.Length; i++) gradData[i] = encodedGrad[i];
            gradBuffer.CopyFromCPU(gradData);

            var parameters = new PositionalEncodingParams(numPoints, inputDim, numFrequencies);

            _positionalEncodingBackwardKernelFloat!(
                _accelerator.DefaultStream,
                outputSize,
                positionsBuffer.View,
                gradBuffer.View,
                outputBuffer.View,
                parameters);

            _accelerator.Synchronize();

            var outputData = outputBuffer.GetAsArray1D();
            return new Tensor<float>(outputShape, new Vector<float>(outputData));
        }
    }

    private Tensor<double> PositionalEncodingBackwardGpuDouble(Tensor<double> positions, Tensor<double> encodedGrad, int numFrequencies, int numPoints, int inputDim)
    {
        var outputShape = positions.Shape;
        int outputSize = numPoints * inputDim;

        lock (_gpuLock)
        {
            using var positionsBuffer = _accelerator!.Allocate1D<double>(positions.Length);
            using var gradBuffer = _accelerator.Allocate1D<double>(encodedGrad.Length);
            using var outputBuffer = _accelerator.Allocate1D<double>(outputSize);

            var posData = new double[positions.Length];
            for (int i = 0; i < positions.Length; i++) posData[i] = positions[i];
            positionsBuffer.CopyFromCPU(posData);

            var gradData = new double[encodedGrad.Length];
            for (int i = 0; i < encodedGrad.Length; i++) gradData[i] = encodedGrad[i];
            gradBuffer.CopyFromCPU(gradData);

            var parameters = new PositionalEncodingParams(numPoints, inputDim, numFrequencies);

            _positionalEncodingBackwardKernelDouble!(
                _accelerator.DefaultStream,
                outputSize,
                positionsBuffer.View,
                gradBuffer.View,
                outputBuffer.View,
                parameters);

            _accelerator.Synchronize();

            var outputData = outputBuffer.GetAsArray1D();
            return new Tensor<double>(outputShape, new Vector<double>(outputData));
        }
    }

    /// <inheritdoc/>
    public Tensor<T> VolumeRendering<T>(Tensor<T> rgbSamples, Tensor<T> densitySamples, Tensor<T> tValues)
    {
        if (!SupportsGpu || !_gpuHealthy)
        {
            return _cpuFallback.VolumeRendering(rgbSamples, densitySamples, tValues);
        }

        // rgbSamples: [numRays, numSamples, numChannels]
        // densitySamples: [numRays, numSamples]
        // tValues: [numRays, numSamples]
        int numRays = rgbSamples.Shape[0];
        int numSamples = rgbSamples.Shape[1];
        int numChannels = rgbSamples.Shape.Length > 2 ? rgbSamples.Shape[2] : 1;

        if (numRays * numChannels < _thresholds.VectorAdd)
        {
            return _cpuFallback.VolumeRendering(rgbSamples, densitySamples, tValues);
        }

        try
        {
            if (typeof(T) == typeof(float) && _volumeRenderingForwardKernelFloat != null)
            {
                return (Tensor<T>)(object)VolumeRenderingGpuFloat(
                    (Tensor<float>)(object)rgbSamples,
                    (Tensor<float>)(object)densitySamples,
                    (Tensor<float>)(object)tValues,
                    numRays, numSamples, numChannels);
            }
            else if (typeof(T) == typeof(double) && _volumeRenderingForwardKernelDouble != null)
            {
                return (Tensor<T>)(object)VolumeRenderingGpuDouble(
                    (Tensor<double>)(object)rgbSamples,
                    (Tensor<double>)(object)densitySamples,
                    (Tensor<double>)(object)tValues,
                    numRays, numSamples, numChannels);
            }
        }
        catch (Exception ex)
        {
            Console.WriteLine($"[GpuEngine] GPU VolumeRendering failed: {ex.Message}. Falling back to CPU.");
        }

        return _cpuFallback.VolumeRendering(rgbSamples, densitySamples, tValues);
    }

    private Tensor<float> VolumeRenderingGpuFloat(Tensor<float> rgb, Tensor<float> density, Tensor<float> tValues, int numRays, int numSamples, int numChannels)
    {
        var outputShape = new int[] { numRays, numChannels };
        int outputSize = numRays * numChannels;

        lock (_gpuLock)
        {
            using var rgbBuffer = _accelerator!.Allocate1D<float>(rgb.Length);
            using var densityBuffer = _accelerator.Allocate1D<float>(density.Length);
            using var tBuffer = _accelerator.Allocate1D<float>(tValues.Length);
            using var outputBuffer = _accelerator.Allocate1D<float>(outputSize);

            var rgbData = new float[rgb.Length];
            for (int i = 0; i < rgb.Length; i++) rgbData[i] = rgb[i];
            rgbBuffer.CopyFromCPU(rgbData);

            var densityData = new float[density.Length];
            for (int i = 0; i < density.Length; i++) densityData[i] = density[i];
            densityBuffer.CopyFromCPU(densityData);

            var tData = new float[tValues.Length];
            for (int i = 0; i < tValues.Length; i++) tData[i] = tValues[i];
            tBuffer.CopyFromCPU(tData);

            var parameters = new VolumeRenderingParams(numRays, numSamples, numChannels);

            _volumeRenderingForwardKernelFloat!(
                _accelerator.DefaultStream,
                outputSize,
                rgbBuffer.View,
                densityBuffer.View,
                tBuffer.View,
                outputBuffer.View,
                parameters);

            _accelerator.Synchronize();

            var outputData = outputBuffer.GetAsArray1D();
            return new Tensor<float>(outputShape, new Vector<float>(outputData));
        }
    }

    private Tensor<double> VolumeRenderingGpuDouble(Tensor<double> rgb, Tensor<double> density, Tensor<double> tValues, int numRays, int numSamples, int numChannels)
    {
        var outputShape = new int[] { numRays, numChannels };
        int outputSize = numRays * numChannels;

        lock (_gpuLock)
        {
            using var rgbBuffer = _accelerator!.Allocate1D<double>(rgb.Length);
            using var densityBuffer = _accelerator.Allocate1D<double>(density.Length);
            using var tBuffer = _accelerator.Allocate1D<double>(tValues.Length);
            using var outputBuffer = _accelerator.Allocate1D<double>(outputSize);

            var rgbData = new double[rgb.Length];
            for (int i = 0; i < rgb.Length; i++) rgbData[i] = rgb[i];
            rgbBuffer.CopyFromCPU(rgbData);

            var densityData = new double[density.Length];
            for (int i = 0; i < density.Length; i++) densityData[i] = density[i];
            densityBuffer.CopyFromCPU(densityData);

            var tData = new double[tValues.Length];
            for (int i = 0; i < tValues.Length; i++) tData[i] = tValues[i];
            tBuffer.CopyFromCPU(tData);

            var parameters = new VolumeRenderingParams(numRays, numSamples, numChannels);

            _volumeRenderingForwardKernelDouble!(
                _accelerator.DefaultStream,
                outputSize,
                rgbBuffer.View,
                densityBuffer.View,
                tBuffer.View,
                outputBuffer.View,
                parameters);

            _accelerator.Synchronize();

            var outputData = outputBuffer.GetAsArray1D();
            return new Tensor<double>(outputShape, new Vector<double>(outputData));
        }
    }

    /// <inheritdoc/>
    public void VolumeRenderingBackward<T>(
        Tensor<T> rgbSamples,
        Tensor<T> densitySamples,
        Tensor<T> tValues,
        Tensor<T> outputGradient,
        out Tensor<T> rgbGradient,
        out Tensor<T> densityGradient)
    {
        // VolumeRendering backward is complex with multiple outputs
        // CPU fallback is acceptable for now as backward pass is less frequent
        _cpuFallback.VolumeRenderingBackward(
            rgbSamples, densitySamples, tValues, outputGradient,
            out rgbGradient, out densityGradient);
    }

    /// <inheritdoc/>
    public (Tensor<T> positions, Tensor<T> directions, Tensor<T> tValues) SampleRayPoints<T>(
        Tensor<T> rayOrigins,
        Tensor<T> rayDirections,
        T nearBound,
        T farBound,
        int numSamples,
        bool stratified = true)
    {
        return _cpuFallback.SampleRayPoints(
            rayOrigins, rayDirections, nearBound, farBound, numSamples, stratified);
    }

    /// <inheritdoc/>
    public Tensor<T> ImportanceSampling<T>(Tensor<T> tValuesCoarse, Tensor<T> weightsCoarse, int numFineSamples)
    {
        return _cpuFallback.ImportanceSampling(tValuesCoarse, weightsCoarse, numFineSamples);
    }

    /// <inheritdoc/>
    public (Tensor<T> origins, Tensor<T> directions) GenerateCameraRays<T>(
        Vector<T> cameraPosition,
        Matrix<T> cameraRotation,
        int imageWidth,
        int imageHeight,
        T focalLength)
    {
        return _cpuFallback.GenerateCameraRays(
            cameraPosition, cameraRotation, imageWidth, imageHeight, focalLength);
    }

    #endregion

    #region Gaussian Splatting Operations

    /// <inheritdoc/>
    public void ProjectGaussians3DTo2D<T>(
        Tensor<T> means3D,
        Tensor<T> covariances3D,
        Matrix<T> viewMatrix,
        Matrix<T> projMatrix,
        int imageWidth,
        int imageHeight,
        out Tensor<T> means2D,
        out Tensor<T> covariances2D,
        out Tensor<T> depths,
        out Tensor<bool> visible)
    {
        _cpuFallback.ProjectGaussians3DTo2D(
            means3D, covariances3D, viewMatrix, projMatrix,
            imageWidth, imageHeight,
            out means2D, out covariances2D, out depths, out visible);
    }

    /// <inheritdoc/>
    public Tensor<T> RasterizeGaussians<T>(
        Tensor<T> means2D,
        Tensor<T> covariances2D,
        Tensor<T> colors,
        Tensor<T> opacities,
        Tensor<T> depths,
        int imageWidth,
        int imageHeight,
        int tileSize = 16)
    {
        return _cpuFallback.RasterizeGaussians(
            means2D, covariances2D, colors, opacities, depths,
            imageWidth, imageHeight, tileSize);
    }

    /// <inheritdoc/>
    public void RasterizeGaussiansBackward<T>(
        Tensor<T> means2D,
        Tensor<T> covariances2D,
        Tensor<T> colors,
        Tensor<T> opacities,
        Tensor<T> depths,
        int imageWidth,
        int imageHeight,
        Tensor<T> outputGradient,
        int tileSize,
        out Tensor<T> means2DGrad,
        out Tensor<T> covariances2DGrad,
        out Tensor<T> colorsGrad,
        out Tensor<T> opacitiesGrad)
    {
        _cpuFallback.RasterizeGaussiansBackward(
            means2D, covariances2D, colors, opacities, depths,
            imageWidth, imageHeight, outputGradient, tileSize,
            out means2DGrad, out covariances2DGrad, out colorsGrad, out opacitiesGrad);
    }

    /// <inheritdoc/>
    public Tensor<T> EvaluateSphericalHarmonics<T>(Tensor<T> shCoefficients, Tensor<T> viewDirections, int degree)
    {
        return _cpuFallback.EvaluateSphericalHarmonics(shCoefficients, viewDirections, degree);
    }

    /// <inheritdoc/>
    public Tensor<T> EvaluateSphericalHarmonicsBackward<T>(
        Tensor<T> shCoefficients,
        Tensor<T> viewDirections,
        int degree,
        Tensor<T> outputGradient)
    {
        return _cpuFallback.EvaluateSphericalHarmonicsBackward(
            shCoefficients, viewDirections, degree, outputGradient);
    }

    /// <inheritdoc/>
    public Tensor<T> ComputeGaussianCovariance<T>(Tensor<T> rotations, Tensor<T> scales)
    {
        return _cpuFallback.ComputeGaussianCovariance(rotations, scales);
    }

    /// <inheritdoc/>
    public void ComputeGaussianCovarianceBackward<T>(
        Tensor<T> rotations,
        Tensor<T> scales,
        Tensor<T> covarianceGradient,
        out Tensor<T> rotationsGrad,
        out Tensor<T> scalesGrad)
    {
        _cpuFallback.ComputeGaussianCovarianceBackward(
            rotations, scales, covarianceGradient,
            out rotationsGrad, out scalesGrad);
    }

    #endregion

    #region Instant-NGP Operations

    /// <inheritdoc/>
    public Tensor<T> MultiresolutionHashEncoding<T>(
        Tensor<T> positions,
        Tensor<T>[] hashTables,
        int[] resolutions,
        int featuresPerLevel)
    {
        return _cpuFallback.MultiresolutionHashEncoding(
            positions, hashTables, resolutions, featuresPerLevel);
    }

    /// <inheritdoc/>
    public Tensor<T>[] MultiresolutionHashEncodingBackward<T>(
        Tensor<T> positions,
        Tensor<T>[] hashTables,
        int[] resolutions,
        int featuresPerLevel,
        Tensor<T> outputGradient)
    {
        return _cpuFallback.MultiresolutionHashEncodingBackward(
            positions, hashTables, resolutions, featuresPerLevel, outputGradient);
    }

    /// <inheritdoc/>
    public Tensor<T> UpdateOccupancyGrid<T>(
        Tensor<T> occupancyGrid,
        Tensor<T> densities,
        Tensor<T> positions,
        int gridSize,
        T threshold,
        T decayFactor)
    {
        return _cpuFallback.UpdateOccupancyGrid(
            occupancyGrid, densities, positions, gridSize, threshold, decayFactor);
    }

    /// <inheritdoc/>
    public (Tensor<T> positions, Tensor<T> directions, Tensor<bool> validMask, Tensor<T> tValues) SampleRaysWithOccupancy<T>(
        Tensor<T> rayOrigins,
        Tensor<T> rayDirections,
        Tensor<uint> occupancyBitfield,
        int gridSize,
        Vector<T> sceneBoundsMin,
        Vector<T> sceneBoundsMax,
        T nearBound,
        T farBound,
        int maxSamples)
    {
        return _cpuFallback.SampleRaysWithOccupancy(
            rayOrigins, rayDirections, occupancyBitfield, gridSize,
            sceneBoundsMin, sceneBoundsMax, nearBound, farBound, maxSamples);
    }

    #endregion

    #region Mesh Convolution Operations

    /// <inheritdoc/>
    public Tensor<T> SpiralConv<T>(
        Tensor<T> vertexFeatures,
        Tensor<int> spiralIndices,
        Tensor<T> weights,
        Tensor<T> biases)
    {
        // GPU kernel implementation for spiral convolution is complex due to
        // the irregular access patterns of mesh topology. For initial implementation,
        // use CPU fallback which is already highly optimized with SIMD.
        // TODO: Implement optimized GPU kernel with shared memory for coalesced access.
        return _cpuFallback.SpiralConv(vertexFeatures, spiralIndices, weights, biases);
    }

    /// <inheritdoc/>
    public Tensor<T> SpiralConvBackwardInput<T>(
        Tensor<T> outputGradient,
        Tensor<int> spiralIndices,
        Tensor<T> weights,
        int inputChannels)
    {
        // Backward pass requires scatter-add operations which have complex
        // synchronization requirements on GPU. Use CPU fallback.
        return _cpuFallback.SpiralConvBackwardInput(outputGradient, spiralIndices, weights, inputChannels);
    }

    /// <inheritdoc/>
    public Tensor<T> SpiralConvBackwardWeights<T>(
        Tensor<T> outputGradient,
        Tensor<T> vertexFeatures,
        Tensor<int> spiralIndices)
    {
        return _cpuFallback.SpiralConvBackwardWeights(outputGradient, vertexFeatures, spiralIndices);
    }

    /// <inheritdoc/>
    public Tensor<T> SpiralConvBackwardBias<T>(Tensor<T> outputGradient)
    {
        return _cpuFallback.SpiralConvBackwardBias(outputGradient);
    }

    /// <inheritdoc/>
    public Tensor<T> DiffusionConv<T>(
        Tensor<T> vertexFeatures,
        Tensor<T> laplacian,
        Tensor<T> weights,
        Tensor<T> biases,
        T diffusionTime)
    {
        // Diffusion convolution requires matrix exponential computation
        // which is efficiently handled by CPU with Taylor series.
        return _cpuFallback.DiffusionConv(vertexFeatures, laplacian, weights, biases, diffusionTime);
    }

    /// <inheritdoc/>
    public (Tensor<T> inputGrad, Tensor<T> weightGrad, Tensor<T> biasGrad) DiffusionConvBackward<T>(
        Tensor<T> outputGradient,
        Tensor<T> vertexFeatures,
        Tensor<T> laplacian,
        Tensor<T> weights,
        T diffusionTime)
    {
        return _cpuFallback.DiffusionConvBackward(outputGradient, vertexFeatures, laplacian, weights, diffusionTime);
    }

    /// <inheritdoc/>
    public Tensor<T> ComputeMeshLaplacian<T>(
        Tensor<T> vertices,
        Tensor<int> faces,
        LaplacianType laplacianType = LaplacianType.Cotangent)
    {
        // Laplacian computation is a one-time preprocessing step per mesh.
        // CPU implementation is sufficient and avoids GPU memory transfer overhead.
        return _cpuFallback.ComputeMeshLaplacian(vertices, faces, laplacianType);
    }

    /// <inheritdoc/>
    public Tensor<int> GenerateSpiralIndices<T>(
        Tensor<T> vertices,
        Tensor<int> faces,
        int spiralLength)
    {
        // Spiral index generation is complex and depends on mesh topology.
        // This is a one-time preprocessing step, CPU implementation is sufficient.
        return _cpuFallback.GenerateSpiralIndices(vertices, faces, spiralLength);
    }


    #region Advanced Vectorization Operations

    /// <inheritdoc/>
    public Tensor<T> PairwiseDistanceSquared<T>(Tensor<T> x, Tensor<T> y)
    {
        if (x.Shape.Length != 2 || y.Shape.Length != 2)
            throw new ArgumentException("Input tensors must be 2D [N, D]");
        if (x.Shape[1] != y.Shape[1])
            throw new ArgumentException("Input tensors must have the same dimensionality");

        int n = x.Shape[0];
        int m = y.Shape[0];
        int d = x.Shape[1];

        var result = new Tensor<T>([n, m]);

        if (typeof(T) == typeof(float))
        {
            var xf = x as Tensor<float>;
            var yf = y as Tensor<float>;
            var rf = result as Tensor<float>;

            using var xBuffer = _accelerator!.Allocate1D<float>(n * d);
            using var yBuffer = _accelerator!.Allocate1D<float>(m * d);
            using var resultBuffer = _accelerator!.Allocate1D<float>(n * m);

            xBuffer.CopyFromCPU(xf!.Data);
            yBuffer.CopyFromCPU(yf!.Data);

            var kernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<float, Stride1D.Dense>, ArrayView1D<float, Stride1D.Dense>,
                ArrayView1D<float, Stride1D.Dense>, int, int, int>(PairwiseDistanceSquaredKernelFloat);

            kernel(n * m, xBuffer.View, yBuffer.View, resultBuffer.View, n, m, d);
            _accelerator!.Synchronize();

            resultBuffer.CopyToCPU(rf!.Data);
        }
        else if (typeof(T) == typeof(double))
        {
            var xd = x as Tensor<double>;
            var yd = y as Tensor<double>;
            var rd = result as Tensor<double>;

            using var xBuffer = _accelerator!.Allocate1D<double>(n * d);
            using var yBuffer = _accelerator!.Allocate1D<double>(m * d);
            using var resultBuffer = _accelerator!.Allocate1D<double>(n * m);

            xBuffer.CopyFromCPU(xd!.Data);
            yBuffer.CopyFromCPU(yd!.Data);

            var kernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<double, Stride1D.Dense>, ArrayView1D<double, Stride1D.Dense>,
                ArrayView1D<double, Stride1D.Dense>, int, int, int>(PairwiseDistanceSquaredKernelDouble);

            kernel(n * m, xBuffer.View, yBuffer.View, resultBuffer.View, n, m, d);
            _accelerator!.Synchronize();

            resultBuffer.CopyToCPU(rd!.Data);
        }
        else
        {
            return _cpuFallback.PairwiseDistanceSquared(x, y);
        }

        return result;
    }

    private static void PairwiseDistanceSquaredKernelFloat(
        Index1D index,
        ArrayView1D<float, Stride1D.Dense> x,
        ArrayView1D<float, Stride1D.Dense> y,
        ArrayView1D<float, Stride1D.Dense> result,
        int n, int m, int d)
    {
        int i = index / m;
        int j = index % m;

        float dist = 0f;
        for (int k = 0; k < d; k++)
        {
            float diff = x[i * d + k] - y[j * d + k];
            dist += diff * diff;
        }
        result[index] = dist;
    }

    private static void PairwiseDistanceSquaredKernelDouble(
        Index1D index,
        ArrayView1D<double, Stride1D.Dense> x,
        ArrayView1D<double, Stride1D.Dense> y,
        ArrayView1D<double, Stride1D.Dense> result,
        int n, int m, int d)
    {
        int i = index / m;
        int j = index % m;

        double dist = 0.0;
        for (int k = 0; k < d; k++)
        {
            double diff = x[i * d + k] - y[j * d + k];
            dist += diff * diff;
        }
        result[index] = dist;
    }

    /// <inheritdoc/>
    public Tensor<T> PairwiseDistance<T>(Tensor<T> x, Tensor<T> y)
    {
        var distSq = PairwiseDistanceSquared(x, y);
        return TensorSqrt(distSq);
    }

    /// <inheritdoc/>
    public (Tensor<T> values, Tensor<int> indices) TopK<T>(Tensor<T> input, int k, int axis = -1, bool largest = true)
    {
        if (axis < 0) axis = input.Shape.Length + axis;
        if (axis < 0 || axis >= input.Shape.Length)
            throw new ArgumentException($"Invalid axis {axis} for tensor with {input.Shape.Length} dimensions");

        int axisSize = input.Shape[axis];
        if (k > axisSize)
            throw new ArgumentException($"k ({k}) cannot be greater than axis size ({axisSize})");

        // Calculate output shape
        var outputShape = (int[])input.Shape.Clone();
        outputShape[axis] = k;

        var values = new Tensor<T>(outputShape);
        var indices = new Tensor<int>(outputShape);

        // Calculate strides
        int outerSize = 1;
        for (int i = 0; i < axis; i++) outerSize *= input.Shape[i];
        int innerSize = 1;
        for (int i = axis + 1; i < input.Shape.Length; i++) innerSize *= input.Shape[i];

        int numSlices = outerSize * innerSize;

        if (numSlices >= 64 && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                TopKGpuFloat(
                    (Tensor<float>)(object)input,
                    (Tensor<float>)(object)values,
                    indices, k, axis, largest, outerSize, axisSize, innerSize);
                return (values, indices);
            }
            if (typeof(T) == typeof(double))
            {
                TopKGpuDouble(
                    (Tensor<double>)(object)input,
                    (Tensor<double>)(object)values,
                    indices, k, axis, largest, outerSize, axisSize, innerSize);
                return (values, indices);
            }
        }

        return _cpuFallback.TopK(input, k, axis, largest);
    }

    private void TopKGpuFloat(Tensor<float> input, Tensor<float> values, Tensor<int> indices,
        int k, int axis, bool largest, int outerSize, int axisSize, int innerSize)
    {
        int numSlices = outerSize * innerSize;

        lock (_gpuLock)
        {
            using var inputBuffer = _accelerator!.Allocate1D<float>(input.Length);
            using var valuesBuffer = _accelerator!.Allocate1D<float>(values.Length);
            using var indicesBuffer = _accelerator!.Allocate1D<int>(indices.Length);

            inputBuffer.CopyFromCPU(input.Data);

            var kernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<float, Stride1D.Dense>, ArrayView1D<float, Stride1D.Dense>,
                ArrayView1D<int, Stride1D.Dense>, int, int, int, int, int>(TopKKernelFloat);

            kernel(numSlices, inputBuffer.View, valuesBuffer.View, indicesBuffer.View,
                   k, outerSize, axisSize, innerSize, largest ? 1 : 0);
            _accelerator!.Synchronize();

            valuesBuffer.CopyToCPU(values.Data);
            indicesBuffer.CopyToCPU(indices.Data);
        }
    }

    private void TopKGpuDouble(Tensor<double> input, Tensor<double> values, Tensor<int> indices,
        int k, int axis, bool largest, int outerSize, int axisSize, int innerSize)
    {
        int numSlices = outerSize * innerSize;

        lock (_gpuLock)
        {
            using var inputBuffer = _accelerator!.Allocate1D<double>(input.Length);
            using var valuesBuffer = _accelerator!.Allocate1D<double>(values.Length);
            using var indicesBuffer = _accelerator!.Allocate1D<int>(indices.Length);

            inputBuffer.CopyFromCPU(input.Data);

            var kernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<double, Stride1D.Dense>, ArrayView1D<double, Stride1D.Dense>,
                ArrayView1D<int, Stride1D.Dense>, int, int, int, int, int>(TopKKernelDouble);

            kernel(numSlices, inputBuffer.View, valuesBuffer.View, indicesBuffer.View,
                   k, outerSize, axisSize, innerSize, largest ? 1 : 0);
            _accelerator!.Synchronize();

            valuesBuffer.CopyToCPU(values.Data);
            indicesBuffer.CopyToCPU(indices.Data);
        }
    }

    // TopK kernel - each thread processes one slice along the axis
    // Uses simple O(n*k) selection algorithm suitable for small k
    private static void TopKKernelFloat(
        Index1D sliceIdx,
        ArrayView1D<float, Stride1D.Dense> input,
        ArrayView1D<float, Stride1D.Dense> values,
        ArrayView1D<int, Stride1D.Dense> indices,
        int k, int outerSize, int axisSize, int innerSize, int largest)
    {
        int outer = sliceIdx / innerSize;
        int inner = sliceIdx % innerSize;

        // Find top-k using simple selection (suitable for small k)
        // For each of k positions, find the best remaining element
        for (int ki = 0; ki < k; ki++)
        {
            float bestVal = largest == 1 ? float.MinValue : float.MaxValue;
            int bestIdx = 0;

            for (int a = 0; a < axisSize; a++)
            {
                int srcIdx = outer * axisSize * innerSize + a * innerSize + inner;
                float val = input[srcIdx];

                // Check if this index was already selected
                bool alreadySelected = false;
                for (int pi = 0; pi < ki; pi++)
                {
                    int prevDstIdx = outer * k * innerSize + pi * innerSize + inner;
                    if (indices[prevDstIdx] == a)
                    {
                        alreadySelected = true;
                        break;
                    }
                }

                if (!alreadySelected)
                {
                    bool isBetter = largest == 1 ? val > bestVal : val < bestVal;
                    if (isBetter)
                    {
                        bestVal = val;
                        bestIdx = a;
                    }
                }
            }

            int dstIdx = outer * k * innerSize + ki * innerSize + inner;
            values[dstIdx] = bestVal;
            indices[dstIdx] = bestIdx;
        }
    }

    private static void TopKKernelDouble(
        Index1D sliceIdx,
        ArrayView1D<double, Stride1D.Dense> input,
        ArrayView1D<double, Stride1D.Dense> values,
        ArrayView1D<int, Stride1D.Dense> indices,
        int k, int outerSize, int axisSize, int innerSize, int largest)
    {
        int outer = sliceIdx / innerSize;
        int inner = sliceIdx % innerSize;

        for (int ki = 0; ki < k; ki++)
        {
            double bestVal = largest == 1 ? double.MinValue : double.MaxValue;
            int bestIdx = 0;

            for (int a = 0; a < axisSize; a++)
            {
                int srcIdx = outer * axisSize * innerSize + a * innerSize + inner;
                double val = input[srcIdx];

                bool alreadySelected = false;
                for (int pi = 0; pi < ki; pi++)
                {
                    int prevDstIdx = outer * k * innerSize + pi * innerSize + inner;
                    if (indices[prevDstIdx] == a)
                    {
                        alreadySelected = true;
                        break;
                    }
                }

                if (!alreadySelected)
                {
                    bool isBetter = largest == 1 ? val > bestVal : val < bestVal;
                    if (isBetter)
                    {
                        bestVal = val;
                        bestIdx = a;
                    }
                }
            }

            int dstIdx = outer * k * innerSize + ki * innerSize + inner;
            values[dstIdx] = bestVal;
            indices[dstIdx] = bestIdx;
        }
    }

    /// <inheritdoc/>
    public Tensor<int> ArgSort<T>(Tensor<T> input, int axis = -1, bool descending = false)
    {
        if (axis < 0) axis = input.Shape.Length + axis;
        if (axis < 0 || axis >= input.Shape.Length)
            throw new ArgumentException($"Invalid axis {axis} for tensor with {input.Shape.Length} dimensions");

        var result = new Tensor<int>(input.Shape);
        int axisSize = input.Shape[axis];

        int outerSize = 1;
        for (int i = 0; i < axis; i++) outerSize *= input.Shape[i];
        int innerSize = 1;
        for (int i = axis + 1; i < input.Shape.Length; i++) innerSize *= input.Shape[i];

        int numSlices = outerSize * innerSize;

        if (numSlices >= 64 && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                ArgSortGpuFloat((Tensor<float>)(object)input, result, axis, descending,
                    outerSize, axisSize, innerSize);
                return result;
            }
            if (typeof(T) == typeof(double))
            {
                ArgSortGpuDouble((Tensor<double>)(object)input, result, axis, descending,
                    outerSize, axisSize, innerSize);
                return result;
            }
        }

        return _cpuFallback.ArgSort(input, axis, descending);
    }

    private void ArgSortGpuFloat(Tensor<float> input, Tensor<int> result, int axis, bool descending,
        int outerSize, int axisSize, int innerSize)
    {
        int numSlices = outerSize * innerSize;

        lock (_gpuLock)
        {
            using var inputBuffer = _accelerator!.Allocate1D<float>(input.Length);
            using var resultBuffer = _accelerator!.Allocate1D<int>(result.Length);

            inputBuffer.CopyFromCPU(input.Data);

            var kernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<float, Stride1D.Dense>, ArrayView1D<int, Stride1D.Dense>,
                int, int, int, int>(ArgSortKernelFloat);

            kernel(numSlices, inputBuffer.View, resultBuffer.View,
                   outerSize, axisSize, innerSize, descending ? 1 : 0);
            _accelerator!.Synchronize();

            resultBuffer.CopyToCPU(result.Data);
        }
    }

    private void ArgSortGpuDouble(Tensor<double> input, Tensor<int> result, int axis, bool descending,
        int outerSize, int axisSize, int innerSize)
    {
        int numSlices = outerSize * innerSize;

        lock (_gpuLock)
        {
            using var inputBuffer = _accelerator!.Allocate1D<double>(input.Length);
            using var resultBuffer = _accelerator!.Allocate1D<int>(result.Length);

            inputBuffer.CopyFromCPU(input.Data);

            var kernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<double, Stride1D.Dense>, ArrayView1D<int, Stride1D.Dense>,
                int, int, int, int>(ArgSortKernelDouble);

            kernel(numSlices, inputBuffer.View, resultBuffer.View,
                   outerSize, axisSize, innerSize, descending ? 1 : 0);
            _accelerator!.Synchronize();

            resultBuffer.CopyToCPU(result.Data);
        }
    }

    // ArgSort kernel using insertion sort (suitable for small axis sizes)
    // Each thread sorts one slice along the axis
    private static void ArgSortKernelFloat(
        Index1D sliceIdx,
        ArrayView1D<float, Stride1D.Dense> input,
        ArrayView1D<int, Stride1D.Dense> result,
        int outerSize, int axisSize, int innerSize, int descending)
    {
        int outer = sliceIdx / innerSize;
        int inner = sliceIdx % innerSize;

        // Initialize indices
        for (int a = 0; a < axisSize; a++)
        {
            int dstIdx = outer * axisSize * innerSize + a * innerSize + inner;
            result[dstIdx] = a;
        }

        // Insertion sort on indices based on values
        for (int i = 1; i < axisSize; i++)
        {
            int keyIdxPos = outer * axisSize * innerSize + i * innerSize + inner;
            int keyIdx = result[keyIdxPos];
            int keySrcPos = outer * axisSize * innerSize + keyIdx * innerSize + inner;
            float keyVal = input[keySrcPos];

            int j = i - 1;
            while (j >= 0)
            {
                int jIdxPos = outer * axisSize * innerSize + j * innerSize + inner;
                int jIdx = result[jIdxPos];
                int jSrcPos = outer * axisSize * innerSize + jIdx * innerSize + inner;
                float jVal = input[jSrcPos];

                bool shouldSwap = descending == 1 ? jVal < keyVal : jVal > keyVal;
                if (!shouldSwap) break;

                // Shift
                int nextIdxPos = outer * axisSize * innerSize + (j + 1) * innerSize + inner;
                result[nextIdxPos] = jIdx;
                j--;
            }

            int insertPos = outer * axisSize * innerSize + (j + 1) * innerSize + inner;
            result[insertPos] = keyIdx;
        }
    }

    private static void ArgSortKernelDouble(
        Index1D sliceIdx,
        ArrayView1D<double, Stride1D.Dense> input,
        ArrayView1D<int, Stride1D.Dense> result,
        int outerSize, int axisSize, int innerSize, int descending)
    {
        int outer = sliceIdx / innerSize;
        int inner = sliceIdx % innerSize;

        for (int a = 0; a < axisSize; a++)
        {
            int dstIdx = outer * axisSize * innerSize + a * innerSize + inner;
            result[dstIdx] = a;
        }

        for (int i = 1; i < axisSize; i++)
        {
            int keyIdxPos = outer * axisSize * innerSize + i * innerSize + inner;
            int keyIdx = result[keyIdxPos];
            int keySrcPos = outer * axisSize * innerSize + keyIdx * innerSize + inner;
            double keyVal = input[keySrcPos];

            int j = i - 1;
            while (j >= 0)
            {
                int jIdxPos = outer * axisSize * innerSize + j * innerSize + inner;
                int jIdx = result[jIdxPos];
                int jSrcPos = outer * axisSize * innerSize + jIdx * innerSize + inner;
                double jVal = input[jSrcPos];

                bool shouldSwap = descending == 1 ? jVal < keyVal : jVal > keyVal;
                if (!shouldSwap) break;

                int nextIdxPos = outer * axisSize * innerSize + (j + 1) * innerSize + inner;
                result[nextIdxPos] = jIdx;
                j--;
            }

            int insertPos = outer * axisSize * innerSize + (j + 1) * innerSize + inner;
            result[insertPos] = keyIdx;
        }
    }

    /// <inheritdoc/>
    public Tensor<T> Gather<T>(Tensor<T> input, Tensor<int> indices, int axis)
    {
        if (axis < 0) axis = input.Shape.Length + axis;
        if (axis < 0 || axis >= input.Shape.Length)
            throw new ArgumentException($"Invalid axis {axis} for tensor with {input.Shape.Length} dimensions");

        var outputShape = new int[input.Shape.Length];
        for (int i = 0; i < input.Shape.Length; i++)
            outputShape[i] = i == axis ? indices.Length : input.Shape[i];

        var result = new Tensor<T>(outputShape);

        int outerSize = 1;
        for (int i = 0; i < axis; i++) outerSize *= input.Shape[i];
        int axisSize = input.Shape[axis];
        int innerSize = 1;
        for (int i = axis + 1; i < input.Shape.Length; i++) innerSize *= input.Shape[i];

        int outputLen = result.Length;

        if (outputLen >= 1024 && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                GatherGpuFloat((Tensor<float>)(object)input, indices, (Tensor<float>)(object)result,
                    outerSize, axisSize, innerSize);
                return result;
            }
            if (typeof(T) == typeof(double))
            {
                GatherGpuDouble((Tensor<double>)(object)input, indices, (Tensor<double>)(object)result,
                    outerSize, axisSize, innerSize);
                return result;
            }
        }

        return _cpuFallback.Gather(input, indices, axis);
    }

    private void GatherGpuFloat(Tensor<float> input, Tensor<int> indices, Tensor<float> result,
        int outerSize, int axisSize, int innerSize)
    {
        int numIndices = indices.Length;

        lock (_gpuLock)
        {
            using var inputBuffer = _accelerator!.Allocate1D<float>(input.Length);
            using var indicesBuffer = _accelerator!.Allocate1D<int>(indices.Length);
            using var resultBuffer = _accelerator!.Allocate1D<float>(result.Length);

            inputBuffer.CopyFromCPU(input.Data);
            indicesBuffer.CopyFromCPU(indices.Data);

            var kernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<float, Stride1D.Dense>, ArrayView1D<int, Stride1D.Dense>,
                ArrayView1D<float, Stride1D.Dense>, int, int, int, int>(GatherKernelFloat);

            kernel(result.Length, inputBuffer.View, indicesBuffer.View, resultBuffer.View,
                   outerSize, axisSize, innerSize, numIndices);
            _accelerator!.Synchronize();

            resultBuffer.CopyToCPU(result.Data);
        }
    }

    private void GatherGpuDouble(Tensor<double> input, Tensor<int> indices, Tensor<double> result,
        int outerSize, int axisSize, int innerSize)
    {
        int numIndices = indices.Length;

        lock (_gpuLock)
        {
            using var inputBuffer = _accelerator!.Allocate1D<double>(input.Length);
            using var indicesBuffer = _accelerator!.Allocate1D<int>(indices.Length);
            using var resultBuffer = _accelerator!.Allocate1D<double>(result.Length);

            inputBuffer.CopyFromCPU(input.Data);
            indicesBuffer.CopyFromCPU(indices.Data);

            var kernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<double, Stride1D.Dense>, ArrayView1D<int, Stride1D.Dense>,
                ArrayView1D<double, Stride1D.Dense>, int, int, int, int>(GatherKernelDouble);

            kernel(result.Length, inputBuffer.View, indicesBuffer.View, resultBuffer.View,
                   outerSize, axisSize, innerSize, numIndices);
            _accelerator!.Synchronize();

            resultBuffer.CopyToCPU(result.Data);
        }
    }

    // Gather kernel - each thread copies one output element
    private static void GatherKernelFloat(
        Index1D index,
        ArrayView1D<float, Stride1D.Dense> input,
        ArrayView1D<int, Stride1D.Dense> indices,
        ArrayView1D<float, Stride1D.Dense> result,
        int outerSize, int axisSize, int innerSize, int numIndices)
    {
        // Compute which outer, index, inner this element corresponds to
        int outer = index / (numIndices * innerSize);
        int remainder = index % (numIndices * innerSize);
        int idx = remainder / innerSize;
        int inner = remainder % innerSize;

        int srcIdx = indices[idx];
        int srcFlatIndex = outer * axisSize * innerSize + srcIdx * innerSize + inner;
        result[index] = input[srcFlatIndex];
    }

    private static void GatherKernelDouble(
        Index1D index,
        ArrayView1D<double, Stride1D.Dense> input,
        ArrayView1D<int, Stride1D.Dense> indices,
        ArrayView1D<double, Stride1D.Dense> result,
        int outerSize, int axisSize, int innerSize, int numIndices)
    {
        int outer = index / (numIndices * innerSize);
        int remainder = index % (numIndices * innerSize);
        int idx = remainder / innerSize;
        int inner = remainder % innerSize;

        int srcIdx = indices[idx];
        int srcFlatIndex = outer * axisSize * innerSize + srcIdx * innerSize + inner;
        result[index] = input[srcFlatIndex];
    }

    /// <inheritdoc/>
    public Tensor<T> Scatter<T>(Tensor<T> input, Tensor<int> indices, Tensor<T> values, int axis)
    {
        if (axis < 0) axis = input.Shape.Length + axis;
        if (axis < 0 || axis >= input.Shape.Length)
            throw new ArgumentException($"Invalid axis {axis} for tensor with {input.Shape.Length} dimensions");

        // Create copy of input
        var result = new Tensor<T>(input.Shape);

        int outerSize = 1;
        for (int i = 0; i < axis; i++) outerSize *= input.Shape[i];
        int axisSize = input.Shape[axis];
        int innerSize = 1;
        for (int i = axis + 1; i < input.Shape.Length; i++) innerSize *= input.Shape[i];

        if (input.Length >= 1024 && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                ScatterGpuFloat((Tensor<float>)(object)input, indices, (Tensor<float>)(object)values,
                    (Tensor<float>)(object)result, outerSize, axisSize, innerSize);
                return result;
            }
            if (typeof(T) == typeof(double))
            {
                ScatterGpuDouble((Tensor<double>)(object)input, indices, (Tensor<double>)(object)values,
                    (Tensor<double>)(object)result, outerSize, axisSize, innerSize);
                return result;
            }
        }

        return _cpuFallback.Scatter(input, indices, values, axis);
    }

    private void ScatterGpuFloat(Tensor<float> input, Tensor<int> indices, Tensor<float> values,
        Tensor<float> result, int outerSize, int axisSize, int innerSize)
    {
        int numIndices = indices.Length;

        lock (_gpuLock)
        {
            using var inputBuffer = _accelerator!.Allocate1D<float>(input.Length);
            using var indicesBuffer = _accelerator!.Allocate1D<int>(indices.Length);
            using var valuesBuffer = _accelerator!.Allocate1D<float>(values.Length);
            using var resultBuffer = _accelerator!.Allocate1D<float>(result.Length);

            inputBuffer.CopyFromCPU(input.Data);
            indicesBuffer.CopyFromCPU(indices.Data);
            valuesBuffer.CopyFromCPU(values.Data);

            // First copy input to result
            var copyKernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<float, Stride1D.Dense>, ArrayView1D<float, Stride1D.Dense>>(CopyKernelFloat);
            copyKernel(input.Length, inputBuffer.View, resultBuffer.View);
            _accelerator!.Synchronize();

            // Then scatter values
            var scatterKernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<int, Stride1D.Dense>, ArrayView1D<float, Stride1D.Dense>,
                ArrayView1D<float, Stride1D.Dense>, int, int, int, int>(ScatterKernelFloat);

            scatterKernel(values.Length, indicesBuffer.View, valuesBuffer.View, resultBuffer.View,
                          outerSize, axisSize, innerSize, numIndices);
            _accelerator!.Synchronize();

            resultBuffer.CopyToCPU(result.Data);
        }
    }

    private void ScatterGpuDouble(Tensor<double> input, Tensor<int> indices, Tensor<double> values,
        Tensor<double> result, int outerSize, int axisSize, int innerSize)
    {
        int numIndices = indices.Length;

        lock (_gpuLock)
        {
            using var inputBuffer = _accelerator!.Allocate1D<double>(input.Length);
            using var indicesBuffer = _accelerator!.Allocate1D<int>(indices.Length);
            using var valuesBuffer = _accelerator!.Allocate1D<double>(values.Length);
            using var resultBuffer = _accelerator!.Allocate1D<double>(result.Length);

            inputBuffer.CopyFromCPU(input.Data);
            indicesBuffer.CopyFromCPU(indices.Data);
            valuesBuffer.CopyFromCPU(values.Data);

            var copyKernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<double, Stride1D.Dense>, ArrayView1D<double, Stride1D.Dense>>(CopyKernelDouble);
            copyKernel(input.Length, inputBuffer.View, resultBuffer.View);
            _accelerator!.Synchronize();

            var scatterKernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<int, Stride1D.Dense>, ArrayView1D<double, Stride1D.Dense>,
                ArrayView1D<double, Stride1D.Dense>, int, int, int, int>(ScatterKernelDouble);

            scatterKernel(values.Length, indicesBuffer.View, valuesBuffer.View, resultBuffer.View,
                          outerSize, axisSize, innerSize, numIndices);
            _accelerator!.Synchronize();

            resultBuffer.CopyToCPU(result.Data);
        }
    }

    private static void CopyKernelFloat(
        Index1D index,
        ArrayView1D<float, Stride1D.Dense> input,
        ArrayView1D<float, Stride1D.Dense> output)
    {
        output[index] = input[index];
    }

    private static void CopyKernelDouble(
        Index1D index,
        ArrayView1D<double, Stride1D.Dense> input,
        ArrayView1D<double, Stride1D.Dense> output)
    {
        output[index] = input[index];
    }

    // Scatter kernel - writes values to indexed positions
    // Note: If multiple indices point to same location, last write wins (no atomics for simple scatter)
    private static void ScatterKernelFloat(
        Index1D index,
        ArrayView1D<int, Stride1D.Dense> indices,
        ArrayView1D<float, Stride1D.Dense> values,
        ArrayView1D<float, Stride1D.Dense> result,
        int outerSize, int axisSize, int innerSize, int numIndices)
    {
        // Compute which outer, index, inner this value corresponds to
        int outer = index / (numIndices * innerSize);
        int remainder = index % (numIndices * innerSize);
        int idx = remainder / innerSize;
        int inner = remainder % innerSize;

        int dstIdx = indices[idx];
        int dstFlatIndex = outer * axisSize * innerSize + dstIdx * innerSize + inner;
        result[dstFlatIndex] = values[index];
    }

    private static void ScatterKernelDouble(
        Index1D index,
        ArrayView1D<int, Stride1D.Dense> indices,
        ArrayView1D<double, Stride1D.Dense> values,
        ArrayView1D<double, Stride1D.Dense> result,
        int outerSize, int axisSize, int innerSize, int numIndices)
    {
        int outer = index / (numIndices * innerSize);
        int remainder = index % (numIndices * innerSize);
        int idx = remainder / innerSize;
        int inner = remainder % innerSize;

        int dstIdx = indices[idx];
        int dstFlatIndex = outer * axisSize * innerSize + dstIdx * innerSize + inner;
        result[dstFlatIndex] = values[index];
    }

    /// <inheritdoc/>
    public Tensor<T> ScatterAdd<T>(Tensor<T> input, Tensor<int> indices, Tensor<T> values, int axis)
    {
        if (axis < 0) axis = input.Shape.Length + axis;
        if (axis < 0 || axis >= input.Shape.Length)
            throw new ArgumentException($"Invalid axis {axis} for tensor with {input.Shape.Length} dimensions");

        var result = new Tensor<T>(input.Shape);

        int outerSize = 1;
        for (int i = 0; i < axis; i++) outerSize *= input.Shape[i];
        int axisSize = input.Shape[axis];
        int innerSize = 1;
        for (int i = axis + 1; i < input.Shape.Length; i++) innerSize *= input.Shape[i];

        if (input.Length >= 1024 && SupportsGpu && _gpuHealthy)
        {
            if (typeof(T) == typeof(float))
            {
                ScatterAddGpuFloat((Tensor<float>)(object)input, indices, (Tensor<float>)(object)values,
                    (Tensor<float>)(object)result, outerSize, axisSize, innerSize);
                return result;
            }
            if (typeof(T) == typeof(double))
            {
                ScatterAddGpuDouble((Tensor<double>)(object)input, indices, (Tensor<double>)(object)values,
                    (Tensor<double>)(object)result, outerSize, axisSize, innerSize);
                return result;
            }
        }

        return _cpuFallback.ScatterAdd(input, indices, values, axis);
    }

    private void ScatterAddGpuFloat(Tensor<float> input, Tensor<int> indices, Tensor<float> values,
        Tensor<float> result, int outerSize, int axisSize, int innerSize)
    {
        int numIndices = indices.Length;

        lock (_gpuLock)
        {
            using var inputBuffer = _accelerator!.Allocate1D<float>(input.Length);
            using var indicesBuffer = _accelerator!.Allocate1D<int>(indices.Length);
            using var valuesBuffer = _accelerator!.Allocate1D<float>(values.Length);
            using var resultBuffer = _accelerator!.Allocate1D<float>(result.Length);

            inputBuffer.CopyFromCPU(input.Data);
            indicesBuffer.CopyFromCPU(indices.Data);
            valuesBuffer.CopyFromCPU(values.Data);

            // First copy input to result
            var copyKernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<float, Stride1D.Dense>, ArrayView1D<float, Stride1D.Dense>>(CopyKernelFloat);
            copyKernel(input.Length, inputBuffer.View, resultBuffer.View);
            _accelerator!.Synchronize();

            // Use atomic add for scatter add
            var scatterAddKernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<int, Stride1D.Dense>, ArrayView1D<float, Stride1D.Dense>,
                ArrayView1D<float, Stride1D.Dense>, int, int, int, int>(ScatterAddKernelFloat);

            scatterAddKernel(values.Length, indicesBuffer.View, valuesBuffer.View, resultBuffer.View,
                             outerSize, axisSize, innerSize, numIndices);
            _accelerator!.Synchronize();

            resultBuffer.CopyToCPU(result.Data);
        }
    }

    private void ScatterAddGpuDouble(Tensor<double> input, Tensor<int> indices, Tensor<double> values,
        Tensor<double> result, int outerSize, int axisSize, int innerSize)
    {
        int numIndices = indices.Length;

        lock (_gpuLock)
        {
            using var inputBuffer = _accelerator!.Allocate1D<double>(input.Length);
            using var indicesBuffer = _accelerator!.Allocate1D<int>(indices.Length);
            using var valuesBuffer = _accelerator!.Allocate1D<double>(values.Length);
            using var resultBuffer = _accelerator!.Allocate1D<double>(result.Length);

            inputBuffer.CopyFromCPU(input.Data);
            indicesBuffer.CopyFromCPU(indices.Data);
            valuesBuffer.CopyFromCPU(values.Data);

            var copyKernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<double, Stride1D.Dense>, ArrayView1D<double, Stride1D.Dense>>(CopyKernelDouble);
            copyKernel(input.Length, inputBuffer.View, resultBuffer.View);
            _accelerator!.Synchronize();

            var scatterAddKernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<int, Stride1D.Dense>, ArrayView1D<double, Stride1D.Dense>,
                ArrayView1D<double, Stride1D.Dense>, int, int, int, int>(ScatterAddKernelDouble);

            scatterAddKernel(values.Length, indicesBuffer.View, valuesBuffer.View, resultBuffer.View,
                             outerSize, axisSize, innerSize, numIndices);
            _accelerator!.Synchronize();

            resultBuffer.CopyToCPU(result.Data);
        }
    }

    // ScatterAdd kernel using atomic operations
    private static void ScatterAddKernelFloat(
        Index1D index,
        ArrayView1D<int, Stride1D.Dense> indices,
        ArrayView1D<float, Stride1D.Dense> values,
        ArrayView1D<float, Stride1D.Dense> result,
        int outerSize, int axisSize, int innerSize, int numIndices)
    {
        int outer = index / (numIndices * innerSize);
        int remainder = index % (numIndices * innerSize);
        int idx = remainder / innerSize;
        int inner = remainder % innerSize;

        int dstIdx = indices[idx];
        int dstFlatIndex = outer * axisSize * innerSize + dstIdx * innerSize + inner;

        // Use atomic add to handle concurrent writes
        Atomic.Add(ref result[dstFlatIndex], values[index]);
    }

    private static void ScatterAddKernelDouble(
        Index1D index,
        ArrayView1D<int, Stride1D.Dense> indices,
        ArrayView1D<double, Stride1D.Dense> values,
        ArrayView1D<double, Stride1D.Dense> result,
        int outerSize, int axisSize, int innerSize, int numIndices)
    {
        int outer = index / (numIndices * innerSize);
        int remainder = index % (numIndices * innerSize);
        int idx = remainder / innerSize;
        int inner = remainder % innerSize;

        int dstIdx = indices[idx];
        int dstFlatIndex = outer * axisSize * innerSize + dstIdx * innerSize + inner;

        Atomic.Add(ref result[dstFlatIndex], values[index]);
    }


    /// <inheritdoc/>
    public Tensor<T> TensorCosh<T>(Tensor<T> tensor)
    {
        var result = new Tensor<T>(tensor.Shape);
        int length = tensor.Length;

        if (typeof(T) == typeof(float))
        {
            var tf = tensor as Tensor<float>;
            var rf = result as Tensor<float>;

            using var inputBuffer = _accelerator!.Allocate1D<float>(length);
            using var outputBuffer = _accelerator!.Allocate1D<float>(length);

            inputBuffer.CopyFromCPU(tf!.Data);

            var kernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<float, Stride1D.Dense>, ArrayView1D<float, Stride1D.Dense>>(CoshKernelFloat);

            kernel(length, inputBuffer.View, outputBuffer.View);
            _accelerator!.Synchronize();

            outputBuffer.CopyToCPU(rf!.Data);
        }
        else if (typeof(T) == typeof(double))
        {
            var td = tensor as Tensor<double>;
            var rd = result as Tensor<double>;

            using var inputBuffer = _accelerator!.Allocate1D<double>(length);
            using var outputBuffer = _accelerator!.Allocate1D<double>(length);

            inputBuffer.CopyFromCPU(td!.Data);

            var kernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<double, Stride1D.Dense>, ArrayView1D<double, Stride1D.Dense>>(CoshKernelDouble);

            kernel(length, inputBuffer.View, outputBuffer.View);
            _accelerator!.Synchronize();

            outputBuffer.CopyToCPU(rd!.Data);
        }
        else
        {
            return _cpuFallback.TensorCosh(tensor);
        }

        return result;
    }

    private static void CoshKernelFloat(
        Index1D index,
        ArrayView1D<float, Stride1D.Dense> input,
        ArrayView1D<float, Stride1D.Dense> output)
    {
        float x = input[index];
        // cosh(x) = (e^x + e^-x) / 2
        float expX = XMath.Exp(x);
        float expNegX = XMath.Exp(-x);
        output[index] = (expX + expNegX) * 0.5f;
    }

    private static void CoshKernelDouble(
        Index1D index,
        ArrayView1D<double, Stride1D.Dense> input,
        ArrayView1D<double, Stride1D.Dense> output)
    {
        double x = input[index];
        // cosh(x) = (e^x + e^-x) / 2
        double expX = XMath.Exp(x);
        double expNegX = XMath.Exp(-x);
        output[index] = (expX + expNegX) * 0.5;
    }

    /// <inheritdoc/>
    public Tensor<T> TensorSinh<T>(Tensor<T> tensor)
    {
        var result = new Tensor<T>(tensor.Shape);
        int length = tensor.Length;

        if (typeof(T) == typeof(float))
        {
            var tf = tensor as Tensor<float>;
            var rf = result as Tensor<float>;

            using var inputBuffer = _accelerator!.Allocate1D<float>(length);
            using var outputBuffer = _accelerator!.Allocate1D<float>(length);

            inputBuffer.CopyFromCPU(tf!.Data);

            var kernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<float, Stride1D.Dense>, ArrayView1D<float, Stride1D.Dense>>(SinhKernelFloat);

            kernel(length, inputBuffer.View, outputBuffer.View);
            _accelerator!.Synchronize();

            outputBuffer.CopyToCPU(rf!.Data);
        }
        else if (typeof(T) == typeof(double))
        {
            var td = tensor as Tensor<double>;
            var rd = result as Tensor<double>;

            using var inputBuffer = _accelerator!.Allocate1D<double>(length);
            using var outputBuffer = _accelerator!.Allocate1D<double>(length);

            inputBuffer.CopyFromCPU(td!.Data);

            var kernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<double, Stride1D.Dense>, ArrayView1D<double, Stride1D.Dense>>(SinhKernelDouble);

            kernel(length, inputBuffer.View, outputBuffer.View);
            _accelerator!.Synchronize();

            outputBuffer.CopyToCPU(rd!.Data);
        }
        else
        {
            return _cpuFallback.TensorSinh(tensor);
        }

        return result;
    }

    private static void SinhKernelFloat(
        Index1D index,
        ArrayView1D<float, Stride1D.Dense> input,
        ArrayView1D<float, Stride1D.Dense> output)
    {
        float x = input[index];
        // sinh(x) = (e^x - e^-x) / 2
        float expX = XMath.Exp(x);
        float expNegX = XMath.Exp(-x);
        output[index] = (expX - expNegX) * 0.5f;
    }

    private static void SinhKernelDouble(
        Index1D index,
        ArrayView1D<double, Stride1D.Dense> input,
        ArrayView1D<double, Stride1D.Dense> output)
    {
        double x = input[index];
        // sinh(x) = (e^x - e^-x) / 2
        double expX = XMath.Exp(x);
        double expNegX = XMath.Exp(-x);
        output[index] = (expX - expNegX) * 0.5;
    }

    /// <inheritdoc/>
    public Tensor<T> TensorOuter<T>(Tensor<T> a, Tensor<T> b)
    {
        if (a.Shape.Length != 1 || b.Shape.Length != 1)
            throw new ArgumentException("Both inputs must be 1D tensors");

        int n = a.Shape[0];
        int m = b.Shape[0];
        var result = new Tensor<T>([n, m]);

        if (typeof(T) == typeof(float))
        {
            var af = a as Tensor<float>;
            var bf = b as Tensor<float>;
            var rf = result as Tensor<float>;

            using var aBuffer = _accelerator!.Allocate1D<float>(n);
            using var bBuffer = _accelerator!.Allocate1D<float>(m);
            using var resultBuffer = _accelerator!.Allocate1D<float>(n * m);

            aBuffer.CopyFromCPU(af!.Data);
            bBuffer.CopyFromCPU(bf!.Data);

            var kernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<float, Stride1D.Dense>, ArrayView1D<float, Stride1D.Dense>,
                ArrayView1D<float, Stride1D.Dense>, int, int>(OuterKernelFloat);

            kernel(n * m, aBuffer.View, bBuffer.View, resultBuffer.View, n, m);
            _accelerator!.Synchronize();

            resultBuffer.CopyToCPU(rf!.Data);
        }
        else if (typeof(T) == typeof(double))
        {
            var ad = a as Tensor<double>;
            var bd = b as Tensor<double>;
            var rd = result as Tensor<double>;

            using var aBuffer = _accelerator!.Allocate1D<double>(n);
            using var bBuffer = _accelerator!.Allocate1D<double>(m);
            using var resultBuffer = _accelerator!.Allocate1D<double>(n * m);

            aBuffer.CopyFromCPU(ad!.Data);
            bBuffer.CopyFromCPU(bd!.Data);

            var kernel = _accelerator!.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView1D<double, Stride1D.Dense>, ArrayView1D<double, Stride1D.Dense>,
                ArrayView1D<double, Stride1D.Dense>, int, int>(OuterKernelDouble);

            kernel(n * m, aBuffer.View, bBuffer.View, resultBuffer.View, n, m);
            _accelerator!.Synchronize();

            resultBuffer.CopyToCPU(rd!.Data);
        }
        else
        {
            return _cpuFallback.TensorOuter(a, b);
        }

        return result;
    }

    private static void OuterKernelFloat(
        Index1D index,
        ArrayView1D<float, Stride1D.Dense> a,
        ArrayView1D<float, Stride1D.Dense> b,
        ArrayView1D<float, Stride1D.Dense> result,
        int n, int m)
    {
        int i = index / m;
        int j = index % m;
        result[index] = a[i] * b[j];
    }

    private static void OuterKernelDouble(
        Index1D index,
        ArrayView1D<double, Stride1D.Dense> a,
        ArrayView1D<double, Stride1D.Dense> b,
        ArrayView1D<double, Stride1D.Dense> result,
        int n, int m)
    {
        int i = index / m;
        int j = index % m;
        result[index] = a[i] * b[j];
    }

    #endregion

    #endregion
}
#endif
